INSERT INTO Paper VALUES ("1","Atmospheric correction of Landsat ETM+ land surface imagery. I. Methods","To extract quantitative information from the Enhanced Thematic Mapper-Plus (ETM+) imagery accurately, atmospheric correction is a necessary step. After reviewing historical development of atmospheric correction of Landsat Thematic Mapper (TM) imagery, the authors present a new algorithm that can effectively estimate the spatial distribution of atmospheric aerosols and retrieve surface reflectance from ETM+ imagery under general atmospheric and surface conditions. This algorithm is therefore suitable for operational applications. A new formula that accounts for adjacency effects is also presented. Several examples are given to demonstrate that this new algorithm works very well under a variety of atmospheric and surface conditions.","2001","16","4","2025-12-02","https://university.edu/papers/8d7f46e2-4043-4d13-a8f8-904dfc0f0122.pdf");
INSERT INTO Paper VALUES ("2","ConQueSt: a Constraint-based Querying System for Exploratory Pattern Discovery","ConQueSt is a constraint-based querying system devised with the aim of supporting the intrinsically exploratory nature of pattern discovery. It provides users with an expressive constraint-based query language which allows the discovery process to be effectively driven toward potentially interesting patterns. Constraints are also exploited to reduce the cost of pattern mining. The system is built around an efficient constraint-based mining engine which entails several data and search space reduction techniques, and allows new user-defined constraints to be easily added.","2006","5","3","2025-12-02","https://university.edu/papers/9c24269a-6ee2-441d-96fd-de89b274cbb7.pdf");
INSERT INTO Paper VALUES ("3","Shaped Gaussian Dictionaries for Quantized Networked Control Systems With Correlated Dropouts","This paper studies fixed rate vector quantisation for noisy networked control systems (NCSs) with correlated packet dropouts. In particular, a discrete-time linear time invariant system is to be controlled over an error-prone digital channel. The controller uses (quantized) packetized predictive control to reduce the impact of packet losses. The proposed vector quantizer is based on sparse regression codes (SPARC), which have recently been shown to be efficient in open-loop systems when coding white Gaussian sources. The dictionaries in existing design of SPARCs consist of independent and identically distributed (i.i.d.) Gaussian entries. However, we show that a significant gain can be achieved by using Gaussian dictionaries that are shaped according to the second-order statistics of the NCS in question. Furthermore, to avoid training of the dictionaries, we provide closed-form expressions for the required second-order statistics in the absence of quantization.","2016","13","4","2025-12-02","https://university.edu/papers/d693be6e-9a50-46af-9422-de7971667075.pdf");
INSERT INTO Paper VALUES ("4","The MOS capacitor amplifier","It is well known that low noise amplification can be performed by using a capacitor whose capacitance can be controlled. In this paper, it is shown that changing the inversion level of a MOS transistor allows voltage amplification. The theoretical characterization of this amplifier in terms of gain and harmonic distortion is made, and comparisons with HSPICE results are performed. Finally, some practical considerations to improve the performance of the circuit are presented.","2004","5","1","2025-12-02","https://university.edu/papers/df00de32-84ff-4ccd-b35d-8cc8a1d3d4b8.pdf");
INSERT INTO Paper VALUES ("5","Non-contact inspection of construction materials using 3-axis multifunctional imaging system with microwave and laser sensing techniques","Microwave imaging techniques have been applied in a wide variety of commercial and scientific applications such as non-destructive testing and evaluation, material characterization and medical applications [1]-[3]. Microwave non-contact techniques have demonstrated the ability to detect flaws in various dielectric and composite materials using relatively simple microwave reflectometers [3]-[8]. These materials include construction materials and composites such as cement-based materials and concrete structures strengthened by carbon fiber reinforced polymer (CFRP) laminates possessing delamination and debonds [3]-[7], and layered dielectric materials with a hidden crack [8]. The assessment of cracks in concrete structures is crucial for their safety and cost effective maintenance since they not only affect their appearance but also the load-carrying capacity and durability [9]-[11]. Several non-invasive testing techniques have been under investigation for the purpose of crack detection in concrete. They include acoustic testing, ultrasonic techniques, optical methods, and microwave techniques. However, if compared with non-invasive methods for metal structures, the non-invasive methods for concrete structures are at a relatively early stage of development [9]-[11].","2016","4","1","2025-12-02","https://university.edu/papers/82f5a902-0bac-45e3-9158-da3ac24c999e.pdf");
INSERT INTO Paper VALUES ("6","An algorithm for fingerprint core point detection","Based on the refinement of two existing techniques, this paper describes the work that introduced region of interest for more accurate fingerprint core point detection. Direction of curvature technique (DC) has been used in coarse core point detection whilst geometry of region (GR) technique is used in the fine finding of the core point. According to the experiment applied to FVC-2002 database, it is found that the technique proposed herewith can improve the identification correctness with slightly better in computation performance.","2007","5","2","2025-12-02","https://university.edu/papers/4ecd3d88-85d4-4d1f-b93e-ebebfb374e72.pdf");
INSERT INTO Paper VALUES ("7","Towards an Early Usability Evaluation for Web Applications","In the Human-Computer Interaction (HCI) community, the usual way to measure usability is through a user test. The disadvantage of this way is that the system must be implemented before performing the test. As a consequence, developers must solve the usability issues in the last stages of the development process. Currently, the model-driven software development is gaining popularity as a solution to reduce changes impact. In this paper, a usability model is proposed to evaluate early usability from the conceptual schemas that represents a Web Application. This approach allows to incorporate usability improvements before the implementation of the final web application. We evaluate the usability of artefacts modelled with OOWS, a model-driven web engineering method. In addition, two case studies are used to verify the instruments proposed to evaluate our early usability model.","2007","12","1","2025-12-02","https://university.edu/papers/79729591-c1f0-4129-8311-79d9e57d4dd3.pdf");
INSERT INTO Paper VALUES ("8","Existence and Homogenization for a Singular Problem Through Rough Surfaces","The paper deals with existence and homogenization for elliptic problems with lower order terms singular in the u-variable (u is the solution) in a cylinder $Q$ in $\mathbb{R}^N$, so that the lower order term becomes infinite on the set $\{u=0\}$. A rapidly oscillating interface inside $Q$ separates the cylinder in two composite connected components. The interface has a periodic microstructure and it is situated in a small neighborhood of a hyperplane which separates the two components of $Q$. At the interface we suppose the following transmission conditions: (i) the flux is continuous, (ii) the jump of a solution at the interface is proportional to the flux through the interface. This is a steady state model for the heat conduction in two heterogeneous electrically conducting materials with an imperfect contact between them. On the exterior boundary Dirichlet boundary conditions are prescribed. We also derive a corrector result for every value of the two parameters $\gamma$ and $\kappa$ which are related,...","2016","8","1","2025-12-02","https://university.edu/papers/868ed234-2258-4aab-bdff-4a5dc2453282.pdf");
INSERT INTO Paper VALUES ("9","An adaptable controller for autonomous robots operating in unexplored environments","Several oscillator-based robot controllers were tested for effectiveness in exploring a dynamic environment. The goal of the project was to have a team of three robots explore an arena with variable lighting and obstacle patterns and, as a team, absorb as much light as possible. Reinforcement learning was used to optimize the parameters of a coupled nonlinear oscillator controller for operation in an unknown environment. The performance of this controller was compared to those of a reactive-based controller, an oscillator controller with fixed parameters and an oscillator controller that used sensor-based parameter adjustments. Experiments indicated the reinforcement learning controller offered better performance than the other controllers. The drawback to using reinforcement learning is that a learning period is required for each milieu the robot operates in. If it is necessary to quickly explore an unknown area or a rapidly changing environment, then the controller with a sensor-based parameter adjustment has an advantage","2004","11","4","2025-12-02","https://university.edu/papers/ce65698e-2194-4c3a-8a54-b12b7f5ecbc6.pdf");
INSERT INTO Paper VALUES ("10","A Bayesian Parametric Test for Multichannel Adaptive Signal Detection in Nonhomogeneous Environments","This paper considers the problem of knowledge-aided space-time adaptive processing (STAP) in nonhomogeneous environments, where the covariance matrices of the training and test signals are assumed random and different from each other. A Bayesian detector is proposed by incorporating some  a priori  knowledge of the disturbance covariance matrices, and exploring their inherent block-Toeplitz structure. Specifically, the block-Toeplitz structure of the covariance matrix allows us to model the training signals as a multichannel auto-regressive (AR) process. The resulting detector is referred to as the Bayesian parametric adaptive matched filter (B-PAMF) which, compared with nonparametric Bayesian detectors, entails a lower training requirement and alleviates the computational complexity. Numerical results show that the proposed B-PAMF detector outperforms the standard PAMF test in nonhomogeneous environments.","2010","20","1","2025-12-02","https://university.edu/papers/989eed36-b5ab-4ead-8455-3ee8fa1a3d1b.pdf");
INSERT INTO Paper VALUES ("11","Aggregation of Product Data for Hierarchical Production Planning","When applying an aggregate view to production planning, the production system is given a hierarchical structure. The problem description at the upper level which is less detailed concerns product groups and machine groups rather than individual products and machines. This means that product structures and capacity requirements also must be expressed in terms of product groups and machine groups. In this paper it is shown under what conditions a perfect aggregation of product data can be obtained. If a perfect aggregation is not possible, our problem is to find a good approximate solution. A mathematical formulation of this approximation problem and its general solution is also given.","1981","14","4","2025-12-02","https://university.edu/papers/d3b97232-88e5-4ba5-a8a4-88e021353850.pdf");
INSERT INTO Paper VALUES ("12","An efficient solution to the millionaires' problem based on homomorphic encryption","We proposed a two-round protocol for solving the Millionaires' Problem in the setting of semi-honest parties. Our protocol uses either multiplicative or additive homomorphic encryptions. Previously proposed protocols used additive or XOR homomorphic encryption schemes only. The computation and communication costs of our protocol are in the same asymptotic order as those of the other efficient protocols. Nevertheless, since multiplicative homomorphic encryption scheme is more efficient than an additive one practically, our construction saves computation time and communication bandwidth in practicality.","2005","10","3","2025-12-02","https://university.edu/papers/df69cead-78d6-40d2-ac4b-7835bdc2fa6a.pdf");
INSERT INTO Paper VALUES ("13","Calibration of projector-camera systems from virtual mutual projection","In this paper, we propose a new calibration method for projector-camera systems. The projector-camera systems have been studied extensively as one of new information presenting systems. For calibrating the systems, we in this paper use virtual mutual projections between a camera and a projector. We first show that by using a shadow of the camera, we can generate mutual projection between a camera and a projector virtually. By using the mutual projection, the projector camera system can be calibrated more stably than the existing calibration methods. Some experimental results show that the mutual projections work quite well for calibrating projector-camera systems.","2008","16","1","2025-12-02","https://university.edu/papers/d0000fa2-7a46-4a9a-aa6b-cddbc0d8d24b.pdf");
INSERT INTO Paper VALUES ("14","Devoicing of vowels in German, a comparison of Japanese and German speakers","In Tokyo Japanese, vowel devoicing is a common process, that leads to the reduction of high, unstressed vowels (  and  ) between unvoiced consonants. This article investigates to what extent native Japanese speakers (L1) learning German as foreign language (L2) show a strong tendency to produce these vowels in the foreign language as devoiced, too. Furthermore, the question is addressed whether German native speakers also devoice vowels in the same context. To this end, a production study of German words with German (L1) and Japanese (L2) native speakers was carried out. Results of this production task show that Japanese speakers devoice vowels in German words quite regularly, whereas German speakers show this pattern only rarely. For the Japanese speakers, the reduction patterns are comparable to those of the native language. Thus, interference of Japanese (L1) patterns can be observed in German (L2) indicating that this process is deeply rooted in Japanese speakers’ phonetic/phonological knowledge and leads to interference when learning a foreign language, irrespective of the existence of the process in that language (L2).","2013","14","2","2025-12-02","https://university.edu/papers/ffac5ca8-2454-4066-ae8a-5c0a400a20f7.pdf");
INSERT INTO Paper VALUES ("15","Hyke: a low-cost remote attendance tracking system for developing regions","Tracking attendance is an important consideration for many developing world interventions. In many cases, these interventions are located in remote areas where its not always feasible to deploy expensive attendance tracking systems. In addition, since many existing systems focus on tracking participants (such as patients or students), rather than agents (such as teachers or health workers), they assume a trusted administrative staff on-site to record attendance. In this paper, we present the design of Hyke, a system for remote and cost effective attendance tracking in developing regions. Hyke combines voice-biometrics with accurate location tagging for tracking attendance in remote locations without the need for a trusted mediator on-site. Hyke was designed based on our observation of a currently deployed teacher attendance tracking system in rural Rajasthan, India. We have implemented some of the key components in Hyke, and discuss some of the security concerns in the system. The Hyke biometric stack for voice recognition is built atop several open source technologies, and provides a simple interface for non-expert users. Our evaluations with Indian speakers over telephone audio suggests the biometric stack is at par with the current state of the art. We believe this will be a useful tool for researchers who would like to incorporate voice technologies in their developing world projects.","2011","20","2","2025-12-02","https://university.edu/papers/6f408d77-b241-46f8-8486-4f4c8e9637d7.pdf");
INSERT INTO Paper VALUES ("16","Case study: Effectiveness of dynamic frequency scaling on server workload","Dynamic frequency scaling (DFS) is a feature commonly found in modern processors. It lowers the clock frequency of a core according to the load level and reduces the power consumption. In this paper, we present a case study of its effectiveness on a server platform with an AMD Phenom II x6 using the SPECjEnterprise2010 as the workload. We show that (1) DFS lowers the power consumption at low load levels significantly, but it overreacts to incidental short serge of core utilization (2) stretching the sampling period of the core utilization further reduces the power consumption, but it slows down the core to adjust its clock frequency when the load level is actually increasing, and (3) increasing the threshold level to switch the core frequency is effective when combined with a longer sampling period in the medium load level, but not in the low load levels.","2014","17","2","2025-12-02","https://university.edu/papers/bee7d8c5-a2c1-4baa-8f90-e84b0153105b.pdf");
INSERT INTO Paper VALUES ("17","Phase lag bounded velocity planning for high performance path tracking","We propose an algorithm for planning the velocity of a vehicle on a pre-planned path applicable to differentially steered, zero turn radius, mobile robots with symmetric mass distribution about the turn axis. This approach uses estimates of path curvature to maintain tracking precision in the vehicle's heading controller. The longitudinal speed of the vehicle is restricted to limit the bandwidth of the input forcing function (the path). As a result, we guarantee bounds on the driving frequency in the heading controller so that the robot stays close to the intended path. The result allows the robot to use the full performance envelope of the drive motors and provides a principled means of regulating precision and time performance during path traversal. Evaluation of the technique is conducted in simulation and in real experiments on the UMass uBot. Results indicate that the proposed velocity planner can make full use of motor performance and reduces path tracking error and traversal times relative to constant velocity plans.","2015","8","3","2025-12-02","https://university.edu/papers/ad67a3c8-781e-4d0d-b7ab-b20cc96d620e.pdf");
INSERT INTO Paper VALUES ("18","Scheduling complex computer simulations on heterogeneous non-dedicated machines: a case study in structural bioinformatics","Complex computer simulations are a class of applications that demands high performance processing power in order to be realized in a feasible time. To achieve this processing power, networks composed of non-dedicated machines are increasingly being investigated. An efficient scheduling scheme is one of the most important issues to make a better use of these resources. In this paper we present an architecture for scheduling complex computer simulations aimed at heterogeneous non-dedicated machines which relies on information provided by the models that are being simulated. Furthermore, a case study demonstrates how the proposed architecture can assist in the execution of complex simulations applied to the protein structure prediction problem, which is one of the most important current challenges in structural bioinformatics.","2005","4","3","2025-12-02","https://university.edu/papers/dfce3b6b-2506-4a04-b7ff-aa68337ea476.pdf");
INSERT INTO Paper VALUES ("19","A novel application of evolutionary computing in process systems engineering","In this article we present a Multi-Objective Genetic Algorithm for Initialization (MOGAI) that finds a starting sensor configuration for Observability Analysis (OA), this study being a crucial stage in the design and revamp of process-plant instrumentation. The MOGAI is a binary-coded genetic algorithm with a three-objective fitness function based on cost, reliability and observability metrics. MOGAI’s special features are: dynamic adaptive bit-flip mutation and guided generation of the initial population, both giving a special treatment to non-feasible individuals, and an adaptive genotypic convergence criterion to stop the algorithm. The algorithmic behavior was evaluated through the analysis of the mathematical model that represents an ammonia synthesis plant. Its efficacy was assessed by comparing the performance of the OA algorithm with and without MOGAI initialization. The genetic algorithm proved to be advantageous because it led to a significant reduction in the number of iterations required by the OA algorithm.","2005","8","4","2025-12-02","https://university.edu/papers/99cc543b-04f9-46c7-a4ac-85c1b2c8eba7.pdf");
INSERT INTO Paper VALUES ("20","Speaker Verification using Weighted Local MFCC Features Extracted by Minimum Verification Error Learning","Text-independent speaker verification using adaptively weighted Mel Frequency Cepstrum Coefficients (MFCC) over multiple neighboring frames, and Gaussian Mixture for likelihood estimation is introduced. For each registrant, optimal linear weightings of multiple speech frames are searched based on Minimum Verification Error (MVE) learning, generalizing the scheme of the use of ¢MFCC feature which attempts to capture inter-frame characteristics. In the verification experiments, the proposed method was found to improve the verification performance under noisy environments and use via phone line, when compared with the conventional methods.","2010","7","4","2025-12-02","https://university.edu/papers/813eef65-ff47-4429-94f5-edb16084b4f7.pdf");
INSERT INTO Paper VALUES ("21","RPV-II: A Stream-Based Real-Time Parallel Vision System and Its Application to Real-Time Volume Reconstruction","In this paper, we present RPV-II, a stream-based real-time parallel image processing environment on distributed parallel computers, or PC-cluster, and its performance evaluation using a realistic application. The system is based on our previous PC-cluster system for real-time image processing and computer vision, and is designed to overcome the problems of our previous system, one of which is long latency when we use pipelined structures. This becomes a serious problem when we apply the system to interactive applications. To make the latency shorter, we have introduced stream data transfer, or fine grained data transfer, to RPV-II. One frame data is divided into small elements such as pixels, lines and voxels, and we have developed efficient real-time data transfer mechanism of those. Using RPV-II we have developed a real-time volume reconstruction system by visual volume intersection method, and we have measured the system performance. Experimental results show better performance than that of our previous system, RPV.","2001","4","2","2025-12-02","https://university.edu/papers/c8d75217-cfe0-41b3-8417-4c50052d58d1.pdf");
INSERT INTO Paper VALUES ("22","A Two-Stage Bootloader to Support Multi-application Deployment and Switching in Wireless Sensor Networks","Wireless sensor networks are built from highly resource constrained embedded systems. Supporting multiple applications on the sensor network is a desirable goal, however, these constraints make supporting multiple concurrent applications on each node difficult. Therefore, we propose a dynamic application switching approach where only a single application is active on each sensor node at a time. In this paper we present a dynamic application switching framework that can automatically reprogram the sensor node in response to application requests. We implement our framework on the TelosB platform and evaluate its performance using a 52-node sensor network testbed. The implementation of a two-stage bootloader reduces the memory requirements to only 1KiB of program memory and 8 bytes of RAM on this platform. We evaluate the implementation using two different modes of application switching; asynchronous and synchronous. Extensive performance studies indicate that dynamic application switching using our two-stage bootloader is a useful approach to support multiple applications in wireless sensor networks.","2009","7","2","2025-12-02","https://university.edu/papers/edcc304b-a56c-4138-b2db-30f5552f4c60.pdf");
INSERT INTO Paper VALUES ("23","A Case Study of Design Space Exploration for Embedded Multimedia Applications on SoCs","Embedded real-time multimedia applications usually imply data parallel processing. SIMD processors embedded in SOCs are cost effective to exploit the underlying parallelism. However, programming applications for SIMD targets requires data placement and operation scheduling which are NP-complete problems. In this paper we show how our tool (based on concurrent constraint programming) can be used to explore the design space of a kernel in H.264 standard (video compression). Different cost functions are considered (e.g. execution time, memory occupancy, chip cost ...) to derive different source codes from the same functional specification. Future work includes model refinement as well as full code generation for rapid prototyping of such hardware and software intensive systems.","2006","8","1","2025-12-02","https://university.edu/papers/a6364761-0581-4889-8cf1-8aa8aaae3d65.pdf");
INSERT INTO Paper VALUES ("24","Three dimensional SAR image focusing from non-uniform samples","Multiple SAR signals acquired along different orbits can be exploited for reconstructing a three dimensional (3-D) reflectivity profile of the scene along azimuth, range and elevation co-ordinates. For the 3-D image formation, the problem of the non-uniform spacing of the orbits has to be considered. In this paper we propose a technique based on two steps: 1) a preprocessing step, in which the samples of the multi-pass signal is computed on a grid which is uniform in the elevation direction, starting from its unevenly spaced samples; 2) a 3-D image focusing based on a simple 3-D convolution operator. The technique proposed has the main advantages of preserving numerical efficiency and allowing to easily include information on the signals bandwidth in the pre-processing step, in such a way to regularize the problem and obtain stable solutions.","2007","5","4","2025-12-02","https://university.edu/papers/c4e69c87-8e84-44a9-b213-aadf7d0347b9.pdf");
INSERT INTO Paper VALUES ("25","Verification of deadlock free property of high level robot control","This paper describes an efficient verification algorithm for deadlock free property of high level robot control called Task Control Architecture (TCA). TCA is a model of concurrent robot control processes. The verification tool we used is the Symbolic Model Verifier (SMV). Since the SMV is not so efficient for verification of liveness properties such as deadlock free property of many concurrent processes, we first described the deadlock free property by using safety properties that SMV can verify efficiently. In addition, we modify the symbolic model checking algorithm of the SMV so that it can handle many concurrent processes efficiently. Experimental measurements show that we can obtain more than 1000 times speed-up by these methods.","2000","2","3","2025-12-02","https://university.edu/papers/c7829b9e-ae37-4396-954d-61ff94fcc4de.pdf");
INSERT INTO Paper VALUES ("26","Ordinary Differential Equation Methods For Markov Decision Processes and Application to Kullback-Leibler Control Cost","A new approach to computation of optimal policies for MDP (Markov decision process) models is introduced. The main idea is to solve not one, but an entire family of MDPs, parameterized by a weighting factor $\zeta$ that appears in the one-step reward function. For an MDP with $d$ states, the family of value functions $\{ h^*_\zeta : \zeta\in\Re\}$ is the solution to an ODE, $$ \frac{d}{d\zeta} h^*_\zeta = {\cal V}(h^*_\zeta) $$ where the vector field ${\cal V}\colon\Re^d\to\Re^d$ has a simple form, based on a matrix inverse. #R##N#This general methodology is applied to a family of average-cost optimal control models in which the one-step reward function is defined by Kullback-Leibler divergence. The motivation for this reward function in prior work is computation: The solution to the MDP can be expressed in terms of the Perron-Frobenius eigenvector for an associated positive matrix. The drawback with this approach is that no hard constraints on the control are permitted. #R##N#It is shown here that it is possible to extend this framework to model randomness from nature that cannot be modified by the controller. Perron-Frobenius theory is no longer applicable -- the resulting dynamic programming equations appear as complex as a completely unstructured MDP model. Despite this apparent complexity, it is shown that this class of MDPs admits a solution via this new ODE technique. This approach is new and practical even for the simpler problem in which randomness from nature is absent.","2016","7","2","2025-12-02","https://university.edu/papers/1713210c-d832-4048-b133-b7beeb6a44c1.pdf");
INSERT INTO Paper VALUES ("27","Toward a new constraint imperative programming language for interactive graphics","To construct interactive graphics such as graphical user interfaces and interactive webpages is an important matter in computer programming. For this purpose, imperative programming usually has been used. On the other hand, researchers have been attempting to apply constraint programming to interactive graphics. Furthermore, the paradigm of constraint imperative programming has been proposed. This position paper reports our ongoing work on P5CP, a new constraint imperative programming language for interactive graphics. To integrate imperative and constraint programming, we adopt the notion of events in imperative programming and the notion of guards in concurrent constraint programming. We show a simple example program in this language.","2016","14","1","2025-12-02","https://university.edu/papers/24e831f1-8cc3-4725-894f-9ea739a6c6ad.pdf");
INSERT INTO Paper VALUES ("28","Retiming and time borrowing: optimizing high-performance pulsed-latch-based circuits","Pulsed-latches take advantage of both latches in their high performance and flip-flops in their convenience of timing analysis. To minimize the clock period of pulsed-latch-based circuits for a higher performance, a problem of combined retiming and time borrowing is formulated, where the latter is enabled by using a handful of different pulse widths. The problem is first approached by formulating it as an integer linear programming to lay a theoretical foundation. A heuristic approach is proposed, which solves the problem by performing clock skew scheduling for the minimum clock period and gradually converting skew into a combination of retiming and time borrowing. Experiments with 45-nm technology demonstrate that the clock period close to the minimum can be achieved for all benchmark circuits with an average of 1.03× with less use of extra latches compared to the conventional retiming. Categories and Subject Descriptors: B.6.1 [Logic Design]: Design Styles-Sequential circuits; B.7.1 [Integrated Circuits]: Types and Design Styles-VLSI General Terms: Algorithms, Design","2009","20","2","2025-12-02","https://university.edu/papers/d0743368-37fe-48d0-ac9c-f978303326c4.pdf");
INSERT INTO Paper VALUES ("29","Empirical Evaluation and Combination of Advanced Language Modeling Techniques","We present results obtained with several advanced language modeling techniques, including class based model, cache model, maximum entropy model, structured language model, random forest language model and several types of neural network based language models. We show results obtained after combining all these models by using linear interpolation. We conclude that for both small and moderately sized tasks, we obtain new state of the art results with combination of models, that is significantly better than performance of any individual model. Obtained perplexity reductions against Good-Turing trigram baseline are over 50% and against modified Kneser-Ney smoothed 5-gram over 40%. Index Terms: language modeling, neural networks, model combination, speech recognition","2011","3","1","2025-12-02","https://university.edu/papers/88103971-d06c-4f2b-9338-e16c51ff5632.pdf");
INSERT INTO Paper VALUES ("30","Inscribed ball and enclosing box methods for the convex maximization problem","Many important classes of decision models give rise to the problem of finding a global maximum of a convex function over a convex set. This problem is known also as concave minimization, concave programming or convex maximization. Such problems can have many local maxima, therefore finding the global maximum is a computationally difficult problem, since standard nonlinear programming procedures fail. In this article, we provide a very simple and practical approach to find the global solution of quadratic convex maximization problems over a polytope. A convex function achieves its global maximum at extreme points of the feasible domain. Since an inscribed ball does not contain any extreme points of the domain, we use the largest inscribed ball for an inner approximation while a minimal enclosing box is exploited for an outer approximation of the domain. The approach is based on the use of these approximations along with the standard local search algorithm and cutting plane techniques.","2015","13","4","2025-12-02","https://university.edu/papers/c05a2c6e-5a04-4466-99ed-dc5165a98de1.pdf");
INSERT INTO Paper VALUES ("31","Limbo: A Fast and Flexible Library for Bayesian Optimization","Limbo is an open-source C++11 library for Bayesian optimization which is designed to be both highly flexible and very fast. It can be used to optimize functions for which the gradient is unknown, evaluations are expensive, and runtime cost matters (e.g., on embedded systems or robots). Benchmarks on standard functions show that Limbo is about 2 times faster than BayesOpt (another C++ library) for a similar accuracy.","2016","17","3","2025-12-02","https://university.edu/papers/83a3db88-0fa9-4b10-96ed-61ac8572f4d0.pdf");
INSERT INTO Paper VALUES ("32","Trace Machines for Observing Continuous-Time Markov Chains","In this paper, we study several linear-time equivalences (Markovian trace equivalence, failure and ready trace equivalence) for continuous-time Markov chains that refer to the probabilities for timed execution paths. Our focus is on testing scenarios by means of push-button experiments with appropriate trace machines and a discussion of the connections between the equivalences. For Markovian trace equivalence, we provide alternative characterizations, including one that abstracts away from the time instances where actions are observed, but just reports on the average sojourn times in the states. This result is used for a reduction of the question whether two finite-state continuous-time Markov chains are Markovian trace equivalent to the probabilistic trace equivalence problem for discrete-time Markov chains (and the latter is known to be solvable in polynomial time).","2006","8","2","2025-12-02","https://university.edu/papers/caf54f19-4400-4ab1-8e08-0aaaaf35ddbc.pdf");
INSERT INTO Paper VALUES ("33","On-chip current sensing technique for CMOS monolithic switch-mode power converters","An on-chip current sensing technique, which is suitable for monolithic switch-mode power converters, is presented in this paper. This current sensing technique has been fabricated with a standard 0.6 /spl mu/m CMOS process. Experimental results show that the switching converter can operate from 300 kHz to 1 MHz with the duty-ratio ranging from 0.2 to 1. The supply voltage of this current sensing circuit is from 3 V to 4.2 V, which is suitable for lithium ion battery applications. The discrepancy between the sensed signal and the inductor current is less than 4%, corresponding to 10 mA with load current 300 mA.","2002","11","4","2025-12-02","https://university.edu/papers/74304b29-6d09-40dd-8c0d-719a6675f43f.pdf");
INSERT INTO Paper VALUES ("34","Maximizing total tardiness on a single machine in O(n 2 ) time via a reduction to half-product minimization","Gafarov et al. (Ann Oper Res 196(1):247–261, 2012 ) have recently presented an $$O(n^2)$$ O ( n 2 ) time dynamic programming algorithm for a single machine scheduling problem to maximize the total job tardiness. We reduce this problem in $$O(n\log n)$$ O ( n log n ) time to a problem of unconstrained minimization of a function of 0–1 variables, called half-product, for which a simple $$O(n^2)$$ O ( n 2 ) time dynamic programming algorithm is known in the literature. Copyright Springer Science+Business Media New York 2015","2015","16","1","2025-12-02","https://university.edu/papers/46018ed5-43af-455a-aa84-b1fafef1a90c.pdf");
INSERT INTO Paper VALUES ("35","Towards an XML-Based Query and Contextual Information Model in Context-Aware Mobile Information Systems","Nowadays database systems (DBSs) are state-of-the art for managing complex data in information systems. Unfortunately, DBSs are not aware of the context of their usage. Query results are retrieved without considering the context of the user/device  issuing the query. In many cases, this feature is added by a context managing middle-ware. This paper outlines a scenario for context aware mobile services. In the paper we introduce an XML-based XREAL model for formalizing contextual information and queries highlighted in the scenario and discuss how XREAL can be implemented in a modern database system. By utilizing XREAL, it is possible to realize context aware mobile information systems based on the available DBSs without additional middle-wares.","2009","17","4","2025-12-02","https://university.edu/papers/6164a1ea-cae6-469d-a3ff-61079eeb6626.pdf");
INSERT INTO Paper VALUES ("36","Models of sequential decision making in consumer lending","In this paper, we introduce models of sequential decision making in consumer lending. From the definition of adverse selection in static lending models, we show that homogenous borrowers take-up offers at different instances of time when faced with a sequence of loan offers. We postulate that bounded rationality and diverse decision heuristics used by consumers drive the decisions they make about credit offers. Under that postulate, we show how observation of early decisions in a sequence can be informative about later decisions and can, when coupled with a type of adverse selection, also inform credit risk. We show through two examples how lenders may use such information in setting their offer rates.","2016","2","3","2025-12-02","https://university.edu/papers/7f62cdf4-56a1-4d39-aa3a-881fecad112f.pdf");
INSERT INTO Paper VALUES ("37","Explicit solutions of the Yang–Baxter-like matrix equation for an idempotent matrix","Let   A     A        be an idempotent matrix. We obtain an explicit expression for all the solutions of the quadratic matrix equation   AXA=XAX     A  X  A  =  X  A  X       , completing the task of finding general solutions of the equation explicitly with a given idempotent matrix   A     A       .","2017","4","3","2025-12-02","https://university.edu/papers/c3025577-c6e5-43f3-9305-c66514d62b09.pdf");
INSERT INTO Paper VALUES ("38","A star topology dynamic model for efficient simulation of multilimbed robotic systems","Many systems of interest in robotics have a star topology structure (multiple serial chains radiating from a common mobile, non-articulated base). In this paper the author utilize the special structure of star topology-based robots to develop algorithms useful for simulating such systems. The algorithm can handle a variety of walking, grasping, and contact situations. As a specific example, a multipedal walking system is analyzed. >","1994","12","3","2025-12-02","https://university.edu/papers/8e8e1837-cba5-4ee6-b99c-810f80ce6e25.pdf");
INSERT INTO Paper VALUES ("39","Why MAC Address Randomization is not Enough: An Analysis of Wi-Fi Network Discovery Mechanisms","We present several novel techniques to track (unassociated) mobile devices by abusing features of the Wi-Fi standard. This shows that using random MAC addresses, on its own, does not guarantee privacy. First, we show that information elements in probe requests can be used to fingerprint devices. We then combine these fingerprints with incremental sequence numbers, to create a tracking algorithm that does not rely on unique identifiers such as MAC addresses. Based on real-world datasets, we demonstrate that our algorithm can correctly track as much as 50% of devices for at least 20 minutes. We also show that commodity Wi-Fi devices use predictable scrambler seeds. These can be used to improve the performance of our tracking algorithm. Finally, we present two attacks that reveal the real MAC address of a device, even if MAC address randomization is used. In the first one, we create fake hotspots to induce clients to connect using their real MAC address. The second technique relies on the new 802.11u standard, commonly referred to as Hotspot 2.0, where we show that Linux and Windows send Access Network Query Protocol (ANQP) requests using their real MAC address.","2016","12","4","2025-12-02","https://university.edu/papers/05682c17-190d-4477-bee1-5d3e65643e54.pdf");
INSERT INTO Paper VALUES ("40","A multitasking continuous time formulation for short-term scheduling of operations in multipurpose plants","Short-term scheduling in multipurpose batch plants has received significant attention in the past two decades. Both discrete-time and continuous time formulations have been proposed to model the problem; however, multipurpose plants that have machines with the ability to process multiple tasks at the same time, i.e. multitasking, have been overlooked by the available continuous time formulations in the literature. This paper presents a novel MILP formulation that is capable of accommodating the multitasking feature in the machines of a facility. The performance of the presented formulation is studied in comparison with a single-tasking formulation. The results show that, while the multitasking formulation is not more costly in terms of solution time, it is capable of producing significantly better solutions. The presented formulation takes into account several other operational constraints of multipurpose facilities and can be readily applied to facilities that have machines capable of multitasking, including plants in the analytical services sector.","2017","8","3","2025-12-02","https://university.edu/papers/d87de2d9-83ff-45a4-945a-280f77ea2f7a.pdf");
INSERT INTO Paper VALUES ("41","Workflow-based authorization service in grid","In a distributed environment, specific rights may be required while a task is controlled and processed. A user should delegate enough rights to a task for processing. Tasks cannot work correctly if delegated rights are insufficient, or security threats may occur if delegated rights are excessive. Restricted delegation is the step that delegates proper rights to a task, and that enables finegrained authorization in grid. We propose WAS architecture as the method for supporting restricted delegation and rights management. In contrast to traditional architecture, WAS architecture uses a workflow that describes the sequence of rights required for normal execution of a task. By using the workflow, WAS architecture is able to check whether the task exercises allowed rights. WAS architecture is implemented on Globus toolkit 2.0.","2003","2","2","2025-12-02","https://university.edu/papers/88440cc2-e363-4855-83aa-58353073a666.pdf");
INSERT INTO Paper VALUES ("42","Wall following with a single ultrasonic sensor","We seek to get better insights into how blind people navigate with the K-Sonar mobility aid and to translate this insight into an autonomous navigation strategy useful to mobile robotics. Current mobile robots that use ultrasonic sensing to follow walls use multiple sensors and use only range to the nearest reflecting point making assumptions about the reflected echo. In this paper, we describe an advanced wall following algorithm, where the robot follows a wall using a single directed Continuous Transmission Frequency Modulated 'CTFM' Ultrasonic Sensor. The sensor is mechanically panned to track the wall, avoid collisions, and check for navigable space. We present results from our mobile robot wall following experiments. These experiments allowed us to compare our robot sensing and navigation system to the approach we have observed blind people use.","2010","2","1","2025-12-02","https://university.edu/papers/b514b3cf-a9fd-4903-8374-ec74746d6488.pdf");
INSERT INTO Paper VALUES ("43","Software radio implementation of a smart antenna system on digital signal processors for cdma2000","This paper presents a software defined radio (SDR) implementation based on programmable digital signal processors (DSP) for smart antenna systems (SAS). We evaluate adaptive beamforming algorithms, namely non-blind-type least mean square (LMS) and blind-type constant modulus (CM) using TI TMS320C6000 high performance DSPs for cdma2000 reverse link. Adaptive beamformers are implemented using TI code composer studio (CCS) that includes assembly language and C code development tools. Performance variation of these sofware radio beamformers in terms of weight computation time and received SINR are compared for different C6000 development boards (TMS320C6701 EVM, TMS320C6711 DSK, and TMS320C6713 DSK) and array topologies under varying multipath propagation conditions. Results show that while antenna array and algorithm type are important for the SINR performance, DSP type becomes important for the weight computation time.","2004","2","3","2025-12-02","https://university.edu/papers/83678417-0924-4d0e-9351-473ecc5d7248.pdf");
INSERT INTO Paper VALUES ("44","Bit-interleaved time-frequency coded modulation for OFDM systems over time-varying channels","Orthogonal frequency-division multiplexing (OFDM) is a promising technology in broadband wireless communications, with its ability to transform a frequency-selective fading channel into multiple flat-fading channels. However, the time-varying characteristics of wireless channels induce the loss of orthogonality among OFDM subcarriers, which was generally considered harmful to system performance. In this paper, we propose a bit-interleaved time-frequency coded modulation (BITFCM) scheme for OFDM to achieve both the time and frequency diversity inherent in broadband time-varying channels. We will show that the time-varying characteristics of the channel are beneficial to system performance. Using the BITFCM scheme, and for relatively low maximum normalized Doppler frequency, a reduced-complexity maximum-likelihood decoding approach is proposed to achieve good performance with low complexity. For high maximum normalized Doppler frequency, the intercarrier interference (ICI) can be large, and an error floor will be induced. To solve this problem, we propose two ICI-mitigation schemes by taking advantage of the second-order channel statistics and the complete channel information, respectively. It will be shown that both schemes can reduce the ICI significantly.","2005","7","3","2025-12-02","https://university.edu/papers/784d2e2a-232e-445b-9b27-b9106040cde6.pdf");
INSERT INTO Paper VALUES ("45","Boosting Active Contours for Weld Pool Visual Tracking in Automatic Arc Welding","Detecting the shape of the non-rigid molten metal during welding, so-called weld pool visual sensing, is one of the central tasks for automating arc welding processes. It is challenging due to the strong interference of the high-intensity arc light and spatters as well as the lack of robust approaches to detect and represent the shape of the nonrigid weld pool. We propose a solution using active contours including an prior for the weld pool boundary composition. Also, we apply Adaboost to select a small set of features that captures the relevant information. The proposed method is applied to weld pool tracking and the presented results verified its feasibility.","2017","16","3","2025-12-02","https://university.edu/papers/2c10ccca-d4c0-4009-bdff-1282271e7ecc.pdf");
INSERT INTO Paper VALUES ("46","Integrating agents in software applications","Face to strong competitive market, current companies tend to new methods of production, switching from a logic of «projected planning»to a logic of 'Just in time'. In this context, the system that allows controlling the production has to be a modular, flexible and reactive system. The hierarchized and classical approaches don't permit any more to take into account the complexity linked to such a system. That's why, we propose an approach, which has reactive, distributive, and emergent properties to control the system of production, based on multi-agent system principles. After having introduced the context and reasoning work, we describe the different parts of our multi-agent model. Lastly, we illustrate this approach on a practical example of production cell.","2002","20","1","2025-12-02","https://university.edu/papers/8bb4f2a5-4da0-4dd3-9860-de1ff4e2021f.pdf");
INSERT INTO Paper VALUES ("47","Convergence analysis of run-time distributed optimization on adaptive systems using game theory","We consider multiprocessor system-on-chip (MP-SoC) integrating several processing elements (PE). These architectures require distributed and scalable control techniques for run-time optimization of applicative parameters. Our approach is to use the game theory as an optimization model to solve the trade-off issues at run-time. We applied it to the distributed dynamic voltage frequency scaling (DVFS) management, adjusting at run-time the frequency set of each PE based on the synchronization between tasks of the application graph and the PE temperature profile. Results show that the analyzed algorithm converges to a solution in about 94% of the cases and in less than 40 calculation cycles for a 100-processor MP-SoC. It reaches an average optimization of 89% compared to an off-line centralized reference but about 140 times faster when simulating.","2008","14","2","2025-12-02","https://university.edu/papers/a2ba2b3d-7ffb-4a40-a252-779d8ca13ea3.pdf");
INSERT INTO Paper VALUES ("48","Symmetric Measurements Attaining the Accessible Information","A theorem of Davies shows that for symmetric quantum states there exists a symmetric positive operator-valued measure (POVM) that has a simple structure and that maximizes the mutual information. To apply this theorem, the representation of the symmetry group has to be irreducible. In the following discussion, similar yet weaker results are obtained for reducible representations. The results are applied to the double trines and it is shown with numerical methods that for these states the pretty good measurement is optimal.","2009","9","4","2025-12-02","https://university.edu/papers/d51e0506-a641-4149-9d86-3a438be400e0.pdf");
INSERT INTO Paper VALUES ("49","Support vector machines based on Lyapunov exponents in power load forecasting model","According to the chaotic and non-linear characters of power load data, the model of support vector machines (SVM) based on Lyapunov exponents was established. The time series matrix was established according to the theory of phase-space reconstruction, and then Lyapunov exponents was computed to determine time delay and embedding dimension. Then support vector machines algorithm was used to predict power load. In order to prove the rationality of chosen dimension, another two random dimensions were selected to compare with the calculated dimension. And to prove the effectiveness of the model, BP algorithm was used to compare with the result of SVM. The results show that the model is effective and highly accurate in the forecasting of short-term power load.","2008","12","3","2025-12-02","https://university.edu/papers/afd0a402-cb64-48d0-a926-7adecc2545c7.pdf");
INSERT INTO Paper VALUES ("50","Minimum-Congestion Weighted Hypergraph Embedding in a Rings Cycle","A rings cycle is an undirected graph obtained from a cycle by replacing each edge of the cycle with a ring so that two rings corresponding to the two end-nodes of any edge have precisely one node in common. Given a weighted hypergraph on a rings cycle, Minimum-Congestion Weighted Hypergraph Embedding in a Rings Cycle (WHERC) is to embed each weighted hyperedges as a path in the rings cycle such that maximal congestion-the sum of weight of embedding paths that use any edge in the rings cycle-is minimized.We prove that the WHERC problem is NP-complete.  2-approximation algorithms are presented for the WHERC problem and a related problem-WDHETR.","2009","10","1","2025-12-02","https://university.edu/papers/ff24d48f-c032-44d0-ba38-9a2f058783bc.pdf");
INSERT INTO Paper VALUES ("51","Direct gray-scale minutiae detection in fingerprints","Most automatic systems for fingerprint comparison are based on minutiae matching. Minutiae are essentially terminations and bifurcations of the ridge lines that constitute a fingerprint pattern. Automatic minutiae detection is an extremely critical process, especially in low-quality fingerprints where noise and contrast deficiency can originate pixel configurations similar to minutiae or hide real minutiae. Several approaches have been proposed in the literature; although rather different from each other, all these methods transform fingerprint images into binary images. In this work we propose an original technique, based on ridge line following, where the minutiae are extracted directly from gray scale images. The results achieved are compared with those obtained through some methods based on image binarization. In spite of a greater conceptual complexity, the method proposed performs better both in terms of efficiency and robustness.","1997","4","1","2025-12-02","https://university.edu/papers/c4d9abff-3cea-42e9-882e-5a53186f1211.pdf");
INSERT INTO Paper VALUES ("52","Architecture for inter-domain service delivery","Facing demands for high performance services, network operators are challenged by upgrading the level of management of their networks. But providing inter-domain Quality of Service (QoS) guaranteed services has to bring incremental revenues to the involved operators realizing needed evolutions of their network infrastructures. Beside these upgrades, operators are not ready to disclose information (e.g. network topologies and capacities) that would simplify the process of establishing end-to-end QoS guaranteed connection. In previous works, we have proposed and defined the notion of network operator alliance. Such an alliance would regroup operators which would find interest in cooperating and where some administrative costs would be shared and revenues split so that incentives to deliver inter-domain QoS guaranteed services would be met. Furthermore, confidentiality and business rules would be determined by the alliance participants. In a previous work [PDDS09], we proposed an architecture for inter-domain service delivery which includes extensions for Operation Support Systems (OSS) and control planes. This paper depicted the implementation of this architecture that covers network management at different plane levels and which has been tested with 5 emulated networks in our lab.","2010","18","2","2025-12-02","https://university.edu/papers/4ede9211-386a-409a-8d84-3e2ccc75c952.pdf");
INSERT INTO Paper VALUES ("53","Fusion center controlled carrier sense multiple access for physical wireless parameter conversion sensor networks","In this paper, a novel fusion center controlled media access control (MAC) protocol for physical wireless parameter conversion sensor networks (PHY-C SN) is proposed. In PHY-C SN, the sensing information is converted to correspond subcarrier numbers of orthogonal frequency division multiplexing (OFDM) signals and sensor nodes can send sensing information simultaneously. Conventionally, each sensor node performs carrier sense for detecting surrounding wireless signal. However, in order to avoid the complexity of a sensor device and to achieve simultaneous transmission from multiple sensor nodes, only the fusion center performs the carrier sense in the proposed protocol. In the proposed protocol, the fusion center detects the surrounding wireless environment and requests sensing information transmission to sensor nodes if no other wireless systems are detected. The transmission power of each sensor is designed not to give harmful interference toward surrounding wireless systems even if each sensor does not have carrier sense function. Finally each sensor node receiving the requested signal simultaneously sends sensing information to a fusion center at the same time. The effectiveness of the proposed protocol is evaluated by computer simulation and confirm the reliable and highly efficient sensing information collection performance.","2015","11","3","2025-12-02","https://university.edu/papers/5a753054-5b8b-481b-8c0d-c7166a8181b9.pdf");
INSERT INTO Paper VALUES ("54","Three-round secret handshakes based on ELGamal and DSA","Secret handshake, introduced recently by Balfanz et al, is a very useful cryptographic mechanism which allows two members of the same group to authenticate each other secretly. In a secret handshake protocol, an honest member in the group will never reveal his group affiliation unless the other party is a valid member of the same group. In other words, only the members who have certificates from the Group Administrator can be successful in handshaking. If a handshake between two parties fails, the identity of either party will not be disclosed. Several secret handshake schemes have been found in the literature, which are based on pairing, CA-Oblivious Encryption and RSA. Furthermore, several Oblivious Signature-Based Envelopes (OSBE) schemes based on the ElGamal signature family were introduced recently by Nasserian and Tsudik, and they proposed a generic construction of secret handshake from OSBE based on ElGamal signature family as well. It is shown in the generic construction that any ElGamal signature family based OSBE scheme can be converted to secret handshake within three communication rounds, except the ElGamal and DSA signature. In this paper, to complement the previous result, we show a three-round secret handshake scheme based on ElGamal signature. We prove that the scheme is existentially unforgeable in the Random Oracle Model (ROM). Finally we extend our scheme to a DSA-based secret handshake which also requires only three rounds.","2006","12","3","2025-12-02","https://university.edu/papers/1269f655-7bb4-4da1-bc37-287ab9e63143.pdf");
INSERT INTO Paper VALUES ("55","Removing bias against membrane proteins in interaction networks.","Background#R##N#Cellular interaction networks can be used to analyze the effects on cell signaling and other functional consequences of perturbations to cellular physiology. Thus, several methods have been used to reconstitute interaction networks from multiple published datasets. However, the structure and performance of these networks depends on both the quality and the unbiased nature of the original data. Due to the inherent bias against membrane proteins in protein-protein interaction (PPI) data, interaction networks can be compromised particularly if they are to be used in conjunction with drug screening efforts, since most drug-targets are membrane proteins.","2011","8","3","2025-12-02","https://university.edu/papers/a7af9889-f019-4476-b36c-fde5d9ecb1d0.pdf");
INSERT INTO Paper VALUES ("56","Routing permutations with link-disjoint and node-disjoint paths in a class of self-routable networks","High-speed interconnects have been gaining much attention from the computer industry recently as interconnects are becoming a limiting factor to the performance of modern computer systems. This trend will even continue in the near future as technology improves. In this paper, we consider efficiently routing permutations in a class of switch-based interconnects. Permutation is an important communication pattern in parallel and distributed computing systems. We present a generic approach to realizing arbitrary permutations in a class of unique-path, self-routable multistage networks. We consider routing arbitrary permutations with link-disjoint paths and node-disjoint paths in such interconnects in a minimum number of passes. In particular, routing with node-disjoint paths has important applications in the emerging optical interconnects. We employ and further expand the Latin square technique used in the all-to-all personalized exchange algorithms for this class of multistage networks for general permutation routing. The implementation is optimal in number of passes and near-optimal in network transmission time.","2002","7","4","2025-12-02","https://university.edu/papers/c53addcd-de49-4d5b-ae86-d7f94c4b07f3.pdf");
INSERT INTO Paper VALUES ("57","Design and Characterization of a Six-axis Accelerometer","External force at the end-effector is often required for the force control of robotic manipulator. In some cases, the force information measured by wrist force sensor consists of the external force and the undesired inertial force arising from the acceleration of the end-effector. Up to now, it is still difficult to extract the external force exactly for the insufficiency of acceleration information. A novel six-axis accelerometer in the type of dual annular membranes structure is presented in this paper. It can simultaneously measure all three linear acceleration components ax, ay, az and three angular acceleration components αx, αy, αz, which can be used to extract the external forces. The sensor structure and its sensing principle are described. The rated strains and interference strains obtained from Finite Element Method (FEM) simulations indicate that the accelerometer has a low level cross-sensitivity. The characteristic experiments reveal that the experimental sensitivities are in good correspondence with the results of the FEM simulations. It also shows that this accelerometer has a good linearity and minor interference errors as well as principle errors.","2005","3","1","2025-12-02","https://university.edu/papers/dc800b4b-21ca-4f0d-8d58-cfe27b6774da.pdf");
INSERT INTO Paper VALUES ("58","Dependent intersection: a new way of defining records in type theory","Records and dependent records are a powerful tool for programming, representing mathematical concepts, and program verification. In this last decade several type systems with records as primitive types were proposed. The question is arisen whether it is possible to define record type in existent type theories using standard types without introducing new primitives. It was known that independent records can be defined in type theories with dependent functions or intersection. On the other hand dependent records cannot be formed using standard types. Hickey introduced a complex notion of very dependent functions to represent dependent records. In the current paper we extend Martin-Lof's type theory with a simpler type constructor dependent intersection, i.e., the intersection of two types, where the second type may depend on elements of the first one (not to be confused with the intersection of a family of types). This new type constructor allows us to define dependent records in a very simple way. It also allows us to define the set type constructor.","2003","5","1","2025-12-02","https://university.edu/papers/f2c85a53-7444-4901-98d6-b6fad73f8aea.pdf");
INSERT INTO Paper VALUES ("59","Profile forward regression screening for ultra-high dimensional semiparametric varying coefficient partially linear models","In this paper, we consider semiparametric varying coefficient partially linear models when the predictor variables of the linear part are ultra-high dimensional where the dimensionality grows exponentially with the sample size. We propose a profile forward regression (PFR) method to perform variable screening for ultra-high dimensional linear predictor variables. The proposed PFR algorithm can not only identify all relevant predictors consistently even for ultra-high semiparametric models including both nonparametric and parametric parts, but also possesses the screening consistency property. To determine whether or not to include the candidate predictor in the model of selected ones, we adopt an extended Bayesian information criterion (EBIC) to select the “best” candidate model. Simulation studies and a real data example are also carried out to assess the performance of the proposed method and to compare it with existing screening methods.","2017","2","2","2025-12-02","https://university.edu/papers/9f74cacd-b013-4848-b8cc-d947050b642a.pdf");
INSERT INTO Paper VALUES ("60","An Adaptive Location Detection scheme for energy-efficiency of smartphones","Global Positioning System (GPS) is widely used for the Location-Based Service (LBS) of smartphones. However, GPS dramatically increases the power consumption of a smartphone due to heavy computation overhead. Cell-tower Based Localization (CBL) can be an alternative solution to perform LBS in an energy-efficient way; but its adoption is limited due to the low positioning accuracy. This paper presents a new location estimation scheme for smartphones called Adaptive Location Detection (ALD). ALD adaptively detects the location of a smartphone considering the category of applications executed, movement pattern of a user, and the battery level. Specifically, ALD categorizes applications according to the required level of positioning accuracy, and then adaptively utilizes GPS and CBL. ALD also takes different actions according to the movement pattern of a user and the remaining battery level of the smartphone. To assess the effectiveness of the proposed scheme, we perform simulations under five location based applications and six scenarios. The evaluation results show that ALD reduces the energy consumption of GPS by 49.5% on average. Nevertheless, it satisfies the accuracy requirement of each situation.","2016","7","4","2025-12-02","https://university.edu/papers/85ba75da-3741-49e6-bd73-2da6fc7e4f23.pdf");
INSERT INTO Paper VALUES ("61","Utility assessment of a multispectral snapshot LWIR imager","The purpose of this study was to asses the utility of a Long Wave Infrared (LWIR) snapshot imager for remote sensing applications. The snapshot imager is made possible by the utilization of a color filter array that selectively allows different wavelengths of light to be collected on separate pixels of the focal plane in same fashion as a typical Bayer array in visible portion of the spectrum [1]. Recent technology developments have made this possible in the LWIR [2]. The primary focus of the study is to develop a band selection technique that is capable of identifying both the optimal number and width of the spectral channels. Once selected, the theoretical sensor performance is used to evaluate the usefulness in a typical remote sensing application.","2010","4","1","2025-12-02","https://university.edu/papers/ce221294-f7f7-4969-a14b-7f25f77b071b.pdf");
INSERT INTO Paper VALUES ("62","Business Process Analytics","Business Process Management Systems are a rich source of events that document the execution of processes and activities within these systems. Business Process Analytics is the family of methods and tools that can be applied to these event streams in order to support decision-making in organizations. The analysis of process events can focus on the behavior of completed processes, evaluate cur- rently running process instances, or focus on predicting the behavior of process in- stances in the future. This chapter provides an overview of the different methods and technologies that can be employed in each of these three areas of process ana- lytics. We discuss the underlying format and types of process events as the com- mon source of analytics information, present techniques for the aggregation and composition of these events, and outline methods that support backward- and for- ward-looking process analytics.","2015","18","3","2025-12-02","https://university.edu/papers/a1fd715f-b934-4823-a785-2f133f44444f.pdf");
INSERT INTO Paper VALUES ("63","Can We Learn to Beat the Best Stock","A novel algorithm for actively trading stocks is presented. While traditional expert advice and 'universal' algorithms (as well as standard technical trading heuristics) attempt to predict winners or trends, our approach relies on predictable statistical relations between all pairs of stocks in the market. Our empirical results on historical markets provide strong evidence that this type of technical trading can 'beat the market' and moreover, can beat the best stock in the market. In doing so we utilize a new idea for smoothing critical parameters in the context of expert learning.","2004","10","4","2025-12-02","https://university.edu/papers/4b6d506b-c609-499c-bd5e-34a005f7cc3b.pdf");
INSERT INTO Paper VALUES ("64","Design problems in automated warehousing","What are the common problems that arise in designing an automated warehouse? What solution and analysis techniques are appropriate for addressing these problems? The objective of this paper is to help provide answers to these two questions. In doing so, emphasis will be placed on describing the design problems. The problems will be classified as physical configuration design problems and operations strategy design problems. The problems will be described generically and then in detail in the context of miniload automated storage and retrieval system (ASRS) design The miniload ASRS was selected primarily because the problems faced in designing a miniload ASRS are common to most automated warehousing design efforts.","1986","7","2","2025-12-02","https://university.edu/papers/bd041731-daea-43b7-9dbc-26daf25f5b7e.pdf");
INSERT INTO Paper VALUES ("65","Uncertainty Quantification of Parameters in SBVPs Using Stochastic Basis and Multi-scale Domain Decomposition☆","Abstract   Quantifying uncertainty effects of coefficients that exhibit heterogeneity at multiple scales is among many outstanding challenges in subsurface flow models. Typically, the coefficients are modeled as functions of random variables governed by certain statistics. To quantify their uncertainty in the form of statistics (e.g., average fluid pressure or concentration) MC methods have been used. In a separate direction, multi-scale numerical methods have been developed to efficiently capture spatial heterogeneity that otherwise would be intractable with standard numerical techniques. Since heterogeneity of individual realizations can drastically differ, a direct use of multi-scale methods in MC simulations is problematic. Furthermore, MC methods are known to be very expensive as a lot of samples are required to adequately characterize the random component of the solution. In this study, we utilize a stochastic representation method that exploits the solution structure of the random process in order to construct a problem dependent stochastic basis. Using this stochastic basis representation a set of coupled yet deterministic equations is constructed. To reduce the computational cost of solving the coupled system, we develop a multi-scale domain decomposition method utilizing Robin transmission conditions. In the proposed method, enrichment of the solution space can be performed at multiple levels that offer a balance between computational cost, and accuracy of the approximate solution.","2016","2","2","2025-12-02","https://university.edu/papers/3c217ae7-c618-4c31-b56e-b2b3e736f8e2.pdf");
INSERT INTO Paper VALUES ("66","A framework for e-government planning and implementation","Nowadays, Information Technology (IT) allows governments to serve citizens in a more timely, effective and cost-efficient way. As many public sector organisations are either planning for or implementing major Electronic Government (e-government) projects, there is a growing need to understand what factors should be considered for successful planning. This paper proposes that the e-government needs to be planned by a holistic view to reduce the associated risks and prevent extra wastage of time and money. The scope of this research is Iran. In this regard, we identified and discussed 30 key strategic factors and elaborately included them in a framework for successful implementation of e-government.","2008","7","4","2025-12-02","https://university.edu/papers/946ff56e-8c2b-4343-8ea2-217d1bd23a92.pdf");
INSERT INTO Paper VALUES ("67","On two problems regarding the Hamiltonian cycle game","We consider the fair Hamiltonian cycle Maker-Breaker game, played on the edge set of the complete graph Kn on n vertices. It is known that Maker wins this game if n is sucien tly large. We are interested in the minimum number of moves needed for Maker in order to win the Hamiltonian cycle game, and in the smallest n for which Maker has a winning strategy for this game. We prove the following results: (1) If n is sucien tly large, then Maker can win the Hamiltonian cycle game within n + 1 moves. This bound is best possible and it settles a question of Hefetz, Krivelevich, Stojakovi c and Szab o; (2) If n 29, then Maker can win the Hamiltonian cycle game. This improves the previously best bound of 600 due to Papaioannou.","2009","18","3","2025-12-02","https://university.edu/papers/d4e26646-0bea-4422-99cd-b91f65b44694.pdf");
INSERT INTO Paper VALUES ("68","Generating VHDL-A—like models using ABSynth","A method for the graphical specification and the automatic generation of analogue behavioural models is presented. This method has been implemented as a new software tool called ABSynth. The behaviour of the component to model is described as a functional diagram, which is then automatically translated into a VHDL-A-like analogue hardware description language. No syntax knowledge is necessary and the modelling time is reduced.","1995","18","3","2025-12-02","https://university.edu/papers/cfcfddca-e20b-403e-b272-8b9f73576b82.pdf");
INSERT INTO Paper VALUES ("69","Robust Environmental Sound Recognition for Home Automation","This work presents a robust environmental sound recognition system for home automation. Specific home automation services can be activated based on identified sound classes. Additionally, when the sound category is human speech, such speech can be recognized for detecting human intentions as in conventional research on home automation. To attain this ambitious goal, this study uses two key techniques: signal-to-noise ratio-aware subspace-based signal enhancement and sound recognition with independent component analysis mel-frequency cepstral coefficients and a frame-based multiclass support vector machines, respectively. Simulations and an experiment in a real-world environment are given to illustrate the performance of the proposed robust sound recognition system.","2008","12","4","2025-12-02","https://university.edu/papers/f35c050e-2880-44a4-a939-6bbaa0f4d9bf.pdf");
INSERT INTO Paper VALUES ("70","Performance Prediction of Service-Oriented Applications based on an Enterprise Service Bus","An enterprise service bus (ESB) is a standards-based integration platform that combines messaging, web services, data transformation, and intelligent routing in a highly distributed environment. The ESB has been adopted as a key component of SOA infrastructures. For SOA implementations with large number of users, services, or traffic, maintaining the necessary performance levels of applications integrated using an ESB presents a substantial challenge, both to the architects who design the infrastructure as well as to IT professionals who are responsible for administration. In this paper, we develop a performance model for analyzing and predicting the runtime performance of service applications composed on a COTS ESB platform. Our approach utilizes benchmarking techniques to measure primitive performance overheads of service routing activities in the ESB. The performance characteristics of the ESB and services running on the ESB are modeled in a queuing network, which facilitates the performance prediction of service oriented applications. This model is validated by an example ESB based service application modeled from real world loan broking business application.","2007","4","4","2025-12-02","https://university.edu/papers/721261fc-c8ec-4b77-97a1-c5d6ce572fed.pdf");
INSERT INTO Paper VALUES ("71","Privacy Protection for Telecare Medicine Information Systems Using a Chaotic Map-Based Three-Factor Authenticated Key Agreement Scheme","Telecare medicine information systems (TMIS) provide flexible and convenient e-health care. However, the medical records transmitted in TMIS are exposed to unsecured public networks, so TMIS are more vulnerable to various types of security threats and attacks. To provide privacy protection for TMIS, a secure and efficient authenticated key agreement scheme is urgently needed to protect the sensitive medical data. Recently, Mishra  et al.  proposed a biometrics-based authenticated key agreement scheme for TMIS by using hash function and nonce, they claimed that their scheme could eliminate the security weaknesses of Yan  et al .'s scheme and provide dynamic identity protection and user anonymity. In this paper, however, we demonstrate that Mishra  et al. 's scheme suffers from replay attacks, man-in-the-middle attacks and fails to provide perfect forward secrecy. To overcome the weaknesses of Mishra  et al .'s scheme, we then propose a three-factor authenticated key agreement scheme to enable the patient to enjoy the remote healthcare services via TMIS with privacy protection. The chaotic map-based cryptography is employed in the proposed scheme to achieve a delicate balance of security and performance. Security analysis demonstrates that the proposed scheme resists various attacks and provides several attractive security properties. Performance evaluation shows that the proposed scheme increases efficiency in comparison with other related schemes.","2017","3","4","2025-12-02","https://university.edu/papers/bade3aee-b18d-4a77-8595-1496c86276b4.pdf");
INSERT INTO Paper VALUES ("72","A broker-assisting trust and reputation system based on artificial neural network","Due to the dynamic and anonymous nature of open environments, it is critically important for agents to identify trustful cooperators which work consistently as they claim. In the e-services and e-commerce communities, trust and reputation systems are applied broadly as one kind of decision support systems, and aim to cope with the consistency problems caused by uncertain trust relationships. However, challenges still exist: on the one hand, we require more flexible trust computation models to satisfy various personal requirements since agents in these communities are heterogeneous; on the other hand, trust and reputation systems calculate the trustworthiness of agents based on the agents' past behavior. The open environments are dynamic, agents are anonymous and the records about agents' past behavior are distributed in the environments, so agents have to search the required records through the environments due to their lack of valid information. Thus, efficient, scalable and effective information collection strategies are required to address these issues. In this paper we present a distributed trust and reputation system to cope with the challenges. We propose a novel and flexible trust computation model based on artificial neural networks. With the advantages of ANN, our trust model tunes the parameters automatically to adapt to various personal requirements. We propose a broker-assisting information collection strategy based on clustering method. With the support of brokers, subcommunities are managed by reputation mechanism in an efficient and scalable way and help their members collect information with high quality. We show the performance of our trust and reputation system by simulation.","2009","14","1","2025-12-02","https://university.edu/papers/99a0675c-b180-4e50-8de3-970bd781652f.pdf");
INSERT INTO Paper VALUES ("73","Two-way communication for programming and measurement in a miniature implantable stimulator.","Implantable stimulators are needed for chronic electrical stimulation of nerves and muscles in experimental studies. The device described exploits the versatility of current microcontrollers for stimulation and communication in a miniature implant. Their standard outputs can provide the required selectable constant-current sources. In this device, pre-programmed stimulation paradigms were selected by transcutaneous light pulses. The potential of a programmable integrated circuit (PIC) was thus exploited. Implantable devices must be biocompatible. A novel encapsulation method that require no specialised equipment and that used two classical encapsulants, silicone and Teflon was developed. It was tested for implantation periods of up to four weeks. A novel way to estimate electrode impedance in awake animals is also presented. It was thus possible to follow the evolution of the nerve-electrode interface and, if necessary, to adjust the stimulation parameters. In practice, the electrode voltage at the end of a known constant-current pulse was measured by the PIC. The binary coded value was then indicated to the user as a series of muscle twitches that represented the binary value of the impedance measurement. This neurostimulator has been successfully tested in vitro and in vivo. Thresholds and impedance values were chronically monitored following implantation of a self-sizing spiral cuff electrode. Impedance variations in the first weeks could reflect morphological changes usually observed after the implantation of such electrodes.","2005","6","3","2025-12-02","https://university.edu/papers/e979ee41-fd84-471c-a237-52f001bc31d2.pdf");
INSERT INTO Paper VALUES ("74","Identifying and localizing robots in a multi-robot system environment","Development of multiple robot systems which solve complex and dynamic problems in parallel and distributed manners is one of the key issues in robotics research. The multiple robot systems require robust methods to identify robots for collaborative behaviors. This paper proposes a method using omnidirectional vision sensors for the identification between the robots. In addition to the several advantages of the omnidirectional vision sensor as a vision of a mobile robot, the omnidirectional vision sensor brings a significant benefit for realizing collaborative behaviors in multiple robot systems. After discussing on the algorithm, this paper shows several simulation results and real experimental results in a real environment.","1999","5","3","2025-12-02","https://university.edu/papers/d3eaa6fc-2e7f-42d2-9f27-a2e63d4b8807.pdf");
INSERT INTO Paper VALUES ("75","Towards a Sociability Theory of Computer Anxiety: An Interpersonal Circumplex Perspective","This study investigates the relationship between individual personality traits and computer anxiety. Much behavioral research on technology-adoption antecedents is focused on individual level variables such as attitudes, beliefs, and personality traits such as computer anxiety and personal innovativeness. However, findings of research linking personality traits to technology adoption have been inconsistent. Our research introduces the Interpersonal Circumplex Model as a means of identifying psychological dimensions and individual traits that may be the exogenous determinants of such variables as anxiety, innovativeness, attitudes and perceptions. In this study, we surveyed 88 healthcare practitioners at a large, mid-western healthcare provider preparing to expand its telemedicine network. The survey measured position on the Interpersonal Circumplex and computer anxiety. Individuals whose trait scores reflected relatively equal degrees of Dominance and Affiliation reported a higher degree of computer anxiety. Our research findings support the notion that individual trait differences affect the level of computer anxiety. This is additional evidence that the Interpersonal Circumplex has promise as integrative trait model for MIS behavioral research.","2005","2","1","2025-12-02","https://university.edu/papers/9b6d5d30-29e6-48d9-b177-f698ae92efef.pdf");
INSERT INTO Paper VALUES ("76","Detail-preserving median based filters in image processing","Abstract   A switching scheme for median filtering which is suitable to be a prefilter before some subsequent processing e.g. edge detection or data compression is presented to remove impulse noises in digital images with small signal distortion. The switching procedure is based on the local measurements of impulses which is called impulse detection. A median and weighted median based impulse detector is devised and the relevant properties are discussed. By using a test image, we demonstrate that the filtering structure yields an output image which is significantly better than those of median, weighted median and optimal stack filters.","1994","7","4","2025-12-02","https://university.edu/papers/de8a6088-3992-444c-a0f1-95189af11d29.pdf");
INSERT INTO Paper VALUES ("77","A PSO approach for robust aircraft routing","To mitigate the impact of unpredictable disruptions, airlines are seeking to proactively design schedules that incorporate some robustness features. In this paper, we propose a novel simulation-optimization approach using a particle swarm optimization algorithm for solving the robust aircraft routing and flight retiming problem. The approach requires inserting buffer times between departure times of flights to improve the robustness of both aircraft and passengers connections. The proposed approach is based on discrete-event simulation for the evaluation of the solutions performance and a Particle Swarm Optimization (PSO) routine for guiding the search towards enhanced solutions. The results of computational experiments that were carried out on a real data are presented.","2015","16","1","2025-12-02","https://university.edu/papers/193acb49-0147-4de4-8aba-72756d66c5b2.pdf");
INSERT INTO Paper VALUES ("78","Farsite: federated, available, and reliable storage for an incompletely trusted environment","Farsite is a secure, scalable file system that logically functions as a centralized file server but is physically distributed among a set of untrusted computers. Farsite provides file availability and reliability through randomized replicated storage; it ensures the secrecy of file contents with cryptographic techniques; it maintains the integrity of file and directory data with a Byzantine-fault-tolerant protocol; it is designed to be scalable by using a distributed hint mechanism and delegation certificates for pathname translations; and it achieves good performance by locally caching file data, lazily propagating file updates, and varying the duration and granularity of content leases. We report on the design of Farsite and the lessons we have learned by implementing much of that design.","2002","6","4","2025-12-02","https://university.edu/papers/553d6d86-654f-4f3e-b178-b9f3f6eb18b4.pdf");
INSERT INTO Paper VALUES ("79","RATIONAL FIRST INTEGRALS FOR POLYNOMIAL VECTOR FIELDS ON ALGEBRAIC HYPERSURFACES OF ℝn+1","Using sophisticated techniques of Algebraic Geometry, Jouanolou in 1979 showed that if the number of invariant algebraic hypersurfaces of a polynomial vector field in ℝn of degree m is at least , then the vector field has a rational first integral. Llibre and Zhang used only Linear Algebra to provide a shorter and easier proof of the result given by Jouanolou. We use ideas of Llibre and Zhang to extend the Jouanolou result to polynomial vector fields defined on algebraic regular hypersurfaces of ℝn+1, this extended result completes the standard results of the Darboux theory of integrability for polynomial vector fields on regular algebraic hypersurfaces of ℝn+1.","2012","17","4","2025-12-02","https://university.edu/papers/9b28091c-6a00-44fd-8360-17c726aac8c5.pdf");
INSERT INTO Paper VALUES ("80","IncidentResponseSim: An Agent-Based Simulation Tool for Risk Management of Online Fraud","Banking and online financial services are part of our critical infrastructure. As such, they comprise an Achilles heel in society and need to be protected accordingly. The last ten years have seen a steady shift from traditional show-off hacking towards cybercrime with great economic consequences for society. The different threats against online services are getting worse, and risk management with respect to denial-of-service attacks, phishing, and banking Trojans is now part of the agenda of most financial institutions. This trend is overseen by responsible authorities who step up their minimum requirements for risk management of financial services and, among other things, require regular risk assessment of current and emerging threats.For the financial institution, this situation creates a need to understand all parts of the incident response process of the online services, including the technology, sub-processes, and the resources working with online fraud prevention. The effectiveness of each countermeasure has traditionally been measured for one technology at a time, for example, leaving the fraud prevention manager with separate values for the effectiveness of authentication, intrusion detection, and fraud prevention. In this thesis, we address two problems with this situation. Firstly, there is a need for a tool which is able to model current countermeasures in light of emerging threats. Secondly, the development process of fraud detection is hampered by the lack of accessible data.In the main part of this thesis, we highlight the importance of looking at the “big risk picture” of the incident response process, and not just focusing on one technology at a time. In the first article, we present a tool which makes it possible to measure the effectiveness of the incident response process. We call this an incident response tree (IRT). In the second article, we present additional scenarios relevant for risk management of online financial services using IRTs. Furthermore, we introduce a complementary model which is inspired by existing models used for measuring credit risks. This enables us to compare different online services, using two measures, which we call Expected Fraud and Conditional Fraud Value at Risk. Finally, in the third article, we create a simulation tool which enables us to use scenario-specific results together with models like return of security investment, to support decisions about future security investments.In the second part of the thesis, we develop a method for producing realistic-looking data for testing fraud detection. In the fourth article, we introduce multi-agent based simulations together with social network analysis to create data which can be used to fine-tune fraud prevention, and in the fifth article, we continue this effort by adding a platform for testing fraud detection.","2015","18","4","2025-12-02","https://university.edu/papers/be82e014-62bf-4ea1-b90f-caa4fac8227c.pdf");
INSERT INTO Paper VALUES ("81","Building User Models for RoboCup-Rescue Visualization","Information visualization is one of the most important fields in RoboCup-Rescue research. As requirements for visualization vary by users and by their purpose of viewer use, we introduce a mechanism called user model. User models hold the requirements of typical users. They are used for the selection and customization of information, controls of viewer, and so on. We implemented the mechanism with five user models in RoboCup-Rescue 2D Viewer.","2002","13","3","2025-12-02","https://university.edu/papers/d00695d3-4017-4687-aec9-df770e968bb5.pdf");
INSERT INTO Paper VALUES ("82","Enhancing neural control systems by fuzzy logic and evolutionary reinforcement","Neural networks are widely used for system modelling and control because of their ability to approximate complex non-linear functions. Fuzzy systems, similarly, have been shown to be able to approximate or model any nonlinear system. Fuzzy-logic and neural systems, however, have very contrasting application requirements and it has been said that their integration offers a facility to bridge symbolic knowledge processing and connectionist learning. The significance of the integration becomes more apparent by considering their disparities. Neural networks do not provide a strong scheme for knowledge representation, while fuzzy systems do not possess capabilities for automated learning. On the other hand, another learning method has emerged recently, as an alternative to inductive techniques used with neural networks, namely, genetic or evolutionary learning. This paper will present a technique for the fusion of the three paradigms in a learning control context. It will describe a type of learning, known as Evolutionary Algorithm Reinforcement Learning (EARL), which is used to optimise a fuzzy neural control system. An application case study is also presented.","1998","7","2","2025-12-02","https://university.edu/papers/6feba097-8dc2-4738-bda5-1567347e7e92.pdf");
INSERT INTO Paper VALUES ("83","Space Complexity of Estimation of Distribution Algorithms","In this paper, we investigate the space complexity of the Estimation of Distribution Algorithms (EDAs), a class of sampling-based variants of the genetic algorithm. By analyzing the nature of EDAs, we identify criteria that characterize the space complexity of two typical implementation schemes of EDAs, the factorized distribution algorithm and Bayesian network-based algorithms. Using random additive functions as the prototype, we prove that the space complexity of the factorized distribution algorithm and Bayesian network-based algorithms is exponential in the problem size even if the optimization problem has a very sparse interaction structure.","2005","1","2","2025-12-02","https://university.edu/papers/5faea21d-dedd-4239-94fe-d0eb1eac921c.pdf");
INSERT INTO Paper VALUES ("84","Area-efficient reed-solomon decoder design for optical communications","A high-speed low-complexity Reed-Solomon (RS) decoder architecture based on the recursive degree computationless modified Euclidean (rDCME) algorithm is presented in this brief. The proposed architecture has very low hardware complexity compared with the conventional modified Euclidean and degree computationless modified Euclidean (DCME) architectures, since it can reduce the degree computation circuitry and replace the conventional systolic architecture that uses many processing elements (PEs) with a recursive architecture using a single PE. A high-throughput data rate is also facilitated by employing a pipelining technique. The proposed rDCME architecture has been designed and implemented using SMIC 0.18-mum CMOS technology. Synthesized results show that the proposed RS (255, 239) decoder requires only about 18 K gates and can operate at 640 MHz to achieve a throughput of 5.1 Gb/s, which meets the requirement of modern high-speed optical communications.","2009","19","2","2025-12-02","https://university.edu/papers/5861ec90-2d28-419d-a40e-c340f18ef9bd.pdf");
INSERT INTO Paper VALUES ("85","Efficient Implementation of Higher Order Image Interpolation.","This work presents a new method of fast cubic and higher order image interpolation. The evaluation of the piecewise n-th order polynomial kernels is accelerated by transforming the polynomials into the interval [0,1], which has the advantage that some terms of the polynomials disappear, and that several coecients could be precalculated, which is proven in the paper. The results are exactly the same as using standard n-th order interpolation, but the computational complexity is reduced. Calculating the interpolation weights for the cubic convolution only needs about 60% of the time compared to the classical method optimized by the Horner’s rule. This allows a new ecient implementation for image interpolation.","2004","19","1","2025-12-02","https://university.edu/papers/a071a47a-3704-4aea-8649-8c9b5a882785.pdf");
INSERT INTO Paper VALUES ("86","On the comparison of CPLEX-computed job schedules with the self-tuning dynP job scheduler","Summary form only given. We present a comparison of CPLEX-computed job schedules with the self-tuning dynP scheduler. This scheduler switches the active scheduling policy dynamically during run time, in order to reject changing characteristics of waiting jobs. Each times the self-tuning dynP scheduler checks for a new policy a quasi offline scheduling is done as the numbers of jobs are fixed. Two questions arise from this fact: what is the optimal schedule in each self-tuning step? And what is the performance difference between the optimal schedule and the best schedule generated with one of the scheduling policies? For that we model the scheduling problem as an integer problem, which is then solved with the well-known CPLEX library. Due to the size of the problem, we apply time-scaling, i.e. the schedule is computed on a larger than one second precise scale. We use the CTC job trace as input for a discrete event simulation and evaluate the performance difference between the CPLEX-computed schedules and the schedules generated by the self-tuning dynP scheduler. The results show, that the performance of the self-tuning dynP scheduler is close to solutions computed by CPLEX. However, the self-tuning dynP scheduler needs much less time for generating the schedules than CPLEX.","2004","17","4","2025-12-02","https://university.edu/papers/a36f0ab3-07a3-4031-902c-d62d63a0707b.pdf");
INSERT INTO Paper VALUES ("87","Converting Continuous-Space Language Models into N -gram Language Models with Efficient Bilingual Pruning for Statistical Machine Translation","The Language Model (LM) is an essential component of Statistical Machine Translation (SMT). In this article, we focus on developing efficient methods for LM construction. Our main contribution is that we propose a Natural  N -grams based Converting (NNGC) method for transforming a Continuous-Space Language Model (CSLM) to a Back-off  N -gram Language Model (BNLM). Furthermore, a Bilingual LM Pruning (BLMP) approach is developed for enhancing LMs in SMT decoding and speeding up CSLM converting. The proposed pruning and converting methods can convert a large LM efficiently by working jointly. That is, a LM can be effectively pruned before it is converted from CSLM without sacrificing performance, and further improved if an additional corpus contains out-of-domain information. For different SMT tasks, our experimental results indicate that the proposed NNGC and BLMP methods outperform the existing counterpart approaches significantly in BLEU and computational cost.","2016","17","3","2025-12-02","https://university.edu/papers/0c5a0254-1ced-42aa-9f70-3caea0bccd15.pdf");
INSERT INTO Paper VALUES ("88","Optimally bracing grid frameworks with holes","We consider the bracing problem of a square grid framework possibly with holes and present an efficient algorithm for making the framework infinitesimally rigid by augmenting it with the minimum number of diagonal braces. This number of braces matches the lower bound given by Gaspar, Radics and Recski 2. Our contribution extends the famous result on bracing the rectangular grid framework by Bolker and Crapo 1.","2015","10","2","2025-12-02","https://university.edu/papers/b95d6d8a-b477-4c86-835e-b40cafdd6680.pdf");
INSERT INTO Paper VALUES ("89","On the correctness of transformations in compiler back-ends","This paper summarizes the results on the correctness of the transformations in compiler back-ends achieved in the DFG-project Verifix. Compiler back-ends transform intermediate languages into code of the target machine. Back-end generators allow to generate compiler back-ends from a set of transformation rules. This paper focuses on the correctness of these transformation rules and on the correctness of the whole transformation stemming from the transformation rules.","2006","10","3","2025-12-02","https://university.edu/papers/ff612da2-96d2-4f28-ba3d-2072bc024f76.pdf");
INSERT INTO Paper VALUES ("90","A plea for the majority method in aggregating judgements","The aim of this article is to vindicate the majority method as a procedure that may be suitable for some judgement aggregation problems. The standard literature on judgement aggregation has emphasized that the majority method may fail to meet some restrictions that are considered as binding. For instance, if the number of persons is even, aggregating individual judgements may fail to return a collective judgement. More importantly, using the majority method may lead to a logically inconsistent set of collective judgements. As a consequence, it has been discredited as a suitable judgement aggregation mechanism, while it is known that it meets many attractive properties. In contrast, this article explains how the standard logical consistency restrictions can be weakened in ways that are plausible for some kinds of judgement aggregation problems, in particular when the aggregation aim is of an informational nature rather than using the collective output for decision making. In addition, it is shown that the majority method meets those weak consistency restrictions. Therefore, the article concludes that the use of the majority method can be vindicated at least in addressing such aggregation problems. In order to do so, the article uses a simple variant of the majority method which ranks propositions according to the number of persons that support them, and is closer to the way that the method is used in social choice theory. In addition, it is shown that such a variant satisfies the translation of all the properties that the method meets in that theory, without facing transitivity difficulties such the voting paradox.","2012","18","1","2025-12-02","https://university.edu/papers/ca9840a3-cd91-4dea-a135-85e649accdae.pdf");
INSERT INTO Paper VALUES ("91","Global optimization algorithm for mixed integer quadratically constrained quadratic program","Mixed integer quadratic programs with quadratic constraints (MIQQP) occur frequently in various areas of engineering practice and management science, but most solution methods for this kind of problems are often designed for its special cases. In this paper, we present a simple global optimization algorithm for solving problem (MIQQP). We first convert problem (MIQQP) into an equivalent generalized bilinear programming problem with integer variables (EIQQP). We next show that replacing the quadratic objective and constraint functions with their convex envelopes is dominated by an alternative methodology based on convexifying the range of the bilinear terms on the feasible region. Finally, by incorporating the reduction-correction techniques and sampling strategies into the branch and bound scheme, the proposed algorithm is developed for solving (MIQQP). Convergence and optimality of the algorithm are presented and numerical examples taken from some recent literature and MINLPLib2 are carried out to validate the performance of the proposed algorithm.","2017","6","2","2025-12-02","https://university.edu/papers/96eeb477-befa-4f4b-b937-9ba4de48280d.pdf");
INSERT INTO Paper VALUES ("92","Genetic Cost Optimization of the GI/M/1/N Finite-Buffer Queue with a Single Vacation Policy","In the artice, problem of the cost optimization of the GI/M/1/N -type queue with finite buffer and a single vacation policy is analyzed. Basing on the explicit representation for the joint transform of the first busy period, first idle time and the number of packets transmitted during the first busy period and fixed values of unit costs of the server's functioning an optimal set of system parameters is found for exponen- tially distributed vacation period and 2-Erlang distribution of inter arrival times. The problem of optimization is solved using genetic algorithm. Dif- ferent variants of the load of the system are considered as well.","2013","2","2","2025-12-02","https://university.edu/papers/03fc4d37-89d8-4872-87bc-cba6b9700a27.pdf");
INSERT INTO Paper VALUES ("93","PI 2 : A Linearized AQM for both Classic and Scalable TCP","This paper concerns the use of Active Queue Management (AQM) to reduce queuing delay. It offers insight into why it has proved hard for a Proportional Integral (PI) controller to remain both responsive and stable while controlling `Classic' TCP flows, such as TCP Reno and Cubic. Due to their non-linearity, the controller's adjustments have to be smaller when the target drop probability is lower. The PI Enhanced (PIE) algorithm attempts to solve this problem by scaling down the adjustments of the controller using a look-up table. Instead, we control an internal variable that is by definition linearly proportional to the load, then post-process it into the required Classic drop probability---in fact we show that the output simply needs to be squared. This allows tighter control, giving responsiveness and stability better or no worse than PIE achieves, but without all its corrective heuristics.   Additionally, with suitable packet classification, it becomes simple to extend this PI2 AQM to support coexistence between Classic and Scalable congestion controls in the public Internet. Unlike a Classic congestion control, a Scalable congestion control ensures sufficient feedback at any flow rate, an example being Data Centre TCP (DCTCP). A Scalable control is linear, so we can use the internal variable directly without any squaring, by omitting the post-processing stage.   We implemented this PI2 AQM as a Linux qdisc to extensively test our claims using Classic and Scalable TCPs.","2016","10","1","2025-12-02","https://university.edu/papers/b707e9a1-9693-4cb9-bf03-1cc75f10fd62.pdf");
INSERT INTO Paper VALUES ("94","Scheduling and performance limits of networks with constantly changing topology","A communication network with tine-varying topology is considered. The network consists of M receivers and N transmitters that, in principle, may access every receiver. An underlying network state process with Markovian statistics is considered that reflects the physical characteristics of the network affecting the link service capacity. The transmissions are scheduled dynamically, based on information about the link capacities and the backlog in the network. The region of achievable throughputs is characterized. A transmission scheduling policy is proposed that utilizes current topology state information and achieves all throughput vectors achievable by any anticipative policy. The changing topology model applies to networks of low-Earth orbit (LEO) satellites, meteor-burst communication networks, and networks with mobile users.","1997","5","3","2025-12-02","https://university.edu/papers/82f6475b-5247-45ad-a19a-3ff31c7fc041.pdf");
INSERT INTO Paper VALUES ("95","UNDECIDABLE RELATIVIZATIONS OF ALGEBRAS OF RELATIONS","In this paper we show that relativized versions of relation set algebras and cylindric set alge- bras have undecidable equational theories if we include coordinatewise versions of the counting operations into the similarity type. We apply these results to the guarded fragment of first-order logic. ?1. Introduction. Relativized algebras of relations are extensively investigated in the literature, cf., e.g., (HMT, HMTAN, Ma82, Mo93, Ne9 1). In general, relativized versions of algebras of relations have a nicer behavior from the computational point of view than the original versions. In this paper, we concentrate on (un)decidability. We show that if we include coordinatewise versions of the counting operations into the similarity type, then the expressive power is strong enough to interpret the tiling problem into the equational theories of relativized relation set algebras and cylindric-relativized set algebras of dimension (at least) three. Thus these equational theories must be undecidable. Finally, in the last section, we apply these results to logic: the corresponding versions of the guarded fragment of first-order logic and of arrow logic are unde- cidable. Acknowledgments: Thanks are due to Hajnal Andreka and an anonymous referee for careful reading and valuable suggestions. Special thanks are due to the members of the Group of Algebraic Logicians in London: Robin Hirsch, Ian Hodkinson and Mark Reynolds. 1.1. Relativization. Relativization of an algebra amounts to intersecting all its elements with a fixed set (usually an element of the algebra or a subset of the unit) and to defining the operations using this set as the unit of the new algebra. It turned out that if we relativize (set) algebras of relations with arbitrary, sym- metric and/or reflexive elements, then we get a class of algebras with nice algebraic properties. For instance, while relation (set) algebras and cylindric (set) algebras of dimension at least three have undecidable equational theories, the sets of equations valid in the above relativizations are decidable. Traditionally, during relativization we keep the original similarity type in the case of relation algebras: Booleans, composition, converse, identity. As a consequence, some operations that are definable in the original version are not available after relativization. An example is the global counting operations once","1999","5","3","2025-12-02","https://university.edu/papers/9c1c0d35-9eff-4385-87b0-535af79b8918.pdf");
INSERT INTO Paper VALUES ("96","LATMAPA: Load-Adaptive Throughput- MAximizing Preamble Allocation for Prioritization in 5G Random Access","Persistently high traffic loads and heterogeneous quality of service (QoS) requirements arising from machine-to-machine communication in wireless 5G systems require effective random access prioritization. 5G systems will likely evolve from mature wireless technologies, e.g., long term evolution (LTE). LTE conducts random access through preamble contention based on slotted Aloha principles. Prior studies have mainly examined random access prioritization for addressing temporary traffic bursts through manipulating the access contention procedure on a given set of preambles, such as adapting the number of permitted transmission attempts and back off windows. We conduct a detailed study of random access prioritization through separating (splitting) the random access preambles into non-overlapping priority classes. Based on the obtained insights, we develop the Load-Adaptive Throughput-MAximizing Preamble Allocation (LATMAPA). LATMAPA automatically adjusts the preamble allocation to the priority classes according to the random access load and a priority tuning parameter. Extensive analytical and simulation evaluations indicate that LATMAPA provides effective QoS differentiation across a wide range of random access loads, which are expected in 5G systems.","2017","2","2","2025-12-02","https://university.edu/papers/601e43e7-518f-445a-81dd-88d063fc3ae5.pdf");
INSERT INTO Paper VALUES ("97","Modellfunktion zur Approximation von Ultraschallkontrastmittelkonzentration zur semi-quantitativen Gewebeperfusionsbestimmung","Institut fur Neuroinformatik, Ruhr-Universit¨ ¨at BochumKai.Ritschel@ini.ruhr-uni-bochum.deKurzfassung. Kontrastmittelultraschall wird zur Diagnose von Tumo-ren der Leber oder Schlaganf¨allen eingesetzt. Die Eignung von Kontrast-mittelultraschall zur Darstellung von Hirntumoren wurde ebenfalls be-reits nachgewiesen. Eine M¨oglichkeit zur Auswertung ist die Approxima-tion von Modellfunktionen, welche insbesondere den Hauptanstieg derKontrastmittelonzentration abbilden.In dieser Arbeit wird ein Modell zur Approximation von Kontrastmittel-verl¨aufen in Ultraschalldaten vorgestellt, welches in der Lage ist zus¨atz-lich zu diesem Hauptanstieg weitere Eigenschaften im Zeitverlauf, wiez.B.einen zweiten Anstieg durch Rezirkulation, abzubilden. Das Modellerreichte eine h¨ohere Genauigkeit der Approximation als die zum Ver-gleich herangezogenen Modelle.","2012","7","1","2025-12-02","https://university.edu/papers/66b0fd9a-0aaf-413f-92ea-f708d83c411d.pdf");
INSERT INTO Paper VALUES ("98","Practical assessment of a combined dispatching policy at a high-mix low-volume ASIC facility","The fabrication of semiconductor devices, even in the area of customer oriented business, is one of the most complex production tasks in the world. A typical wafer production process consists of several hundred steps with numerous resources including equipment and operating staff. A reasonable assignment of each resource at each time for a certain number of wafers is vital for an efficient production process. Several requirements defined by the customers and facility management must be taken into consideration with the objective to find the best trade-off between the different needs. In this paper we describe the practical assessment of a combined dispatching policy presented in Gissrau and Rose (2012). Besides the facility performance influence, also the human factor is taken into consideration. This includes dispatch compliance parameter and staff surveys.","2013","1","3","2025-12-02","https://university.edu/papers/996c6f49-35fd-4c53-9586-3a2326d9d792.pdf");
INSERT INTO Paper VALUES ("99","A Novel Energy Efficient Wireless Sensor MAC Protocol","Wireless sensor networks (WSN) have been widely used in many important areas. Medium access control (MAC) protocols have a significant influence on the function and performance of WSN. In existing protocols such as sensor MAC (SMAC), the sensor nodes reduce energy consumption by introducing an active/sleep duty cycle, which always leads to more control packets. These control packets waste a lot of energy. Other contention-based MAC protocols either cannot solve the idle listening or fail to consider the complexity of the protocol. Based on SMAC, we propose a novel contention-based MAC protocol, which decreases the control packets by modifying the control packets message and canceling time synchronization. The simulation result indicates that the performance of our protocol is much better than that of SMAC protocol in energy consumption.","2008","20","3","2025-12-02","https://university.edu/papers/6fbfebb2-169e-49b6-a751-fa3ee3779c3d.pdf");
INSERT INTO Paper VALUES ("100","Synchronization of Kuramoto Oscillators with Adaptive Couplings","We study the synchronization of Kuramoto oscillators with adaptive coupling in interacting networks. Network dynamics preserves the sum of all incoming pairwise coupling strengths and is designed to adaptively interact with system dynamics. For adaptive couplings, we use two adaptive coupling laws for the pairwise coupling strength. Kuramoto oscillators are assumed to be on the nodes of the networks. We present frameworks that guarantee the emergence of synchronization for various coupling feedback laws. Our results generalize earlier work on the synchronization of Kuramoto oscillators in fixed and symmetric networks.","2016","11","1","2025-12-02","https://university.edu/papers/573c17d9-a0f6-4b96-974e-2aef9c5a3a40.pdf");
INSERT INTO Paper VALUES ("101","End-effector calibration and registration procedure for robot assisted laser material processing: Tailored to the particular needs of short pulsed CO 2 laser bone ablation","Material processing using a laser has become a widely used method for industrial procedures (e.g. laser welding or cutting). Furthermore the medical laser has become an integral part of dermatology, neurosurgery, ENT, esthetic, plastic and general surgery. Recent publications have shown, that the short pulsed CO 2  laser is suitable to ablate bony and cartilage tissue and proposes fundamentally new operative techniques in medicine. The obtainable precision in cutting (in the hundred micrometers range) with a laser system can only be reached using means of computer and robot assisted surgery. We established the first robot assisted laser bone ablation setup, comprising a prototype CO 2  laser system and a six degree of freedom robot. The laser beam is guided through a passive articulated mirror arm to the robots end-effector. The endeffector is composed of a two mirror galvanometric scan head, which deflects the pulsed laser beam onto the tissue. In this paper we present an end-effector calibration and registration method to determine the parameters which are critical in obtaining precise and accurate cutting results.","2009","18","3","2025-12-02","https://university.edu/papers/85943f17-0d87-4a3a-b9b0-7ffac2e00009.pdf");
INSERT INTO Paper VALUES ("102","Discriminative learning can succeed where generative learning fails","Generative algorithms for learning classifiers use training data to separately estimate a probability model for each class. New items are classified by comparing their probabilities under these models. In contrast, discriminative learning algorithms try to find classifiers that perform well on all the training data. We show that there is a learning problem that can be solved by a discriminative learning algorithm, but not by any generative learning algorithm. This statement is formalized using a framework inspired by previous work of Goldberg [P. Goldberg, When can two unsupervised learners achieve PAC separation?, in: Proceedings of the 14th Annual COLT, 2001, pp. 303-319].","2007","5","4","2025-12-02","https://university.edu/papers/b97ccdb2-1298-46ca-99a5-c480ac4707ef.pdf");
INSERT INTO Paper VALUES ("103","A Slope K method for image based localization","In this paper, we present a SIFT based Slope K method which is faster and more robust than the classical SIFT in landmark based localization. First, the slope k value can be used to erase mismatched feature points (outliers) of the two compared images. Second, the y position is determined by the slope k value. Therefore, the Slope K method is able to localizes about twice as more accurate as the classical SIFT. Another advantage of the proposed method is that the number of database images needed to be matched is significantly reduced, compared to the classical SIFT. Therefore the time cost is approximate 4 times less than that of the classical SIFT.","2009","20","3","2025-12-02","https://university.edu/papers/785ea90d-24a9-4bc6-b933-ac4f5f0818e5.pdf");
INSERT INTO Paper VALUES ("104","Utilisation of metadata fields and query expansion in cross-lingual search of user-generated internet video","Recent years have seen significant efforts in the area of Cross Language Information Retrieval (CLIR) for text retrieval. This work initially focused on formally published content, but more recently research has begun to concentrate on CLIR for informal social media content. However, despite the current expansion in online multimedia archives, there has been little work on CLIR for this content. While there has been some limited work on Cross-Language Video Retrieval (CLVR) for professional videos, such as documentaries or TV news broadcasts, there has to date, been no significant investigation of CLVR for the rapidly growing archives of informal user generated (UGC) content. Key differences between such UGC and professionally produced content are the nature and structure of the textual UGC metadata associated with it, as well as the form and quality of the content itself. In this setting, retrieval effectiveness may not only suffer from translation errors common to all CLIR tasks, but also recognition errors associated with the automatic speech recognition (ASR) systems used to transcribe the spoken content of the video and with the informality and inconsistency of the associated user-created metadata for each video. This work proposes and evaluates techniques to improve CLIR effectiveness of such noisy UGC content. Our experimental investigation shows that different sources of evidence, e.g. the content from different fields of the structured metadata, significantly affect CLIR effectiveness. Results from our experiments also show that each metadata field has a varying robustness to query expansion (QE) and hence can have a negative impact on the CLIR effectiveness. Our work proposes a novel adaptive QE technique that predicts the most reliable source for expansion and shows how this technique can be effective for improving CLIR effectiveness for UGC content.","2016","11","1","2025-12-02","https://university.edu/papers/661e63c2-1957-48b6-a18f-637b048b1a24.pdf");
INSERT INTO Paper VALUES ("105","Exploring the hardware/software continuum in a computer engineering capstone design class using FPGA-based programmable logic","The focus of the computer engineering capstone design classes at the University of Alabama in Huntsville, UAH, has been the application of modern design methodology to the development of electronic systems that have both digital hardware and software components. In these classes, it is stressed that efficient digital system design involves the careful consideration of the many possible hardware/software design trade-offs - areas which we feel are the cornerstone of the Computer Engineering discipline. This paper describes the manner in which FPGA-based rapid prototyping techniques have been applied to allow students to empirically explore sets of design alternatives that span the entire hardware/software continuum.","2001","1","3","2025-12-02","https://university.edu/papers/841ee2a8-399c-44ef-8dbf-a8545b039077.pdf");
INSERT INTO Paper VALUES ("106","IBDP: An Industrial Big Data Ingestion and Analysis Platform and Case Studies","The Internet of Things (IoT) brings traditional Internet industry and society with new trends and promising technologies. For industrial information with high amount and renewal speed characteristics, resulting in difficult data ingestion and analysis, this paper presented an Industrial Big Data ingestion and analy-sis Platform (IBDP). In the platform, we integrated HDFS, Spark, Hive, HBase, Flume, Sqoop, OpenStack etc. It works well for industrial data ingestion and analysis. In addition, we report some case studies on industrial big data processing flows respect to different data types.","2015","8","3","2025-12-02","https://university.edu/papers/62bea786-f676-4d68-a0a4-ffd0732a9b08.pdf");
INSERT INTO Paper VALUES ("107","Robotic Home Assistant Care-O-bot® 3 Product Vision and Innovation Platform","The development of a mobile robot to assist people in their home is a long term goal of Fraunhofer IPA. In order to meet this goal, three generations of a robotic home assistant 'Care-O-bot®****** have been developed so far. As a vision of a future household product, Care-O-bot® 3 is equipped with the latest industrial state-of-the art hardware components. It offers all modern multi-media and interaction equipment as well as most advanced sensors and control. It is able to navigate among humans, detect and grasp objects and pass them safely to human users using its tray. Care-O-bot® 3 has been presented to the public on several occasions where it distributed drinks to the visitors of trade fairs and events.","2009","6","3","2025-12-02","https://university.edu/papers/d7a35fef-aa4f-4594-ab7c-80bb149741c0.pdf");
INSERT INTO Paper VALUES ("108","Sorting with Forbidden Intermediates","A wide range of applications, most notably in comparative genomics, involve the computation of a shortest sorting sequence of operations for a given permutation, where the set of allowed operations is fixed beforehand. Such sequences are useful for instance when reconstructing potential scenarios of evolution between species, or when trying to assess their similarity. We revisit those problems by adding a new constraint on the sequences to be computed: they must \emph{avoid} a given set of \emph{forbidden intermediates}, which correspond to species that cannot exist because the mutations that would be involved in their creation are lethal. We initiate this study by focusing on the case where the only mutations that can occur are exchanges of any two elements in the permutations, and give a polynomial time algorithm for solving that problem when the permutation to sort is an involution.","2016","1","1","2025-12-02","https://university.edu/papers/dab0acf6-0db1-4b0a-a1ef-93ebc1905806.pdf");
INSERT INTO Paper VALUES ("109","Designing reconfigurable manufacturing systems using reconfigurable object Petri nets","In reconfigurable manufacturing systems RMSs, the structure of the system can be changed during its execution. This reconfiguration can be triggered by several motivations: a new requirement in the production process, avoiding some problems caused by machines breakdowns, etc. RMSs are characterised by their flexibility which guarantees productivity and efficiency. However, their design is more complicated and needs new techniques and paradigms. The use of high level Petri nets PNs offers the ability to design these systems and to analyse their properties. In this article, the authors apply reconfigurable object nets RONs for the modelling, simulation and analysis of RMSs. Indeed, a formal method is proposed, where the reconfiguration process is specified explicitly as a graph transformation, the simulation is realised using the RON-tool, and the analysis exploits the TINA-tool timed nets analyser tool.","2016","13","3","2025-12-02","https://university.edu/papers/f3eb79f9-f1dc-4828-9187-52a50ffd6737.pdf");
INSERT INTO Paper VALUES ("110","Joint Estimation of Topics and Hashtag Relevance in Cross-Lingual Tweets","Twitter is a widely used platform for sharing news articles. An emerging trend in multi-lingual communities is to share non-English news articles using English tweets in order to spread the news to a wider audience. In general, the choice of relevant hashtags for such tweets depends on the topic of the non-English news article. In this paper, we address the problem of automatically detecting the relevance of the hashtags of such tweets. More specifically, we propose a generative model to jointly model the topics within an English tweet and those within the non-English news article shared from it to predict the relevance of the hashtags of the tweet. For conducting experiments, we compiled a collection of English tweets that share news articles in Bengali (a South Asian language). Our experiments on this dataset demonstrate that this joint estimation based approach using the topics from both the non-English news articles and the tweets proves to be more effective for relevance estimation than that of only using the topics of a tweet itself.","2016","20","2","2025-12-02","https://university.edu/papers/9216faf7-310a-4d64-b6f2-37e6c8ad13f2.pdf");
INSERT INTO Paper VALUES ("111","Few-exemplar Information Extraction for Business Documents","The automatic extraction of relevant information from business documents (sender, recipient, date, etc.) is a valuable task in the application domain of document management and archiving. Although current scientific and commercial self-learning solutions for document classification and extraction work pretty well, they still require a high effort of on-site configuration done by domain experts and administrators. Small office/home office (SOHO) users and private individuals do often not benefit from such systems. A low extraction effi- ciency especially in the starting period due to a small number of initially available example documents and a high effort to annotate new documents, drastically lowers their acceptance to use a self-learning information extraction system. Therefore we present a solution for information extraction that fits the requirements of these users. It adopts the idea of one-shot learning from computer vision to the domain of business document processing and requires only a minimal number of training to reach competitive extraction efficiency. Our evaluation on a document set of 12,500 documents following 399 different layouts/templates shows extraction results of 88% F1 score on 10 commonly used fields like document type, sender, recipient, and date. We already reach an F1 score of 78% with only one document of each template in the training set.","2014","15","2","2025-12-02","https://university.edu/papers/7480dd74-33c6-417d-a6ba-59dfc0367922.pdf");
INSERT INTO Paper VALUES ("112","EEG recordings as a source for the detection of IRBD.","The purpose of this pilot study was to develop a supportive algorithm for the detection of idiopathic Rapid Eye-Movement (REM) sleep Behaviour Disorder (iRBD) from EEG recordings. iRBD is defined as REM sleep without atonia with no current sign of neurodegenerative disease, and is one of the earliest known biomarkers of Parkinson's Disease (PD). It is currently diagnosed by polysomnography (PSG), primarily based on EMG recordings during REM sleep. The algorithm was developed using data collected from 42 control subjects and 34 iRBD subjects. A feature was developed to represent high amplitude contents of the EEG and a semi-automatic signal reduction method was introduced. The reduced feature set was used for a subject-based classification. With a subject specific re-scaling of the feature set and the use of an outlier detection classifier the algorithm reached an accuracy of 0.78. The result shows that EEG recordings contain valid information for a supportive algorithm for the detection of iRBD. Further investigation could lead to promising application of EEG recordings as a supportive source for the detection of iRBD.","2015","11","3","2025-12-02","https://university.edu/papers/04d150bb-165d-495a-9193-f03d5c1080dc.pdf");
INSERT INTO Paper VALUES ("113","Performance of Wald-Type Estimator for Parametric Component in Partial Linear Regression with a Mixture of Berkson and Classical Error Models","This article discusses a consistent and almost unbiased estimation approach in partial linear regression for parameters of interest when the regressors are contaminated with a mixture of Berkson and classical errors. Advantages of the presented procedure are: (1) random errors and observations are not necessarily to be parametric settings; (2) there is no need to use additional sample information, and to consider the estimation of nuisance parameters. We will examine the performance of our presented estimate in a variety of numerical examples through Monte Carlo simulation. The proposed approach is also illustrated in the analysis of an air pollution data.","2015","7","4","2025-12-02","https://university.edu/papers/e3a3237a-c3e9-4dca-bbad-09d1468d353f.pdf");
INSERT INTO Paper VALUES ("114","Integrating distributed object transactions with wide-area content-based publish/subscribe systems","Transactions are necessary for many distributed applications to deliver reasonable results. Typically, said transaction engines enhance system dependability by providing atomicity, consistency, isolation, and durability. Yet, emerging paradigms in distributed systems seem to challenge these traditional concepts. This paper presents early results in integrating distributed object transactions with content-based publish/subscribe systems. Essentially, the paper illustrates a novel and generic integration framework that 1) supports application-dependent message failure models and 2) exhibits a full messaging transaction mechanism. We discuss integration challenges, analyze middleware requirements, and position our attempt among existing approaches.","2005","5","4","2025-12-02","https://university.edu/papers/9c171fc8-2176-4aae-bc3a-fc4c16219095.pdf");
INSERT INTO Paper VALUES ("115","Computer support system for aneurysm treatment","An important medical problem in the noninvasive treatment of brain aneurysms demands special attention. The main reason is that, in many cases, it is necessary to have direct information about the size, shape and exact location of the aneurysm. To provide a medical specialist with such information, a virtual aneurysm system has been created. Problems with its realization and efficiency are discussed in this paper. A novel approach to the simulation and visualization of biomedical systems is suggested, so as to achieve higher efficiency. This approach is called 'branching simulation'.","2000","8","4","2025-12-02","https://university.edu/papers/7464ad80-52a4-4505-b198-c98103978a9b.pdf");
INSERT INTO Paper VALUES ("116","Mining Frequent Bipartite Episode from Event Sequences","In this paper, first we introduce a  bipartite episode  of the form  A  *** B  for two sets  A  and  B  of events, which means that every event of  A  is followed by every event of  B  . Then, we present an algorithm that finds all frequent bipartite episodes from an input sequence without duplication in  O  (|Σ| · N  ) time per an episode and in  O  (|Σ|2  n  ) space, where Σ is an alphabet,  N  is total input size of $\mathcal S$, and  n  is the length of  S  . Finally, we give experimental results on artificial and real sequences to evaluate the efficiency of the algorithm.","2009","12","2","2025-12-02","https://university.edu/papers/ea845cd5-dff7-4f89-b6a7-29f5a9cb699e.pdf");
INSERT INTO Paper VALUES ("117","A forward-chaining multiple-context reasoner and its application to logic design","The authors present an extended production system architecture which can deal with forward reasoning in multiple contexts. The proposed architecture consists of a compiler of clauses and defaults into a Rete-like network, a Rete-based inference engine, and an assumption-based truth maintenance system (ATMS). The inference engine gives intermediate justifications to the ATMS and stores intermediate dependent assumptions of two-input nodes in the Rete-like network, allowing faster multiple-context reasoning. By means of this method, the multiple-context reasoner called APRICOT/0 has been implemented. An experiment under the logic design knowledge base shows that APRICOT/0 is about six to ten times faster than a system with a simple combination of a production system and the ATMS. >","1990","16","1","2025-12-02","https://university.edu/papers/7d3e0f75-76e4-43ed-a035-8d9ad16c1ed5.pdf");
INSERT INTO Paper VALUES ("118","Spatial properties of pulsed-Doppler current profiling systems","The spatial response and sampling properties of a ship-mounted, four-beam Doppler current profiler are considered. We obtain expressions for the effect of beamwidth, beam separation, and block averaging on the system response. We observe that spatial aliasing may occur above a certain depth, and that pulse width reduction cannot reduce vertical resolution beyond a limit imposed by system geometry.","1984","16","2","2025-12-02","https://university.edu/papers/be224743-4352-4480-9123-73beb6a3288f.pdf");
INSERT INTO Paper VALUES ("119","PHC: a rapid parallel hierarchical cubing algorithm on high dimensional OLAP","Data cube has been playing an essential role in OLAP (online analytical processing). The pre-computation of data cubes is critical for improving the response time of OLAP systems. However, as the size of data cube grows, the time it takes to perform this pre-computation becomes a significant performance bottleneck. In a high dimensional OLAP, it might not be practical to build all these cuboids and their indices. In this paper, we propose a parallel hierarchical cubing algorithm, based on an extension of the previous minimal cubing approach. The algorithm has two components: decomposition of the cube space based on multiple dimension attributes, and an efficient OLAP query engine based on a prefix bitmap encoding of the indices. This method partitions the high dimensional data cube into low dimensional cube segments. Such an approach permits a significant reduction of CPU and I/O overhead for many queries by restricting the number of cube segments to be processed for both the fact table and bitmap indices. The proposed data allocation and processing model support parallel I/O and parallel processing, as well as load balancing for disks and processors. Experimental results show that the proposed parallel hierarchical cubing method is significantly more efficient than other existing cubing methods.","2007","15","2","2025-12-02","https://university.edu/papers/88bd9b9d-5888-4a51-b206-6dc8a98aaf7f.pdf");
INSERT INTO Paper VALUES ("120","A Fast and Flexible Sorting Algorithm with CUDA","In this paper, we propose a fast and flexible sorting algorithm with CUDA. The proposed algorithm is much more practical than the previous GPU-based sorting algorithms, as it is able to handle the sorting of elements represented by integers, floats and structures. Meanwhile, our algorithm is optimized for the modern GPU architecture to obtain high performance. We use different strategies for sorting disorderly list and nearly-sorted list to make it adaptive. Extensive experiments demon- strate our algorithm has higher performance than previous GPU-based sorting algorithms and can support real-time applications.","2009","6","2","2025-12-02","https://university.edu/papers/99368471-046e-4bac-a760-e46b5178bd95.pdf");
INSERT INTO Paper VALUES ("121","Design and implementation of an unmanned tail-sitter","We present the design and implementation of a small Vertical-Take-Off-and-Landing (VTOL) aircraft. The vehicle requires minimal additional components to achieve the hover capability and is thus very efficient in forward flight. We improve over the state of the art by using a single controller in all flight modes without using blending between hover condition and fixed wing controllers or gain scheduling. We present a compact airflow estimation model for VTOL airframes which rely on the slipstream across control surfaces for hover attitude control. Furthermore we show attitude and position control results in simulation. Finally we show outdoor flight experiments validating our simulation results.","2015","19","4","2025-12-02","https://university.edu/papers/ba0ec186-7873-4ad4-baca-2fc2487b363b.pdf");
INSERT INTO Paper VALUES ("122","Non-Bayesian social learning☆","We develop a dynamic model of opinion formation in social networks when the information required for learning a parameter may not be at the disposal of any single agent. Individuals engage in communication with their neighbors in order to learn from their experiences. However, instead of incorporating the views of their neighbors in a fully Bayesian manner, agents use a simple updating rule which linearly combines their personal experience and the views of their neighbors. We show that, as long as individuals take their personal signals into account in a Bayesian way, repeated interactions lead them to successfully aggregate information and learn the true parameter. This result holds in spite of the apparent naivete of agentsʼ updating rule, the agentsʼ need for information from sources the existence of which they may not be aware of, worst prior views, and the assumption that no agent can tell whether her own views or those of her neighbors are more accurate.","2012","6","3","2025-12-02","https://university.edu/papers/f7bdbe54-2c17-4fa5-9577-976e6546e887.pdf");
INSERT INTO Paper VALUES ("123","On Quantum Capacity of Compound Channels","In this paper we address the issue of universal or robust communication over quantum channels. Specifically, we consider a memoryless communication scenario with channel uncertainty which is an analog of the compound channel in classical information theory. We determine the quantum capacity of finite compound channels and arbitrary compound channels with an informed decoder. Our approach in the finite case is based on the observation that perfect channel knowledge at the decoder does not increase the capacity of finite quantum compound channels. As a consequence, we obtain a coding theorem for finite quantum averaged channels, the simplest class of channels with long-term memory. The extension of these results to quantum compound channels with uninformed encoder and decoder and infinitely many constituents remains an open problem.","2008","1","3","2025-12-02","https://university.edu/papers/a9587bfe-9ab4-4355-8b85-6d23eab242e5.pdf");
INSERT INTO Paper VALUES ("124","Design, Implementation and Evaluation of Virtual Resource Description and Clustering Framework","This paper presents an approach to speed up and enhance matching of virtual network requests to available resources in virtual network provisioning frameworks. The method consists of introducing a weight or score expressing the importance of the resources, their attributes and the values taken by these attributes. The scores are obtained through statistical analysis of the requests for virtual network resources. Previous methods treat resources equally and experience longer delays and lower efficiency during the matching process. They were originally not designed for virtual network provisioning and the proposed method in this work aims at addressing their weaknesses in scalability, in resource representation and incremental updates. To highlight this new method, a functional comparison with these previous techniques is proposed. Evaluation results of the score based clustering and matching algorithm show improved scalability and performance in clustering efficiency and matching delays for virtual network provisioning.","2011","6","2","2025-12-02","https://university.edu/papers/f90f987d-dc27-4c5b-93d5-67f175247211.pdf");
INSERT INTO Paper VALUES ("125","Polar codes for discrete alphabets","An open problem in polarization theory is whether all memoryless channels and sources with composite (that is, non-prime) alphabet sizes can be polarized with deterministic, Arikan-like methods. This paper answers the question in the affirmative by giving a method to polarize all discrete memoryless channels and sources. The method yields codes that retain the low encoding and decoding complexity of binary polar codes.","2012","13","2","2025-12-02","https://university.edu/papers/ddf2b728-6762-4bcb-a46b-dab65585b679.pdf");
INSERT INTO Paper VALUES ("126","CONVEX GAMES VERSUS CLAN GAMES","In this paper we provide characterizations of convex games and total clan games by using properties of their corresponding marginal games. We show that a 'dualize and restrict' procedure transforms total clan games with zero worth for the clan into monotonic convex games. Furthermore, each monotonic convex game generates a total clan game with zero worth for the clan by a 'dualize and extend' procedure. These procedures are also useful for relating core elements and elements of the Weber set of the corresponding games.","2008","3","2","2025-12-02","https://university.edu/papers/a7e634cb-b986-4260-9e5c-4a2f3b640e06.pdf");
INSERT INTO Paper VALUES ("127","Automated target selection for DrivenShape","DrivenShape is a data-driven deformation that uses pre-computed data (a.k.a. targets) to approximate the effects of a computationally expensive cloth simulation [Kim and Vendrovsky 2008]. Rather than computing a true, accurate solution, DrivenShape produces a quick approximation that satisfies an acceptable margin of error, where error is defined as a difference in appearance or shape.","2010","3","4","2025-12-02","https://university.edu/papers/9b7fe529-0b00-43b8-9d84-93564915556b.pdf");
INSERT INTO Paper VALUES ("128","An image data hiding scheme using fractional logistic map and fractional integrator","In this paper, an image data hiding scheme using fractional logistic map and fractional integrator is presented. First, the discrete fractional logistic map (FLM) is implemented by using fractional integrator and its chaos is used to generate the number square. Then, the embedding and extraction methods of a digital image data hiding scheme is developed by using number square. The order of fractional logistic map can be used as a secret key for embedding and extraction. Finally, several examples are demonstrated to show the effectiveness of the proposed image hiding method.","2015","8","4","2025-12-02","https://university.edu/papers/fac91825-24a4-496e-bf2f-ef7de78a9cc5.pdf");
INSERT INTO Paper VALUES ("129","Decentralized hash tables for mobile robot teams solving intra-logistics tasks","Although a remarkably high degree of automation has been reached in production and intra-logistics nowadays, human labor is still used for transportation using handcarts and forklifts. High labor cost and risk of injury are the undesirable consequences. Alternative approaches in automated warehouses are fixed installed conveyors installed either overhead or floor-based. The drawback of such solutions is the lack of flexibility, which is necessary when the production lines of the company change. Then, such an installation has to be re-built.#R##N##R##N#In this paper, we propose a novel approach of decentralized teams of autonomous robots performing intra-logistics tasks using distributed algorithms. Centralized solutions suffer from limited scalability and have a single point of failure. The task is to transport material between stations keeping the communication network structure intact and most importantly, to facilitate a fair distribution of robots among loading stations. Our approach is motivated by strategies from peer-to-peer-networks and mobile ad-hoc networks. In particular we use an adapted version of distributed heterogeneous hash tables (DHHT) for distributing the tasks and localized communication. Experimental results presented in this paper show that our method reaches a fair distribution of robots over loading stations.","2010","13","1","2025-12-02","https://university.edu/papers/6dd9599f-0985-4f03-a1d4-af65ebbe6232.pdf");
INSERT INTO Paper VALUES ("130","Distributed Multiscale Computations Using the MAPPER Framework","We present a global overview of the methodology developed within the MAPPER European project to design, implement and run a multiscale simulation on a distributed supercomputing infrastructure. Our goal is to highlight the main steps required when developing an application within this framework. More specifically, we illustrate the proposed approach in the case of hydrology applications. A performance model describing the execution time of the application as a function of its spatial resolution and the hardware performance is proposed. It shows that Distributed Multiscal Computation is beneficial for large scale problems.","2013","17","2","2025-12-02","https://university.edu/papers/9d1f07fd-a29a-4ff1-9fad-783a82577351.pdf");
INSERT INTO Paper VALUES ("131","A novel method for digital image steganography based on a new three-dimensional chaotic map","This paper, presents a novel chaos-based image steganography algorithm. Because of efficient property of chaos based security systems besides steganography applicability in providing secure communication, chaos based steganography algorithms served as a hot topic in recent researches. The proposed scheme possess novelties and advantageous such as: 1) Introducing a novel 3-dimensional chaotic map (LCA map) with strong chaotic characteristics and maximum Lyapunov exponent 20.58, which is used for generating three chaotic sequences, each of them represents the number of row, column, and colour component, respectively. 2) Utilizing random selection procedure for selecting subsequences with length of 2L, which L is the length of secret message 3) Specifying L pairs of triples host positions for embedding LSBs and MSBs of secret message by using three high level chaotic maps. 4) Entering some parameters dependent on elementary initial values, host image, and secret message features as a key point for adding additional layer of security alongside providing high sensitivity. 5) Providing high capacity for embedding secret message, which is equal to 50 % of whole image capacity (M × N × 12). The proposed method could be applied in different criterion such as, confidential communication and data storing, protection of data alteration, and etc. Our experimental results guarantees that our scheme is not only robust against differential attacks, but also has promising results such as highly sensitive keys, Quality index, PSNR, MSE, and hiding capacity as shown in statistical security analysis.","2016","1","1","2025-12-02","https://university.edu/papers/d105d5a8-7a2d-4571-9bee-89d5b72b669d.pdf");
INSERT INTO Paper VALUES ("132","Two-Dimensional Structured-Compressed-Sensing-Based NBI Cancelation Exploiting Spatial and Temporal Correlations in MIMO Systems","Narrowband interference (NBI) caused by narrowband licensed or unlicensed services is a major concern that constrains the performance of multiple-input multiple-output (MIMO) systems. In this paper, the new and powerful signal processing theory of structured compressed sensing (SCS) is introduced to solve this problem. Exploiting the 2-D spatial and temporal correlations of NBI in MIMO systems, a novel NBI recovery method, i.e., the spatial multiple differential measuring method, is proposed in the framework of 2-D SCS. At each receive antenna, a differential measurement vector is acquired from the repeated training sequences in the IEEE 802.11 series preamble. Then, multiple measurement vectors from all receive antennas are utilized to recover and cancel NBI using the proposed SCS greedy algorithm of structured sparsity adaptive matching pursuit. Simulation results indicate that the proposed scheme outperforms the conventional schemes over the wireless MIMO channel.","2016","13","4","2025-12-02","https://university.edu/papers/9643bf50-5795-47be-beba-de1b1f3de1f4.pdf");
INSERT INTO Paper VALUES ("133","Inter-operator spectrum sharing from a game theoretical perspective","We address the problem of spectrum sharing where competitive operators coexist in the same frequency band. First, we model this problem as a strategic non-cooperative game where operators simultaneously share the spectrum according to the Nash Equilibrium (NE). Given a set of channel realizations, several Nash equilibria exist which renders the outcome of the game unpredictable. Then, in a cognitive context with the presence of primary and secondary operators, the inter-operator spectrum sharing problem is reformulated as a Stackelberg game using hierarchy where the primary operator is the leader. The Stackelberg Equilibrium (SE) is reached where the best response of the secondary operator is taken into account upon maximizing the primary operator's utility function. Moreover, an extension to the multiple operators spectrum sharing problem is given. It is shown that the Stackelberg approach yields better payoffs for operators compared to the classical water-filling approach. Finally, we assess the goodness of the proposed distributed approach by comparing its performance to the centralized approach.","2009","1","1","2025-12-02","https://university.edu/papers/a2d27907-0c8f-4871-9222-6cfe9790f00e.pdf");
INSERT INTO Paper VALUES ("134","Evaluating explicitly context-sensitive program slicing","One of the important issues in constructing interprocedural program slices is maintaining  context-sensitivity  or preserving calling context when a procedure is called at multiple call sites. Though a number of context-sensitive techniques have been presented in the last decade, the following important questions remain unanswered: 1) What is the level of precision lost if context-sensitivity is not maintained ? 2) What are the additional costs for achieving context-sensitivity?  In this paper, we evaluate a PDG based explicitly context-sensitive interprocedural program slicing technique for accuracy and efficiency. We compare this technique against a context-insensitive technique using a program slicing framework we have developed for Java programs for which only the byte-code sequences are available.  Our results show that the context-sensitive technique, in spite of its worst case exponential complexity, can be very efficient in practice. The execution time for our set of benchmarks is, on the average, only twice as much as the execution time for the context-insensitive technique. The results on the accuracy for the context-insensitive technique are mixed. For  53% of the 2464 slicing criteria used in our experiments, the context-insensitive technique does not loose accuracy. However, in some cases, it can also lead to slices with 35 times more vertices. On the average, the slices constructed from the context-insensitive technique are twice as large as the one from the context-sensitive technique.","2001","1","1","2025-12-02","https://university.edu/papers/919b0c8d-58df-417c-bac3-b3bfd99e1d93.pdf");
INSERT INTO Paper VALUES ("135","RSVP keyboard: An EEG based typing interface","Humans need communication. The desire to communicate remains one of the primary issues for people with locked-in syndrome (LIS). While many assistive and augmentative communication systems that use various physiological signals are available commercially, the need is not satisfactorily met. Brain interfaces, in particular, those that utilize event related potentials (ERP) in electroencephalography (EEG) to detect the intent of a person noninvasively, are emerging as a promising communication interface to meet this need where existing options are insufficient. Existing brain interfaces for typing use many repetitions of the visual stimuli in order to increase accuracy at the cost of speed. However, speed is also crucial and is an integral portion of peer-to-peer communication; a message that is not delivered timely often looses its importance. Consequently, we utilize rapid serial visual presentation (RSVP) in conjunction with language models in order to assist letter selection during the brain-typing process with the final goal of developing a system that achieves high accuracy and speed simultaneously. This paper presents initial results from the RSVP Keyboard system that is under development. These initial results on healthy and locked-in subjects show that single-trial or few-trial accurate letter selection may be possible with the RSVP Keyboard paradigm.","2012","5","2","2025-12-02","https://university.edu/papers/b66c12cc-962e-4f83-a3dc-8a9c3f60a83d.pdf");
INSERT INTO Paper VALUES ("136","Complex shadow-boundary segmentation using the entry-exit method","Shadows provide information that allows inferences to be made about the three-dimensional nature of objects. Essential to those inferences is the ability to identify segments of the shadow boundary that correspond to various portions of the object that has cast the shadow. Entry-exit vertices, that are extremes of the boundary, and tangent to the projection of the light beams, can be identified as junctions of specific segments of the shadow boundary. The authors restrict the analysis to smooth convex bodies, and prove that points of discontinuity of the derivative on the shadow boundary form another set of vertices. These two types of junctions are discussed extensively, and combined into a labeling scheme that can segment the boundary into logically consistent pieces. The authors discuss the possible ambiguities that may arise during the labeling process due to occlusion of one object by another, and show that there is no ambiguity in the cases of occlusion of shadows and of shadows that fall on other objects. >","1988","3","3","2025-12-02","https://university.edu/papers/e4fa6b6c-f3ed-4caf-bf04-86a106e0ce02.pdf");
INSERT INTO Paper VALUES ("137","Price Competition on the Market of Counterfeiting Software","In this paper, the market of software products is considered. Regularly this market is suffering from existence of counterfeit or pirate products which causes problems and challenges for original software developers. Taking this fact into account the paper is trying to solve the problem of price competition on this market. The software company set the price and the quality of the software product while the counterfeit or pirate company suggests the consumers the product of the lower quality. First the general model is analyzed and price equilibrium is defined. Second, the monopoly case is considered separately and optimal software price is defined. Finally, it is supposed that there are two companies that produce original software on the market who compete and differentiate in product quality, and there are two pirate companies who produce the same type of software. The duopoly case is analyzed and equilibrium prices for competing companies are obtained in the explicit form.","2016","5","1","2025-12-02","https://university.edu/papers/f89c1af8-e188-40c6-bb69-a673d50195e0.pdf");
INSERT INTO Paper VALUES ("138","Optimal light trail design in WDM optical networks","The enabling technology for supporting IP centric traffic over optical transport networks evolves as the amount of traffic grows. In this paper, we first review a recently proposed concept called light trails. Light trails can enable high speed provisioning, accommodate multigranularity traffic, support high data rates and offer a good candidate for carrying IP traffic over optical networks. Next, we focus on light trail design. We propose a two-step approach for solving the light trail design problem. The first step is called traffic matrix preprocessing, it divides single long hop paths into several shorter paths that satisfy the hop-length constraint. In the second step, the light trail design problem is formulated as an integer linear programming (ILP) optimization problem. The results obtained from our experiments show that the resulting light trail network has high wavelength utilization.","2004","1","1","2025-12-02","https://university.edu/papers/ee221c7b-3980-4d3d-9181-01bdbaf2ece7.pdf");
INSERT INTO Paper VALUES ("139","Approximation Algorithms for a Link Scheduling Problem in Wireless Relay Networks with QoS Guarantee","The emerging wireless relay networks (WRNs) are expected to provide significant improvement on throughput and extension of coverage area for next-generation wireless systems. We study an optimization problem for multihop link scheduling with bandwidth and delay guarantees over WRNs. Our optimization problem is investigated under a more general interference model with a generic objective. The objective can be based on various kinds of performance indexes (e.g., throughput, fairness, and capacity), which can be determined by service providers. Through our theoretical analysis, the intractability and inapproximability of the optimization problem are shown. Due to the intractable computational complexity, we present efficient algorithms to provide a reasonable small approximation factor against any optimal solution even for a worst-case input. Furthermore, some experimental results indicate that our algorithms yield near-optimal performance in the average case.","2010","18","3","2025-12-02","https://university.edu/papers/af4123e3-e478-4bf2-b678-eb65d34caf76.pdf");
INSERT INTO Paper VALUES ("140","ESTIMATING CURVATURE ON TRIANGULAR MESHES","This paper takes a systematic look at methods for estimating the curvature of surfaces represented by triangular meshes. We have developed a suite of test cases for assessing both the detailed behavior of these methods, and the error statistics that occur for samples from a general mesh. Detailed behavior is represented by the sensitivity of curvature calculation methods to noise, mesh resolution, and mesh regularity factors. Statistical analysis breaks out the effects of valence, triangle shape, and curvature sign. These tests are applied to existing discrete curvature approximation techniques and common surface fitting methods. We provide a summary of existing curvature estimation methods, and also look at alternatives to the standard parameterization techniques. The results illustrate the impact of noise and mesh related issues on the accuracy of these methods and provide guidance in choosing an appropriate method for applications requiring curvature estimates.","2006","3","2","2025-12-02","https://university.edu/papers/c81c5a4e-9e92-4df0-95b9-c4aca7307ac4.pdf");
INSERT INTO Paper VALUES ("141","Lessons learned applying UML in embedded software systems designs","This paper provides a series of lessons learned with respect to designing embedded software systems using the object-oriented paradigm and specifically with the application of the Unified Modeling Language (UML). The experiences captured in this paper are based on the author's observations across multiple embedded software systems and pertain to both the development processes and the application of UML models.","2004","5","4","2025-12-02","https://university.edu/papers/6934e625-4ba1-498d-82ee-3d2c14424a51.pdf");
INSERT INTO Paper VALUES ("142","A load-adapative cloud resource scheduling model based on ant colony algorithm","Dynamic scheduling cloud resources according to the change of the load are key to improve cloud computing on-demand service capabilities. This paper proposes a load-adaptive cloud resource scheduling model based on ant colony algorithm. By real-time monitoring virtual machine of performance parameters, once judging overload, it schedules fast cloud resources using ant colony algorithm to bear some load on the load-free node. So that it can meet changing load requirements. By analyzing an example result, the model can meet the goals and requirements of self-adaptive cloud resources scheduling and improve the efficiency of the resource utilization.","2011","19","4","2025-12-02","https://university.edu/papers/87744a2d-1e4c-48b1-ae6b-478a50037403.pdf");
INSERT INTO Paper VALUES ("143","On-Demand Routing Algorithm with Mobility Prediction in the Mobile Ad-hoc Networks","In this paper, we propose an ad-hoc on-demand distance vector routing algorithm for mobile ad-hoc networks taking into account node mobility. Changeable topology of such mobile ad-hoc networks provokes overhead messages in order to search available routes and maintain found routes. The overhead messages impede data delivery from sources to destination and deteriorate network performance. To overcome such a challenge, our proposed algorithm estimates link duration based neighboring node mobility and chooses the most reliable route. The proposed algorithm also applies the estimate for route maintenance to lessen the number of overhead messages. Via simulations, the proposed algorithm is verified in various mobile environments. In the low mobility environment, by reducing route maintenance messages, the proposed algorithm significantly improves network performance such as packet data rate and end-to-end delay. In the high mobility environment, the reduction of route discovery message enhances network performance since the proposed algorithm provides more reliable routes.","2016","6","3","2025-12-02","https://university.edu/papers/d381fcb2-61d8-4c0d-abb0-e194d75fc008.pdf");
INSERT INTO Paper VALUES ("144","Debugging memory issues in Embedded Linux: A case study","Debugging denotes the process of detecting root causes of unexpected observable behaviors in programs, such as a program crash, an unexpected output value being produced or an assertion violation. Debugging of program errors is a difficult task and often takes a significant amount of time in the software development life cycle. In the context of embedded software, the probability of bugs is quite high. Due to requirements of low code size and less resource consumption, embedded softwares typically do away with a lot of sanity checks during development time. This leads to high chance of errors being uncovered in the production code at run time. In this paper we propose a methodology for debugging errors in BusyBox, a de-facto standard for Linux in embedded systems. Our methodology works on top of Valgrind, a popular memory error detector and Daikon, an invariant analyzer. We have experimented with two published errors in BusyBox and report our findings in this paper.","2011","11","4","2025-12-02","https://university.edu/papers/fb863ebb-cdef-458a-8e3c-ec63f954f691.pdf");
INSERT INTO Paper VALUES ("145","Heterogeneity, school-effects and the North/South achievement gap in Italian secondary education: evidence from a three-level mixed model","Abstract With the aim of assessing the extent of the differences in the context of Italian educational system, the paper applies multilevel modeling to a new administrative dataset, containing detailed information for more than 500,000 students at grade 6 in the year 2011/2012, provided by the Italian Institute for the Evaluation of Educational System. Data are grouped by classes, schools and geographical areas. Different models for each area are fitted, in order to properly address the heteroscedasticity of the phenomenon. The results show that it is possible to estimate statistically significant “school effects”, i.e., the positive/negative association of attending a specific school and the student’s test score, after a case-mix adjustment. Therefore, the paper’s most important message is that school effects are different in terms of magnitude and types in the three geographical macro areas (Northern, Central and Southern Italy) and are dependent on specific students’ and schools’ characteristics.","2017","5","2","2025-12-02","https://university.edu/papers/ae1c3545-ec58-49d3-9c86-0f0cb7e84894.pdf");
INSERT INTO Paper VALUES ("146","Decentralized Multi-Level Duty Cycling in Sensor Networks","Prolonging network lifetime while efficiently detecting and reporting events are arguably the most important objectives of wireless sensor networks (WSNs). Different WSN protocols aim to improve such measures, yet partially focus on certain aspects (eg. reliability and time latency) and sacrifice others (eg. power efficiency) in application specific approaches. We present DMULD (decentralized multi-level duty cycling), a cross-layer design paradigm aiming at raising performance measures of general WSNs. It integrates tailored multi-level sleep states having varying levels of performance (hence energy consumption) with novel sensing, medium access control (MAC) and routing protocols. Nodes carry on tasks in a decentralized manner with efficient load balancing. DMULD is a dynamic model which is adaptable to application specific requirements, through fine tuning its parameters. DMULD was thoroughly simulated, examining the effects of varying its parameters on network lifetime and efficiency. It achieved over double the lifetime of multi-hop CSMA/CA.","2008","2","3","2025-12-02","https://university.edu/papers/5c20d92b-fde6-4735-b229-234d19053d43.pdf");
INSERT INTO Paper VALUES ("147","Region Queries without Segmentation for Image Retrieval by Content","Content-based image retrieval is today ubiquitous in computer vision. Most systems use the query-by-example approach, performing queries such as 'show me more images that look like this one'. Most often, the user is more specifically interested in specifying an object (or region) and in retrieving more images with similar objects (or regions), as opposed to similar images as a whole. This paper deals with that problem, called region querying. We suggest a method that uses a multiresolution quadtree representation of the images and thus avoids the hard problem of region segmentation. Several experimental results are presented in real-world databases.","1999","18","1","2025-12-02","https://university.edu/papers/e9a68c18-501a-45cf-afc4-57e0a9060f7b.pdf");
INSERT INTO Paper VALUES ("148","High accuracy numerical methods for the Gardner-Ostrovsky equation","The Gardner–Ostrovsky equation, also known as the extended rotation-modified Korteweg–de Vries (KdV) equation, describes weakly nonlinear internal oceanic waves under the influence of Earth’ rotation. High accuracy numerical methods are needed to follow with precision the long time evolution of the solutions of this equation, with the additional difficulty that the numerical methods have to conserve very accurately several invariants of the solutions, including the mass and the energy of the waves. Finite-difference methods traditionally used for the solution of the KdV equation fails to preserve accurately these invariants for large times. In this paper we show that this difficulty can be overcome by using a high accuracy finite-difference (HAFD) numerical method. We present a strong-stability-preserving finite-difference scheme and compare its performance, using some relevant examples, with those of two recently published numerical methods for solving this kind of equation: a simpler second order finite-difference method and a pseudospectral numerical scheme that enforces the conservation of energy. The numerical comparison shows that the three methods have similar accuracy for short times, but the simpler finite-difference scheme is less accurate in preserving the three invariants, affecting the numerical accuracy of the solution as time goes on. On the contrary, the HAFD method presented here preserves the invariants with even better accuracy than the pseudospectral scheme, but with a much lower computational cost. In addition, the numerical implementation of the HAFD method is as easy as that of the simpler finite-difference method, being both much simpler than the intricate energy conservation pseudospectral scheme. These advantages makes the HAFD method presented here very appropriate for solving numerically this type of equations, particularly for studying long time wave propagation.","2014","1","1","2025-12-02","https://university.edu/papers/b6c04bc6-2d6e-48a4-b27d-5d3d556c447f.pdf");
INSERT INTO Paper VALUES ("149","Monte Carlo for large credit portfolios with potentially high correlations","In this paper we develop efficient Monte Carlo methods for large credit portfolios. We assume the default indicators admit a Gaussian copula. Therefore, we are able to embed the default correlations into a continuous Gaussian random field, which is capable of incorporating an infinite size portfolio and potentially highly correlated defaults. We are particularly interested in estimating the expectations, such as the expected number of defaults given that there is at least one default and the expected loss given at least one default. All these quantities turn out to be closely related to the geometric structure of the random field. We will heavily employ random field techniques to construct importance sampling based estimators and provide rigorous efficiency analysis.","2010","4","3","2025-12-02","https://university.edu/papers/a412e72a-e27a-4006-854c-418f33af72f9.pdf");
INSERT INTO Paper VALUES ("150","Coordinating the ordinary: social information uses of Facebook by adults","Social network sites (SNSs) are bundles of information and communication tools that can be used to support collaboration, among other uses. In a qualitative study of adult Facebook users (N=18), we found that some users did turn to the site for information uses that are embedded in social activities, including organizing events, establishing online groups, and seeking information. We also discuss the features of Facebook that respondents discussed as being important to these uses.","2011","4","4","2025-12-02","https://university.edu/papers/4daa56ae-a73d-4aa7-a0d6-beeb629d950a.pdf");
INSERT INTO Paper VALUES ("151","Semiglobal Leader-Following consensus for generalized homogenous agents","In the present paper, the Leader-Following consensus problem is investigated and sufficient conditions are given for the solvability of the problem, assuming that the agents are described by a nonlinear dynamics incrementally homogeneous in the upper bound.","2015","5","1","2025-12-02","https://university.edu/papers/c12b05df-8a8a-44c2-a6f7-b630a91425ff.pdf");
INSERT INTO Paper VALUES ("152","A Novel Approach Using Time–Frequency Analysis of Pulse-Oximeter Data to Detect Progressive Hypovolemia in Spontaneously Breathing Healthy Subjects","Accurate and early detection of blood volume loss would greatly improve intraoperative and trauma care. This study has attempted to determine early diagnostic and quantitative markers for blood volume loss by analyzing photoplethysmogram (PPG) data from ear, finger, and forehead sites with our high-resolution time-frequency spectral (TFS) technique in spontaneously breathing healthy subjects (n=11) subjected to lower body negative pressure (LBNP). The instantaneous amplitude modulations (AM) present in heart rate (AM HR ) and breathing rate (AM BR ) band frequencies of PPG signals were calculated from the high-resolution TFS. Results suggested that the changes (P  BR  and especially in AM HR  values can be used to detect the blood volume loss at an early stage of 20% LBNP tolerance when compared to the baseline values. The mean percent decrease in AM HR  values at 100% LBNP tolerance was 78.3%, 72.5%, and 33.9% for ear, finger, and forehead PPG signals, respectively. The mean percent increase in AM BR  values at 100% LBNP tolerance was 99.4% and 19.6% for ear and finger sites, respectively; AM BR  values were not attainable for forehead PPG signal. Even without baseline AM HR  values, our results suggest that hypovolemia detection is possible with specificity and sensitivity greater than 90% for the ear and forehead locations when LBNP tolerance is 100%. Therefore, the TFS analysis of noninvasive PPG waveforms is promising for early diagnosis and quantification of hypovolemia at levels not identified by vital signs in spontaneously breathing subjects.","2011","8","1","2025-12-02","https://university.edu/papers/8b4668b5-75d9-4b9e-9edc-ed15732953ff.pdf");
INSERT INTO Paper VALUES ("153","Big Social Data and Political Sentiment: The Tweet Stream during the UK General Election 2015 Campaign","The General Election for the 56th United Kingdom Parliament was held on 7 May 2015. Tweets related to UK politics, not only those with the specific hashtag '#GE2015', have been collected in the period between March 1 and May 31, 2015. The resulting dataset contains over 28 million tweets for a total of 118 GB in uncompressed format or 15 GB in compressed format. This study describes the method that was used to collect the tweets and presents some analysis, including a political sentiment index, and outlines interesting research directions on Big Social Data based on Twitter microblogging.","2015","8","4","2025-12-02","https://university.edu/papers/8062bec7-e2a9-4bb6-9413-9081f7f4c2da.pdf");
INSERT INTO Paper VALUES ("154","A Study of the Effects of Teaching Avatars on Students' Learning of Surveying Mathematics","The paper reports a research study aimed at investigating the appeal and pedagogical efficacy of animated teaching avatars. Specifically, the goal of the study was to determine whether animated characters could be effective and engaging teachers in the context of undergraduate surveying mathematics. The study included two forms of evaluation: formative and summative. Findings from the formative evaluation with forty-four undergraduate students show that three animated lectures delivered by a teaching avatar that speaks, gestures and points to a virtual board were perceived as engaging and useful for learning surveying mathematics concepts and procedures. Results of the summative evaluation with fifty-two undergraduate students show that watching the animated avatar lectures led to an increase in subjects' mathematical competence by 31%. The study also compared the animated avatar lectures to interactive 2D visualizations illustrating equivalent surveying math concepts. Findings show that watching the teaching avatar lectures led to significantly higher learning gains.","2016","13","2","2025-12-02","https://university.edu/papers/8324eb73-fd11-4427-8081-35c9624ea99b.pdf");
INSERT INTO Paper VALUES ("155","The Plank: designing a simple haptic controller","Active force-feedback holds the potential for precise and rapid controls. A high performance device can be built from a surplus disk drive and controlled from an inexpensive microcontroller. Our new design, The Plank has only one axis of force-feedback with limited range of motion. It is being used to explore methods of feeling and directly manipulating sound waves and spectra suitable for live performance of computer music.","2002","12","3","2025-12-02","https://university.edu/papers/ff75b183-2b22-4a7e-bc2f-19ecbcba4f8b.pdf");
INSERT INTO Paper VALUES ("156","Interception in distance-vector routing networks","Despite the large effort devoted to cybersecurity research over the last decades, cyber intrusions and attacks are still increasing. With respect to routing networks, route hijacking has highlighted the need to reexamine the existing protocols that govern traffic routing. In particular, our pri- mary question is how the topology of a network affects the susceptibility of a routing protocol to endogenous route misdirection. In this paper we define and analyze an abstract model of traffic interception (i.e. eavesdropping) in distance-vector routing networks. Specifically, we study al- gorithms that measure the potential of groups of dishonest agents to divert traffic through their infrastructure under the constraint that messages must reach their intended destinations. We relate two variants of our model based on the allowed kinds of lies, define strategies for colluding agents, and prove optimality in special cases. In our main theorem we derive a provably optimal monitoring strategy for subsets of agents in which no two are adjacent, and we extend this strategy to the general case. Finally, we use our results to analyze the susceptibility of real and synthetic networks to endogenous traffic interception. In the Autonomous Systems (AS) graph of the United States, we show that compromising only 18 random nodes in the AS graph surprisingly captures 10% of all traffic paths in the network in expectation when a distance-vector routing protocol is in use.","2016","8","4","2025-12-02","https://university.edu/papers/25287c3b-4e3d-485c-9baa-ccb7d96c5e4f.pdf");
INSERT INTO Paper VALUES ("157","Towards a knowledge-based system prototype for aeronautical Search and Rescue operations","The long-term objective of our project is to develop a knowledge-based tool for Search and Rescue (SAR) operations to support a Canadian search mission coordinator in determining the likely location of a missing aircraft overland. In order to attain this objective, we used a knowledge engineering approach to acquire, structure and model SAR experts' knowledge. This knowledge was modeled and implemented in a knowledge-based system prototype. The input to the interactive prototype consists of the known information regarding a given SAR case. Its main output is a set of scenarios describing the various hypotheses on what might have happened to the missing aircraft, why and where, the plausible routes followed, as well as the possibility area, defined as the region most likely to contain the missing aircraft. In this paper, we introduce the knowledge model, present an application example and briefly describe the prototype.","2010","4","4","2025-12-02","https://university.edu/papers/af403016-138d-4776-8e96-75f7b3e56250.pdf");
INSERT INTO Paper VALUES ("158","Distributed security for multi-agent systems - review and applications","As two major communication technologies, the internet and wireless, are maturing rapidly to dominate our civilised life, the authors urgently need to re-establish users’ confidence to harvest new potential applications of large-scale distributed systems. Service agents and distributed multi-agent systems (MASs) have shown the potential to help with this move as the lack of trust caused by heavily compromised security issues and concerns coupled with the out-of-date solutions are hindering the progress. The authors therefore seek new remedies to ensure that the continuity in developing new economies is maintained through building new solutions to address today's techno-economical problems. Following a scan of the literature the authors discuss the state-of-the-art progress followed by some observations and remarks for the researchers in the field. Here the authors recognise the need for new ‘distributed security’ solutions, as an overlay service, to rejuvenate and exploit the distributed artificial intelligence (AI) techniques for secure MAS as a natural solution to pave the way to enable a long awaited application paradigm of the near future.","2010","6","1","2025-12-02","https://university.edu/papers/9d045ea4-16f4-4cbf-9541-14959bff02a3.pdf");
INSERT INTO Paper VALUES ("159","A three-year study on the freshness of web search engine databases","This paper deals with one aspect of the index quality of search engines: index freshness. The purpose is to analyse the update strategies of the major web search engines Google, Yahoo, and MSN/Live.com. We conducted a test of the updates of 40 daily updated pages and 30 irregularly updated pages. We used data from a time span of six weeks in the years 2005, 2006 and 2007. We found that the best search engine in terms of up-to-dateness changes over the years and that none of the engines has an ideal solution for index freshness. Indexing patterns are often irregular, and there seems to be no clear policy regarding when to revisit Web pages. A major problem identified in our research is the delay in making crawled pages available for searching, which differs from one engine to another.","2008","8","1","2025-12-02","https://university.edu/papers/df5f4272-b3f0-4263-9b1f-98291ec051b9.pdf");
INSERT INTO Paper VALUES ("160","Czech Machine Translation in the project CzechMATE","We present various achievements in statistical machine translation from English, German, Spanish and French into Czech. We discuss specific properties of the individual source languages and describe techniques that exploit these properties and address language-specific errors. Besides the translation proper, we also present our contribution to error analysis.","2014","10","3","2025-12-02","https://university.edu/papers/f2a74c1e-192d-445b-a59c-286ecd006483.pdf");
INSERT INTO Paper VALUES ("161","Paid Exchanges are Worth the Price","We consider the list update problem as defined in the seminal work on competitive analysis by Sleator and Tarjan [12]. In this problem, a sequence of requests, consisting of items to access in a linked list, is given. After an item is accessed it can be moved to any position forward in the list at no cost (free exchange), and, at any time, any two adjacent items can be swapped at a cost of 1 (paid exchange). The cost to access an item is its current position in the list. The goal is to dynamically rearrange the list so as to minimize the total cost (accrued from accesses and exchanges) over the request sequence.#R##N##R##N#We show a lower bound of 12/11 on the worst-case ratio between the performance of an (offline) optimal algorithm that can only perform free exchanges and that of an (offline) optimal algorithm that can perform both paid and free exchanges. This  answers an outstanding question that has been open since 1996 [10].","2015","3","3","2025-12-02","https://university.edu/papers/c261b847-053e-4646-a6d0-7e4552d3a4f5.pdf");
INSERT INTO Paper VALUES ("162","A concept-level approach to the analysis of online review helpfulness","Helpfulness of online reviews serves multiple needs of different Web users. Several types of factors can drive reviews' helpfulness. This study focuses on uninvestigated factors by looking at not just the quantitative factors (such as the number of concepts), but also qualitative aspects of reviewers (including review types such as the regular, comparative and suggestive reviews and reviewer helpfulness) and builds a conceptual model for helpfulness prediction. The set of 1500 reviews were randomly collected from TripAdvisor.com across multiple hotels for analysis. A set of four hypotheses were used to test the proposed model. Our results suggest that the number of concepts contained in a review, the average number of concepts per sentence, and the review type contribute to the perceived helpfulness of online reviews. The regular reviews were not statistically significant predictors of helpfulness. As a result, review types and concepts have a varying degree of impact on review helpfulness. The findings of this study can provide new insights to e-commerce retailers in understanding the importance of helpfulness of reviews. We have examined the factors that participate in online reviews helpfulness.The regular, comparative and suggestive are included as qualitative aspect.The numbers of concepts in opinion types are examined as quantitative factors.Further challenges are discussed for coming researchers.","2016","4","3","2025-12-02","https://university.edu/papers/36978874-c811-4a5e-bb3c-e8328f935629.pdf");
INSERT INTO Paper VALUES ("163","A multivariate method to determine the dimensionality of neural representation from population activity","How do populations of neurons represent a variable of interest? The notion of feature spaces is a useful concept to approach this question: According to this model, the activation patterns across a neuronal population are composed of different pattern components. The strength of each of these components varies with one latent feature, which together are the dimensions along which the population represents the variable. Here we propose a new method to determine the number of feature dimensions that best describes the activation patterns. The method is based on Gaussian linear classifiers that use only the first d most important pattern dimensions. Using cross-validation, we can identify the classifier that best matches the dimensionality of the neuronal representation. We test this method on two datasets of motor cortical activation patterns measured with functional magnetic resonance imaging (fMRI), during (i) simultaneous presses of all fingers of a hand at different force levels and (ii) presses of different individual fingers at a single force level. As expected, the new method shows that the representation of force is low-dimensional; the neural activation for different force levels is scaled versions of each other. In comparison, individual finger presses are represented in a full, four-dimensional feature space. The approach can be used to determine an important characteristic of neuronal population codes without knowing the form of the underlying features. It therefore provides a novel tool in the building of quantitative models of neuronal population activity as measured with fMRI or other approaches.","2013","3","1","2025-12-02","https://university.edu/papers/738d9742-5ad4-40ca-91f7-7e39e37b3570.pdf");
INSERT INTO Paper VALUES ("164","Discriminant-EM algorithm with application to image retrieval","In many vision applications, the practice of supervised learning faces several difficulties, one of which is that insufficient labeled training data result in poor generalization. In image retrieval, we have very few labeled images from query and relevance feedback so that it is hard to automatically weight image features and select similarity metrics for image classification. This paper investigates the possibility of including an unlabeled data set to make up the insufficiency of labeled data. Different from most current research in image retrieval, the proposed approach tries to cast image retrieval as a transductive learning problem, in which the generalization of an image classifier is only defined on a set of images such as the given image database. Formulating this transductive problem in a probabilistic framework the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically. Our experiments show that D-EM has a satisfactory performance in image retrieval applications. D-EM algorithm has the potential to many other applications.","2000","20","2","2025-12-02","https://university.edu/papers/7e7d82ae-865f-46eb-9a38-ad180c1d1d60.pdf");
INSERT INTO Paper VALUES ("165","Contextual Mobile Learning for professionals working in the 'Smart City'","In this study, we propose an innovative approach using the 'Contex- tual Mobile Learning System' based on the 'Electronic Performance Support System' (EPSS) to support efficient just-in-time learning for professionals working in the 'Smart city'. In this paper, we present the principle and the structure of our contextual mobile learning system, which uses a search engine to find appropriate learning units in relation with working activities and condi- tions and the user's / worker's profile. We further discuss the proposed system structure, supportive process and context-driven engine. Finally, we describe a scenario using our contextual mobile learning system.","2013","6","4","2025-12-02","https://university.edu/papers/ed202978-cbe9-49ad-893b-b19cc0f4a445.pdf");
INSERT INTO Paper VALUES ("166","The contribution of primary and secondary somatosensory cortices to the representation of body parts and body sides: An fmri adaptation study","Although the somatosensory homunculus is a classically used description of the way somatosensory inputs are processed in the brain, the actual contributions of primary (SI) and secondary (SII) somatosensory cortices to the spatial coding of touch remain poorly understood. We studied adaptation of the fMRI BOLD response in the somatosensory cortex by delivering pairs of vibrotactile stimuli to the finger tips of the index and middle fingers. The first stimulus (adaptor) was delivered either to the index or to the middle finger of the right or left hand, and the second stimulus (test) was always administered to the left index finger. The overall BOLD response evoked by the stimulation was primarily contralateral in SI and was more bilateral in SII. However, our fMRI adaptation approach also revealed that both somatosensory cortices were sensitive to ipsilateral as well as to contralateral inputs. SI and SII adapted more after subsequent stimulation of homologous as compared with nonhomologous fingers, showing a distinction between different fingers. Most importantly, for both somatosensory cortices, this finger-specific adaptation occurred irrespective of whether the tactile stimulus was delivered to the same or to different hands. This result implies integration of contralateral and ipsilateral somatosensory inputs in SI as well as in SII. Our findings suggest that SI is more than a simple relay for sensory information and that both SI and SII contribute to the spatial coding of touch by discriminating between body parts (fingers) and by integrating the somatosensory input from the two sides of the body (hands).","2012","17","3","2025-12-02","https://university.edu/papers/c3eece97-7b9f-4350-8716-e2fefb55b5db.pdf");
INSERT INTO Paper VALUES ("167","Critical review and creative suggestions for the native English speaking teacher policy in South Korea","In order to invigorate communicative language teaching, until recently the South Korean government actively promoted the hiring of native English speaking teachers (NESTs) at state schools. However, mainly due to constrained budgets, many local offices of education have now started to rapidly cut the number of NESTs. This paper takes a critical approach to examine possible impacts of the recent variation in NEST policy on the disparity in learning opportunities between financially privileged and underprivileged students. We begin with a brief review of the history of NEST employment in South Korean state schools. Then, we delve into whether there are pedagogical advantages in team teaching over sole Korean English Teacher teaching. Later, the current policy's driving forces, potential beneficiaries and victims, and outcome of the policy will be discussed. On the basis of the analysis of the recent trend in NEST policy, suggestions for future policy reforms are provided.","2016","20","2","2025-12-02","https://university.edu/papers/fae876e2-b9ec-4082-a34b-598874302d17.pdf");
INSERT INTO Paper VALUES ("168","FRAME: filters, random fields, and minimax entropy towards a unified theory for texture modeling","In this paper, a minimax entropy principle is studied, based on which a novel theory, called FRAME (Filters, Random fields And Minimax Entropy) is proposed for texture modeling. FRAME combines attractive aspects of two important themes in texture modeling: multi-channel filtering and Markov random field (MRF) modeling. It incorporates the responses of a set of well selected filters into the distribution over a random field and hence has a much stronger descriptive ability than the traditional MRF models. Furthermore, it interprets and clarifies many previous concepts and methods for texture analysis and synthesis from a unified point of view. Algorithms are proposed for probability inference, stochastic simulation and filter selection. Experiments on a variety of textures are described to illustrate our theory and to show the performance of our algorithms. These experiments demonstrate that many textures previously considered as different categories can be modeled and synthesized in a common framework.","1996","14","2","2025-12-02","https://university.edu/papers/657dc877-eda1-4b98-8ec4-3e575c615ed3.pdf");
INSERT INTO Paper VALUES ("169","Program downloadable adapter for home network","This paper describes our new home network adapter that connects every household appliance to an existing home network. The adapter can download a conversion program which enables communication protocol between an appliance and the home network. The adapter has two controllers that make the electric current supplied from an appliance smooth, and the appliance can reduce the power supply capacity required for the adapter 1 .","2007","10","3","2025-12-02","https://university.edu/papers/7cf1cd41-9cbb-435a-a108-aa00e7a6588b.pdf");
INSERT INTO Paper VALUES ("170","Common-Mode Differential-Mode (CMDM) Method for Double-Nuclear MR Signal Excitation and Reception at Ultrahigh Fields","Double-tuned radio-frequency (RF) coils for heteronuclear mangentic resonance (MR) require sufficient electromagnetic isolation between the two resonators operating at two Larmor frequencies and independent tuning in order to attain highly efficient signal acquisition at each frequency. In this work, a novel method for double-tuned coil design at 7T based on the concept of common-mode differential-mode (CMDM) was developed and tested. Common mode (CM) and differential mode (DM) currents exist within two coupled parallel transmission lines, e.g., microstrip lines, yielding two different current distributions. The electromagnetic (EM) fields of the CM and DM are orthogonal to each other, and thus, the two modes are intrinsically EM decoupled. The modes can be tuned independently to desired frequencies, thus satisfying the requirement of dual-frequency MR applications. To demonstrate the feasibility and efficiency of the proposed CMDM technique, CMDM surface coils and volume coils using microstrip transmission line for  1 H and  13 C MRI/MRSI were designed, constructed, and tested at 7T. Bench test results showed that the isolations between the two frequency channels of the CMDM surface coil and volume coil were better than -30 and -25 dB, respectively. High quality MR phantom images were also obtained using the CMDM coils. The performance of the CMDM technique was validated through a comparison with the conventional two-pole design method at 7T. The proposed CMDM technique can be also implemented by using other coil techniques such as lumped element method, and can be applied to designing double-tuned parallel imaging coil arrays. Furthermore, if the two resonant modes of a CMDM coil were tuned to the same frequency, the CMDM coil becomes a quadrature coil due to the intrinsic orthogonal field distribution of CM and DM.","2011","12","1","2025-12-02","https://university.edu/papers/bc135646-5153-43c7-96fe-2603426479b3.pdf");
INSERT INTO Paper VALUES ("171","Analytical Approximations of EESM Effective SNR Distribution Using Pearson System","Link adaptation is an important technique in achieving good system spectral efficiency. However, due to the effect of frequency selective fading, the SNRs of adjacent sub-carriers in an OFDMA system can potentially be different. To provide a reasonable signalling overhead, the smallest unit of channel quality feedback is represented in terms of a group of sub-carrier SNRs, or effective SNR for short. The knowledge of the PDF or CDF of the effective SNR can be very useful in performance analysis of systems involving frequency selective feedback. However, closed-form expressions of these statistical quantities are very difficult to obtained. In this paper, we propose to approximate these quantities using the method of Pearson system. Numerical results show that the proposed approximation is very accurate.","2011","9","4","2025-12-02","https://university.edu/papers/f84ddd4e-29e0-41af-ba24-e8f07f922b9b.pdf");
INSERT INTO Paper VALUES ("172","On the Complexity and Approximability of Budget-Constrained Minimum Cost Flows","We investigate the complexity and approximability of the budget-constrained minimum cost flow problem, which is an extension of the traditional minimum cost flow problem by a second kind of costs associated with each edge, whose total value in a feasible flow is constrained by a given budget B. This problem can, e.g., be seen as the application of the {\epsilon}-constraint method to the bicriteria minimum cost flow problem. We show that we can solve the problem exactly in weakly polynomial time $O(\log M \cdot MCF(m,n,C,U))$, where C, U, and M are upper bounds on the largest absolute cost, largest capacity, and largest absolute value of any number occuring in the input, respectively, and MCF(m,n,C,U) denotes the complexity of finding a traditional minimum cost flow. Moreover, we present two fully polynomial-time approximation schemes for the problem on general graphs and one with an improved running-time for the problem on acyclic graphs.","2016","12","3","2025-12-02","https://university.edu/papers/dde52914-0f7a-4a79-aad7-e2c7de626d05.pdf");
INSERT INTO Paper VALUES ("173","A fast and distributed algorithm for vehicular network coding","It is significant to discover an efficient method to construct network codes such as a linear multicast or broadcast. It is valuable if we find a practical way to apply the technique to a vehicular ad hoc network (VANET) to improve the throughput to broadcast large data. It would be essential to discover a fast and distributed coding scheme since VANETs are well-known to change their topology quickly. In this paper, we present such a network coding algorithm suitable to a VANET. It will be guaranteed that the obtained code forms a two-dimensional linear multicast over a network that meets natural restrictions for a VANET on a multi-lane road. Due to the completely decentralized process, it is non-trivial to prove the correctness of construction even for the dimension 2. We will also discuss additional practical performance enhancement for the basic algorithm.","2010","3","1","2025-12-02","https://university.edu/papers/d373090d-7178-43c7-90fd-126bf6f2cbb4.pdf");
INSERT INTO Paper VALUES ("174","A high-speed method of detecting contact-state transitions and its implementation in a task-coordinate manipulation system","We have developed a highly reliable method of detecting contact-state transitions in real time. In the detection algorithm, feature variables, which fluctuate abruptly when a contact state transition occurs, are selected. The differential of the feature trajectory is monitored to distinguish the transition region from the stable region. To confirm that a state transition has actually occurred in the region, the duration of the region is measured. With this method, a contact-state transition can be detected with a 40-msec delay. We also have developed an experimental manipulation system, in which motion execution management and motion monitoring and execution modules operate independently. Using transputers and a six-degree-of-freedom direct-drive manipulator, a square-peg insertion task is carried out to evaluate the effectiveness of the detection method in an actual environment. The experimental results show that contact-state transitions can be accurately detected and that motion commands can be quickly switched by using the detected transition information.","1996","5","2","2025-12-02","https://university.edu/papers/c547359a-edb7-4ccd-9b3c-c8212fcc338e.pdf");
INSERT INTO Paper VALUES ("175","The reusability challenge","The traditional 'reuse or redo' dilemma is unacceptable; we need to reuse what is applicable to our current need and redo the rest. This is where object technology helps. The argument we examine-that object technology promotes reusability-has been one of the central claims of OO proponents since the field's emergence in the mid-1980s. The paper considers the features that make object oriented ideas so special in the quest for reusable software.","1996","11","2","2025-12-02","https://university.edu/papers/b8dbdeb5-9a13-42af-9f54-283c16e02ea9.pdf");
INSERT INTO Paper VALUES ("176","Cross lingual speech emotion recognition using canonical correlation analysis on principal component subspace","This paper proposes an analytical approach based on Kernel Canonical Correlation Analysis (KCCA) for domain adaptation. To generate paired instances for KCCA, we mapped source and target data onto both source and target principal components. We performed pair-wise domain adaptation between four emotional speech corpora with different languages (English, German, Italian, and Polish) to validate the approach. We compared our approach with the Shared-Hidden-Layer Auto-Encoder (SHLA) and kernel based principal components. On average, the proposed approach yields higher classification performance.","2016","13","4","2025-12-02","https://university.edu/papers/e6b1f276-6314-4d2d-a551-64151c4035aa.pdf");
INSERT INTO Paper VALUES ("177","A performance analysis tool for performance-driven micro-cell generation","A new method is presented to determine the power dissipation and propagation-delay time of small logical blocks (micro-cells). This method is a combination of the RC-tree and the macro modeling methods. It is a fast and accurate method, three orders of magnitude faster that SPICE, while the maximal error is ten percent. This method can be used in a performance-driven micro-cell generator for a sea-of-gates environment. >","1991","16","1","2025-12-02","https://university.edu/papers/b61cf10a-819c-4918-8ec8-0484607258b5.pdf");
INSERT INTO Paper VALUES ("178","Effective SNR for space-time modulation over a time-varying Rician channel","Rapid temporal variations in wireless channels pose a significant challenge for space-time modulation and coding algorithms. This letter examines the performance degradation that results when time-varying flat fading is encountered when using trained and unitary space-time modulation. Performance is characterized for a channel having a constant specular component plus a time-varying diffuse component. A first-order autoregressive (AR) model is used to characterize diffuse channel coefficients that vary from symbol to symbol, and is shown to lead to an effective signal-to-noise ratio (SNR) that decreases with time. Differential modulation is shown to have an advantage in effective SNR over trained unitary modulation at high power. Simulation results are provided to support our analysis.","2004","4","4","2025-12-02","https://university.edu/papers/b02584e5-f82d-449c-987c-328c6f67838d.pdf");
INSERT INTO Paper VALUES ("179","An SDN-Based Network Architecture for Extremely Dense Wireless Networks","Telecommunications networks are undergoing major changes so as to meet the requirements of the next generation of users and services, which create a need for a general revised architectural approach rather than a series of local and incremental technology updates. This is especially manifest in mobile broadband wireless access, where a major traffic increase is expected, mostly because of video transmission and cloud-based applications. The installation of a high number of very small cells is foreseen as the only practical way to achieve the demands. However, this would create a struggle on the mobile network operators because of the limited backhaul capacity, the increased energy consumption, and the explosion of signalling. In the FP7 project CROWD, Software Defined Networking (SDN) has been identified as a solution to tame extreme density of wireless networks. Following this paradigm, a novel network architecture accounting for MAC control and Mobility Management has been proposed, being the subject of this paper.","2013","9","2","2025-12-02","https://university.edu/papers/c1741e64-6633-4735-921a-15c19428651b.pdf");
INSERT INTO Paper VALUES ("180","Cluster Analysis Based on Dimensional Information with Applications to Feature Selection and Classification","A new clustering algorithm is presented that is based on dimensional information. The algorithm includes an inherent feature selection criterion, which is discussed. Further, a heuristic method for choosing the proper number of intervals for a frequency distribution histogram, a feature necessary for the algorithm, is presented. The algorithm, although usable as a stand-alone clustering technique, is then utilized as a global approximator. Local clustering techniques and configuration of a global-local scheme are discussed, and finally the complete global-local and feature selector configuration is shown in application to a real-time adaptive classification scheme for the analysis of remote sensed multispectral scanner data.","1974","3","3","2025-12-02","https://university.edu/papers/4b0e2ca5-4d95-43cb-b18f-1bf9fd64bacf.pdf");
INSERT INTO Paper VALUES ("181","Methods of Hierarchical Clustering","We survey agglomerative hierarchical clustering algorithms and discuss efficient implementations that are available in R and other software environments. We look at hierarchical self-organizing maps, and mixture models. We review grid-based clustering, focusing on hierarchical densitybased approaches. Finally we describe a recently developed very efficient (linear time) hierarchical clustering algorithm, which can also be viewed as a hierarchical grid-based algorithm.","2011","5","2","2025-12-02","https://university.edu/papers/938734ee-fb23-4ed3-b7fd-ba21b731c287.pdf");
INSERT INTO Paper VALUES ("182","First arrival detection based on channel estimation for positioning in wireless OFDM systems","Based on the estimated channel, this paper presents a new method for first arrival estimation for positioning application in OFDM mobile communication systems. In the new method, the characteristics of the information theoretic criteria is exploited to estimate the time of arrival (TOA). The information theoretic criteria is established on the basic of the different statistical characteristics of noise and the mobile channel. In the proposed algorithm, the calculation of the autocorrelation matrix and their eigenvalues are not required. Therefore, the complexity of the proposed method is low. Simulation results show that the performance of system in terms of the detection rate is very high. An accurate estimation of the first arrival path (or the time of arrival) can be obtained even though the first arrival path is strongly attenuated and the system suffers from strong additive noise.","2006","13","3","2025-12-02","https://university.edu/papers/d18ae684-6758-47e8-8083-c2e1d686bc8a.pdf");
INSERT INTO Paper VALUES ("183","Weighted Reed-Muller codes and algebraic-geometric codes","A generalization of the Reed-Muller codes, the weighted Reed-Muller codes, is presented. The code parameters are estimated and the duals are shown also to be weighted Reed-Muller codes. It is shown how the minimum distance of certain algebraic-geometric codes in many cases can be determined exactly or an upper bound can be found, using subcodes which are weighted Reed-Muller codes. >","1992","11","4","2025-12-02","https://university.edu/papers/74cf28f1-be84-43cf-9e9c-1f2e50dfe1a5.pdf");
INSERT INTO Paper VALUES ("184","Ranking intuitionistic fuzzy values with the Euclidean distance","Ranking intuitionistic fuzzy values is a very important research topic in the field of intuitionistic fuzzy set. To address this issue, we attempt to propose an approach, based on the concept of the Euclidean distance, to ordering intuitionistic fuzzy values. Also, we study some properties in our theory, which in turn show that the problems in the existing approaches do not occur in our theory.","2015","14","4","2025-12-02","https://university.edu/papers/00558782-8a42-41cb-a0cd-3a7a884883f0.pdf");
INSERT INTO Paper VALUES ("185","Multi-agent Based Vehicle Integrated Control Framework for Coordination of Active Steering, Driveline and Braking Systems","Multi-agent based real-time control algorithm has prominent advantages in solving complicated distributed control problem. In this paper, a multi-agent based integrated control framework is proposed to organize the active steering, driveline and braking controllers, traditionally they have been relatively independent. Supervisor-like coordination mechanism is employed to manage interdependences and conflicts among the local controller agents, so as to improve adaptability and robustness of the global controller. The controller subsystems and the integrated control architecture are implemented in Matlab/Simulink to study the vehicle handing capability under critical maneuvering condition. Simulation results show that the proposed multi-agent based control framework is competent of managing the subsystems and providing with excellent critical performance for the vehicle longitudinal and lateral movement control.","2008","14","3","2025-12-02","https://university.edu/papers/bad79a60-ad18-4858-a87b-7ce5c0bd3ae0.pdf");
INSERT INTO Paper VALUES ("186","Cuffless and Continuous Blood Pressure Estimation from the Heart Sound Signals","Cardiovascular disease, like hypertension, is one of the top killers of human life and early detection of cardiovascular disease is of great importance. However, traditional medical devices are often bulky and expensive, and unsuitable for home healthcare. In this paper, we proposed an easy and inexpensive technique to estimate continuous blood pressure from the heart sound signals acquired by the microphone of a smartphone. A cold-pressor experiment was performed in 32 healthy subjects, with a smartphone to acquire heart sound signals and with a commercial device to measure continuous blood pressure. The Fourier spectrum of the second heart sound and the blood pressure were regressed using a support vector machine, and the accuracy of the regression was evaluated using 10-fold cross-validation. Statistical analysis showed that the mean correlation coefficients between the predicted values from the regression model and the measured values from the commercial device were 0.707, 0.712, and 0.748 for systolic, diastolic, and mean blood pressure, respectively, and that the mean errors were less than 5 mmHg, with standard deviations less than 8 mmHg. These results suggest that this technique is of potential use for cuffless and continuous blood pressure monitoring and it has promising application in home healthcare services.","2015","5","2","2025-12-02","https://university.edu/papers/5c8a9313-defd-4c7f-919b-26be03c99e0f.pdf");
INSERT INTO Paper VALUES ("187","Programmable multi-hop wireless networks towards IoT: Architecture and key techniques","In conventional multi-hop wireless networks towards IoT, network resources are static normally. As a result, if one network is overloaded, it cannot borrow any resources from other adjacent under loaded networks. The reason for this problem is that there is none of a uniform architecture and supporting techniques between these adjacent networks. In this paper, we propose a novel architecture and corresponding key techniques for multi-hop wireless networks. The proposed architecture are programmable and universal. By such proposal, all adjacent networks following the proposed architecture are managed by one control center. The network resources are optimally and dynamically managed among these networks to meet all application requirements.","2016","13","4","2025-12-02","https://university.edu/papers/c174e115-11fb-4da9-8131-3163b44e71dc.pdf");
INSERT INTO Paper VALUES ("188","Dealing with acoustic mismatch for training multilingual subspace Gaussian mixture models for speech recognition","The subspace Gaussian mixture model (SGMM) has been recently proposed as an acoustic modeling technique suitable for configuring multilingual speech recognition systems. It is attractive for this purpose since its parametrization allows its “shared” model parameters to be trained with data from multiple languages [1]. In this work, we report on the results of an experimental study carried out with the goal of improving native Spanish language speech recognition performance using an existing telephone speech corpus of English spoken by speakers of Spanish origin. Compensation for sources of acoustic variability between Spanish and English language data sets was found to be important in obtaining good multilingual ASR performance. We conclude with a discussion about the notion of acoustic similarity between the state dependent parameters of the SGMM, and its possible use in effectively modelling pronunciation variation.","2012","18","4","2025-12-02","https://university.edu/papers/8fa79639-6410-4ca8-8ab1-f4ddb96d1618.pdf");
INSERT INTO Paper VALUES ("189","Applying acoustic array processing to the estimation of the propagation speed of waves in a car exhaust","A parametric method based on spatial filter techniques (beamforming) is proposed to estimate the propagation speed of acoustic waves. The propagation speed estimate is analyzed for the case of narrowband signals and compared to the maximum likelihood estimate (MLE) of the propagation speed. It is shown that for an array of 3 sensors our estimate coincides with the ML estimate but its performance analysis is simpler and its computational cost is much more reduced. The proposed estimate is also applied to the wideband waves propagating along a car exhaust. It is shown that the signal-to-noise ratio and the magnitude of the relative aperture (distance between the array sensors respect to the wavelength) for each frequency could limit the good performance of the speed estimator. Good results have been achieved when these limitations have been taken into account.","1997","18","4","2025-12-02","https://university.edu/papers/865c6003-6a17-4e08-a5ec-3c119874330f.pdf");
INSERT INTO Paper VALUES ("190","Mining Sequential Patterns with Negative Conclusions","The new type of patterns: sequential patterns with the negative conclusions is proposed in the paper. They denote that a certain set of items does not occur after a regular frequent sequence. Some experimental results and the SPAWN algorithm for mining sequential patterns with the negative conclusions are also presented.","2008","18","2","2025-12-02","https://university.edu/papers/4c95729e-3267-4d38-9df8-42b3ee2f28bd.pdf");
INSERT INTO Paper VALUES ("191","One-Color Two-Phase Asynchronous Communication Links Based on Multiple-Valued Simultaneous Control","This paper presents one-color two-phase asynchronous communication links for a high-performance asynchronous system. The proposed communication links based on simple one-color encoding is effectively connected to processing cores. Since the communication is controlled by simultaneous handshaking, where a request and an acknowledge signals are overlapped, the number of communication steps is greatly reduced. Moreover, the use of multiple-valued current-mode circuit makes it possible to realize asynchronous communication with just two wires. The asynchronous transmission circuits based on the proposed encoding are implemented and evaluated using HSPICE simulation with 0.13 um CMOS technology. Throughput of the proposed 2-bit transmission attains 0.45Gbps/wire, which is three times faster than that of the conventional two-color two-phase transmission.","2010","13","1","2025-12-02","https://university.edu/papers/f6a81409-b3f2-43e6-83d1-5e98bcb18535.pdf");
INSERT INTO Paper VALUES ("192","Integration of Big Data Using Semantic Web Technologies","In order to realize the promise of Big Data, applications will have to consider the integration of many disparate data sources. Due to data heterogeneity, this task presents a number of challenges that may not be completely resolved with existing Extract-Transform-Load (ETL)-based frameworks. In this paper, we explore the potential of Semantic Web Technologies as a means of integration and development of Big Data applications. In demonstration, a usage case study is presented examining supplier chain operations. Additionally, we review the overall challenges of data integration in this area.","2016","19","4","2025-12-02","https://university.edu/papers/f96d3627-ad43-4f9e-9cfe-c2ef5b2a5b2e.pdf");
INSERT INTO Paper VALUES ("193","Estimating relationships between NDVI and climate change in Guizhou Province, Southwest China","The objective of this study was to examine the vegetation response to the climatic variation in Guizhou province, Southwest China. The relationship between vegetation and climate change was investigated with Normalized Difference Vegetation Index (NDVI) (1982–1999) images derived from the Advanced Very High Resolution Radiometer (AVHRR), and climate data acquired from 19 meteorological stations in Guizhou province. Five climate variables during the growing season (March to October): precipitation, evaporation, mean temperature, solar irradiation and water surplus (the arithmetic difference between precipitation and evaporation) at 10-day time scale were regressed on NDVI derived from 8 km×8 km pixels where the weather stations located. The main results were: (a) temperature and evaporation are the most significant climatic variables controlling vegetation condition; (b) evaporation are positive to vegetation growth at the 10-day time scale. The model also indicated that 11.8% variation in NDVI is accounted for by climate. Other factors contributing to NDVI variation include environmental factors (soil, groundwater and terrain) and sensor variation. The present study will be helpful in estimations of response of the regional terrestrial biosphere to global environmental change.","2010","17","2","2025-12-02","https://university.edu/papers/7663d8e2-c3b7-4d83-98ed-2474f2311fd5.pdf");
INSERT INTO Paper VALUES ("194","Partial chaos suppression in a fractional order macroeconomic model","This work investigates the possibility of suppressing chaos in a fractional-nonlinear macroeconomic dynamic model. The system generalizes a model recently reported in the literature in which chaos is strongly present. This description involves the inclusion of the public sector deficit and its coupling with other variables. The system is simulated for integer and non-integer orders that produce a complex dynamics. The time histories and the phase diagrams are presented. The main contribution of this work refers to the adoption of the largest Lyapunov exponent (LLE) criteria based on Wolf's algorithm. This approach improves the response of the system, suppressing, at least partially, the strong presence of chaos reported in previous studies.","2016","3","2","2025-12-02","https://university.edu/papers/3b4ec9cb-6cd8-46fc-8106-e4b11098dabe.pdf");
INSERT INTO Paper VALUES ("195","CATT: potential based routing with content caching for ICN","Information Centric Networking (ICN) has shown possibilities to solve several problems of the Internet. At the same time, some problems need to be tackled in order to advance this promising architecture. In this paper we address two of the problems, namely routing and content caching. For the routing, we introduce the Potential Based Routing (PBR) to achieve several design goals such as availability, adaptability, diversity, and robustness. In addition, we examine the performance of a random caching policy which can be a promising candidate for ICN. The integrated system of both PBR and a caching policy is named the Cache Aware Target idenTification (CATT). Simulation results demonstrate that PBR with replications located on less than 1% of total nodes can achieve a near optimal routing performance (close to the shortest path routing) even though a request message is randomly forwarded.","2012","12","1","2025-12-02","https://university.edu/papers/c1da8bbe-2000-4276-a80c-ed7cba93bd7b.pdf");
INSERT INTO Paper VALUES ("196","Comparative analysis of classification models in diagnosis of type 2 diabetes","Diabetes has become one of the major causes of premature diseases and death in most countries. A major problem in medical science and bioinformatics analysis is to obtain the correct diagnosis on specific important information. In general, several tests are done that includes clustering or classification on large scale of data. However, many tests might complicate the main diagnosis process and lead to difficulty in getting the final results. Machine learning techniques are used to build models to overcome this kind of difficulty. Therefore, there are two main purposes of this study. First, implementing classification models to diagnose diabetes efficiently and easily. Second, investigating and comparing the performance of different classification models. In this study, we proposed Fuzzy Expert System (FES) that used Fuzzy Inference System (FIS) model for incidence of diabetes. We applied two common classification algorithms which are logistic regression and support vector machine on Pima Indian Dataset to compare them with our proposed FIS model. In order to perform our experiment, we used two data mining tools named WEKA and MATLAB.","2016","7","1","2025-12-02","https://university.edu/papers/fcb95e8f-2333-4567-8bab-87ef2b600e60.pdf");
INSERT INTO Paper VALUES ("197","The Impact of Diversity on Online Ensemble Learning in the Presence of Concept Drift","Online learning algorithms often have to operate in the presence of concept drift (i.e., the concepts to be learned can change with time). This paper presents a new categorization for concept drift, separating drifts according to different criteria into mutually exclusive and nonheterogeneous categories. Moreover, although ensembles of learning machines have been used to learn in the presence of concept drift, there has been no deep study of why they can be helpful for that and which of their features can contribute or not for that. As diversity is one of these features, we present a diversity analysis in the presence of different types of drifts. We show that, before the drift, ensembles with less diversity obtain lower test errors. On the other hand, it is a good strategy to maintain highly diverse ensembles to obtain lower test errors shortly after the drift independent on the type of drift, even though high diversity is more important for more severe drifts. Longer after the drift, high diversity becomes less important. Diversity by itself can help to reduce the initial increase in error caused by a drift, but does not provide the faster recovery from drifts in long-term.","2010","12","4","2025-12-02","https://university.edu/papers/91f9a0cb-8509-44f1-9870-94081655cfe1.pdf");
INSERT INTO Paper VALUES ("198","Interactive textbook and interactive Venn diagram: natural and intuitive interfaces on augmented desk system","This paper describes two interface prototypes which we have developed on our augmented desk interface system, EnhancedDesk. The first application is Interactive Textbook, which is aimed at providing an effective learning environment. When a student opens a page which describes experiments or simulations, Interactive Textbook automatically retrieves digital contents from its database and projects them onto the desk. Interactive Textbook also allows the student hands-on ability to interact with the digital contents. The second application is the Interactive Venn Diagram, which is aimed at supporting effective information retrieval. Instead of keywords, the system uses real objects such as books or CDs as keys for retrieval. The system projects a circle around each book; data corresponding the book are then retrieved and projected inside the circle. By moving two or more circles so that the circles intersect each other, the user can compose a Venn diagram interactively on the desk. We also describe the new technologies introduced in EnhancedDesk which enable us to implement these applications.","2000","5","1","2025-12-02","https://university.edu/papers/f498b84a-d0b5-4fed-9061-7beb92fbcd21.pdf");
INSERT INTO Paper VALUES ("199","Analysis of long duration traces","This paper introduces a new set of long duration captures of Internet traffic headers. The capture is being performed on a continuous on-going basis and is approaching a year in duration. Based on the current extent of the archive some typical analyses are presented, covering protocol mix, network trip times and TCP flag analysis.","2005","2","3","2025-12-02","https://university.edu/papers/d3a4e97d-69af-40de-927f-f168cef6e4ac.pdf");
INSERT INTO Paper VALUES ("200","A decision model for managing software development projects","The paper first examines some issues that hinder the effective management of, and decision-making on, quality software development process and products delivery by practitioners. It then generates a decision model for managing software development projects. The model uses four concepts: mappability, accountability, interoperability and controllability in decision-making which is assumed to be based on a set of indicators that link task status of the development process and its quality assessment to the responsible authorities. The quality of the tasks, and hence, of the deliverables is measured using four attributes: completeness, correctness, consistency and compliance. A web-based example implementation is then discussed. We thus show that the model is flexible, extensible and scalable. Implementation challenges and implications are then discussed.","2006","12","2","2025-12-02","https://university.edu/papers/c9d6446e-cc4b-4158-a8e3-aa5d8a1fe905.pdf");
INSERT INTO Paper VALUES ("201","High-speed VLSI architectures for soft-output Viterbi decoding","During the last few years decoding algorithms that make not only the use of soft quantized inputs but also deliver soft decision outputs have attracted considerable attention because additional coding gains are obtainable in concatenated systems. A prominent member of this class of algorithms is the soft-output viterbi algorithm. In this paper two architectures for high speed VLSI implementations of the soft-output viterbi-algorithm are proposed and area estimates are given for both architectures. The well known trade-off between computational complexity and storage requirements is played to obtain new VLSI architectures with increased implementation efficiency. Area savings in excess of 40% in comparison to straightforward solutions are reported. >","1992","10","4","2025-12-02","https://university.edu/papers/67fc9377-a8f0-463f-a496-713645f963e5.pdf");
INSERT INTO Paper VALUES ("202","Fatal Attraction: Conceptual and methodological problems in the ranking of universities by bibliometric methods","Ranking of research institutions by bibliometric methods is an improper tool for research performance evaluation, even at the level of large institutions. The problem, however, is not the ranking as such. The indicators used for ranking are often not advanced enough, and this situation is part of the broader problem of the application of insufficiently developed bibliometric indicators used by persons who do not have clear competence and experience in the field of quantitative studies of science. After a brief overview of the basic elements of bibliometric analysis, I discuss the major technical and methodological problems in the application of publication and citation data in the context of evaluation. Then I contend that the core of the problem lies not necessarily at the side of the data producer. Quite often persons responsible for research performance evaluation, for instance scientists themselves in their role as head of institutions and departments, science administrators at the government level and other policy makers show an attitude that encourages ‘quick and dirty’ bibliometric analyses whereas better quality is available. Finally, the necessary conditions for a successful application of advanced bibliometric indicators as support tool for peer review are discussed.","2005","5","4","2025-12-02","https://university.edu/papers/58dc5d35-2b6e-4abc-881d-229a9352de99.pdf");
INSERT INTO Paper VALUES ("203","Interactive remote control of legacy home appliances through a virtually wired sensor network","With the advance of wireless communications technology, home automation based on home networks has regained attention. This paper proposes a wireless network protocol and a control device, which make it possible to control legacy home appliances in an interactive way. The proposed wireless network protocol provides a bidirectional communication channel between a gateway and control devices. The control device hooked up to the wireless network controls a legacy home appliance requested by a user using IR signals and returns the result of the control action as a digested image so that the user can determine if the control operation has been conducted properly. The feasibility of the network protocol and control device is demonstrated by an experiment in which a wireless network is constructed using the proposed network protocol and TVs and air conditioners are controlled via the wireless network and the result is fed back to the user.","2010","8","2","2025-12-02","https://university.edu/papers/a8d8485b-50f8-482f-adee-aa870dc25393.pdf");
INSERT INTO Paper VALUES ("204","PAC learning with generalized samples and an application to stochastic geometry","In this paper, we introduce an extension of the standard PAC learning model which allows the use of generalized samples. We view a generalized sample as a pair consisting of a functional on the concept class together with the value obtained by the functional operating on the unknown concept. It appears that this model can be applied to a number of problems in signal processing and geometric reconstruction to provide sample size bounds under a PAC criterion. We consider a specific application of the model to a problem of curve reconstruction, and discuss some connections with a result from stochastic geometry.","1992","8","1","2025-12-02","https://university.edu/papers/d2a6478e-e335-4833-8443-0f7512314d43.pdf");
INSERT INTO Paper VALUES ("205","View Caching: efficient software shared memory for dynamic computations","Software distributed shared memory (DSM) techniques, while effective on applications with coarse-grained sharing, yield poor performance for the fine-grained sharing encountered in applications increasingly relying on sophisticated adaptive and hierarchical algorithms. Such applications exhibit irregular communication patterns unsynchronized with computation, incurring large overheads for synchronous (request-reply) DSM protocols that require responsive processing of coherence messages. We describe a new DSM framework, View Caching, that addresses this problem by utilizing application knowledge of data access semantics to enable the construction of low-overhead, asynchronous coherence protocols. Experiments on the Gray T3D show that view caching enables efficient execution of fine-grained irregular applications, reducing both coherence overheads and idle time to improve performance by up to 35% over a weakly-consistent DSM implementation.","1997","5","1","2025-12-02","https://university.edu/papers/dd28b6f7-7749-4a2e-a604-a2f8d0cac3ba.pdf");
INSERT INTO Paper VALUES ("206","Iteration Algebras for UnQL Graphs and Completeness for Bisimulation","This paper shows an application of Bloom and ´ Esik’s iteration algebras to model graph data in a graph database query language. About twenty years ago, Buneman et al. developed a graph database query language UnQL on the top of a functional meta-language UnCAL for describing and manipulating graphs. Recently, the functional programming community has shown renewed interest in UnCAL, because it provides an effi cient graph transformation language which is useful for various applications, such as bidirectional computation. However, no mathematical semantics of UnQL/UnCAL graphs has been developed. In this paper, we give an equational axiomatisation and algebraic semantics of UnCAL graphs. The main result of this paper is to prove that completeness of our equational axioms for UnCAL for the original bisimulation of UnCAL graphs via iteration algebras. Another benefit of algebraic semantics is a clean characterisation o f structural recursion on graphs using free iteration algebra.","2015","5","4","2025-12-02","https://university.edu/papers/62216630-aed2-432e-a80d-726b7f06e780.pdf");
INSERT INTO Paper VALUES ("207","Improving flow line scheduling by upstream mixed integer resource allocation in a wafer test facility","The effort for scheduling real manufacturing systems is generally very high for mathematical as well as for simulation-based methods. Combining both methods is the key for solving complex scheduling problems. The paper introduces a special approach, where at first a static resource allocation problem is solved by mixed integer programming (MIP). Based on the resulting reduced dedication matrices, feasible schedules are then generated by a discrete event simulation (DES). Possible applications can be found in many parts of the semiconductor manufacturing process, for example in the wafer test. The investigated wafer test consists of two pronounced bottlenecks; each of it is formed as a workcenter with its own dedication matrix. After testing the method with practice oriented benchmarks, the benefits of the approach are shown on data derived directly from the semiconductor manufacturing process.","2012","1","4","2025-12-02","https://university.edu/papers/65a194ab-e685-420b-9a88-2ea9c10dab51.pdf");
INSERT INTO Paper VALUES ("208","Agent-based approach to enhance the new born social Web of Services","In this paper, we developed a business model of Social Web of Services that combines the idea of common social web and usual service selling, enhancing usual suggested ways of controlling smart devices. We modelled human-thing interactions using an agent-based simulation (ABM) to investigate the impact of IoT on human (user) behaviour patterns in order to provide analytical support and enhance the analysed business model. Results of this work can be used to predict people's way of living in the era of Smart things observing viral effects of Things application.","2015","12","1","2025-12-02","https://university.edu/papers/369ac29b-fbdf-4abf-9851-a051274d8c0d.pdf");
INSERT INTO Paper VALUES ("209","Pre-silicon prototyping of a unified hardware architecture for cryptographic manipulation detection codes","Engineers developing complex embedded SoC designs are increasingly finding that traditional verification techniques are inadequate for delivering bug-free first pass silicon. The design community is turning to pre-silicon prototypes built from FPGA devices as a technique for meeting such challenges. We propose 'HashChip' and implement a strategy for its pre-silicon prototyping. The 'HashChip' is a hardware architecture aimed at providing a unified solution for three different cryptographic manipulation detection codes extensively used in the field of network security, namely, MD5, SHAI and RIPEMD160. Prototyping is attempted on a wide variety of FPGAs prior to ASIC implementation and the performance of the architecture is analyzed.","2004","4","1","2025-12-02","https://university.edu/papers/b34c266a-6144-48cc-a44c-11fd140664ee.pdf");
INSERT INTO Paper VALUES ("210","Creating a smarter membrane: automatic code generation for modular self-reconfigurable robots","This work extends previous research on developing control software for modular robotic smart membranes to a second module type with more complicated movement, to 3-D membranes, to the presence of gravity, and to less easily manipulatable objects. Moreover, it extends the capabilities of the membranes from simple filtering to more complex sorting tasks. The control software we developed is completely decentralized, and automatically generated.","2002","16","2","2025-12-02","https://university.edu/papers/70448837-9a23-4cad-968c-a49a6fc8343f.pdf");
INSERT INTO Paper VALUES ("211","The knowledge gradient for sequential decision making with stochastic binary feedbacks","We consider the problem of sequentially making decisions that are rewarded by 'successes' and 'failures' which can be predicted through an unknown relationship that depends on a partially controllable vector of attributes for each instance. The learner takes an active role in selecting samples from the instance pool. The goal is to maximize the probability of success, either after the offline training phase or minimizing regret in online learning. Our problem is motivated by real-world applications where observations are time consuming and/or expensive. With the adaptation of an online Bayesian linear classifier, we develop a knowledge-gradient type policy to guide the experiment by maximizing the expected value of information of labeling each alternative, in order to reduce the number of expensive physical experiments. We provide a finite-time analysis of the estimated error and demonstrate the performance of the proposed algorithm on both synthetic problems and benchmark UCI datasets.","2016","1","2","2025-12-02","https://university.edu/papers/3761815f-0a61-4279-9cc4-a66ed05b4ba9.pdf");
INSERT INTO Paper VALUES ("212","Node-to-Set Disjoint-path Routing in Metacube","The metacube interconnection network introduced a few years ago has some very interesting properties: it has a short diameter similar to the hypercube, and its degree is much lower than that of a hypercube of the same size. In this paper, we describe an efficient algorithm for finding disjoint paths between one source node and at most m+k target nodes in a metacube MC(k, m) excluding MC(*,1), MC(2,2), MC(3,2) and MC(3,3). We show that we can find m+k disjoint paths between the source node and the m+k targets of length at most metacube diameter plus (k+4) with time complexity of order of metacube degree times its diameter.","2009","12","2","2025-12-02","https://university.edu/papers/4ab6eaa4-0b44-489d-90c5-790db4c9060e.pdf");
INSERT INTO Paper VALUES ("213","An Electronic Clearance Marketplace Leveraging Collaborations in Supplier and Buyer Communities: A Design Science Research Study","Effective clearance of unused service capacity is an issue of importance for managers and practitioners in consumer service industries. Taking a design science research approach, this research-in-progress paper proposes an innovative electronic clearance marketplace (clearance e-marketplace) based on novel design principles, namely, shared bundle purchasing and shared customer pooling, which arguably leads to more effective results than traditional clearance methods. We explain the design and implementation of this Information System (IS) artifact and develop hypotheses arguing that consumer service providers' use of this proposed clearance e-marketplace in clearing their unused service capacity would lead to improved performance gains on new customer acquisition and percentage sales compared to their traditional self-managed clearance campaigns. Furthermore, we explain the details of an empirical study to evaluate the efficacy of the proposed clearance e-marketplace in achieving the said performance gains.","2015","3","2","2025-12-02","https://university.edu/papers/a187f2d9-268c-43f1-9ada-4a2d73144122.pdf");
INSERT INTO Paper VALUES ("214","Development of a cooperative system behavior for a highly automated vehicle guidance concept based on the Conduct-by-Wire principle","Conduct-by-Wire (CbW) is a research project which breaks away from today's vehicle guidance by shifting the vehicle control task from a stabilization level to a conducting level. Instead of continuous stabilization on a designated trajectory - using the conventional control elements for manual steering, braking and accelerating - a Conduct-by-Wire vehicle is controlled by means of maneuver commands. By keeping the driver in the loop, the vehicle guidance is cooperatively shared between the driver and the automation. This article introduces an approach for the analysis of realizable automation levels and the design of a cooperative system behavior depending on the interaction concept between the human driver and the automation. Following a top-down approach, different driving scenarios are systematically analyzed as to the information needs that occur. This approach builds the basis for assessing the technical feasibility of a maneuver-based vehicle guidance concept based on the Conduct-by-Wire principle.","2011","3","1","2025-12-02","https://university.edu/papers/eda3436c-965b-442f-83d2-94e9b912fd69.pdf");
INSERT INTO Paper VALUES ("215","Automating quantum experiment control","The field of quantum information processing is rapidly advancing. As the control of quantum systems approaches the level needed for useful computation, the physical hardware underlying the quantum systems is becoming increasingly complex. It is already becoming impractical to manually code control for the larger hardware implementations. In this chapter, we will employ an approach to the problem of system control that parallels compiler design for a classical computer. We will start with a candidate quantum computing technology, the surface electrode ion trap, and build a system instruction language which can be generated from a simple machine-independent programming language via compilation. We incorporate compile time generation of ion routing that separates the algorithm description from the physical geometry of the hardware. Extending this approach to automatic routing at run time allows for automated initialization of qubit number and placement and additionally allows for automated recovery after catastrophic events such as qubit loss. To show that these systems can handle real hardware, we present a simple demonstration system that routes two ions around a multi-zone ion trap and handles ion loss and ion placement. While we will mainly use examples from transport-based ion trap quantum computing, many of the issues and solutions are applicable to other architectures.","2017","19","4","2025-12-02","https://university.edu/papers/c765d268-8fe6-4b9d-8fcc-43313b26b153.pdf");
INSERT INTO Paper VALUES ("216","MM-DSM: Multi-threaded Multi-home Distributed Shared Memory Systems","Most traditional Distributed Shared Memory (DSM) systems support data sharing in multi-process applications. This paper proposed a Multi-threaded Multi-home DSM system (MM-DSM) to support both data sharing and computation synchronization in multi-threaded applications whose threads are grouped into bundles and distributed across multiple computers for parallel execution. Globally shared data are rearranged and assigned to different thread bundles based on their access patterns. As thread bundles move around, their hosting nodes will act as the homes of the associated data blocks to reduce communication cost. Programmers can still stick to the shared memory programming paradigm whereas data consistency, distributed lock, false sharing and multiple writes are taken care of by MM-DSM. Experimental results demonstrate its effectiveness and correctness.","2009","5","2","2025-12-02","https://university.edu/papers/742563b9-efc4-4a01-b0a3-72f89b87b90a.pdf");
INSERT INTO Paper VALUES ("217","Network management with Intelligent Trader","The authors describe the concept of Intelligent Trader and the network management architecture based on it. First, we describe problems in the modern network system, from the viewpoint of network management. Next, we describe the similarity and difference between network management and application integration. Then we discuss the merits and problems of the application integration technique when applying it to network management. Finally, we propose the intelligent trader system which incorporates the application integration technique into the network management.","2000","16","2","2025-12-02","https://university.edu/papers/ebfed26f-066d-4357-986a-285c3eb46c24.pdf");
INSERT INTO Paper VALUES ("218","Trust Modeling in Cloud Computing","Though, cloud computing continues to gain popularity and has enormous economic gains, the perceived lack of trust from end-users accessing these resources continues to hinder its full deployment, usage and adoption. Tradition security and privacy controls continue to be implemented on cloud but due to its fluid and dynamic nature, research work in the area of end-user attestable trust evaluation of the cloud platform seem to be limited. With the nature of cloud, service level agreements are not enough, the user would want a transparent system with a traceability facility that allows the user to determine the relationship between varying trust relationships across the cloud layers, components, algorithms and applications especially at large scale. This paper presents some security mechanisms that enable cloud service end users to evaluate the trust level of various cloud services and resources. These mechanisms are evaluated based on fuzzy theory on a Eucalyptus cloud platform.","2016","17","3","2025-12-02","https://university.edu/papers/7ede0413-2004-4b56-964f-8cc8ecf1d1c4.pdf");
INSERT INTO Paper VALUES ("219","Instantaneous phase tracking of oscillatory signals using emd and Rao-Blackwellised particle filtering","A new method for instantaneous phase tracking of oscillatory signals in a narrow band frequency range is proposed. Empirical mode decomposition (EMD), as an adaptive and data-driven method for analyzing non-linear and non-stationary time series, is applied to a mixture of signals. Then, one of the resulted intrinsic mode functions (IMFs) is used for estimating the instantaneous phase of the signal in a certain frequency band. Since by applying EMD to the noisy signal the noise is distributed over the IMFs, the Rao-Blackwellised particle filtering (RBPF) is used to track the actual instantaneous phase from the noisy IMF. The formulated RBPF operates based on smoothing the instantaneous frequency traces in Hilbert domain and denoising the signal in time domain. Finally, the method is able to track the instantaneous phases across consecutive time points. The method is applied to both simulated and real data. As an application, it can be used for mental fatigue analysis based on the changes in phase synchronization of different brain rhythms in different brain regions before and during the fatigue state.","2011","16","4","2025-12-02","https://university.edu/papers/df7252d9-3196-4f88-9194-764c6c14c675.pdf");
INSERT INTO Paper VALUES ("220","Interactive Simulation of Digital Communication Systems","In this paper we describe efforts to develop a comprehensive tool for the digital simulation of a wide variety of point-to-point digital communication systems. These efforts have resulted in the interactive communications simulator (ICS); a flexible, graphics-oriented, and highly interactive hardware/software system consisting of a typical minicomputer acting as host to a fast peripheral array processor. This system is presently being employed both to evaluate existing modem performance and to explore new modulation/coding concepts appropriate for military, commercial, and space applications. A detailed functional description of the ICS is provided together with pertinent software considerations. An outline of existing ICS capabilities is presented and illustrated through typical, graphical output. A thorough discussion of channel modeling considerations is provided. The use of the ICS in the overall design of receiver structures for impulsive noise channels will be illustrated.","1984","11","4","2025-12-02","https://university.edu/papers/cd3c99db-e815-470c-af2e-2f301ae604d5.pdf");
INSERT INTO Paper VALUES ("221","Improved mapping of protein binding sites.","Summary Computational mapping methods place molecular probes – small molecules or functional groups – on a protein surface in order to identify the most favorable binding positions by calculating an interaction potential. Mapping is an important step in a number of flexible docking and drug design algorithms. We have developed improved algorithms for mapping protein surfaces using small organic molecules as molecular probes. The calculations reproduce the binding of eight organic solvents to lysozyme as observed by NMR, as well as the binding of four solvents to thermolysin, in good agreement with x-ray data. Application to protein tyrosine phosphatase 1B shows that the information provided by the mapping can be very useful for drug design. We also studied why the organic solvents bind in the active site of proteins, in spite of the availability of alternative pockets that can very tightly accommodate some of the probes. A possible explanation is that the binding in the relatively large active site retains a number of rotational states, and hence leads to smaller entropy loss than the binding elsewhere else. Indeed, the mapping reveals that the clusters of the ligand molecules in the protein’s active site contain different rotational-translational conformers, which represent different local minima of the free energy surface. In order to study the transitions between different conformers, reaction path and molecular dynamics calculations were performed. Results show that most of the rotational states are separated by low free energy barriers at the experimental temperature, and hence the entropy of binding in the active site is expected to be high.","2003","1","3","2025-12-02","https://university.edu/papers/835bf803-cfd4-47d0-8287-51e461bba28e.pdf");
INSERT INTO Paper VALUES ("222","Solving Goal Recognition Design Using ASP","Goal Recognition Design involves identifying the best ways to modify an underlying environment that agents operate in, typically by making asubset of feasible actions infeasible, so that agents are forced to reveal their goals as early as possible. Thus far, existing work has focused exclusively on imperative classical planning. In this paper, we address the same problem with a different paradigm, namely, declarative approaches based on Answer Set Programming (ASP). Our experimental results show that one of our ASP encodings is more scalable and is significantly faster by up to three orders of magnitude than thecurrent state of the art.","2016","4","2","2025-12-02","https://university.edu/papers/99070ac0-db80-46aa-9f4a-33a122040e29.pdf");
INSERT INTO Paper VALUES ("223","A novel DNN-HMM-based approach for extracting single loads from aggregate power signals","This paper presents a new supervised approach to extract the power trace of individual loads from single channel aggregate power signals in non-intrusive load monitoring (NILM) systems. Recent approaches to this source separation problem are based on factorial hidden markov models (FHMM). Drawbacks are the needed knowledge of HMM models for all loads, what is infeasible for large buildings, and the large combinatorial complexity. Our approach trains HMM with two emission probabilities, one for the single load to be extracted and the other for the aggregate power signal. A Gaussian distribution is used to model observations of the single load whereas observations of the aggregate signal are modeled with a Deep Neural Network (DNN). By doing so, a single load can be extracted from the aggregate power signal without knowledge of the remaining loads. The performance of the algorithm is evaluated on the Reference Energy Disag-gregation (REDD) dataset.","2016","2","1","2025-12-02","https://university.edu/papers/b9c543dc-9dd0-4d9a-8131-395fb94266a9.pdf");
INSERT INTO Paper VALUES ("224","Routing with Guaranteed Delivery on Virtual Coordinates","We propose four simple algorithms for routing on planar graphs using virtual coordinates. These algorithms are superior to existing algorithms in that they are oblivious, work also for non-triangular graphs, and their virtual coordinates are easy to construct.","2006","20","2","2025-12-02","https://university.edu/papers/c3374ec9-91c7-40df-a976-f94afad7c753.pdf");
INSERT INTO Paper VALUES ("225","A framework for design engineering education in a global context","This paper presents a framework for teaching design engineering in a global context using innovative technologies to enable distributed teams to work together effectively across international and cultural boundaries. The Digital Libraries for Global Distributed Innovative Design, Education, and Teamwork (DIDET) Framework represents the findings of a 5-year project conducted by the University of Strathclyde, Stanford University, and Olin College that enhanced student learning opportunities by enabling them to partake in global, team-based design engineering projects, directly experiencing different cultural contexts and accessing a variety of digital information sources via a range of innovative technology. The use of innovative technology enabled the formalization of design knowledge within international student teams as did the methods that were developed for students to store, share, and reuse information. Coaching methods were used by teaching staff to support distributed teams and evaluation work on relevant classes was carried out regularly to allow ongoing improvement of learning and teaching and show improvements in student learning. Major findings of the 5-year project include the requirement to overcome technological, pedagogical, and cultural issues for successful eLearning implementations. The DIDET Framework encapsulates all the conclusions relating to design engineering in a global context. Each of the principles for effective distributed design learning is shown along with relevant findings and suggested metrics. The findings detailed in the paper were reached through a series of interventions in design engineering education at the collaborating institutions. Evaluation was carried out on an ongoing basis and fed back into project development, both on the pedagogical and the technological approaches.","2010","17","2","2025-12-02","https://university.edu/papers/e5700207-1346-43a4-8eb1-27438efb4cfe.pdf");
INSERT INTO Paper VALUES ("226","On Cost-Aware Biased Respondent Group Selection for Minority Opinion Survey","This paper discusses a new approach to use a specially constructed social relation graph with high homophily to select a survey respondent group under a limited budget such that the result of the survey is biased to the minority opinions. This approach has a wide range of potential applications, e.g., collecting diversified complaints from the customers while most of them are satisfied, but is hardly investigated. We formulate the problem of computing such a group as the p-biased-representative selection problem (p-BRSP), where p represents the size of the group constraint by the available budget. This problem has two independent optimization goals and therefore is difficult to deal with. We introduce two polynomial time algorithms for the problem, where each of which has an approximation ratio with respect to each of the objectives when the other optimization objective is substituted with a constraint. Under the substituted constraint, we prove that the first algorithm is an O(lnΔ)-approximation (which is best possible) algorithm with respect to the first objective and the second algorithm is a 2-approximation (which is best possible) with respect to the second objective, where Δ is the degree of the input social relation graph.","2016","1","4","2025-12-02","https://university.edu/papers/dd5f6e95-8b01-4040-bc06-b318e555e426.pdf");
INSERT INTO Paper VALUES ("227","Analytic model for SDN controller traffic and switch table occupancy","Software Defined Networking (SDN) is a major paradigm in the field of current communication networks. SDN is used as the basis of many new networks although few performance models are available in the literature, and the majority of performance evaluations are based primarily on practical measurements. To fill this gap, we develop an analytical model to assess SDN control plane traffic as well as the occupancy of the flow table of an SDN switch. The contribution of this work is the formulation of the model for the performance-decisive parameters control-plane traffic and flow table occupancy and the application of the model for different data plane traffic characteristics. In the end, there is a discussion about the setting of time-out values for storing flow entries in the switch flow table depending on the traffic characteristics in the data plane. The trade-off between the signaling traffic in the control plane and the occupancy of the flow table is discussed to minimize both.","2016","14","4","2025-12-02","https://university.edu/papers/5fa20975-d4b3-4e40-9db2-9343722dfd7f.pdf");
INSERT INTO Paper VALUES ("228","Mapping the Early Modern News Flow: An Enquiry by Robust Text Reuse Detection","Early modern printed gazettes relied on a system of news exchange and text reuse largely based on handwritten sources. The reconstruction of this information exchange system is possible by detecting reused texts. We present a method to individuate text borrowings within noisy OCRed texts from printed gazettes based on string kernels and local text alignment. We apply our methods on a corpus of Italian gazettes for the year 1648. Beside unveiling substantial overlaps in news sources, we are able to assess the editorial policy of different gazettes and account for a multi-faceted system of text reuse.","2015","18","3","2025-12-02","https://university.edu/papers/c8a72b96-6c8e-4627-bccf-6219910da00f.pdf");
INSERT INTO Paper VALUES ("229","A Representation Model for Reusable Assets to Support User Context","In the field of software reuse, methods for storage and retrieval of software assets abound. However, these methods have limitations and fail to find the suitable reusable components or software assets that satisfy the requirements of a particular software system. We identify two problems to be the leading cause of this situation. One is the lack of accurate semantics for describing software assets. The other is the ignorance of user context in the query. In this paper we present an XML-based asset representation model which incorporates the user contextual information into the description of software assets that can be reused in the software development process. The proposed model provides semantic metadata for the user context in the asset description in order to build the foundation for semantic reasoning in the retrieval process.","2008","19","3","2025-12-02","https://university.edu/papers/d9a90b7a-8a67-425a-8490-92bf3bc32897.pdf");
INSERT INTO Paper VALUES ("230","Evaluating the iLoc indoor localization system: Competition outcomes and lessons learned","iLoc is an ultrasound ranging based indoor localization system deployed at the iHomeLab at Lucerne University of Applied Sciences and the Embedded Systems Lab at Stuttgart University of Applied Sciences. The system tracks humans in AAL scenarios which bear an ultrasound transmitter for example in the form of a name badge. The transmitter can be localized with an average accuracy well below 1 meter, by means of wired reference nodes distributed in the lab rooms. A small battery may suffice for several month of transmitter operation. The original deployment consists of wired nodes. Data and power is supplied via the IPoK fieldbus. Configuration data, i.e. node positions, are measured manually and entered in a database. The system participated at the first EvAAL competition 2011 and reached best accuracy score. iLoc+, A modified system comprising battery powered wireless nodes and an automatic configuration procedure was used at the second EvAAL Competition 2012. Both solutions are compared with focus on obtained accuracy and installation effort, using data from the respective competitions. Results of the comparison are discussed and possible optimizations are outlined. The implications may also be relevant for other positioning technologies in the AAL sector.","2015","8","4","2025-12-02","https://university.edu/papers/507b41ed-09d7-4651-9de0-4fec398b2fd8.pdf");
INSERT INTO Paper VALUES ("231","Paths to thought characterization-examination of user-defined graphic predictors","The SearchMap software encourages users to incorporate experience and intuition into decisions that involve multiple layers of map information. Users define search configurations, search distances, and interlayer weights, and they 'learn' from visual images, iterating search parameters until satisfied with the result. Successive sets of parameters record the thought paths of the user. In a gold exploration example, the thinking of an expert evolves to emphasize rock type, the presence of faulting, and occurrences of silver to locate gold deposits; de-emphasizing topography and the presence of arsenic as guides to ore. Correlating thought paths with brain function awaits expert input.","2000","6","3","2025-12-02","https://university.edu/papers/9ffa71cc-0414-41ff-9992-03563a84d97b.pdf");
INSERT INTO Paper VALUES ("232","A server centric authentication protocol for a RFID system","A large scale implementation of RFID technology in many practical applications including supply chain and retail stores require the resolution of the either-or dichotomy between low-cost RFID tags and secure RFID systems. This research proposes an approach in which the complexity and hence the cost of RFID tags can be drastically reduce by eliminating the security-assuring computational resources from the RFID tags and placing the security burden on the data processing server. This approach can make it possible to carry out secure transactions even with simple and inexpensive RFID tags. This research investigates a multiple ID authentication protocol based on this approach. The paper presents an empirical formula for the prediction of the performance of the protocol in terms of the number of spoofs per transaction for a given protocol configuration.","2009","3","4","2025-12-02","https://university.edu/papers/bab4ba8b-6652-4bda-97fa-b96aac83f89a.pdf");
INSERT INTO Paper VALUES ("233","A New Secure Data Deduplication Approach Supporting User Traceability","The notion of data deduplication enables a user to eliminate duplicate copies of data so that it can save the amount of storage space and network bandwidth. Convergent encryption, as the state-of-art approach, has been widely adopted to perform secure deduplication in the cross-user scenario. However, all the existing solutions cannot support user traceability. That is, there is no way to trace the identities of malicious users for instance in case a user performed a duplicate faking attack. To cope with this issue, in this paper, we propose a novel secure deduplication scheme supporting user traceability by incorporating traceable signatures with the state of the art deduplication technique, such as interactive randomized convergent encryption and proof of ownership.","2015","5","2","2025-12-02","https://university.edu/papers/5611be95-7128-4736-8b02-d4eecfcaedd4.pdf");
INSERT INTO Paper VALUES ("234","Comparison of discrete-time approximations for continuous-time nonlinear systems","This work addresses the problem of approximating the sampled input-output (i/o) behavior of continuous-time nonlinear systems using discrete-time Volterra models. For an exactly band-limited nonlinear system for which a Volterra representation exists, the discrete-time Volterra model exactly corresponds to the sampled continuous-time Volterra kernels. Physical systems, as they are causal, are never exactly band-limited. Thus, a modeling error is introduced. By relaxing the causality condition and allowing a small processing delay, it is shown through simulation that more accurate discrete-time Volterra models, compared to sampled continuous-time Volterra models, can be generated.","2004","13","1","2025-12-02","https://university.edu/papers/f2cddec6-c055-4d09-a737-9a30002a68d4.pdf");
INSERT INTO Paper VALUES ("235","A visual query system for the specification and scientific analysis of continual queries","The lack of a facility that would allow nonprogrammers to easily formulate temporal ad hoc analyses over a network of heterogeneous, constantly-updated data sources has been a significant impediment to research, particularly in the scientific community. In this paper we describe WebFormulate, an Internet-based system which facilitates the development of analyses using information obtained from databases on the Internet. The main distinction between this system and existing Internet facilities to retrieve information and assimilate it into computations is that WebFormulate provides the necessary facilities to perform continual queries, developing and maintaining dynamic links such that computations and reports automatically maintain themselves. A further distinction is that this system is specifically designed for users of spreadsheet-level ability, rather than professional programmers.","2001","8","4","2025-12-02","https://university.edu/papers/c3d62b48-ba2e-4b80-854a-f38c0b9ed13b.pdf");
INSERT INTO Paper VALUES ("236","Comparison of Several Difference Schemes on 1D and 2D Test Problems for the Euler Equations","The results of computations with eight explicit finite difference schemes on a suite of one-dimensional and two-dimensional test problems for the Euler equations are presented in various formats. Both dimensionally split and two-dimensional schemes are represented, as are central and upwind-biased methods, and all are at least second-order accurate.","2003","6","1","2025-12-02","https://university.edu/papers/a6e2a034-293f-44a8-9645-6854f17aa619.pdf");
INSERT INTO Paper VALUES ("237","A novel iterative method for computing generalized inverse","In this letter, we propose a novel iterative method for computing generalized inverse, based on a novel KKT formulation. The proposed iterative algorithm requires making four matrix and vector multiplications at each iteration and thus has low computational complexity. The proposed method is proved to be globally convergent without any condition. Furthermore, for fast computing generalized inverse, we present an acceleration scheme based on the proposed iterative method. The global convergence of the proposed acceleration algorithm is also proved. Finally, the effectiveness of the proposed iterative algorithm is evaluated numerically.","2014","15","4","2025-12-02","https://university.edu/papers/710e1f63-de7e-4c19-826e-182cd7a3b658.pdf");
INSERT INTO Paper VALUES ("238","22.6 A 22V compliant 56µW active charge balancer enabling 100% charge compensation even in monophasic and 36% amplitude correction in biphasic neural stimulators","Functional electrical stimulation (FES) is a technique that stimulates nerves by electrical charge, but carries the risk of charge accumulation, voltage pile-up, electrode corrosion and finally tissue destruction. Using biphasic stimulus current pulses, the main transferred charge is compensated by reversing the current direction. However, due to PVT variations in integrated circuits mismatch in the biphasic waveform always occurs. Charge balancing (CB) has thus become an integral part of FES to ensure safe chronic stimulation [1].","2016","11","4","2025-12-02","https://university.edu/papers/2a51fa0c-2fe3-42d7-8e7d-94305b1762f7.pdf");
INSERT INTO Paper VALUES ("239","Integrating trust management and access control in data-intensive Web applications","The widespread diffusion of Web-based services provided by public and private organizations emphasizes the need for a flexible solution for protecting the information accessible through Web applications. A promising approach is represented by credential-based access control and trust management. However, although much research has been done and several proposals exist, a clear obstacle to the realization of their benefits in data-intensive Web applications is represented by the lack of adequate support in the DBMSs. As a matter of fact, DBMSs are often responsible for the management of most of the information that is accessed using a Web browser or a Web service invocation.   In this article, we aim at eliminating this gap, and present an approach integrating trust management with the access control of the DBMS. We propose a trust model with a SQL syntax and illustrate an algorithm for the efficient verification of a delegation path for certificates. Our solution nicely complements current trust management proposals allowing the efficient realization of the services of an advanced trust management model within current relational DBMSs. An important benefit of our approach lies in its potential for a robust end-to-end design of security for personal data in Web scenario, where vulnerabilities of Web applications cannot be used to violate the protection of the data residing on the database server. We also illustrate the implementation of our approach within an open-source DBMS discussing design choices and performance impact.","2012","13","2","2025-12-02","https://university.edu/papers/9d9594cb-3e7f-4a9b-9978-a38011e3e308.pdf");
INSERT INTO Paper VALUES ("240","Link layer FEC for quality-of-service provision for Mobile Internet Services over DVB-S2","Abstract#R##N##R##N#This paper presents the performance that can be achieved when applying forward error correction (FEC) at the link layer (LL) level for Digital Video Broadcasting (DVB)-S2-based transmission to attain reliable reception in mobile environments. Our scenario of interest is the interactive railway scenario with two different channel assumptions: Line-of-Sight together with the effect of railway Power Archers (LOS+PA) and non-Line-of-Sight (nLOS). We analyze the performance and compatibility of the different LL-FEC schemes already available in the DVB family of standards: Multiple Protocol Encapsulation-FEC (MPE-FEC) and MPE Inter-Burst FEC (MPE-IFEC). We compare their performance when adopting Reed-Solomon (RS) or Raptor FEC Codes. Both theoretical and simulation analysis reveal that LL-FEC can overcome the fade in the railway scenario by selecting appropriate FEC codes. The solution finally adopted by the DVB-RCS+M standard is discussed and two cross-layer transmission architectures are presented that allow adaptive Quality-of-Service provision over generic LL encapsulation. Copyright © 2009 John Wiley & Sons, Ltd.","2010","2","3","2025-12-02","https://university.edu/papers/fda2430f-bc9f-4ef7-9f8f-e8aa69e41a38.pdf");
INSERT INTO Paper VALUES ("241","Students’ Perception of Different Learning Options and Use of Authentic Research Papers in a First Year Engineering Course","This case study presents a teaching strategy for an engineering dynamics course using a range of different learning options supporting different learning styles. The teaching strategy was implemented in a blended learning environment by combining traditional lectures with online resources. Additionally, hand-in assignments based on authentic research papers were introduced. Two sets of questionnaires were given to evaluate the students’ perception of the different learning options. The study shows that the students found online pencasts very useful as a means to increase the outcome of studying a traditional textbook. The implementation of an electronic audience response system to enhance active learning by peer instruction in combination with traditional lecturing was highly appreciated by the students. The students found it difficult and time consuming to work with real research papers but many students expressed that it was stimulating to see that the theory is used today by practitioners in engineering. Finally, the study indicates that the proposed teaching strategy as estimated by the students leads to increased motivation and engagement in their study.","2015","14","2","2025-12-02","https://university.edu/papers/84638d70-9f91-4bf0-b617-07ba240640a9.pdf");
INSERT INTO Paper VALUES ("242","Efficient embedded SoC hardware/software codesign using virtual platform","A complete framework and methodology to design, simulate, and debug large SoC is presented. Full VP creation using efficient tools is described. An efficient tool to allow co-debug of HW/SW on VP is also presented. The tools enable debugging and analyzing an application and a Linux driver that run on the VP. Breakpoints and mon commands can be used to detect and correct errors, access registers and review their values. The tools provide simulation of SW and HW on the same timeline. They also, involve building, uploading and debugging a Linux driver on the VP. The procedure steps for debugging the application code on the VP are provided. How to create an analyzer project with an analyzer session to perform SW and HW analysis, and save the results are also described. Functions and capabilities to investigate the tracing results are presented. Preparing the Environment of Linux Software Development with VP is needed before running the debug flow. How to prepare the system environment is summarized. Complex applications can run on the VP. Debugging both the application and the Linux drivers, and analyzing both the SW and the HW are made easy. Powerful SW tracing is provided. HW architecture analysis is an additional domain to be explored by the methodology. SW and HW profiling is shown to be not only feasible, but also handy. Very graphical waveforms and user friendly environment with easy Graphical User Interface (GUI) show how flexible and powerful the methodology is. A test case demonstrating the flexibility and efficiency of our technique is presented.","2014","9","1","2025-12-02","https://university.edu/papers/fa6ca100-2cf6-4e8a-9aaf-bb071ef0037f.pdf");
INSERT INTO Paper VALUES ("243","A unified theory for software production","Abstract#R##N##R##N#The central problem of software engineering, namely an overall strategy for the successful production of large-scale software, has not yet been solved. Various techniques do exist for separate sections of the production process, but largely owing to the huge costs involved, it is virtually impossible to perform controlled experiments to test their validity, or to compare competing methodologies.#R##N##R##N##R##N##R##N#One alternative way of deciding which techniques are to be preferred is to set up a science of software management, and to evaluate methodologies within its framework. This paper is a first step towards such a science. It notes similarities between certain techniques for structuring the programming group, the program modules, the testing process and the actual code itself. A theory is then deduced which enables programming managers to choose from among the wide selection of available techniques those which are applicable to the specific system to be written.","1982","4","1","2025-12-02","https://university.edu/papers/ff42850e-ae77-44f0-8997-27885108a978.pdf");
INSERT INTO Paper VALUES ("244","Access policy specification for Web applications","We show how access to Web resources may be controlled by using an access control program that implements a reactive agent. The agent reasons about the events, actions and a history (of events and actions) that relate to a user in order to make decisions about permitting the user to access information that is held on remote servers. The access control program is based on an abstract access control model that is formally specified as a clause form theory. Access policies may be efficiently implemented in a variety of practical languages.","2004","12","3","2025-12-02","https://university.edu/papers/894ff03b-3340-40d2-9c94-619a694e3a15.pdf");
INSERT INTO Paper VALUES ("245","Fast shadows and lighting effects using texture mapping","Generating images of texture mapped geometry requires projecting surfaces onto a two-dimensional screen. If this projection involves perspective, then a division must be performed at each pixel of the projected surface in order to correctly calculate texture map coordinates. We show how a simple extension to perspective-comect texture mapping can be used to create various lighting effects, These in- clude arbitrary projection of two-dimensional images onto geom- etry, realistic spotlights, and generation of shadows using shadow maps( 10). These effects are obtained in real time using hardware that performs correct texture mapping.","1992","1","2","2025-12-02","https://university.edu/papers/5cfb8158-03a7-4053-bb06-c33127276ca7.pdf");
INSERT INTO Paper VALUES ("246","Argus: A Multi-tenancy NoSQL store with workload-aware resource reservation","Multi-tenancy in cloud hosted NoSQL data stores is favored by cloud providers as it allows more effective resource sharing amongst different tenants thus lowering operating costs. A NoSQL provider will often present to each tenant a dedicated view of the store but then behind the scenes consolidate tenant access into a shared instance. This multi-tenancy approach with tenant data and workloads coexisting in the same infrastructure, under certain conditions can lead to performance degradation of one tenant caused by another as we show experimentally. This paper introduces Argus, a NoSQL store equipped with resource reservation to prevent performance interference across tenants in a multi-tenancy environment. Cache reservation is enforced through partitioning the cache space and disk reservation enforced through scheduling requests to a Distributed File System (DFS). We model the reservation on various workloads as a constrained optimization problem and use the stochastic hill climbing algorithm to find a near-optimum plan for different resource reservations. Empirical results show that Argus is able to prevent interference, adapt to dynamic workloads, and outperform A-Cache, another interference preventing NoSQL solution.","2016","10","2","2025-12-02","https://university.edu/papers/666dda69-44e8-4f1f-be2a-49fcfdafb909.pdf");
INSERT INTO Paper VALUES ("247","MOOE: A new online education mode: Virtual simulation experiment MOOE platform for FPGA","This paper proposed a new kind of online education mode, MOOE (Massive Open Online Experiment). MOOE was produced based on the thoughts of the Internet thinking and the opening-and-sharing resources and was the organic combination of MOOC and experimental teaching. The main contributions were made: (1) Instructed MOOE's concept and characteristics. MOOE build a network laboratory with the advanced information technology to make experimenters complete all the experimental activities through the Internet without the limitation of time, space and resources. (2) Analyzed the similarities and differences between MOOE and MOOC. MOOE was the extension and expansion of MOOC, which realized the online learning of all the teaching activities including the theoretical courses and their related experiments. MOOE inherited the advantaged of MOOC, but paid more attention to the virtualization of experimental equipment, operations and contents. (3) Described the implement and application of MOOE by taking an experimental course titled “FPGA Based Multi-core Computing” as an example. The feasibility and advantage of MOOE were proved by the actual statistical data of the course.","2016","18","1","2025-12-02","https://university.edu/papers/e16ca0bb-a4c2-4399-8fad-c55ac5e11f85.pdf");
INSERT INTO Paper VALUES ("248","Further results on LDPC decoding scheduling for faster convergence","This paper presents a listed maximum mutual information increase (LM2I2)-based algorithm, which is used to arrange low-density parity-check (LDPC) decoding schedules for faster convergence. The increments in the predicted mutual information for the messages to be updated is used to guide the arrangement of the fixed decoding schedule. Consequently, by looking ahead for several decoding stages, a high-order prediction can be realized. For each decoding stages, the searching branches can be trimmed to fit a predetermined size of list, and the efficiency in the selection of update candidates is thus increased. Comparing to previous algorithms, the proposed LM2I2-based algorithm can be used to arrange the decoding schedules converged in the same speed with lower complexity, or accelerate the convergence with the same computation cost.","2015","3","2","2025-12-02","https://university.edu/papers/2bda59f3-dbc5-45b2-8ecf-0c82b2b0613a.pdf");
INSERT INTO Paper VALUES ("249","Leakage power optimization in standard-cell designs","Leakage power consumption is a growing concern in integrated circuit design. Nanometer CMOS transistors are characterized by significant sub-threshold and gate leakage currents and feature size scaling is exacerbating this problem. In today's technologies (i.e., 90nm), sub-threshold leakage currents are still dominant with respect to gate currents (although the trend shows that the latter grows more rapidly as technology scales).In this talk, we will introduce a complete methodology for sub-threshold leakage current reduction based on the concept of sleep transistor insertion. Our insertion approach is layout-aware and it is fully compatible with industry-standard row-based layout styles and the supporting design tools. Sleep transistor cells are chosen from a library of cells that has been designed for high layout efficiency. These cells are inserted at the boundaries of existing cell rows, causing minimal disruption in placement and routing. The methodology ensures tight control of area and delay overheads, as it allows to selectively choose which gates in the netlist will be connetcted to the sleep transistors.The effectiveness of the sleep transistor insertion methodology has been benchmarked on a set of design examples for which a physical implementation was obtained through commercial EDA tools; the results we have achieved show a reduction of leakage power ranging from 74% to 83%, depending on the circuit.","2004","20","1","2025-12-02","https://university.edu/papers/8dba1116-369f-4db3-97a2-cf9ec281b013.pdf");
INSERT INTO Paper VALUES ("250","Capacity of Ultra-Wideband Power-Constrained Ad Hoc Networks","In this correspondence, we show that the uniform throughput capacity of an ultra-wideband (UWB) power-constrained ad hoc network is given by , where is the per-node power constraint, is the fading exponent of radio signal and is the number of nodes randomly distributed inside a disk of unit area. This is a stronger result than the upper bound and the lower bound previously shown by Negi and Rajeswaran. Our proof is simple given the prior work by Gupta and Kumar.","2008","10","2","2025-12-02","https://university.edu/papers/5b21de38-7a5f-4c00-987f-7f8ee1eeec83.pdf");
INSERT INTO Paper VALUES ("251","Using importance of transactions and optimistic concurrency control in firm real-time databases","In a real-time database system, it is difficult to meet all of the timing constraints due to the consistency requirements of the underlying database. However, when the transactions in the system are heterogeneous, they are not all of the same importance-some are of greater importance than others. In this paper, we propose a new protocol called OCC-PDATI (Optimistic Concurrency Control Protocol using Dynamic Adjustment of serialization order and Transaction Importance), which uses information about the importance of the transactions in the conflict resolution. Performance studies of our protocol have been carried out in a prototype real-time database system. The results clearly indicate that OCC-PDATI meets the goal of favoring transactions of high importance.","2000","18","2","2025-12-02","https://university.edu/papers/98c821e1-0633-484d-9ae8-854f274f9d4b.pdf");
INSERT INTO Paper VALUES ("252","Intersection Graphs of Rays and Grounded Segments","We consider several classes of intersection graphs of line segments in the plane and prove new equality and separation results between those classes. In particular, we show that: (1) intersection graphs of grounded segments and intersection graphs of downward rays form the same graph class, (2) not every intersection graph of rays is an intersection graph of downward rays, and (3) not every intersection graph of rays is an outer segment graph. The first result answers an open problem posed by Cabello and Jej\v{c}i\v{c}. The third result confirms a conjecture by Cabello. We thereby completely elucidate the remaining open questions on the containment relations between these classes of segment graphs. We further characterize the complexity of the recognition problems for the classes of outer segment, grounded segment, and ray intersection graphs. We prove that these recognition problems are complete for the existential theory of the reals. This holds even if a 1-string realization is given as additional input.","2016","2","2","2025-12-02","https://university.edu/papers/93000428-4794-4dc3-89e7-b21305245474.pdf");
INSERT INTO Paper VALUES ("253","Evolved reversible cascades realized on the CAM-brain machine","This paper presents a new approach to reversible cascade evolution based on a 3D cellular automaton. As a research platform we used the ATR's CAMBrain Machine (CBM). Reversible circuits are investigated because they are expected to dissipate much less energy than their irreversible counterparts. One day they will be implemented as nano-scale 3-dimensional chips. A circuit is reversible if the number of its inputs equals the number of its outputs and there is a one-to-one mapping between spaces of input vectors and output vectors. This paper provides: (1) a brief introduction to reversible logic concentrating on definitions and properties of the Feynman, Toffoli, Fredkin gates; (2) an introduction to the 3D cellular logic machine (CLM) that is a cellular automaton with frozen and pulsing state variables; and (3) a collection of reversible structures evolved using a dedicated GA and located in the CBM using the NeuroMaze 3.0 Pro, a software tool for computer-aided design of CBM-style structures.","2003","9","1","2025-12-02","https://university.edu/papers/6ab5dcf7-9d46-43ed-b41b-64f5f3c017fb.pdf");
INSERT INTO Paper VALUES ("254","Extracting fractal features for analyzing protein structure","This paper is concerned with the development of a computational methodology based on fractal geometry for determining 3D structure of protein with imagery projection operations. In this investigation, the density-map image is a 2D projection of the 3D electron density map according to its depth of the density distribution along the projection direction. We extract fractal features of the density-map image in a region and use these features to look for candidate regions with similar patterns of density-map. We analyze its fractal signatures for determining 3D pattern of regions of density distribution. This paper presents preliminary results of such a study, wherein the protein surface was assumed to be a fractal, and computed fractal features (fractal dimension and fractal signature) were analyzed and found to possess fairly reasonable pattern for improving the discrimination abilities of the protein structure.","2002","19","1","2025-12-02","https://university.edu/papers/b9441fe5-813b-42fe-b304-d7acff45b43b.pdf");
INSERT INTO Paper VALUES ("255","Coupling Strength Allocation for Synchronization in Complex Networks Using Spectral Graph Theory","Using spectral graph theory and especially its graph comparison techniques, we propose new methodologies to allocate coupling strengths to guarantee global complete synchronization in complex networks. The key step is that all the eigenvalues of the Laplacian matrix associated with a given network can be estimated by utilizing flexibly topological features of the network. The proposed methodologies enable the construction of different coupling-strength combinations in response to different knowledge about subnetworks. Adaptive allocation strategies can be carried out as well using only local network topological information. Besides formal analysis, we use simulation examples to demonstrate how to apply the methodologies to typical complex networks.","2014","19","4","2025-12-02","https://university.edu/papers/f17ecc80-b466-40da-bd5f-c53f0f5c4f91.pdf");
INSERT INTO Paper VALUES ("256","Automatic Test Wrapper Synthesis for a Wireless ATE Platform","To ensure reliable test data communication in a wireless test system, information can be encapsulated in packets equipped with error correction and retransmission capability. Systems employing such an approach require a complex test interface (test wrapper) to bridge communication and test modules. This article proposes a modular test wrapper design and an automation tool to create a wrapper for a target circuit under test and associated test program.","2010","2","1","2025-12-02","https://university.edu/papers/89ac29bd-fb33-4789-86a4-ea4ee89cca4b.pdf");
INSERT INTO Paper VALUES ("257","Constacyclic symbol-pair codes: lower bounds and optimal constructions","Symbol-pair codes introduced by Cassuto and Blaum (2010) are designed to protect against pair errors in symbol-pair read channels. The higher the minimum pair distance, the more pair errors the code can correct. MDS symbol-pair codes are optimal in the sense that pair distance cannot be improved for given length and code size. The contribution of this paper is twofold. First we present three lower bounds for the minimum pair distance of constacyclic codes, the first two of which generalize the previously known results due to Cassuto and Blaum (2011) and Kai {\it et al.} (2015). The third one exhibits a lower bound for the minimum pair distance of repeated-root cyclic codes. Second we obtain new MDS symbol-pair codes with minimum pair distance seven and eight through repeated-root cyclic codes.","2016","11","1","2025-12-02","https://university.edu/papers/dabeca07-edb8-4bae-b2ee-f7acc66663b1.pdf");
INSERT INTO Paper VALUES ("258","Simulating non-stationary congestion systems using splitting with applications to cyber security","According to the former counterterrorism czar, Richard A. Clarke (2010), our national infrastructure could be severely damaged in 15 minutes by a cyber attack. A worm attack on an Internet Protocol (IP) network is one type of attack that is possible. Such an attack would result in a non-stationary arrival process of packets on a link in the network. In this paper we present an initial use of our Optimal Splitting Technique for Rare Events (OSTRE) to simulate the congestion imposed by the worm on the link. This initial application is oriented to testing the technique in this dynamic environment and report on its use as compared with conventional simulations.","2010","10","1","2025-12-02","https://university.edu/papers/5a47a167-1275-4184-9077-b77595ca8317.pdf");
INSERT INTO Paper VALUES ("259","A sequence labeling approach to deriving word variants","This paper describes a learning-based approach for automatic derivation of word variant forms by the suffix-ation process. We employ the sequence labeling technique, which entails learning when to preserve, delete, substitute, or add a letter to form a new word from a given word. The features used by the learner are based on characters, phonetics, and hyphenation positions of the given word. To ensure that our system is robust to word variants that can arise from different forms of a root word, we generate multiple variant hypothesis for each word based on the sequence labeler's prediction. We then filter out ill-formed predictions, and create clusters of word variants by merging together a word and its predicted variants with other words and their predicted variants provided the groups share a word in common. Our results show that this learning-based approach is feasible for the task and warrants further exploration.","2015","12","3","2025-12-02","https://university.edu/papers/9a1da59c-5591-4d76-95f6-9eb8b15ce3ff.pdf");
INSERT INTO Paper VALUES ("260","Fixed-point square roots","Square root (SQRT) is a common arithmetic operation used in many DSP algorithms. In this paper, we evaluate square rooting methods suitable for implementation on fixed-point (FxP) DSP processors with a fast multiplying unit. The finite wordlength effect on the square rooting methods is highlighted, and it is shown that the theoretically derived convergence rate for the Newton-Raphson (NR) based square rooting methods are not suitable for FxP processor. Also, the most efficient methods for 8-bit and 16-bit FxP processors are identified.","2012","13","2","2025-12-02","https://university.edu/papers/6f899327-9358-4f81-8cd6-416c42004706.pdf");
INSERT INTO Paper VALUES ("261","Subband based classification of speech under stress","This study proposes a new set of feature parameters based on subband analysis of the speech signal for classification of speech under stress. The new speech features are scale energy (SE), autocorrelation-scale-energy (ACSE), subband based cepstral parameters (SC), and autocorrelation-SC (ACSC). The parameters' ability to capture different stress types is compared to widely used mel-scale cepstrum based representations: mel-frequency cepstral coefficients (MFCC) and autocorrelation-mel-scale (AC-mel). Next, a feedforward neural network is formulated for speaker-dependent stress classification of 10 stress conditions: angry, clear, cond50/70, fast, loud, lombard, neutral, question, slow, and soft. The classification algorithm is evaluated using a previously established stressed speech database (SUSAS) (Hansen and Bou-Ghazale 1997). Subband based features are shown to achieve +7.3% and +9.1% increase in the classification rates over the MFCC based parameters for ungrouped and grouped stress closed vocabulary test scenarios respectively. Moreover the average scores across the simulations of new features are +8.6% and +13.6% higher than MFCC based features for the ungrouped and grouped stress test scenarios respectively.","1998","11","4","2025-12-02","https://university.edu/papers/7181f4f2-9f9d-45c6-bb6a-d9c8fdd8e20f.pdf");
INSERT INTO Paper VALUES ("262","Energy optimization in unsynchronized TDD systems for joint uplink downlink scheduling","Energy is an important resource in wireless communications systems that has to be optimized in order to guarantee low interference in the network as well as efficient use of the available resources. One of the prominent options within the Long Term Evolution (LTE) standard is the Time Division Duplexing (TDD) option where both Uplink (UL) and Downlink (DL) share the same bandwidth and they are allocated on different times. One of the major problems in the practical implementation of TDD systems is that adjacent cells may have different loads for their UL and DL, so that the resources are allocated in a different portion between UL-DL. Such an unsynchronization among cells generates interference that downgrades the system performance. This paper calculates the optimum amount of energy that should be allocated to each entity in the system to mitigate the interference effect and to guarantee minimum Quality of Service (QoS) satisfaction at all receivers. Closed form expressions and computer simulations show the advantages of the proposed energy allocation scheme.","2013","12","2","2025-12-02","https://university.edu/papers/caa115a6-1891-43f3-86f0-6575ae5288f8.pdf");
INSERT INTO Paper VALUES ("263","A Student-Centered Approach to the Business School Management Science Course","We describe a student-centered approach for the required business school management science course. We articulate three principles for teaching management science to business students: real-world context, spreadsheet-native attitude, and student self-efficacy. We examine the implications of these principles and how they affect course content and delivery. We show how to establish relevance as perceived by business students. We highlight the business analysis lifecycle as a valuable 'roadmap' for students and instructors alike. We explain costs, benefits, and techniques for spreadsheet-native modeling. Spreadsheet modeling should be treated as a computer programming process, based on the properties of the spreadsheet programming language. We explain how and why to separate the modeling process from the act of typing into a spreadsheet. Spreadsheets can function as valuable organizational assets. We candidly discuss the challenges faced transitioning from a tools-based teaching approach to a student-centered approach.","2016","4","3","2025-12-02","https://university.edu/papers/ce649532-14e5-45c6-bff0-806d6e314bfb.pdf");
INSERT INTO Paper VALUES ("264","Multi-Task Rank Learning for Visual Saliency Estimation","Visual saliency plays an important role in various video applications such as video retargeting and intelligent video advertising. However, existing visual saliency estimation approaches often construct a unified model for all scenes, thus leading to poor performance for the scenes with diversified contents. To solve this problem, we propose a multi-task rank learning approach which can be used to infer multiple saliency models that apply to different scene clusters. In our approach, the problem of visual saliency estimation is formulated in a pair-wise rank learning framework, in which the visual features can be effectively integrated to distinguish salient targets from distractors. A multi-task learning algorithm is then presented to infer multiple visual saliency models simultaneously. By an appropriate sharing of information across models, the generalization ability of each model can be greatly improved. Extensive experiments on a public eye-fixation dataset show that our multi-task rank learning approach outperforms 12 state-of-the-art methods remarkably in visual saliency estimation.","2011","14","1","2025-12-02","https://university.edu/papers/924671a7-97dc-474d-b9c5-1cfd817253c2.pdf");
INSERT INTO Paper VALUES ("265","An architectural model of trees to estimate forest structural attributes using terrestrial LiDAR","Terrestrial lidar (TLiDAR) has been used increasingly over recent years to assess tree architecture and to extract metrics of forest canopies. Analysis of TLiDAR data remains a difficult task mainly due to the effects of object occlusion and wind on the quality of the retrieved results. We propose to link TLiDAR and tree structure attributes by means of an architectural model. The proposed methodology uses TLiDAR scans combined with allometric relationships to define the total amount of foliage in the crown and to build the tree branching structure. It uses the range (distance) and intensity information of the TLiDAR scans (i) to extract the stem and main branches of the tree, (ii) to reconstruct the fine branching structure at locations where the presence of foliage is very likely, and (iii) to use the availability of light as a criterion to add foliage in the center of the crown where TLiDAR information is sparse or absent due to occlusion effects. An optimization algorithm guides the model towards a realistic tree structure that fits the information gathered from TLiDAR scans and field inventory. The robustness and validity of the proposed model is assessed on five trees belonging to four different conifer species from natural forest environments. This approach addresses the data limitation of TLiDAR scans and aims to extract forest architectural metrics at different structural levels.","2011","17","2","2025-12-02","https://university.edu/papers/69a18680-0a31-4c5e-b7d0-bf92e7856b78.pdf");
INSERT INTO Paper VALUES ("266","Circular-Mellin features for texture segmentation","Texture is an important cue in region-based segmentation of images. We provide an insight into the development of a new set of distortion-invariant texture operators. These “circular-Mellin” operators are invariant to both scale and orientation of the target and represent the spectral decomposition of the image scene in the polar-log coordinate system. Coupled with the unique shift invariance property of the correlator architecture, we show that these circular-Mellin operators can be used for rotation-and scale-invariant feature extraction. We note that while these feature extractors have a functional form that is similar to the Gabor operators, they have distortion-invariant characteristics unlike the Gabor functions that make them more suitable for texture segmentation. A detailed analytical description of these operators and segmentation results to highlight their salient properties are presented","1995","1","4","2025-12-02","https://university.edu/papers/f8fc3297-a97a-4407-ab78-3a65197fc9bd.pdf");
INSERT INTO Paper VALUES ("267","Design and performance analysis of MAC schemes for Wireless Sensor Networks Powered by Ambient Energy Harvesting","Energy consumption is a perennial issue in the design of wireless sensor networks (WSNs) which typically rely on portable sources like batteries for power. Recent advances in ambient energy harvesting technology have made it a potential and promising alternative source of energy for powering WSNs. By using energy harvesters with supercapacitors, WSNs are able to operate perpetually until hardware failure and in places where batteries are hard or impossible to replace. In this paper, we study the performance of different medium access control (MAC) schemes based on CSMA and polling techniques for WSNs which are solely powered by ambient energy harvesting using energy harvesters. We base the study on (i) network throughput (S), which is the rate of sensor data received by the sink, (ii) fairness index (F), which determines whether the bandwidth is allocated to each sensor node equally and (iii) inter-arrival time (@c) which measures the average time difference between two packets from a source node. For CSMA, we compare both the slotted and unslotted variants. For polling, we first consider identity polling. Then we design a probabilistic polling protocol that takes into account the unpredictability of the energy harvesting process to achieve good performance. Finally, we present an optimal polling MAC protocol to determine the theoretical maximum performance. We validate the analytical models using extensive simulations incorporating experimental results from the characterization of different types of energy harvesters. The performance results show that probabilistic polling achieves high throughput and fairness as well as low inter-arrival times.","2011","16","1","2025-12-02","https://university.edu/papers/971bf00c-73b3-4c00-ba3f-8deedb0331f8.pdf");
INSERT INTO Paper VALUES ("268","Gradient independent translation via differential morphology","A new multi-scale image enhancement mechanism is presented. Derived from the differential representation of the morphological filters, it approximates a median filter and alleviates many of the image blotching and noise preserving characteristics of morphological filtering. In one-dimension, the process is shown to be idempotent and to converge. In two dimensions, experimental results demonstrate convergence and display the ability to remove impulsive noise. Gradient independent translation avoids the two dimensional convergence problems of the median filter and does not involve the expensive rank-ordering of pixel intensities. Describing a scale space with median filter characteristics, it provides a multi-scale analysis method suitable for compression, coding, and feature extraction.","1998","10","2","2025-12-02","https://university.edu/papers/8e8fe7a8-8dee-4beb-bcd5-47027f7c5eee.pdf");
INSERT INTO Paper VALUES ("269","Sky/ground modeling for autonomous MAV flight","Recently, we have implemented a computer-vision based horizon-tracking algorithm for flight stability and autonomy in micro air vehicles (MAVs) [S. M. Ettinger et al., 2002]. Occasionally, this algorithm fails in scenarios where the underlying Gaussian assumption for the sky and ground appearances is not appropriate. Therefore, in this paper, we present a general statistical image modeling framework which we have use to build prior models of the sky and ground. Once trained, these models can be incorporated into our existing horizon-tracking algorithm. Since the appearances of the sky and ground vary enormously, no single feature is sufficient for accurate modeling: as such, we rely both on color and texture as critical features in our modeling framework. Specifically, we choose hue and intensity for our color representation, and the complex wavelet transform (CWT) for our texture representation. We then use hidden Markov tree (HMT) models, which are particularly well suited for the CWT's inherent tree structure, as our underlying statistical models over our feature space. With this approach, we have achieved reliable and robust image segmentation of flight images from on-board our MAVs as well as on more difficult-to-classify sky/ground images.","2003","5","4","2025-12-02","https://university.edu/papers/c9c7fab7-98b3-4373-ac4a-2ab883105234.pdf");
INSERT INTO Paper VALUES ("270","A novel conjugate gradient-based source localization algorithm","A new method for the subspace-based direction of arrival (DOA) estimation procedure without eigenvector computation is proposed. From the residual vectors of the conjugate gradient (CG) method which form a Krylov subspace basis, we build a test spectrum for DOA estimation. This approach is based on the same recently developed procedure which uses a non-eigenvector basis derived from the auxiliary vectors (AV). The AV basis calculation algorithm is replaced by the residual vectors of the CG algorithm. The initial conditions of the CG algorithm start with the linear transformation of the array response search vector by the input covariance matrix. Then, successive orthogonal gradient vectors are derived to form a basis of the signal subspace. The proposed CG-based method outperforms its counterparts in term of resolution of closely spaced-sources with a small number of snapshots and a low signal-to-noise ratio (SNR).","2007","3","1","2025-12-02","https://university.edu/papers/b75ef012-c7ee-4918-b5e9-92b6410881da.pdf");
INSERT INTO Paper VALUES ("271","A contrario patch matching, with an application to keypoint matches validation","© 2015 IEEE.We describe a simple metric for image patches similarity, together with a robust criterion for unsupervised patch matching. The gradient orientations at corresponding positions in the two patches are compared and the normalized errors are accumulated. Based on the a contrario framework, the matching criterion validates a match between two patches when this cumulative error is too small to have occurred as the result of an accidental agreement. The method is illustrated in the validation of keypoint matches.","2015","8","2","2025-12-02","https://university.edu/papers/dd91f831-f69b-45c6-a86d-da1116f9d701.pdf");
INSERT INTO Paper VALUES ("272","An evaluation of multimodal 2D+3D face biometrics","We report on the largest experimental study to date in multimodal 2D+3D face recognition, involving 198 persons in the gallery and either 198 or 670 time-lapse probe images. PCA-based methods are used separately for each modality and match scores in the separate face spaces are combined for multimodal recognition. Major conclusions are: 1) 2D and 3D have similar recognition performance when considered individually, 2) combining 2D and 3D results using a simple weighting scheme outperforms either 2D or 3D alone, 3) combining results from two or more 2D images using a similar weighting scheme also outperforms a single 2D image, and 4) combined 2D+3D outperforms the multi-image 2D result. This is the first (so far, only) work to present such an experimental control to substantiate multimodal performance improvement.","2005","5","2","2025-12-02","https://university.edu/papers/a009f819-ca2d-47d4-812e-20f02876c950.pdf");
INSERT INTO Paper VALUES ("273","Addressing complexity, coordination, and automation in software development with the KBSA/ADM","This paper describes how the Knowledge-Based Software Assistant/Advanced Development Model brings together technologies from the KBSE domain along with more traditional software engineering practices in order to address the pervasive software development problems associated with complexity coordination, and automation. This paper describes how the KBSA/ADM realizes and refines the vision of Rome Laboratory's Knowledge-Based Software Assistant research program. The most innovative aspects of this work have been in the areas of contextual knowledge (i.e., design history, discussion databases, and object linking), process support (i.e., personalized agendas and process enactment), evolution transformations (i.e., transformations which automate stereotypical changes to a model), and critics (i.e., integrating intelligent analysis with process enactment).","1996","17","3","2025-12-02","https://university.edu/papers/83454302-068d-4b19-92ef-9c24795c75c1.pdf");
INSERT INTO Paper VALUES ("274","Output-feedback stabilization of the wave equation with spatially varying propagation speed","For the wave equation with spatially varying wave propagation speed coefficient, output feedback stabilization by boundary control is considered. Controllers and an observer are designed through the backstepping method to achieve exponential stabilization of the closed-loop system.","2010","15","2","2025-12-02","https://university.edu/papers/7b27ce4a-137b-45a9-984d-57e9f6f18da7.pdf");
INSERT INTO Paper VALUES ("275","Mean-driven and fluctuation-driven persistent activity in recurrent networks","Spike trains from cortical neurons show a high degree of irregularity, with coefficients of variation (CV) of their interspike interval (ISI) distribution close to or higher than one. It has been suggested that this irregularity might be a reflection of a particular dynamical state of the local cortical circuit in which excitation and inhibition balance each other. In this 'balanced' state, the mean current to the neurons is below threshold, and firing is driven by current fluctuations, resulting in irregular Poisson-like spike trains. Recent data show that the degree of irregularity in neuronal spike trains recorded during the delay period of working memory experiments is the same for both low-activity states of a few Hz and for elevated, persistent activity states of a few tens of Hz. Since the difference between these persistent activity states cannot be due to external factors coming from sensory inputs, this suggests that the underlying network dynamics might support coexisting balanced states at different firing rates. We use mean field techniques to study the possible existence of multiple balanced steady states in recurrent networks of current-based leaky integrate-and-fire (LIF) neurons. To assess the degree of balance of a steady state, we extend existing mean-field theories so that not only the firing rate, but also the coefficient of variation of the interspike interval distribution of the neurons, are determined self-consistently. Depending on the connectivity parameters of the network, we find bistable solutions of different types. If the local recurrent connectivity is mainly excitatory, the two stable steady states differ mainly in the mean current to the neurons. In this case, the mean drive in the elevated persistent activity state is suprathreshold and typically characterized by low spiking irregularity. If the local recurrent excitatory and inhibitory drives are both large and nearly balanced, or even dominated by inhibition, two stable states coexist, both with subthreshold current drive. In this case, the spiking variability in both the resting state and the mnemonic persistent state is large, but the balance condition implies parameter fine-tuning. Since the degree of required fine-tuning increases with network size and, on the other hand, the size of the fluctuations in the afferent current to the cells increases for small networks, overall we find that fluctuation-driven persistent activity in the very simplified type of models we analyze is not a robust phenomenon. Possible implications of considering more realistic models are discussed.","2007","11","3","2025-12-02","https://university.edu/papers/ada70660-6608-4639-a737-8a16aeb26cad.pdf");
INSERT INTO Paper VALUES ("276","Preservation research and sustainable digital libraries","The National Science Foundation and DELOS , the European Commission sponsored Network for Digital Libraries, supported a working group to define a research agenda for digital archiving and preservation (DAP-WG) within the context of digital libraries. The report of this group, Invest to Save, has laid out a range of research challenges that need to be addressed if we are to make progress in the development of sustainable digital libraries. DAP-WG considered archiving and preservation needs and the research that had been conducted to address these. It concluded that research in this domain could benefit from being expanded and refocused--new research communities must be engaged, the approaches to conducting the research must be made more rigorous, and a significant shift in what was being researched needed to be taken. The Group identified twenty-two key research activities worthy of investigation.","2005","12","4","2025-12-02","https://university.edu/papers/696bbe4d-b06f-45ce-88c5-050150dfb704.pdf");
INSERT INTO Paper VALUES ("277","Piecewise Linear Models with Guaranteed Closeness to the Data","This paper addresses the problem of piecewise linear approximation of point sets without any constraints on the order of data points or the number of model components (line segments). We point out two problems with the maximum likelihood estimate (MLE) that present serious drawbacks in practical applications. One is that the parametric models obtained using a classical MLE framework are not guaranteed to be close to data points. It is typically impossible, in this classical framework, to detect whether a parametric model fits the data well or not. The second problem is related to accurately choosing the optimal number of model components. We first fit a nonparametric density to the data points and use it to define a neighborhood of the data. Observations inside this neighborhood are deemed informative; those outside the neighborhood are deemed uninformative for our purpose. This provides us with a means to recognize when models fail to properly fit the data. We then obtain maximum likelihood estimates by optimizing the Kullback-Leibler Divergence (KLD) between the nonparametric data density restricted to this neighborhood and a mixture of parametric models. We prove that, under the assumption of a reasonably large sample size, the inferred model components are close to their ground-truth model component counterparts. This holds independently of the initial number of assumed model components or their associated parameters. Moreover, in the proposed approach, we are able to estimate the number of significant model components without any additional computation.","2009","2","4","2025-12-02","https://university.edu/papers/e6129288-5b73-493d-82a0-d9e9258bb897.pdf");
INSERT INTO Paper VALUES ("278","Tracking with Bayesian networks: extension to arbitrary topologies","It was recently proposed an object tracking method, which is able to deal with object occlusions and group tracking, using Bayesian networks. The Bayesian network (BN) tracker has shown promising results in difficult situations but its architecture is limited to a maximum of 2 parents/2 children per node, in order to avoid the combinatorial explosion and difficult network generation procedures from the video signal. This paper addresses the major limitation of the BN tracker and presents a method to generalize the tracker to cope with arbitrary topologies, allowing the tracker to operate in more complex scenes.","2005","8","2","2025-12-02","https://university.edu/papers/6013cafe-59d1-4f02-be09-03c0a2b97e56.pdf");
INSERT INTO Paper VALUES ("279","Vibrotactile rendering for simulating virtual environment in a mobile game","Vibrotactile rendering is a process of computing and generating haptic information in response to a user's interaction with virtual objects. The crucial procedure in the vibrotactile rendering is to transform the simulated behavior of a virtual object into vibrotactile information according to user's action. This paper presents a vibrotactile rendering method that expresses the reaction of a car on a road surface in a racing game using vibrotactile information. To this end, we first design a miniaturized vibrotactile rendering system with an eccentric vibration motor and a solenoid actuator, which generates vibrotactile information having a large bandwidth and amplitude. We also construct an interactive racing game as a test bed for the proposed vibration rendering method. We designed voltage input patterns that can be haptically discriminated by human for experiments. The proposed vibrotactile rendering based on these patterns generates control input to vibrotactile actuators to make users realistically feel the sensation of collision, driving on a bump, driving on a hard shoulder. To evaluate the proposed vibrotactile rendering method, nine persons experience two kind of racing games: one is the game with the proposed vibrotactile rendering, and the other is the game without the vibrotactile rendering. After the experiment, participants are asked to compare and appraise those two games based on suggested criteria. The experiment clearly shows the effectiveness and the feasibility of the proposed vibrotactile rendering method, which implies the sufficient applicability of the proposed vibrotactile rendering system to mobile devices","2006","20","1","2025-12-02","https://university.edu/papers/7088b337-f37f-403d-9dff-2089b66a4d6c.pdf");
INSERT INTO Paper VALUES ("280","Soft capacity modeling for WCDMA radio resource management","This work addresses wireless capacity models and capacity consumption models for 3G WCDMA system analysis. Uplink and downlink capacities are viewed as multiple heterogeneous circuit-switched and packet-switched pools of various bit rate channels, wherein traffic channels and control channels contend for the same capacity within a cell. An individual user's consumption of capacity is formulated as a function of the user's traffic class, activity factor and negotiated QoS. Simulation based analysis, of resource management algorithms that employ admission control and channel rate- and type-switching, are undertaken to compare results obtained using the proposed capacity and capacity consumption models to that obtained using existing homogeneous models. The primary results demonstrate that differentiating between channel modes, giving consideration to control channel utilization, and giving consideration to user's service type can each significantly impact the results and conclusions drawn from resource management protocol analysis.","2003","5","4","2025-12-02","https://university.edu/papers/efd21e04-8186-466b-9079-08b145bbb6fe.pdf");
INSERT INTO Paper VALUES ("281","Drifting technologies and multi-purpose networks: the case of the Swedish cashcard","In this paper, we combine two theories of the dynamics of a large socio-technical system — technology drift and actor-network theory — to address how and why information technologies often need to change, relative to their initial conceptions, during implementation. We analyze the failure of the first introduction of electronic cash in Umea˚, Sweden as an example of what happens when drift does not occur: the lack of drift resulted in the socio-technical system’s failure to stabilize. Lack of flexibility is identified as an important reason for the card’s poor public acceptance. Banks ignored the critical comments of merchants, thus refusing to negotiate about the intended role of the technology. The cards were perceived as serving only the needs of the banks, while ignoring the needs of merchants and card users. Based on the findings in this case study, we argue that in order for a socio-technical system to stabilize it must drift from a single-purpose network, reflecting the interest and agenda of its designers/originators, to a multi-purpose network that reflects the interests of all involved social actors. In addition, we argue that a network-building process can be successful only if the network is flexible enough to serve the multiple purposes of its constituent actors. ! 2001 Published by Elsevier Science Ltd.","2001","4","1","2025-12-02","https://university.edu/papers/a16157b5-453a-42fc-b648-b6fc8ae0c0b5.pdf");
INSERT INTO Paper VALUES ("282","A Fully Integrated EPC Gen-2 UHF-Band Passive Tag IC Using an Efficient Power Management Technique","We present a system-on-chip passive tag integrated circuit (IC) for secure near-field RF identification applications. The design of the RF transceiver and the digital control of the tag IC are based on the EPCglobal ultrahigh-frequency Gen-2 protocol. A new design technique for the power management of the tag IC is presented, which includes a low-voltage bandgap, a low-dropout regulator with a bias-boosted gain stage, and an adaptive dc limiter. With the proposed design technique, we achieve a high power conversion efficiency of 47% at a low input power of -12 dBm. To support data security, we use one-time programmable (OTP) memory for nonvolatile data storage. The 4-kb (256 × 16 b) OTP memory array is based on a two-transistor (2-T) gate-oxide antifuse that can be programmed with a voltage of less than 6 V. The tag chip was fabricated in a 1-poly 6-metal standard 0.13- μm CMOS process. The power consumption levels of the tag IC are 29.2 and 71.2 μW for the read and programming modes, respectively. The size of the tag chip is 1.1×1 mm 2 .","2014","5","3","2025-12-02","https://university.edu/papers/7663c1d3-8cb1-49c4-bd5c-4320e4b27290.pdf");
INSERT INTO Paper VALUES ("283","Optimal Linear Combination of Facial Regions for Improving Identification Performance","This paper presents a novel 3D multiregion face recognition algorithm that consists of new geometric summation invariant features and an optimal linear feature fusion method. A summation invariant, which captures local characteristics of a facial surface, is extracted from multiple subregions of a 3D range image as the discriminative features. Similarity scores between two range images are calculated from the selected subregions. A novel fusion method that is based on a linear discriminant analysis is developed to maximize the verification rate by a weighted combination of these similarity scores. Experiments on the Face Recognition Grand Challenge V2.0 dataset show that this new algorithm improves the recognition performance significantly in the presence of facial expressions.","2007","18","1","2025-12-02","https://university.edu/papers/a44e7fed-d961-4d33-812a-845c0424f0bd.pdf");
INSERT INTO Paper VALUES ("284","Mitigation of outdoor insulators failure using silicone coating","Insulator is one of the most important equipments in an electric power system. Since long time ago ceramic insulators are widely used in transmission as well as in distribution lines. As outdoor insulators, the insulators are subjected to outdoor environmental stresses such as humidity, temperature and pollution. Under polluted and wet condition, high leakage current may flow on the insulator surface. As the result a dry band arching may take place and in the long time it may degrade the insulator and initiate the insulator flash over leading to the failure of the lines. Several efforts may be taken to improve the insulator performance under polluted condition. They are increasing the number of insulator strings, modification of insulator design to increase the creepage distance and regular washing. This paper reports a proposal to mitigate the outdoor insulator failure using silicone coating. This paper explains the experimental results on the silicone compound coating on the medium voltage ceramic insulators under various environmental condition. It was found that the coating was significantly suppressed the magnitude of leakage current and drastically eliminated the harmonic content. The coating also drastically suppressed the corona on the insulator and reduced the surface temperature. The coating also significantly increased the flash over voltage of the insulator. Surface analysis indicated that increasing of the water repellence of the insulators played important role in the increase of the insulator performance.","2011","16","1","2025-12-02","https://university.edu/papers/b07a9497-088b-4e57-bb4e-1d1fa516ba14.pdf");
INSERT INTO Paper VALUES ("285","Performance Evaluation of OpenACC Compilers","The OpenACC standard joint effort represents a step forward in the way of alleviating the programming effort when exploiting heterogeneous HPC using hardware accelerators. The lack of OpenACC annotated codes is a drawback for the adoption of the standard. Before real life OpenACC codes become available, benchmarking with synthetic codes is a useful tool to evaluate compilers and the OpenACC standard itself. In this work we use the recently published EPCC OpenACC benchmark suite to evaluate available OpenACC compilers from both industry and academia. We present computational result for the benchmark using both Fermi and Kepler NVIDIA architectures.","2014","15","3","2025-12-02","https://university.edu/papers/f332402e-427c-4cf4-9c35-1e91d645493b.pdf");
INSERT INTO Paper VALUES ("286","A method for one-dimensional topological entity matching in integration of heterogeneous CAD systems","In the feature modeling procedure, one-dimensional topological entities (edges) are always used as references or operational objects. Hence, to realize the integration of heterogeneous CAD systems, the corresponding one-dimensional topological entities must be found in the target CAD system to match the source ones. This paper presents a method to gain one-dimensional topological entity matching. The method is based on two algorithms, i.e. combining algorithm and matching algorithm. The combining algorithm is adopted to combine the edges retrieved in a source CAD system. Then, for each combined edge, the matching edges are found by using the matching algorithm in a target CAD system. The experiments prove that our method is valid for both offline and online integrations.","2011","6","3","2025-12-02","https://university.edu/papers/f8631b6c-43f7-434a-b02c-97abbfdc52e3.pdf");
INSERT INTO Paper VALUES ("287","Mini-max integral sliding-mode control for multimodel linear uncertain systems","An original linear time-varying system with matched and unmatched disturbances and uncertainties is replaced by a finite set of dynamic models such that each one describes a particular uncertain case including exact realizations of possible dynamic equations as well as external unmatched bounded disturbances. Such a tradeoff between an original uncertain linear time varying dynamic system and a corresponding higher order multimodel system containing only matched uncertainties leads to a linear multi-model system with known unmatched bounded disturbances and unknown matched disturbances as well. Each model from a given finite set is characterized by a quadratic performance index. The developed minimax integral sliding mode control strategy gives an optimal minimax linear quadratic (LQ)-control with additional integral sliding mode term. The design of this controller is reduced to a solution of an equivalent mini-max LQ problem that corresponds to the weighted performance indices with weights from a finite dimensional simplex. The additional integral sliding mode controller part completely dismisses the influence of matched uncertainties from the initial time instant. Two numerical examples illustrate this study.","2004","6","1","2025-12-02","https://university.edu/papers/a3b0aa8e-8d0b-4640-9722-57272f863128.pdf");
INSERT INTO Paper VALUES ("288","On fair e-cash systems based on group signature schemes","A fair electronic cash system is a system that allows customers to make payments anonymously. Moreover, under certain circumstances, a trusted authority can revoke the anonymity of suspicious transactions. Various fair e-cash systems using group signature schemes have been proposed [4,15,16,18]. Unfortunately, they do not realize coin tracing [4,15,18] (the possibility to trace the coins withdrawn by a customer). In this paper, we describe several failures in the solution of [16] and we present a secure and efficient fair e-cash system based on a group signature scheme. Our system ensures traceability of double-spenders, supports coin tracing and provides coins that are unforgeable and anonymous under standard assumptions.","2003","9","3","2025-12-02","https://university.edu/papers/8469f724-16e7-4410-8394-b39a68aab3a5.pdf");
INSERT INTO Paper VALUES ("289","Stochastic Convex Optimization with Multiple Objectives","In this paper, we are interested in the development of efficient algorithms for convex optimization problems in the simultaneous presence of multiple objectives and stochasticity in the first-order information. We cast the stochastic multiple objective optimization problem into a constrained optimization problem by choosing one function as the objective and try to bound other objectives by appropriate thresholds. We first examine a two stages exploration-exploitation based algorithm which first approximates the stochastic objectives by sampling and then solves a constrained stochastic optimization problem by projected gradient method. This method attains a suboptimal convergence rate even under strong assumption on the objectives. Our second approach is an efficient primal-dual stochastic algorithm. It leverages on the theory of Lagrangian method in constrained optimization and attains the optimal convergence rate of O(1/√T) in high probability for general Lipschitz continuous objectives.","2013","12","1","2025-12-02","https://university.edu/papers/d830d25a-123b-4b29-8946-f4db27f60307.pdf");
INSERT INTO Paper VALUES ("290","Robust Measurement Validation in Target Tracking Using Geometric Structure","Selection schemes for forming data validation regions for target tracking are discussed in this paper. We develop a novel algorithm, less sensitive to gate size than conventional approaches. This new gate selection method combines a conventional threshold based algorithm with a geometric metric measure based on the  Voronoi diagram . An adaptive search based on the Voronoi measure is then used to select valid data points for target tracking.","2010","3","2","2025-12-02","https://university.edu/papers/922a3b47-76dd-4898-9391-099322e4465f.pdf");
INSERT INTO Paper VALUES ("291","Knowledge Mediation: A Procedure for the Cooperative Construction of Domain Ontologies","In order to enable knowledge sharing and reuse among software entities, artificial intelligence researchers have proposed to develop 'ontologies' as the explicit formal specifications of conceptualizations. These ontologies were normally designed by knowledge engineers who laid down the basic categories and relations for a certain domain. However, in any practical setting there will be conflicting interests which pertain to different conceptualizations of which a knowledge engineer will usually not be aware of. For this reason, we propose a three-phased ontology construction procedure in which the knowledge engineer mediates between the differing conceptions experts or users may hold about a knowledge domain. This procedure is described in detail in this paper and subsequently empirically demonstrated and evaluated in a study with 28 participants. The evaluation reveals convincing advantages of the proposed knowledge mediation procedure. We conclude that an ontology construction process is not only an engineering task but more importantly also a social process where the relevant parties for example of a work place need to be involved before successful and durable solutions can be","2004","15","3","2025-12-02","https://university.edu/papers/c8601446-187f-472c-9509-8489ee36ed0b.pdf");
INSERT INTO Paper VALUES ("292","Novel second-language words and asymmetric lexical access","The lexical and phonetic mapping of auditorily confusable L2 nonwords was examined by teaching L2 learners novel words and by later examining their word recognition using an eye-tracking paradigm. During word learning, two groups of highly proficient Dutch learners of English learned 20 English nonwords, of which 10 contained the English contrast /e/-ae/ (a confusable contrast for native Dutch speakers). One group of subjects learned the words by matching their auditory forms to pictured meanings, while a second group additionally saw the spelled forms of the words. We found that the group who received only auditory forms confused words containing /ae/ and /e/ symmetrically, i.e., both /ae/ and /e/ auditory tokens triggered looks to pictures containing both /ae/ and /e/. In contrast, the group who also had access to spelled forms showed the same asymmetric word recognition pattern found by previous studies, i.e., they only looked at pictures of words containing /e/ when presented with /e/ target tokens, but looked at pictures of words containing both /ae/ and /e/ when presented with /ae/ target tokens. The results demonstrate that L2 learners can form lexical contrasts for auditorily confusable novel L2 words. However, and most importantly, this study suggests that explicit information over the contrastive nature of two new sounds may be needed to build separate lexical representations for similar-sounding L2 words.","2008","16","3","2025-12-02","https://university.edu/papers/cabdf49c-dbbd-487a-84de-9ddba30056e9.pdf");
INSERT INTO Paper VALUES ("293","The BluePost - a smart car heating system","The BluePost is an enhanced car heating post, an electrical distribution box used for heating car engines during cold weather. We saw a need for enhancement of current models, since the design has been relatively unchanged for decades and the user interface is somewhat restricted to simple mechanical on/off control. The BluePost provides additional functionality and a more intuitive user interface, and its energy saving features helps us to save electricity. The BluePost features wireless control and a distributed architecture, utilising both embedded systems and wireless networks.","2005","15","2","2025-12-02","https://university.edu/papers/b4ca60b6-50ea-4a85-b726-6f0b434ddd45.pdf");
INSERT INTO Paper VALUES ("294","Stability analysis of self-sensing magnetic bearing controllers","The controllers designed for position-sensorless voltage-controlled active magnetic bearings (AMBs) are investigated from the viewpoint of strong stabilization. First, magnetic bearings with laminated iron cores are treated in which the effects of eddy currents are negligible. It is shown that full- and reduced-order observer-based stabilizing controllers differ in stability; any reduced-order observer-based stabilizing controller is always unstable while most of the full-order observer-based stabilizing controllers are stable. Second, self-sensing suspension in magnetic bearings with solid iron cores is discussed. It is shown that the full-order observer-based stabilizing controller is destabilized by a modification including the effects of eddy currents flowing through the cores. It accounts for the difficulty of actual self-sensing suspension in solid-cored magnetic bearings.","1996","4","4","2025-12-02","https://university.edu/papers/ae40e37a-3c32-4b37-baef-4ea69171d714.pdf");
INSERT INTO Paper VALUES ("295","How foreign function integration conquers heterogeneous query processing","With the emergence of application systems which encapsulate databases and related application components, pure data integration using, for example, a federated database system is not possible anymore. Instead, access via predefined functions is the only way to get data from an application system. As a result, retrieval of such heterogeneous and encapsulated data sources needs the combination of generic query as well as predefined function access. In this paper, we present a middleware approach supporting such a novel and extended kind of integration. Starting with the overall architecture, we explain the functionality and cooperation of its core components: a federated database system and a workflow management system connected via a wrapper. Afterwards, we concentrate on essential aspects of query processing across these heterogeneous components focusing on the impact of the functions included. We discuss the operations the wrapper should provide in order to extend the workflow system's native functionality. In addition to selection and projection, these operations could include aggregation and the support of subqueries. Moreover, we point out modifications to the traditional cost model needed to consider the cost estimates for the function calls as well.","2001","2","3","2025-12-02","https://university.edu/papers/edea6330-9642-489d-9b21-937f4251802a.pdf");
INSERT INTO Paper VALUES ("296","MULTIOBJECTIVE PARTICLE SWARM OPTIMIZATION BASED ON DIMENSIONAL UPDATE","For multiobjective particle swarm optimization (MOPSO), two particles may be incomparable, i. e., not dominated by each other. The personal best and the global best for the particle become less optimal, thus the convergence becomes slow. Even worse, an archive of a limited size can not cover the entire region dominated by the Pareto front, the uncovered region can contain unidentifiable nondominated solutions that are not optimal, and thus the precision the algorithm achieves encounters a plateau. Therefore we propose dimensional update, i. e., evaluating the particle's fitness after updating each variable of its position. Separate consideration of the impact of each variable decreases the occurrence of incomparable relations, thus improves the performance. Experimental results validate the efficiency of our algorithm.","2013","10","4","2025-12-02","https://university.edu/papers/9ad6fe04-40c1-4c48-a675-7bc96058c65c.pdf");
INSERT INTO Paper VALUES ("297","Using Pot-Magnets to Enable Stable and Scalable Electromagnetic Tactile Displays","We present the design, fabrication, characterization, and psychophysical testing of a scalable haptic display based on electromagnetic (EM) actuators. The display consists of a 4 × 4 array of taxels, each of which can be in a raised or a lowered position, thus generating different static configurations. One of the most challenging aspects when designing densely-packed arrays of EM actuators is obtaining large actuation forces while simultaneously generating only weak interactions between neighboring taxels. In this work, we introduce a lightweight and effective magnetic shielding architecture. The moving part of each taxel is a cylindrical permanent magnet embedded in a ferromagnetic pot, forming a pot-magnet. An array of planar microcoils attracts or repels each pot-magnet. This configuration reduces the interaction between neighboring magnets by more than one order of magnitude, while the coil/magnet interaction is only reduced by 10 percent. For 4 mm diameter pins on an 8 mm pitch, we obtained displacements of 0.55 mm and forces of 40 mN using 1.7 W. We measured the accuracy of human perception under two actuation configurations which differed in the force versus displacement curve. We obtained 91 percent of correct answers in pulling configuration and 100 percent in pushing configuration.","2017","14","2","2025-12-02","https://university.edu/papers/3b11a05a-a33b-48d0-92e6-fea9adf0ad42.pdf");
INSERT INTO Paper VALUES ("298","Neuronal Fiber Delineation in Area of Edema from Diffusion Weighted MRI","Diffusion Tensor Magnetic Resonance Imaging (DT-MRI) is a non invasive method for brain neuronal fibers delineation. Here we show a modification for DT-MRI that allows delineation of neuronal fibers which are infiltrated by edema. We use the Muliple Tensor Variational (MTV) framework which replaces the diffusion model of DT-MRI with a multiple component model and fits it to the signal attenuation with a variational regularization mechanism. In order to reduce free water contamination we estimate the free water compartment volume fraction in each voxel, remove it, and then calculate the anisotropy of the remaining compartment. The variational framework was applied on data collected with conventional clinical parameters, containing only six diffusion directions. By using the variational framework we were able to overcome the highly ill posed fitting. The results show that we were able to find fibers that were not found by DT-MRI.","2006","15","3","2025-12-02","https://university.edu/papers/72ed67ce-a5ff-4e1f-80e8-15f73ec7e047.pdf");
INSERT INTO Paper VALUES ("299","Profile-Based Text Classification for Children with Dyslexia","Although extensive research has been conducted in the field of text-readability and user modelling, scholars and researchers have taken into consideration only linguistic complexity in order to classify a text as readable or not. In this paper, the authors move one step forward by considering one more factor, namely intended reader's skills, and by trying to study text readability from a user-specific perspective. Central to our approach is the notion of the user's profile which carries information regarding the linguistic difficulties a user with dyslexia may experience. Based on the user's profile, they develop heuristics for evaluating text's readability for the specific user. The developed heuristics are incorporated in the text classification services of the iLearnRW project, aiming to facilitate the selection of appropriate/suitable reading resources, written in English or Greek, for children with dyslexia1.","2015","17","3","2025-12-02","https://university.edu/papers/0e78deb5-a2fc-4c5c-8c84-fa3676e99ad9.pdf");
INSERT INTO Paper VALUES ("300","Efficient stereo segment scheduling in peer-to-peer 3D/multi-view video streaming","3D (or stereo) video has been a visually appealing and costly affordable technology. More sophisticated multi-view videos have also been demonstrated. Yet their remarkably increased data volume poses greater challenges to the conventional client/server streaming systems, which has already suffered from supporting 2D videos. The stringent multi-stream synchronization further complicate the system design. In this paper, we present an initial attempt toward efficient streaming of stereo/multi-view videos over a peer-to-peer network. We show that the inherent multi-stream nature of stereo video makes segment scheduling more difficult, which is particularly acute with the existence of multiple senders in a peer-to-peer overlay. We formulate the stereo segment scheduling problem as a Binary Quadratic Programming problem and optimally solve it using an MIQP solver. However, given the high peer dynamics and the stringent playback deadline in real-time streaming, the optimal solution is too costly to be obtained. Thus, we develop two efficient algorithms to allow peers frequently compute the scheduling. We show that one of the proposed algorithms can achieve an analytical guarantee in the worst case performance, in particular, the approximation factor is at most 3 comparing with the optimal solution. We implement the proposed algorithms and the optimal in a peer-to-peer simulating system, and show that the proposed algorithms can achieve near-optimal performance efficiently. We further implement two other scheduling algorithms that are used in popular peer-to-peer streaming systems for comparison, and extend our design to support multi-view video with view diversity and dynamics. Under different end-system and network configurations with both stereo and multi-view streaming, the simulation results demonstrate that our algorithms outperform others in terms of streaming quality, stream synchronization/smoothness and scalability.","2011","12","1","2025-12-02","https://university.edu/papers/d6bfe7b5-5bbb-4526-929d-10fb830cb461.pdf");
INSERT INTO Paper VALUES ("301","A popularity based caching strategy for the future Internet","Information-Centric Networking (ICN) is an attractive network model receiving increasing consideration by the research community because of its inspiring features. To better manage the Internet usage move from host-centric communication to receiver-driven content retrieval, revolutionary ICN architectures have been proposed. A distinguished characteristic of these innovative architectures is to provide ubiquitous and transparent in-network caching to enhance network resource utilization and accelerate content dissemination. With the exponential increase of Internet traffic, the issue of content storage is a growing concern in ICN. In this paper, we present a caching strategy that considerably increases cache hit rate and reduces stretch ratio, which are the most important metrics in the evaluation of ICN caching. Through extensive simulations, it is shown that our proposed work is a favorable and realistic contribution for the standardization exercise of data caching for achieving accurate and valid network performance in the future Internet.","2016","14","4","2025-12-02","https://university.edu/papers/dd5f15b8-bf5a-4470-bc8f-c07ec413604d.pdf");
INSERT INTO Paper VALUES ("302","Haptic Interactions Using Virtual Manipulator Coupling With Applications to Underactuated Systems","Haptic interactions have become increasingly important as an interface to computer-generated simulations in virtual-reality (VR) applications. Many haptic devices are designed to be used as a force feedback mouse, where the user's hand is in contact with the haptic device while the object contact and force generation occur on a computer screen. In this paper, we present an approach using a “virtual probe” to interact with the environment and introduce a new method to generate impedance-based haptic forces based on the use of a virtual manipulator. The virtual probe is connected directly to the haptic device and is projected from the hand to the environment, much like a scalpel or sword. As the probe comes in contact with the environment, the haptic device generates appropriate forces on the hand. We extend this approach to include underactuated haptic devices, which do not have fully powered joints. We show that the approach compensates for missing joint actuation in the underactuated haptic devices. We show experimental results for a simple case of haptic interaction; we also present an experimental implementation in six degrees of freedom (DOF) using one of the most popular devices: the PHANTOM.","2011","9","1","2025-12-02","https://university.edu/papers/b4f6f665-5d32-4051-9360-a9429ab95690.pdf");
INSERT INTO Paper VALUES ("303","RadSS: A radiolarian classifier using support vector machines","Radiolarian assemblages have played a significant role as a biostratigraphic and paleoenvironmental tool used in the geological settings. These species can be used in studying sediments lacking calcareous fossils. Easy identification of these species would allow micropaleontologists to proceed further into studying the structure and way of living of these Radiolarians. RaDSS is a decision support system that could help researchers in classifying microphotographs of Radiolarian species through image processing and machine learning algorithms such as SVM.","2016","20","1","2025-12-02","https://university.edu/papers/b3346f93-fd92-4c6b-8069-ec39ba74f351.pdf");
INSERT INTO Paper VALUES ("304","Algebraic and uniqueness properties of parity ordered binary decision diagrams and their generalization","Ordered binary decision diagrams (OBDDs) and parity OBDDs are data structures representing Boolean functions. In addition, we study their generalization which we call parity AOBDDs, give their algebraic characterization and compare their minimal size to the size of parity OBDDs. We prove that the constraint that no arcs test conditions of type x i  = 0 does not affect the node-size of parity (A)OBDDs and we give an efficient algorithm for finding such parity (A)OBDDs. We obtain a canonical form for parity OBDDs and discuss similar results for parity AOBDDs. Algorithms for minimization and transformation to the canonical form for parity OBDDs running in time O(S 3 ) and space O(S 2 ) or in time O(S 3 /log S) and space O(S 3 /log S) and an algorithm for minimization of parity AOBDDs running in time O(nS 3 ) and space O(nS 2 ) are presented (n is the number of variables, S is the number of vertices). All the results are extendable to case of shared parity (A)OBDDs -data structures for representation of Boolean function sequences.","2000","8","1","2025-12-02","https://university.edu/papers/4a151be2-1648-453a-9491-a1e225692052.pdf");
INSERT INTO Paper VALUES ("305","Equivalence of the MTS Method and CMR Method for Differential Equations Associated with Semisimple Singularity","In this paper, the equivalence of the multiple time scales (MTS) method and the center manifold reduction (CMR) method is proved for computing the normal forms of ordinary differential equations and delay differential equations. The delay equations considered include general delay differential equations (DDE), neutral functional differential equations (NFDE) (or neutral delay differential equations (NDDE)), and partial functional differential equations (PFDE). The delays involved in these equations can be discrete or distributed. Particular attention is focused on dynamics associated with the semisimple singularity, and both the MTS and CMR methods are applied to compute the normal forms near the semisimple singular point. For the ordinary differential equations (ODE), we show that the two methods are equivalent up to any order in computing the normal forms; while for the differential equations with delays, we obtain the conditions under which the normal forms, derived by using the MTS and CMR methods, are identical up to third order. Different types of practical examples with delays are presented to demonstrate the application of the theoretical results, associated with Hopf, Hopf-zero and double-Hopf singularities.","2014","5","1","2025-12-02","https://university.edu/papers/b44874b4-5d2b-4b75-b111-68017e72e787.pdf");
INSERT INTO Paper VALUES ("306","Localization Using Iterative Angle of Arrival Method Sharing Snapshots of Coherent Subarrays","In this paper, we propose a localization method using iterative angle of arrival (AOA) method sharing snapshots of coherent subarrays. The conventional AOA method is restricted in some applications because array antenna used for receivers requires many antennas to improve localization accuracy. The proposed method improves localization accuracy without increasing elements of antenna arrays, and thus the lower costs and smaller devices are expected. First, we estimate rough location of source with each subarray-small number of antennas-in initial estimation. Then, we configurate virtual arrays by sharing snapshots based on the initial AOAs, estimate again with virtual arrays-large number of antennas-in update estimation, and update the location iteratively. Simulation results show that the localization accuracy of the proposed method is better than that of the conventional method using the same number of antennas if the appropriate virtual arrays are configurated and the phase synchronization error between two subarrays is smaller than 0.14 of a wavelength.","2011","10","4","2025-12-02","https://university.edu/papers/d456e176-381f-4380-b014-2b4627001d39.pdf");
INSERT INTO Paper VALUES ("307","Heterogeneous fuzzy logic networks: fundamentals and development studies","The recent trend in the development of neurofuzzy systems has profoundly emphasized the importance of synergy between the fundamentals of fuzzy sets and neural networks. The resulting frameworks of the neurofuzzy systems took advantage of an array of learning mechanisms primarily originating within the theory of neurocomputing and the use of fuzzy models (predominantly rule-based systems) being well established in the realm of fuzzy sets. Ideally, one can anticipate that neurofuzzy systems should fully exploit the linkages between these two technologies while strongly preserving their evident identities (plasticity or learning abilities to be shared by the transparency and full interpretability of the resulting neurofuzzy constructs). Interestingly, this synergy still becomes a target yet to be satisfied. This study is an attempt to address the fundamental interpretability challenge of neurofuzzy systems. Our underlying conjecture is that the transparency of any neurofuzzy system links directly with the logic fabric of the system so the logic fundamentals of the underlying architecture become of primordial relevance. Having this in mind the development of neurofuzzy models hinges on a collection of logic driven processing units named here fuzzy (logic) neurons. These are conceptually simple logic-oriented elements that come with a well-defined semantics and plasticity. Owing to their diversity, such neurons form essential building blocks of the networks. The study revisits the existing categories of logic neurons, provides with their taxonomy, helps understand their functional features and sheds light on their behavior when being treated as computational components of any neurofuzzy architecture. The two main categories of aggregative and reference neurons are deeply rooted in the fundamental operations encountered in the technology of fuzzy sets (including logic operations, linguistic modifiers, and logic reference operations). The developed heterogeneous networks come with a well-defined semantics and high interpretability (which directly translates into the rule-based representation of the networks). As the network takes advantage of various logic neurons, this imposes an immediate requirement of structural optimization, which in this study is addressed by utilizing various mechanisms of genetic optimization (genetic algorithms). We discuss the development of the networks, elaborate on the interpretation aspects and include a number of illustrative numeric examples.","2004","6","4","2025-12-02","https://university.edu/papers/b122bb5f-2782-4737-a8b9-440f9304ac85.pdf");
INSERT INTO Paper VALUES ("308","Empirical study of neural network language models for Arabic speech recognition","In this paper we investigate the use of neural network language models for Arabic speech recognition. By using a distributed representation of words, the neural network model allows for more robust generalization and is better able to fight the data sparseness problem. We investigate different configurations of the neural probabilistic model, experimenting with such parameters as N-gram order, output vocabulary, normalization method, and model size and parameters. Experiments were carried out on Arabic broadcast news and broadcast conversations data and the optimized neural network language models showed significant improvements over the baseline N-gram model.","2007","3","2","2025-12-02","https://university.edu/papers/a434f0a3-54f4-4617-a2a8-69a968f5afcf.pdf");
INSERT INTO Paper VALUES ("309","Tensor-Based Blind Channel Identification","We propose a blind FIR channel identification method based on the parallel factor (Parafac) analysis of a 3rd-order tensor composed of the 4-th order output cumulants. Our algorithm is based on a single-step least squares (LS) minimization procedure instead of using classical three-step alternating least squares (ALS) methods. Using a Parafac-based decomposition, we avoid any kind of pre-processing such as the prewhitening operation, which is mandatory in most methods using higher-order statistics. Our method retrieves the channel vector without any permutation or scaling ambiguities. In addition, we establish a link between the cumulant tensor decomposition and the joint-diagonalization approach. Computer simulations illustrate the performance gains that our method provides with respect to other classical solutions. Initialization and convergence issues are also addressed.","2007","13","4","2025-12-02","https://university.edu/papers/eeab6634-e812-4c92-8b4a-fb965c6074e1.pdf");
INSERT INTO Paper VALUES ("310","Combining temporal interpolation and DCNN for faster recognition of micro-expressions in video sequences","Micro-expressions are the hidden human emotions that are short lived and are very hard to detect them in real time conversations. Micro-expressions recognition has proven to be an important behavior source for lie detection during crime interrogation. SMIC and CASME II are the two widely used, spontaneous micro-expressions datasets which are available publicly with baseline results that uses LBP-TOP for feature extraction. Estimation of correct parameters is the key factor for feature extraction using LBP-TOP, which results in long computation time. In this paper, the video sequences are interpolated using temporal interpolation(TIM) and then the facial features are extracted using deep convolutional neural network(DCNN) on CUDA enabled General Purpose Graphics Processing Unit(GPGPU) system. Results show that the proposed combination of DCNN and TIM can achieve better performance than the results published in baseline publications. The feature extraction time is reduced due to the usage of GPU enabled systems.","2016","3","3","2025-12-02","https://university.edu/papers/6d7fe49a-111b-4cf2-b504-8ae2583ab273.pdf");
INSERT INTO Paper VALUES ("311","Model Update for Automated Planning","Model update is a formal approach to correct a system model M w.r.t some property not satisfied by M. In this work, we show how this formal approach can be used for plan and planning domain verification and update. While a model checking method can directly be used to perform plan verification, model update techniques can be used to either update an incorrect plan and\or update a planning domain specification. Well known model update approaches are based on CTL — a logic which does not take into account the actions. In previous work, we have proposed the alpha-CTL logic, a logic whose semantics is based on actions. Here, we are proposing a model update system based on alpha-CTL which is able to automatically modify a plan M, generating a new plan M' that satisfies phi or, if there is not such a plan, to automatically update the corresponding planning domain.","2011","15","4","2025-12-02","https://university.edu/papers/7090df13-a6b9-413d-8917-9a53e9e7d42e.pdf");
INSERT INTO Paper VALUES ("312","PowQ: a user-friendly package for the design of variance component multipoint linkage analysis studies","Summary: A user-friendly, graphical package for power evaluation and enhancement planning through variance component linkage analysis in a multipoint framework.#R##N##R##N#Availability: The package is made available at: http://www.twin-research.ac.uk/WebPowQ/PowQ.htm#R##N##R##N#Contact: mario.falchi@kcl.ac.uk","2006","18","4","2025-12-02","https://university.edu/papers/f768993a-b141-45a3-b99a-bab8c54635c5.pdf");
INSERT INTO Paper VALUES ("313","Term Extraction and Disambiguation for Semantic Knowledge Enrichment: A Case Study on Initial Public Offering (IPO) Prospectus Corpus","Domain knowledge bases are a basis for advanced knowledge-based systems, manually creating a formal knowledge base for a certain domain is both resource consuming and non-trivial. In this paper, we propose an approach that provides support to extract, select, and disambiguate terms embedded in domain specific documents. The extracted terms are later used to en-rich existing ontologies/taxonomies, as well as to bridge domain specific knowledge base with a generic knowledge base such as Word Net. The proposed approach addresses two major issues in the term extraction domain, namely quality and efficiency. Also, the proposed approach adopts a feature-based method that assists in topic extraction and integration with existing ontologies in the given domain. The proposed approach is realized in a research prototype, and then a case study is conducted in order to illustrate the feasibility and the efficiency of the proposed method in the finance domain. A preliminary empirical validation by the domain experts is also conducted to determine the accuracy of the proposed approach. The results from the case study indicate the advantages and potential of the proposed approach.","2015","4","1","2025-12-02","https://university.edu/papers/59561760-ead7-4d93-9531-6254e1738d03.pdf");
INSERT INTO Paper VALUES ("314","A comparison of shape constrained facial feature detectors","We consider the problem of robustly and accurately locating facial features. The relative positions of different feature points are represented using a statistical shape model. We construct an individual detector for each feature point, which is used to generate a feature response image. The quality of a given hypothesised shape can be evaluated quickly by combining values from each response image. We use global search to predict the approximate position of the face, and then refine the hypothesis using non-linear optimisation. The result is an algorithm capable of robustly and accurately matching a face model to new images, which we refer to as shape optimised search (SOS). We describe SOS in detail and compare the performance of the algorithm when three different classes of feature detectors are used. We demonstrate that the approach is capable of outperforming the well known active appearance model method.","2004","6","1","2025-12-02","https://university.edu/papers/7a285bf6-29e3-47c1-8c99-7b9156bdb22c.pdf");
INSERT INTO Paper VALUES ("315","Big Graph Analytics Systems","In recent years we have witnessed a surging interest in developing Big Graph processing systems. To date, tens of Big Graph systems have been proposed. This tutorial provides a timely and comprehensive review of existing Big Graph systems, and summarizes their pros and cons from various perspectives. We start from the existing vertex-centric systems, which which a programmer thinks intuitively like a vertex when developing parallel graph algorithms. We then introduce systems that adopt other computation paradigms and execution settings. The topics covered in this tutorial include programming models and algorithm design, computation models, communication mechanisms, out-of-core support, fault tolerance, dynamic graph support, and so on. We also highlight future research opportunities on Big Graph analytics.","2016","13","4","2025-12-02","https://university.edu/papers/95ae2e36-1857-4818-9fdd-a000943e113f.pdf");
INSERT INTO Paper VALUES ("316","Improvement of medical image resolution using an extended 2D factorized form complex number parametric model","We showed that multidimensional parametric modeling is an interesting method to improve the spatial resolution of ultrasound images. The major issue is to estimate simultaneously the model parameters and orders. We recently proposed a least-square-based technique which is able to estimate both orders and parameters of a general N-dimensional auto-regressive (AR) model. This method has been extended to an instrumental variable-like approach accounting for the characteristics of ultrasound images. The proposed method is based on specific factorization of the regression matrix. The methodology developed may be applied to an AR model of any dimension (3 or 4D). However, we focus here on the 2D situation and show improvement of resolution of ultrasound images by this method.","2010","7","4","2025-12-02","https://university.edu/papers/77bd491a-4fac-413b-a557-4af53c01e1ef.pdf");
INSERT INTO Paper VALUES ("317","Structural soil crust development from raindrop impacts using two-dimensional discrete element method","The mechanical nature of crust formation as a result of raindrop impacts was simulated within a discrete element modeling environment. Simulations were conducted in two-dimensions (2D) using both linear and non-linear elastic contact models. The 2D approach was found to minimize the computational effort required and maximize the number of particles in the soil profile. For the non-linear model, the effect of the coefficient of restitution (COR) for soil-rain and soil-soil was investigated. Finally, the comparison between the linear and nonlinear elastic contact model was presented. The simulation indicated that the COR for rain-soil had negligible effect on the crust development but the computational time was exponentially increased with increasing coefficient value. In contrast, the COR for soil-soil had a dominant influence on the crust development. To validate the numerical results, a micro computerized tomography (microCT) technique was applied to characterize the changes in pore structure to a USCS SP soil after exposure under a rainfall simulator. Additionally, the effect of cyclic wetting and drying (without rainfall) on the changes in porosity was investigated. The experimental results showed that the rainfall simulator sufficiently densified the soil but the effect of cyclic wetting and drying was negligible. The numerical simulations showed similar changes in porosity along the depth of the soil profile as compared with the experimental results thus validating the DEM technique to simulate crust development.","2016","11","1","2025-12-02","https://university.edu/papers/d278431a-43fd-4690-8348-5cefe9c879ef.pdf");
INSERT INTO Paper VALUES ("318","SegChain: Towards a generic automatic video segmentation framework, based on lexical chains of audio transcriptions","With the advances in multimedia broadcasting through a rich variety of channels and with the vulgarization of video production, it becomes essential to be able to provide reliable means of retrieving information within videos, not only the videos themselves. Research in this area has been widely focused on the context of TV news broadcasts, for which the structure itself provides clues for story segmentation. The systematic employment of these clues would lead to thematically driven systems that would not be easily adaptable in the case of videos of other types. The systems are therefore dependent on the type of videos for which they have been designed. In this paper we aim at introducing SegChain, a generic unsupervised framework for story segmentation, based on lexical chains from transcriptions. SegChain takes into account the topic changes by perceiving the fluctuations of the most frequent terms throughout the video.","2016","11","3","2025-12-02","https://university.edu/papers/4553e3a8-3818-4877-b5ce-44f35ff66fce.pdf");
INSERT INTO Paper VALUES ("319","Analysis of emotion recognition using facial expressions, speech and multimodal information","The interaction between human beings and computers will be more natural if computers are able to perceive and respond to human non-verbal communication such as emotions. Although several approaches have been proposed to recognize human emotions based on facial expressions or speech, relatively limited work has been done to fuse these two, and other, modalities to improve the accuracy and robustness of the emotion recognition system. This paper analyzes the strengths and the limitations of systems based only on facial expressions or acoustic information. It also discusses two approaches used to fuse these two modalities: decision level and feature level integration. Using a database recorded from an actress, four emotions were classified: sadness, anger, happiness, and neutral state. By the use of markers on her face, detailed facial motions were captured with motion capture, in conjunction with simultaneous speech recordings. The results reveal that the system based on facial expression gave better performance than the system based on just acoustic information for the emotions considered. Results also show the complementarily of the two modalities and that when these two modalities are fused, the performance and the robustness of the emotion recognition system improve measurably.","2004","20","4","2025-12-02","https://university.edu/papers/9f6587c6-b2d9-453c-ade9-d2f3527149a5.pdf");
INSERT INTO Paper VALUES ("320","Http-Burst: Improving HTTP Efficiency in the Era of Bandwidth Hungry Web Applications","The Hypertext Transfer Protocol (HTTP), a key building block of the World Wide Web, has succeeded to enable information exchange worldwide. Since its first version in 1996, HTTP/1.0, the average number of inlined objects and average total bytes per webpage have been increasing significantly for desktops and mobiles, from 1-10 objects in 1996 to more than 100 objects in June 2014. Even if the retrieving of inlined objects can be parallelized as a given Hypertext Markup Language (HTML) document is streamed, a maximum number of connections is allocated, and thus as the number of inlined objects increases, the overall webpage load duration grows, and the HTTP servers loading also gets higher. To overcome this issue, we propose a new HTTP method called BURST, which allows to retrieve the missing inlined objects of a webpage efficiently by requesting sets of web objects. We experimentally demonstrate the potential via a proof-of-concept demonstration, by comparing the regular HTTP to proposed HTTP-Burst using a virtual private server and real HTTP client and server over the Internet. The results indicate a latency reduction of webpage load duration compared to HTTP as high as 52 % under the considered configurations.","2015","7","4","2025-12-02","https://university.edu/papers/a72a52ab-e1cd-4cfd-a678-007dfbe3d95b.pdf");
INSERT INTO Paper VALUES ("321","Terrain analysis using radar shape-from-shading","This paper develops a maximum a posteriori (MAP) probability estimation framework for shape-from-shading (SFS) from synthetic aperture radar (SAR) images. The aim is to use this method to reconstruct surface topography from a single radar image of relatively complex terrain. Our MAP framework makes explicit how the recovery of local surface orientation depends on the whereabouts of terrain edge features and the available radar reflectance information. To apply the resulting process to real world radar data, we require probabilistic models for the appearance of terrain features and the relationship between the orientation of surface normals and the radar reflectance. We show that the SAR data can be modeled using a Rayleigh-Bessel distribution and use this distribution to develop a maximum likelihood algorithm for detecting and labeling terrain edge features. Moreover, we show how robust statistics can be used to estimate the characteristic parameters of this distribution. We also develop an empirical model for the SAR reflectance function. Using the reflectance model, we perform Lambertian correction so that a conventional SFS algorithm can be applied to the radar data. The initial surface normal direction is constrained to point in the direction of the nearest ridge or ravine feature. Each surface normal must fall within a conical envelope whose axis is in the direction of the radar illuminant. The extent of the envelope depends on the corrected radar reflectance and the variance of the radar signal statistics. We explore various ways of smoothing the field of surface normals using robust statistics. Finally, we show how to reconstruct the terrain surface from the smoothed field of surface normal vectors. The proposed algorithm is applied to various SAR data sets containing relatively complex terrain structure.","2003","4","3","2025-12-02","https://university.edu/papers/e35621c9-d12d-4e49-83a6-cbae927c44f0.pdf");
INSERT INTO Paper VALUES ("322","Robust Detection of Microaneurysms for Sight Threatening Retinopathy Screening","Diabetic retinopathy is one of the major causes of blindness. However, diabetic retinopathy does not usually causea loss of sight until it has reached an advanced stage. The earliest sign of the disease are microaneurysms (MA) which appear as small red dots on retinal fundus images. Various screening programmes have been established in the UK and other countries to collect and assess images on a regular basis, especially in the diabetic population. A considerable amount of time and money is spent in manually grading these images, a large percentage of which are normal. By automatically identifying the normal images, the manual workload and costs could be reduced greatly while increasing the effectiveness of the screening programmes. A novel method of microaneurysm detection from digital retinal screening images is proposed. It is based on filtering using complex-valued circular-symmetric filters, and an eigen-image, morphological analysis of the candidate regions to reduce the false-positve rate. We detail the image processing algorithms and present results on a typical set of 89 image from a published database. Our method is shown to have a best operating sensitivity of 82.6% at a specificity of 80.2% which makes it viable for screening. We discuss the results in the context of a model of visual search and the ROC curves that it can predict.","2008","15","1","2025-12-02","https://university.edu/papers/43bd8b2d-9547-442c-9066-2a9a18b43910.pdf");
INSERT INTO Paper VALUES ("323","The pynchon gate: a secure method of pseudonymous mail retrieval","We describe the Pynchon Gate, a practical pseudonymous message retrieval system. Our design uses a simple distributed-trust private information retrieval protocol to prevent adversaries from linking recipients to their pseudonyms, even when some of the infrastructure has been compromised. This approach resists global traffic analysis significantly better than existing deployed pseudonymous email solutions, at the cost of additional bandwidth. We examine security concerns raised by our model, and propose solutions.","2005","18","2","2025-12-02","https://university.edu/papers/82837ec5-122f-43bc-8497-7adfda526759.pdf");
INSERT INTO Paper VALUES ("324","Lipless Tracking and Emotion Estimation","Automatic human lip tracking is one of the key components tomany facial image analysis tasks, such as, lip-reading and emotion from lips. It has been a classical hard image analysis problem over decades. In this paper, we propose an indirect lip tracking strategy: `lipless tracking'. It is based on the observation that many of us don't have clear lips and some even don't have visible lips. The strategy is to select and localize stable lip features around the mouth for tracking. For this purpose deformable contour-segments are modelled based on lip features and tracking is done using dynamic programming and Viterbi Algorithm. The strength of proposed algorithm is demonstrated in emotion estimation domain. Finally, real-time video experiments performed on private and publicity available data set (MMI face database) have shown the robustness of our proposed lipless tracking technique.","2007","16","2","2025-12-02","https://university.edu/papers/afd25845-ace4-4f5e-afdf-affecd36bff6.pdf");
INSERT INTO Paper VALUES ("325","Tangible actions","We present Tangible Actions, an ad-hoc, just-in-time, visual programming by example language designed for large multitouch interfaces. With the design of Tangible Actions, we contribute a continually-created system of programming tokens that occupy the same space as the objects they act on. Tangible Actions are created by the gestural actions of the user, and they allow the user to reuse and modify their own gestures with a lower interaction cost than the original gesture. We implemented Tangible Actions in three different tabletop applications, and ran an informal evaluation. While we found that study participants generally liked and understood Tangible Actions, having the objects and the actions co-located can lead to visual and interaction clutter.","2011","7","3","2025-12-02","https://university.edu/papers/66f969fd-4253-48d0-9722-070ca5a82b2c.pdf");
INSERT INTO Paper VALUES ("326","Allocating fixed costs with considering the return to scale: A DEA approach","When the allocated fixed cost is treated as the complement of other costs, conventional data envelopment analysis (DEA) researches have ignored the effect of the return to scale (RTS) in fixed cost allocation problems. This paper first demonstrates why the RTS should be considered in fixed cost allocation problems. Then treating the fixed cost as a complementary input, the authors investigate the relationship between the allocated cost and the variable return to scale (VRS) efficiency based on the super BCC DEA model. However, the infeasibility problem may exist in this situation. To deal with it, the authors propose an algorithm. The authors find that the super BCC efficiency is a monotone non-increasing function of the allocated cost. Based on the relationship, the authors finally propose a fixed cost allocation approach in terms of principles as: (i) The fixed cost proportion allocated to inelastic DMUs should be consistent with their consumed cost proportion, and (ii) the same efficiency satisfaction degree to the rest DMUs. The optimal allocation scheme is unique. A numerical example and a real example of allocating fixed costs among 13 subsidiaries are employed to illustrate the proposed approach.","2016","19","1","2025-12-02","https://university.edu/papers/f7f43f76-1e46-447b-bd41-5dc9f055ce99.pdf");
INSERT INTO Paper VALUES ("327","A Maximum Likelihood Watermark Decoding Scheme","Based on the observation that an attack applied on a watermarked image, from a decoding point of view, modifies the distribution of the detection values away from the ideal distribution (without attack) for corresponding watermarking scheme, we propose a generic maximum likelihood decoding scheme by approximating the distribution with a finite Gaussian mixture model. The parameters of the model are estimated using expectation-maximization algorithm. The scheme allows the decoding to be automatically adapted to attacks that the watermarked images have undergone and, in consequence, to improve the decoding accuracy. Experiments on a QIM based watermarking system have clearly verified the significant improvement of the decoding accuracy achieved by the proposed maximum likelihood decoding in comparison to conventional threshold decoding.","2007","20","4","2025-12-02","https://university.edu/papers/b99da785-d69e-4329-959b-be46461af562.pdf");
INSERT INTO Paper VALUES ("328","JASPER: Just A new Space-filling and Pixel-oriented layout for large graph ovERview.","When analysing data and handling a visualisation, users mainly spend their cognitive resources making sense of the graph-ical representation and mapping it back to the data and domain. This task becomes even more critical when dealing with larger data sets. Therefore, a valuable visualisation design strategy is to couple graphical representations and user tasks to better support the sense making process. This paper focuses on a particular task where users must make sense of state changes occurring on nodes of a graph. To this end, we propose JASPER, a new layout algorithm focusing on the visualisation of nodes inspired from pixel-oriented layouts, relying on node clustering to identify and represent existing connections through spatial adjacency. JASPER can layout moderate size graphs in real-time and is able to tackle large graphs with up to 2 million nodes and 5 million edges in reasonable time (about half a minute). Furthermore, although JASPER has been designed around a specific application , the underlying methodology can be employed to draw quick overviews of any type of graphs. The paper lays down the underlying principles of JASPER, and reports it performances (execution times) on increasingly large graphs. JASPER is then used and showcased to visualise network propagation phenomenon in large graphs.","2016","2","3","2025-12-02","https://university.edu/papers/516c6248-758a-4226-bad6-8f917d240928.pdf");
INSERT INTO Paper VALUES ("329","Interconnection Networks: Architectural Challenges for Utility Computing Data Centers","Advancing research will enable an interconnection network to support the same seamless virtualization found in other parts of hardware, such as CPUs. Such a network thus poses particular challenges as well as opportunities for a utility computing data center.","2008","14","4","2025-12-02","https://university.edu/papers/f6fa5802-0585-4a82-9f5e-87b3184ddfcf.pdf");
INSERT INTO Paper VALUES ("330","SHOP2: an HTN planning system","The SHOP2 planning system received one of the awards for distinguished performance in the 2002 International Planning Competition. This paper describes the features of SHOP2 which enabled it to excel in the competition, especially those aspects of SHOP2 that deal with temporal and metric planning domains.","2003","7","1","2025-12-02","https://university.edu/papers/acc364d8-c6b9-47aa-bbd1-d70197c0703e.pdf");
INSERT INTO Paper VALUES ("331","Statically and Dynamically Verifiable SLA Metrics","There is a gap between run-time service behaviours and the contracted quality expectations with the customers that is due to the informal nature of service level agreements. We explain how to bridge the gap by formalizing service level agreements with metric functions. We therefore discuss an end-to-end analysis flow that can either statically verify if a service code complies with a metric function or use run-time monitoring systems to report possible misbehaviours. In both cases, our approach provides a feedback loop to fix and improve the metrics and eventually the resource configurations of the service itself.","2016","7","1","2025-12-02","https://university.edu/papers/0f96c91e-1321-4160-a6cb-d9b1f4e2c28e.pdf");
INSERT INTO Paper VALUES ("332","Prediction of DNA-binding residues from sequence","Motivation: Thousands of proteins are known to bind to DNA; for most of them the mechanism of action and the residues that bind to DNA, i.e. the binding sites, are yet unknown. Experimental identification of binding sites requires expensive and laborious methods such as mutagenesis and binding essays. Hence, such studies are not applicable on a large scale. If the 3D structure of a protein is known, it is often possible to predict DNA-binding sites in silico. However, for most proteins, such knowledge is not available.#R##N##R##N#Results: It has been shown that DNA-binding residues have distinct biophysical characteristics. Here we demonstrate that these characteristics are so distinct that they enable accurate prediction of the residues that bind DNA directly from amino acid sequence, without requiring any additional experimental or structural information. In a cross-validation based on the largest non-redundant dataset of high-resolution protein–DNA complexes available today, we found that 89% of our predictions are confirmed by experimental data. Thus, it is now possible to identify DNA-binding sites on a proteomic scale even in the absence of any experimental data or 3D-structural information.#R##N##R##N#Availability: http://cubic.bioc.columbia.edu/services/disis #R##N##R##N#Contact: yo135@columbia.edu","2007","14","3","2025-12-02","https://university.edu/papers/6df11d9c-6cae-4d34-88a9-dbfdb2efc9a0.pdf");
INSERT INTO Paper VALUES ("333","Experimental approach: two-stage spectrum sensing using gnu radio and usrp to detect primary user's signal","Spectrum sensing plays a critical role in improving spectrum utilization for cognitive radio networks. The majority of existing sensing approaches aim to detect the existence of a signal on a busy channel without differentiating whether a signal originates from a primary user or not. In this paper, we attempt to solve this challenge by an experimental approach using GNU radio and Universal Software Radio Peripheral (USRP) board. A two-stage sensing strategy is proposed to detect channel states. The first stage detects whether a channel is busy or idle by observing both the energy level and bandwidth. Once the channel is busy, we further determine the channel is occupied by a Primary User (PU) and an Secondary User (SU). From experiments, we observe that a receiver cannot successfully receive a signal if it implements different demodulation schemes with a transmitter. For example, a Binary Phase Shift Keying (BPSK) demodulator cannot detect a Quadrature Phase Shift Keying (QPSK) signal transmitted by a transmitter. Motivated by this observation, we propose that at the second stage, PUs and SUs are negotiated to conduct different modulations. Then SUs are equipped with two demodulators that will be able to demodulate both the PUs signal and the SUs signal. Given that SU and PU perform distinct modulations, once the PU comes to its licensed channel, the SU communicating on that channel will recognize it and withdraw from the channel immediately. Extensive experiments using GNU radio and USRP boards are carried out under various scenarios to evaluate the effectiveness of the proposed approach.","2016","9","2","2025-12-02","https://university.edu/papers/21a3cba1-6a8a-4521-961a-d7c09e0e1b3b.pdf");
INSERT INTO Paper VALUES ("334","A Gaussian derivative based version of JPEG for image compression and decompression","The compression and decompression of continuous-tone images is important in document management and transmission systems. This paper considers an alternative image representation scheme, based on Gaussian derivatives, to the standard discrete cosine transformation (DCT), within a Joint Photographic Experts Group (JPEG) framework. Depending on the computer arithmetic hardware used, the approach developed might yield a compression/decompression technique twice as fast as the DCT and of (essentially) equal quality.","1998","3","2","2025-12-02","https://university.edu/papers/d3357168-ad3c-4937-8272-78e8c7af1872.pdf");
INSERT INTO Paper VALUES ("335","Maximizing Cooperative Diversity Energy Gain for Wireless Networks","We are concerned with optimally grouping active mobile users in a two-user-based cooperative diversity system to maximize the cooperative diversity energy gain in a radio cell. The optimization problem is formulated as a non-bipartite weighted-matching problem in a static network setting. The weighted-matching problem can be solved using maximum weighted (MW) matching algorithm in polynomial time O(n 3 ). To reduce the implementation and computational complexity, we develop a Worst-Link-First (WLF) matching algorithm, which gives the user with the worse channel condition and the higher energy consumption rate a higher priority to choose its partner. The computational complexity of the proposed WLF algorithm is O(n) while the achieved average energy gain is only slightly lower than that of the optimal maximum weighted- matching algorithm and similar to that of the 1/2-approximation Greedy matching algorithm (with computational complexity of O(n 2  log n)) for a static-user network. We further investigate the optimal matching problem in mobile networks. By intelligently applying user mobility information in the matching algorithm, high cooperative diversity energy gain with moderate overhead is possible. In mobile networks, the proposed WLF matching algorithm, being less complex than the MW and the Greedy matching algorithms, yields performance characteristics close to those of the MW matching algorithm and better than the Greedy matching algorithm.","2007","3","3","2025-12-02","https://university.edu/papers/c17ff1fd-377b-4dcf-9593-4420cb677fb8.pdf");
INSERT INTO Paper VALUES ("336","A 650 V, 3 A three-phase fully-integrated BLDC motor driver with charge pump and level shifters","A 650 V three-phase IGBT motor driver is presented in this article. Apart from the power transistors and predrivers, also freewheeling diodes are present in the output power stage to drive inductive loads. The 15 V overdrive voltage as well as all other floating supplies are generated on-chip by means of a charge pump and cascoded current mirrors. The input signals for all switches are at ground level and level-shifted internally. Each half-bridge is able to switch at 20 kHz a 1.5 A current at 600 V and a 3 A current at 300 V. The ground connection contains a current shunt and a sense-amplifier, which can be used as a feedback signal in the BLDC control loop. The system is implemented in a 1 µm SoI technology with 650 V IGBT transistors.","2016","13","1","2025-12-02","https://university.edu/papers/71173258-6336-482f-933a-ab3bdac8b3b2.pdf");
INSERT INTO Paper VALUES ("337","A Strategy-Based Interpretation of Stroop.","Most accounts of the Stroop effect (Stroop, 1935) emphasize its negative aspect, namely, that in particular situations, processing of an irrelevant stimulus dimension interferes with participants’ performance of the instructed task. In contrast, this paper emphasizes the fact that, even with that interference, participants actually can (and usually do) exert enough control to perform the instructed task. An Adaptive Control of Thought–Rational (ACT–R) model of the Stroop task interprets this as a kind of learned strategic control. Specifically, the concept of utility is applied to the two processes that compete in the Stroop task, and a utility-learning mechanism serves to update the corresponding utility values according to experience and hence influence the competition. This model both accounts for various extant Stroop results and makes novel predictions about when people can reduce their susceptibility to Stroop interference. These predictions are tested in three experiments that involve a double-response variant of the Stroop task.","2005","10","4","2025-12-02","https://university.edu/papers/8d07693d-1bcf-429c-b596-903f533ab75b.pdf");
INSERT INTO Paper VALUES ("338","Reconciling OntoNotes: Unrestricted Coreference Resolution in OntoNotes with Reconcile.","This paper describes our entry to the 2011 CoNLL closed task (Pradhan et al., 2011) on modeling unrestricted coreference in OntoNotes. Our system is based on the Reconcile coreference resolution research platform. Reconcile is a general software infrastructure for the development of learning-based noun phrase (NP) coreference resolution systems. Our entry for the CoNLL closed task is a configuration of Reconcile intended to do well on OntoNotes data. This paper describes our configuration of Reconcile as well as the changes that we had to implement to integrate with the OntoNotes task definition and data formats. We also present and discuss the performance of our system under different testing conditions on a withheld validation set.","2011","14","2","2025-12-02","https://university.edu/papers/ab3d5adc-3b22-4664-a945-9f6a56224885.pdf");
INSERT INTO Paper VALUES ("339","Soft-Decode-and-Forward for Asynchronous Wireless Networks with Doubly-Selective Fading","A new soft-decode-and-forward (SDF) relay strategy for asynchronous wireless networks is presented in this paper. Unlike most previous works that assume simplified or idealized channel conditions, the new SDF relay strategy is designed to operate in practical asynchronous wireless networks with doubly-selective (both time-selective and frequency selective) fading. To combat the impairments caused by doubly-selective fading, as well as to preserve the correlation between signals delivered by the source and the relay, the relay nodes perform soft decoding, and forward reliability information to destination. A block decision feedback equalizer (BDFE) is employed at relay nodes to extract the soft information from the distorted signals. Distributed orthogonal frequency division multiplexing (OFDM) is adopted to cope with node asynchronism and fading time dispersion. Distributed OFDM systems in the literature were usually developed based on the assumption of perfect decoding at relay nodes, and such unrealistic assumption is not required by the new SDF relay strategy. Simulation results show that the new SDF method can flexibly adapt to the dynamic signal qualities at relay nodes, and it always outperforms the decode-and-forward relay strategy with hard decoding at relay.","2009","9","2","2025-12-02","https://university.edu/papers/9f8a6d0c-67da-4bd4-a8b9-dd3488fd83e1.pdf");
INSERT INTO Paper VALUES ("340","Analysis and Optimization for Multicast System with Regenerative Network Coding","It has been proved that wireless network coding can increase the throughput of multi-access system [2] and bidirectional system [5] by taking the advantage of the broadcast nature of electromagnetic waves. In this paper, we introduce the wireless network coding into cooperative multicast system. We establish a basic 2-source and 2-destination cooperative system model with arbitrary number of relays (2-N -2 system). Then two regenerative network coding (RNC) protocols are designed to execute the basic idea of network coding in complex field (RCNC) and Galois field respectively (RGNC). We illuminate how network coding can enhance the throughput distinctly in cooperative multicast system. Power allocation schemes as well as precoder design are also concentratively studied to improve the system performance in terms of system frame error probability.","2009","2","1","2025-12-02","https://university.edu/papers/8de6615c-bda5-4075-99cc-ef0f7c7a2d84.pdf");
INSERT INTO Paper VALUES ("341","ESTIMATED AND ACCURATE SYSTEM RELIABILITIES OF A MAINTAINABLE COMPUTER NETWORK SUBJECT TO MAINTENANCE BUDGET","This paper proposes a performance index to evaluate the capability of a maintainable computer network (MCN) that is required to send d units of data from the source to the sink through two paths within time T. The proposed system reliability performance index quantifies the probability that a MCN delivers a sufficient capacity with a maintenance budget no greater than B. Two procedures are integrated in the algorithm — an estimation procedure for estimated system reliability and an adjusting procedure utilizing the branch-and-bound approach for accurate system reliability. Subsequently, the estimated system reliability with lower bound and upper bound, and accurate system reliability can be derived by applying the recursive sum of disjoint products (RSDP) algorithm.","2012","14","3","2025-12-02","https://university.edu/papers/b9101f53-a3e4-4361-85fb-571b65e5b44c.pdf");
INSERT INTO Paper VALUES ("342","Adaptive sensing system for human detecting with dynamic disposition","In this paper, we propose a novel human detecting system using several stationary and moving laser range finders(LRF). The occluded area where the stationary sensors cannot measure will be covered by the actively moving sensor. The occlusion is perceived by overlaying visible area of the stationary sensors. The moving sensor will move to the target position where the sensor can measure the occluded area. Finally, the measured information of all sensors will be merged for data fusion. The experimental results show the effectiveness of the system.","2009","10","2","2025-12-02","https://university.edu/papers/5ac8b258-a1e7-4338-9db3-6f4f62f9c5c2.pdf");
INSERT INTO Paper VALUES ("343","3 Megapixel Camera Signal Processor for Mobile Camera Applications","This paper describes a low power and high performance camera signal processor system on chip (SoC) architecture for mobile applications such as the mobile phone, the personal digital assistant (PDA), and the personal multimedia player (PMP). In this work, the presented SoC architecture of the camera signal processor (CSP) provides not only image signal processing functions but also various actuator interfaces. Additionally, we propose an adaptive data synchronization method using the glitch-free clock switching technique. The area of this chip 2.8times2.7 mm and it was fabricated with the 0.18-mum CMOS process. This device packaged with Flash memory in a multi-chip package (MCP) technology and dissipates 76 mW at 1.8 V/50 MHz.","2006","7","3","2025-12-02","https://university.edu/papers/ba13b44f-3822-4e08-a8b1-8dc495be4a16.pdf");
INSERT INTO Paper VALUES ("344","Composable memory transactions","Writing concurrent programs is notoriously difficult, and is of increasing practical importance. A particular source of concern is that even correctly-implemented concurrency abstractions cannot be composed together to form larger abstractions. In this paper we present a new concurrency model, based on  transactional memory , that offers far richer composition. All the usual benefits of transactional memory are present (e.g. freedom from deadlock), but in addition we describe new modular forms of  blocking  and  choice  that have been inaccessible in earlier work.","2005","14","4","2025-12-02","https://university.edu/papers/72ce85d6-4093-4f4e-bb4c-c38f5d3d52ce.pdf");
INSERT INTO Paper VALUES ("345","A Performance-Based Scheme for Pricing Resources in the Cloud","With the rapid growth of the cloud computing marketplace, the issue of pricing resources in the cloud has been the subject of much study in recent years. In this paper, we identify and study a new issue: how to price resources in the cloud so that the customer's risk is minimized, while at the same time ensuring that the provider accrues his fair share. We do this by correlating the revenue stream of the customer to the prices charged by the provider. We show that our mechanism is incentive compatible in that it is in the best interest of the customer to provide his true revenue as a function of the resources rented. We next add another restriction to the price function, i.e., that it be linear. This removes the distortion that creeps in when the customer has to pay more money for less resources. Our algorithms for both the schemes mentioned above are efficient.","2016","16","2","2025-12-02","https://university.edu/papers/5d9acde4-2931-4e43-b15c-70a1be1e9028.pdf");
INSERT INTO Paper VALUES ("346","The value of asset visibility in the supply chain single and dual source models","We investigate the value of asset visibility in two inventory ordering models. The first model is a basic single source model, and we use a previous result to show that in this case asset visibility does not reduce costs. We then generalize this model to include a second supply option and show that if decisions are made optimally and asset visibility can add value. We apply these results to an application in which random security inspections are introduced in the supply chain.","2004","14","3","2025-12-02","https://university.edu/papers/d16df3e2-9039-4f0f-aae1-0bdb96e3f01e.pdf");
INSERT INTO Paper VALUES ("347","Very low bit rate video coding using 3D subband approach","A video coder for very low bit rate applications is designed and simulated. It employs subband analysis technique to first split the video signal into four temporal subbands. Motion detection is performed to classify the co-sited macroblocks of the subbands into temporal activity (TA) macroblocks or no temporal activity (NTA) macroblocks. For the TA macroblocks, motion classification is carried out by further dividing the four temporal subbands into 16 spatiotemporal subbands. The base temporal subband (LL/sub t/) is coded using a H.261-like (European COST 211 ter SIM3) coder with the motion estimation replaced by a reduced-motion search algorithm. The higher temporal subbands (LH/sub t/, HL/sub t/, HH/sub t/) are vector-quantized. The NTA-macroblocks (except in the baseband) are not coded at all. Simulation results are presented at 9.6 kbits per second (kbps) at five frames per second (fps) for a typical videoconferencing sequence. Comparisons are made with results obtained by the SIM3 coder. >","1994","19","4","2025-12-02","https://university.edu/papers/78dddde5-450b-4610-b209-810e9f6b92e7.pdf");
INSERT INTO Paper VALUES ("348","Towards a Multiscale Model of Acute HIV Infection","Human Immunodeficiency Virus (HIV) infection of humans represents a complex biological system and a great challenge to public health. Novel approaches for the analysis and prediction of the infection dynamics based on a multi-scale integration of virus ontogeny and immune reactions are needed to deal with the systems’ complexity. The aim of our study is: (1) to formulate a multi-scale mathematical model of HIV infection; (2) to implement the model computationally following a hybrid approach; and (3) to calibrate the model by estimating the parameter values enabling one to reproduce the “standard” observed dynamics of HIV infection in blood during the acute phase of primary infection. The modeling approach integrates the processes of infection spread and immune responses in Lymph Nodes (LN) to that observed in blood. The spatio-temporal population dynamics of T lymphocytes in LN in response to HIV infection is governed by equations linking an intracellular regulation of the lymphocyte fate by intercellular cytokine fields. We describe the balance of proliferation, differentiation and death at a single cell level as a consequence of gene activation via multiple signaling pathways activated by IL-2, IFNa and FasL. Distinct activation thresholds are used in the model to relate different modes of cellular responses to the hierarchy of the relative levels of the cytokines. We specify a reference set of model parameter values for the fundamental processes in lymph nodes that ensures a reasonable agreement with viral load and CD4+ T cell dynamics in blood.","2017","1","2","2025-12-02","https://university.edu/papers/1469b350-d221-4ff3-8be9-32d210170053.pdf");
INSERT INTO Paper VALUES ("349","Capacity optimization for UMTS: Bounds and benchmarks for interference reduction","UMTS has been designed as the next platform for mobile mass market communication. After a slow start, the usage of UMTS in terms of subscribers and volume is picking up momentum. Following the initial coverage-driven phase, network capacity is moving into focus. During network planning and optimization, cell capacity can be improved by explicitly designing for minimal interference. This article introduces planning methodologies that allow to minimize interference overhead while maintaining the established network coverage. Our main contribution is the first practicable approach for comparing interference to lower bounds and benchmarks. This comparison on realistic datasets suggests that our optimization methods produce first-class results.","2008","3","2","2025-12-02","https://university.edu/papers/c6fbae72-35a3-48a1-b45b-5392e24dd9ef.pdf");
INSERT INTO Paper VALUES ("350","Patient-Specific Cortical Electrodes for Sulcal and Gyral Implantation","Purpose:  Noninvasive localization of certain brain functions may be mapped on a millimetre level. However, the interelectrode spacing of common clinical brain surface electrodes still remains around 10 mm. Here, we present details on development of electrodes for attaining higher quality electrocorticographic signals for use in functional brain mapping and brain–machine interface (BMI) technologies.  Methods : We used platinum-plate-electrodes of 1-mm diameter to produce sheet electrodes after the creation of individualized molds using a 3-D printer and a press system that sandwiched the electrodes between personalized silicone sheets.   Results : We created arrays to fit the surface curvature of the brain and inside the central sulcus, with interelectrode distances of 2.5 mm (a density of 16 times previous standard types). Rat experiments undertaken indicated no long term toxicity. We were also able to custom design, rapidly manufacture, safely implant, and confirm the efficacy of personalized electrodes, including the capability to attain meaningful high-gamma-band information in an amyotrophic lateral sclerosis patient.  Conclusion:  We developed cortical sheet electrodes with a high-spatial resolution, tailor-made to match an individual's brain.  Significance:   This sheet electrode may contribute to the higher performance of BMI's.","2015","11","3","2025-12-02","https://university.edu/papers/c8177bcf-ed78-4bc0-8f19-c5009e3a4835.pdf");
INSERT INTO Paper VALUES ("351","Machine Learning for Author Affiliation within Web Forums -- Using Statistical Techniques on NLP Features for Online Group Identification","Although there have been previous studies performing authorship attribution to a specific individual, we find a shortage of efforts to group authors based on their affiliations. This paper presents our work on classification of website forum posts by the author's group affiliation. Specifically, we seek to classify translated website forum posts by the (inferred) political affiliation of the author. The two datasets that we attempt to classify consist of real-world data discussing current issues -- Israeli/Palestinian dialogue (Bitter Lemons corpus) and translated Extremist/Moderate forum entries (from internet websites). To achieve our goal of reliable authorship affiliation, we extract term frequency-based features (that are conventional in document classification) along with less commonly used linguistic style-based features. The resulting set of stylometric features are then utilized in two widely used supervised classification algorithms, namely k-Nearest Neighbor algorithm and Support Vector Machines. Specifically, we used k-NN with cosine distance and Support Vector Machines with two different kernel functions. In addition to the popular RBF kernels, we also evaluate the applicability and performance of the recently introduced arc-cosine kernels for group affiliation. The results of our experiments show strong performance across a range of pertinent metrics.","2011","1","2","2025-12-02","https://university.edu/papers/1985aa7f-2b14-4fcb-8a99-da799c78b3d9.pdf");
INSERT INTO Paper VALUES ("352","A comparative study of two useful discrete-valued random fields for the statistical modeling of images","The author presents two interesting discrete-valued random fields for the statistical modeling and analysis of random images. The first random field, the mutually compatible Gibbs random field, is a special nontrivial case of a general Gibbs random field, whereas the second random field, the semi-Markov random field is a non-Markovian generalization of a mutually compatible Gibbs random field. >","1988","15","2","2025-12-02","https://university.edu/papers/7fa99a80-7485-48e7-a831-3d8afeed142a.pdf");
INSERT INTO Paper VALUES ("353","Video to reference image alignment in the presence of sparse features and appearance change","A robust, multi-frame, progressive refinement framework for registering narrow field of view video to reference imagery is presented. A major strength of the approach is its effectiveness in the presence of dissimilar video and reference image appearance. Normalized oriented energy image pyramids are employed to enable alignment of images with global visual dissimilarities, yet local feature commonality. Local matching is then applied coarse-to-fine, along four dimensions: spatial frequency, local support, search range, and model order (a robust parametric model fit is used to reject outliers at each iteration). Globally optimal multi-frame alignment is obtained with respect to several constraints: frame-to-reference local matches, recovered frame-to-frame motion, and optional a priori estimates of sensor pose. The framework is described in detail and applied to two examples: aerial video to geographic reference image alignment (georegistration) and retinal slit lamp video to fundus image alignment.","2001","16","3","2025-12-02","https://university.edu/papers/82bda1b3-7b52-45b9-b5aa-0512488329c3.pdf");
INSERT INTO Paper VALUES ("354","Autonomous Fall Detection With Wearable Cameras by Using Relative Entropy Distance Measure","Timely, precise, and reliable detection of fall events is very important for systems monitoring activities of elderly people, especially the ones living independently. In this paper, we propose an autonomous fall detection system by taking a completely different view compared with existing vision-based activity monitoring systems and applying a reverse approach. In our system, in contrast with static sensors installed at fixed locations, the camera is worn by the subject, and thus, monitoring is not limited only to areas where the sensors are located and extends to wherever the subject may travel. Moreover, the camera provides a richer set of data and helps lower the false positive rates compared with accelerometer-only systems. We employ a modified version of the histograms of oriented gradients (HOG) approach together with the gradient local binary patterns (GLBP). It is shown that, with the same training set, the GLBP feature is more descriptive and discriminative than HOG, histograms of template, and semantic local binary patterns. Moreover, we autonomously compute a threshold, for the detection of fall events, from the training data based on relative entropy, which is a member of Ali–Silvey distance measures. Experiments are performed with ten different people and a total of around 300 associated fall events indoors and outdoors. Experimental results show that, with the autonomously computed threshold, the proposed method provides 93.78% and 89.8% accuracy for detecting falls with indoor and outdoor experiments, respectively.","2017","4","4","2025-12-02","https://university.edu/papers/61a0ffbf-30f3-4cd5-999a-dbd5b87f2cdb.pdf");
INSERT INTO Paper VALUES ("355","A 3-D model-based registration approach for the PET, MR and MCG cardiac data fusion","In this paper, a new approach is presented for the assessment of a 3-D anatomical and functional model of the heart including structural information from magnetic resonance imaging (MRI) and functional information from positron emission tomography (PET) and magnetocardiography (MCG). The method uses model-based co-registration of MR and PET images and marker-based registration for MRI and MCG. Model-based segmentation of MR anatomical images results in an individualized 3-D biventricular model of the heart including functional parameters from PET and MCG in an easily interpretable 3-D form.","2003","9","1","2025-12-02","https://university.edu/papers/f9a7dada-a843-4b89-ad20-48b775900474.pdf");
INSERT INTO Paper VALUES ("356","The design and implementation of a digital music library","The design and implementation of Harbin Institute of Technology--Digital Music Library (HIT-DML) is presented in this paper. Firstly, a novel framework, a music data model, and a query language are proposed as the theoretical foundation of the library. Secondly, music computing algorithms used in the library for feature extracting and matching are described. In addition, indices are introduced for both mining themes of music objects and accelerating content-based information retrieval. Finally, experimental results on the indices and the current development of the library are provided.#R##N##R##N#HIT-DML is distinguished by the following points. First, it is inherently based on database systems, and combines database technologies with multimedia technologies seamlessly. Musical data are structurally stored. Second, it has a solid theoretical foundation, from framework and data model to query language. Last, it can retrieve musical information based on content against different kinds of musical instruments. The indices used, also power the library.","2006","15","2","2025-12-02","https://university.edu/papers/55dfa05a-9bcb-4af5-8991-ec7e02741a93.pdf");
INSERT INTO Paper VALUES ("357","Integral plus double integral synchronization control for multiple piezoelectric actuators","In this paper, an integral plus double integral synchronization controller is developed for multiple piezoelectric actuators through a state feedback approach. Dynamic modeling of the piezoelectric nanopositioner is conducted through both linear and nonlinear phenomenological models. The linear and nonlinear models are then used along with the experimental system to perform hardware in the loop (HITL) simulations of the synchronization controller for a parallel three-axis nanopositioning system. This would allow the piezoelectrics to form the basis of an ultra-precise 2-D Fabry-Perot interferometer as the gap spacing of the device could be controlled at the nanometer level.","2015","15","1","2025-12-02","https://university.edu/papers/c961a887-993f-461e-afec-6a9f1a185ba7.pdf");
INSERT INTO Paper VALUES ("358","Reduction of inherent ambiguities in structure from motion problem using inertial data","The reduction of inherent ambiguities in structure from motion (SfM) using inertial data is addressed. First, we show that the translation-rotation ambiguity in SfM from a noisy flow field computed from two frames can be completely eliminated by using noise free inertial rate data. Secondly, we show that the admissible solution space for SfM from noisy feature correspondences can be reduced by using inertial data.","2000","2","2","2025-12-02","https://university.edu/papers/a5f20243-9218-44a0-9a23-43bcf11ab8dd.pdf");
INSERT INTO Paper VALUES ("359","EyeContext: recognition of high-level contextual cues from human visual behaviour","In this work we present  EyeContext , a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues:  social  (interacting with somebody vs. no interaction),  cognitive  (concentrated work vs. leisure),  physical  (physically active vs. not active), and  spatial  (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.","2013","7","4","2025-12-02","https://university.edu/papers/8a46c175-d799-4215-ba43-9be3bf517711.pdf");
INSERT INTO Paper VALUES ("360","TRIBLER: a social-based peer-to-peer system","SUMMARY Most current P2P file-sharing systems treat their users as anonymous, unrelated entities, and completely disregard any social relationships between them. However, social phenomena such as friendship and the existence of communities of users with similar tastes or interests may well be exploited in such systems in order to increase their usability and performance. In this paper we present a novel social-based P2P filesharing paradigm that exploits social phenomena by maintaining social networks and using these in content discovery, content recommendation, and downloading. Based on this paradigm’s main concepts such as taste buddies and friends, we have designed and implemented the TRIBLER P2P file-sharing system as a set of extensions to Bittorrent. We present and discuss the design of TRIBLER, and we show evidence that TRIBLERenables fast content discovery and recommendation at a low additional overhead, and a significant improvement in download performance.","2008","18","2","2025-12-02","https://university.edu/papers/dcbba265-fa46-46ed-b6e7-43745b43542b.pdf");
INSERT INTO Paper VALUES ("361","Optimizing neural networks for public opinion trends prediction","This paper describes the method of public opinion trends prediction based on back-propagation (BP) neural networks. This paper compares two measures which are used to optimize shortcomings of the BP neural network: genetic algorithms and simulated annealing algorithm. To improve both genetic algorithms and simulated annealing, we combine these two algorithms to optimize the BP neural network. It can not only solve the dependence on the initial sample values of the BP neural network, but also prevent its falling into local minimum. It is this dual optimization on the BP neural network that will enhance the accuracy of public opinion trends prediction significantly.","2015","20","4","2025-12-02","https://university.edu/papers/17aaa88c-745c-4dc8-b7e7-f3ac505143e3.pdf");
INSERT INTO Paper VALUES ("362","A neural algorithm for variable thresholding of images","A two-stage thresholding for gray scale images is presented in this paper. The first stage is based on a conventional application of the histograms which provides fixed global threshold value. This threshold value is then assigned as the initial state of a set of neurons which will process the image in parallel, in a horizontal scan, producing the binary image at the output. The state of the neurons is updated using the Kohonen self-organizing learning algorithm. This technique has two properties, First it smooths the spike noise, and second the low frequency illumination variation is compensated for and the segmented binary image regions are not affected by lighting conditions. Several examples are processed and presented to show the performance of the algorithm. >","1991","7","3","2025-12-02","https://university.edu/papers/986f0a58-d91e-49e9-b012-2812a81b0f62.pdf");
INSERT INTO Paper VALUES ("363","Novel intrusion prediction mechanism based on honeypot log similarity","International Journal of Network Management#R##N#Early View (Online Version of Record published before inclusion in an issue)","2016","7","2","2025-12-02","https://university.edu/papers/0bc11927-3f9c-46a7-a31b-1dbb7899524b.pdf");
INSERT INTO Paper VALUES ("364","A Bayesian model for estimating multi-state disease progression","A growing number of individuals who are considered at high risk of cancer are now routinely undergoing population screening. However, noted harms such as radiation exposure, overdiagnosis, and overtreatment underscore the need for better temporal models that predict who should be screened and at what frequency. The mean sojourn time (MST), an average duration period when a tumor can be detected by imaging but with no observable clinical symptoms, is a critical variable for formulating screening policy. Estimation of MST has been long studied using continuous Markov model (CMM) with Maximum likelihood estimation (MLE). However, a lot of traditional methods assume no observation error of the imaging data, which is unlikely and can bias the estimation of the MST. In addition, the MLE may not be stably estimated when data is sparse. Addressing these shortcomings, we present a probabilistic modeling approach for periodic cancer screening data. We first model the cancer state transition using a three state CMM model, while simultaneously considering observation error. We then jointly estimate the MST and observation error within a Bayesian framework. We also consider the inclusion of covariates to estimate individualized rates of disease progression. Our approach is demonstrated on participants who underwent chest x-ray screening in the National Lung Screening Trial (NLST) and validated using posterior predictive p-values and Pearson's chi-square test. Our model demonstrates more accurate and sensible estimates of MST in comparison to MLE.","2017","19","1","2025-12-02","https://university.edu/papers/28938440-7236-4fb4-beb3-ad7f27dadc4c.pdf");
INSERT INTO Paper VALUES ("365","Adaptive Spectrum Sensing Algorithm Under Different Primary User Utilizations","Spectrum sensing is one of the key technologies to realize dynamic spectrum access in cognitive radio (CR) systems. In this letter, a novel adaptive threshold spectrum sensing algorithm is proposed to achieve an efficient trade-off between the detection and false alarm probability. The proposed adaptive threshold algorithm demonstrates a better spectrum efficiency for both primary users (PUs) and secondary users (SUs) in comparison with the conventional fixed one. A closed-from expression between PUs' spectrum utilization ratio and the proposed adaptive threshold is derived and simplified.","2013","12","3","2025-12-02","https://university.edu/papers/4b7fa1a8-edb5-4f84-b982-8e9159c88590.pdf");
INSERT INTO Paper VALUES ("366","Fuzzy representations need a careful design","This paper tries to show, from a theoretical perspective, the importance of designing well the representation of fuzzy systems whose behaviour is described by a linguistic description. The way in which this design of the representation is done by means of fuzzy sets, connectives and relations marks a distinction between the fuzzy and the formal logic methodologies, two different disciplines whose design process and agendas are not coincidental.","2010","1","3","2025-12-02","https://university.edu/papers/b254ac5f-fbc4-4497-a42e-4af283b0304b.pdf");
INSERT INTO Paper VALUES ("367","Smoothness of Surgical Tool Tip Motion Correlates to Skill in Endovascular Tasks","Current performance assessment techniques in endovascular surgery are subjective or limited to grading scales based solely on an expert's observation of a novice's task execution. Since most endovascular procedures involve performing fine motor control tasks that require complex dexterous movements, this paper evaluates objective and quantitative metrics of performance that capture movement quality through the computation of tool tip movement smoothness. An experiment was designed that involved recording the catheter tip movement from 20 subjects performing four fundamental endovascular tasks in each of three sessions using manual catheterization on a physical model and in a simulation environment. Several motion-based performance measures that have been shown to reliably assess skill in other domains were computed and tested for correlation with subjective data that were simultaneously obtained from the global rating scale assessment tool. Metrics that captured movement smoothness produced statistically significant correlations with the observation-based assessment metrics and were able to differentiate skill among participants. In particular, submovement analysis led to metrics that captured statistically significant differences across ability group, session, experimental platform, and task. Objective and quantitative metrics that capture movement smoothness could be incorporated into future training protocols to provide detailed feedback on trainee performance.","2016","10","1","2025-12-02","https://university.edu/papers/80e0d84d-f88d-400b-8048-1eb21fa9a3fc.pdf");
INSERT INTO Paper VALUES ("368","Patient status monitoring for smart home healthcare","We propose smart home health care system for the realization of smart cities to fulfill the needs of elderly people in order to have continued care. An elderly person should be monitored constantly, specifically if he or she is diagnosed for health-related problems before. In the proposed system, a patient's condition is monitored by using multimodal inputs, specifically, speech and video. Video cameras and microphones are installed in the smart homes; these sensors constantly capture video and speech of the patient, and transmit them to a dedicated cloud. In the cloud, the data are processed, and a classification score on the patient's condition, whether he is normal, tensed, or in pain, is produced. Depending on the condition of the person, the doctors prescribe the person via audio, video or message services, or the caregivers rush to the location for emergency. For data processing in the server, we extract robust and low-dimensional discriminating features from voice and video frames. Experimental results show that the combined modality achieves better accuracy than that using a single modality to correctly classify the patient's condition.","2016","16","4","2025-12-02","https://university.edu/papers/115c4757-c190-443c-8880-55a77a86ad7e.pdf");
INSERT INTO Paper VALUES ("369","On the Evolution of Remote Laboratories for Prototyping Digital Electronic Systems","The design of digital electronic systems for industrial applications can benefit in many ways from the prototyping capabilities of field-programmable gate array (FPGA) platforms. This paper presents three evolutionary releases of an FPGA-based remote laboratory and discusses the didactical and technical motivations behind each release, aiming to reduce the overhead of setting up and operate a laboratory environment where designers and students can use FPGA prototyping to validate their designs. To achieve that, a number of abstraction layers were introduced, allowing configuration and data processing in remote FPGA platforms, as well as integrating such platforms within a simulation environment. The proposed approach supported a number of projects where groups of designers and students could specify, refine, and prototype electronic systems using a pool of remotely available FPGA platforms.","2007","14","4","2025-12-02","https://university.edu/papers/d5f0689a-d318-4b18-8b57-619bfb698553.pdf");
INSERT INTO Paper VALUES ("370","Metaphors be with you! (Metaphor System)","The original formulation of XP promoted metaphor to the status of essential practice. XP was the only agile method that made the use of metaphor this explicit and essential - unique. Unique: and immediately controversial. Few practitioners claimed to understand the intent of metaphor as a practice, how to devise and evaluate metaphors, or the relationship of metaphor to design and the other XP practices. As XP evolved metaphor was demoted and is no longer a separate practice. Most agile proponents mention metaphor and acknowledge minor uses. This paper argues that XP was wrong to abandon metaphor and advocates a more systematic discussion of how metaphor informs development.","2005","12","3","2025-12-02","https://university.edu/papers/ff9276fb-edc2-4a9c-b1ab-d17b695e91a2.pdf");
INSERT INTO Paper VALUES ("371","Building a hierarchical representation of membership functions","Deriving inference rules from training examples is one of the most common machine-learning approaches. Fuzzy systems that can automatically derive fuzzy if-then rules and membership functions from numeric data have recently been developed. In this paper, we propose a new hierarchical representation for membership functions, and design a procedure to derive them. Experimental results on the Iris data show that our method can achieve high accuracy. The proposed method is thus useful in constructing membership functions and in managing uncertainty and vagueness.","1998","18","4","2025-12-02","https://university.edu/papers/72855515-5754-4d47-9640-8bcc488729c4.pdf");
INSERT INTO Paper VALUES ("372","A new class of Fibonacci sequence based error correcting codes","A new class of matrices is introduced for use in error control coding. This extends previous results on the class of Fibonacci error correcting codes. For a given integer p, a (p+1)×(p+1) binary matrix Mp is given whose nonzero entries are located either on the superdiagonal or the last row of the matrix. The matrices \({M^{n}_{p}}\) and \(M^{-n}_{p}\), the nth power of Mp and its inverse, are employed as the encoding and decoding matrices, respectively. It is shown that for sufficiently large n, independent of the message matrix M, relations exist among the elements of the encoded matrix \(E=M\times {M_{p}^{n}}\). These relations play a key role in the error detection and correction.","2017","17","3","2025-12-02","https://university.edu/papers/3786970a-c62d-4289-a6a8-df17554bfb0d.pdf");
INSERT INTO Paper VALUES ("373","A Kalman filter based visual tracking algorithm for an object moving in 3D","Robust and effective real-time visual tracking is realized by combining the first order differential invariants with stochastic filtering. The Kalman filter as an optimal stochastic filter is used to estimate the motion parameters, namely the plant state vector of the moving object with the unknown dynamics in successive image frames. Using the fact that the relative motion between the moving object and the moving observer causes the deformation, we compute the first differential invariants of the image velocity field. The surface orientation and the depth estimate between the observer and the object are computed based on these first order differential invariants. We demonstrate the robustness and feasibility of the proposed tracking algorithm through real experiments in which an X-Y Cartesian robot tracks a toy vehicle moving along 3D rails.","1995","4","2","2025-12-02","https://university.edu/papers/572a9d0c-df14-4412-ab7d-e123c3a65d1f.pdf");
INSERT INTO Paper VALUES ("374","Structured estimation of sparse channels in quasi-synchronous DS-CDMA","We explore the channel estimation problem in the case of quasi-synchronous users in a DS-CDMA system. Knowledge of the transmit (TX) filter is assumed, and the anti-aliasing low-pass front end receive (RX) filter is designed for critical sampling at the Nyquist rate for the TX filter. It is shown that when the sampling frequency is larger than the Nyquist frequency, the discrete-time representation of the channel is not unique. However, all representations can be treated in a similar fashion once the Nyquist rate is satisfied. On the other hand, fractionally sampling the channel leads to a scenario in which the cut-off frequency can be approached arbitrarily close to the Nyquist rate. In the case of sparse channels, sampling the channel at any rate lends to a small number of non-zero coefficients in the finite-impulse response(FIR) representation of the channel. The structured channel estimation algorithm presented in this paper exploits the sparseness of this model. Results are compared with those of other previously proposed structured methods.","2000","15","4","2025-12-02","https://university.edu/papers/c9d63d57-f0c0-4a0b-8e15-0fb3e0145bc8.pdf");
INSERT INTO Paper VALUES ("375","A metropolitan area radio system using scanning pencil beams","A metropolitan-area radio system that, from a centrally located base station, provides continuously 360 degrees coverage over a large service region is proposed. The base station blankets the service region with a raster of very narrow pencil beams that can be rapidly scanned to any position in synchronism with the switching sequences of a time-division-multiple-access (TDMA) assignment. By deploying multiple scanning spot beams, the allocated spectrum can be reused many times. A centralized network controller, executing an efficient TDMA assignment algorithm, dynamically allocates the resources of a small transceiver pool among the far larger number of beam positions in response to real-time requests for service. By varying the dwell time at each beam position in response to the traffic intensity of the position, highly efficient resource utilization is provided. The high antenna gain of the base station antenna provides adequate arain fade margin to permit operation in the uncongested portion of the ratio spectrum above 20 GHz. The system is particularly well suited to emerging, direct-to-end-user wideband digital service offerings. >","1991","12","2","2025-12-02","https://university.edu/papers/4cead660-dd20-496b-9113-492dc8fb6b20.pdf");
INSERT INTO Paper VALUES ("376","Conceptual Imitation Learning: An Application to Human-Robot Interaction","In general, imitation is imprecisely used to address dierent levels of social learning from high level knowledge transfer to low level regeneration of motor commands. However, true imitation is based on abstraction and conceptualization. This paper presents a con- ceptual approach for imitation learning using feedback cues and interactive training to abstract spatio-temporal demonstrations based on their perceptual and functional char- acteristics. Abstraction, concept acquisition, and self-organization of proto-symbols are performed through an incremental and gradual learning algorithm. In this algorithm, Hid- den Markov Models (HMMs) are used to abstract perceptually similar demonstrations. However, abstract (relational) concepts emerge as a collection of HMMs irregularly scat- tered in the perceptual space. Performance of the proposed algorithm is evaluated in a human-robot interaction task of imitating signs produced by hand movements. Exper- imental results show eciency of our model for concept extraction, symbol emergence, motion pattern recognition, and regeneration.","2010","18","2","2025-12-02","https://university.edu/papers/cfa1f190-1178-4949-80a6-e340eceb2163.pdf");
INSERT INTO Paper VALUES ("377","Doctors' online information needs, cognitive search strategies, and judgments of information quality and cognitive authority: How predictive judgments introduce bias into cognitive search models","Literature examining information judgments and Internet search behaviors notes a number of major research gaps, including how users actually make these judgments outside of experiments or researcher-defined tasks, and how search behavior is impacted by a user's judgment of online information. Using the medical setting, where doctors face real consequences in applying the information found, we examine how information judgments employed by doctors to mitigate risk impact their cognitive search. Diaries encompassing 444 real clinical information search incidents, combined with semistructured interviews across 35 doctors, were analyzed via thematic analysis. Results show that doctors, though aware of the need for information quality and cognitive authority, rarely make evaluative judgments. This is explained by navigational bias in information searches and via predictive judgments that favor known sites where doctors perceive levels of information quality and cognitive authority. Doctors' mental models of the Internet sites and Web experience relevant to the task type enable these predictive judgments. These results suggest a model connecting online cognitive search and information judgment literatures. Moreover, this implies a need to understand cognitive search through longitudinal- or learning-based views for repeated search tasks, and adaptations to medical practitioner training and tools for online search. © 2010 Wiley Periodicals, Inc.","2010","18","4","2025-12-02","https://university.edu/papers/ed805e37-6ecc-460b-96fa-e2a89f31f3df.pdf");
INSERT INTO Paper VALUES ("378","SHIELD: a software hardware design methodology for security and reliability of MPSoCs","Security of MPSoCs is an emerging area of concern in embedded systems. Security is jeopardized by  code injection  attacks, which are the most common types of software attacks. Previous attempts to detect code injection in MPSoCs have been burdened with significant performance overheads. In this work, we present a hardware/software methodology 'SHIELD' to detect code injection attacks in MPSoCs. SHIELD instruments the software programs running on application processors in the MPSoC and also extracts control flow and basic block execution time information for runtime checking.   We employ a dedicated security processor (monitor processor) to supervise the application processors on the MPSoC. Custom hardware is designed and used in the monitor and application processors. The monitor processor uses the custom hardware to rapidly analyze information communicated to it from the application processors at runtime. We have implemented SHIELD on a commercial extensible processor (Xtensa LX2) and tested it on a multiprocessor JPEG encoder program. In addition to code injection attacks, the system is also able to detect 83% of bit flips errors in the control flow instructions.   The experiments show that SHIELD produces systems with runtime which is at least 9 times faster than the previous solution. SHIELD incurs a runtime (clock cycles) performance overhead of only 6.6% and an area overhead of 26.9%, when compared to a non-secure system.","2008","13","3","2025-12-02","https://university.edu/papers/de4c79d9-318d-4eec-844a-dc8e4665f261.pdf");
INSERT INTO Paper VALUES ("379","Aibiki: supporting shamisen practice with adaptive automatic score scroll","We present a system called  Aibiki , which can support users in practicing the  shamisen , a three-stringed Japanese musical instrument, via an automatic and adaptive score scroll. We chose  Nagauta , as an example of a type of shamisen music. Each piece typically lasts 10-40 min; furthermore, both hands are required to play the shamisen, and it is not desirable to turn pages manually during a performance. In addition, there are some characteristic issues that are particular to the shamisen, including the variable tempo of the music and the unique timbre of the instrument, which makes pitch detection difficult using standard techniques. In this work, we describe an application that automatically scrolls through a musical score, initially at a predefined tempo. Because there is often a difference between the predefined tempo and tempo with which the musician plays the piece, the application adjusts speed of the score scroll based on the input from a microphone. We evaluated the performance of the application via a user study. We find that the system was able to scroll the score in time to the actual performance, and that the system was useful for practicing and playing the shamisen.","2014","14","3","2025-12-02","https://university.edu/papers/e96ebe07-0d74-464a-b610-040aba48ae5b.pdf");
INSERT INTO Paper VALUES ("380","Stochastic time-frequency analysis using the analytic signal: why the complementary distribution matters","We challenge the perception that we live in a 'proper world', where complex random signals can always be assumed to be proper (also called circularly symmetric). Rather, we stress the fact that the analytic signal constructed from a nonstationary real signal is, in general, improper, which means that its complementary correlation function is nonzero. We explore the consequences of this finding in the context of stochastic time-frequency analysis in Cohen's class. There, the analytic signal plays a prominent role because it reduces interference terms. However, the usual time-frequency representation (TFR) based on the analytic signal gives only an incomplete signal description. It must be augmented by a complementary TFR whose properties we develop in detail. We show why it is still advantageous to use the pair of standard and complementary TFRs of the analytic signal rather than the TFR of the corresponding real signal.","2003","20","1","2025-12-02","https://university.edu/papers/bd77b4e5-e422-4e12-a76f-e64257d65815.pdf");
INSERT INTO Paper VALUES ("381","Supervisory Control Architecture for Discrete-Event Systems","A flexible decentralized and hierarchical architecture is presented to reduce computational effort in designing optimal nonblocking supervisors for discrete-event systems (DES). We organize a DES into modular subsystems that embody internal interacting dependencies. Verification of, and coordination among modular subsystems are achieved through their model abstractions. Sufficient conditions are presented to guarantee that coordinators and modular supervisors result in maximally permissive and nonblocking control. A medium-sized example demonstrates the computational effectiveness of our approach.","2008","3","1","2025-12-02","https://university.edu/papers/ad4100ff-d8b8-4c5b-8696-f9de9d51e3cf.pdf");
INSERT INTO Paper VALUES ("382","Symbolic and Abstract Interpretation for C/C++ Programs","We present a construction technique for abstract interpretations which is generic in the choice of data abstractions. The technique is specialised on C/C++ code, internally represented by the GIMPLE control flow graph as generated by the gcc compiler. The generic interpreter handles program transitions in a symbolic way, while recording a history of symbolic memory valuations. An abstract interpreter is instantiated by selecting appropriate lattices for the data types under consideration. This selection induces an instance of the generic transition relation. All resulting abstract interpretations can handle pointer arithmetic, type casts, unions and the aliasing problems involved. It is illustrated how switching between abstractions can improve the efficiency of the verification process. The concepts described in this paper are implemented in the test automation and static analysis tool RT-Tester which is used for the verification of embedded systems in the fields of avionics, railways and automotive control.","2008","3","1","2025-12-02","https://university.edu/papers/4e2187d7-611d-41bd-b090-2e021b481d32.pdf");
INSERT INTO Paper VALUES ("383","Cracking Classifiers for Evasion: A Case Study on the Google's Phishing Pages Filter","Various classifiers based on the machine learning techniques have been widely used in security applications. Meanwhile, they also became an attack target of adversaries. Many existing studies have paid much attention to the evasion attacks on the online classifiers and discussed defensive methods. However, the security of the classifiers deployed in the client environment has not got the attention it deserves. Besides, earlier studies only concentrated on the experimental classifiers developed for research purposes only. The security of widely-used commercial classifiers still remains unclear. In this paper, we use the Google's phishing pages filter (GPPF), a classifier deployed in the Chrome browser which owns over one billion users, as a case to investigate the security challenges for the client-side classifiers. We present a new attack methodology targeting on client-side classifiers, called classifiers cracking. With the methodology, we successfully cracked the classification model of GPPF and extracted sufficient knowledge can be exploited for evasion attacks, including the classification algorithm, scoring rules and features, etc. Most importantly, we completely reverse engineered 84.8% scoring rules, covering most of high-weighted rules. Based on the cracked information, we performed two kinds of evasion attacks to GPPF, using 100 real phishing pages for the evaluation purpose. The experiments show that all the phishing pages (100%) can be easily manipulated to bypass the detection of GPPF. Our study demonstrates that the existing client-side classifiers are very vulnerable to classifiers cracking attacks.","2016","20","4","2025-12-02","https://university.edu/papers/1e8bf6aa-43cf-4126-9e42-805640bb0330.pdf");
INSERT INTO Paper VALUES ("384","A new group Diffie-Hellman key generation proposal for secure VANET communications","Vehicular Networks must be sufficiently secured against the wide variety of security challenges to which they are exposed. Cryptography provides tools to solve many of these security problems. In this paper, we address the secure group communications problem in VANETs. By generating a secret group key that can be used to encrypt or authenticate, the members of a VANET platoon can thus guarantee secure communication between them. To address this need, we propose a new secure variant of the Diffie-Hellman algorithm for groups that we fortified by a pre-shared secret to withstand the famous Man in the Middle attack. As necessary, our proposal can be used by several types of authentication and encryption VANET applications. We demonstrate the unforgeability and the privacy of our scheme and we study its secure-efficiency.","2016","4","4","2025-12-02","https://university.edu/papers/8470cd80-0df5-438d-9af5-aa167f7c4a80.pdf");
INSERT INTO Paper VALUES ("385","Cache performance impacts for stack machines in embedded systems","Java, with its advantages as being an overspread multiplatform object oriented language, has been gaining popularity in the embedded system market over the years. However, because of its extra layer of interpretation, it is also believed that it is a slow language while being executed. Nevertheless, when this execution is done directly in hardware, Java advantages caused by its stack nature start to appear. One of these advantages concerns memory utilization, impacting in less accesses and cache misses. In this work we analyze this impact in performance and energy consumption, comparing a Java processor with a RISC one based on aMIPS architecture with similar characteristics.","2006","20","1","2025-12-02","https://university.edu/papers/d45b3aee-bb70-4e50-95b9-f3d43ec33ea8.pdf");
INSERT INTO Paper VALUES ("386","Requirements Engineering Current Practice and Capability in Small and Medium Software Development Enterprises in New Zealand","This paper presents research on current industry practices with respect to requirements engineering as implemented within software development companies in New Zealand. A survey instrument is designed and deployed. The results are analysed and compared against what is internationally considered 'best practice' and previous New Zealand and Australian studies. An attempt is made to assess the requirements engineering capability of New Zealand companies using both formal and informal frameworks","2011","15","1","2025-12-02","https://university.edu/papers/78d29c39-a779-4ea3-9380-187171cf8117.pdf");
INSERT INTO Paper VALUES ("387","Mechanized proofs for a recursive authentication protocol","A novel protocol has been formally analyzed using the prover Isabelle/HOL, following the inductive approach described in earlier work (L.C. Paulson, 1997). There is no limit on the length of a run, the nesting of messages or the number of agents involved. A single run of the protocol delivers session keys for all the agents, allowing neighbours to perform mutual authentication. The basic security theorem states that session keys are correctly delivered to adjacent pairs of honest agents, regardless of whether other agents in the chain are compromised. The protocol's complexity caused some difficulties in the specification and proofs, but its symmetry reduced the number of theorems to prove.","1997","10","4","2025-12-02","https://university.edu/papers/82251595-e79a-49bf-9a36-74189a2ff96c.pdf");
INSERT INTO Paper VALUES ("388","GPS anti-spoofing technology based on RELAX algorithm in smart grid","Smart grid is established on top of traditional power grid. With the help of the advanced information technology, power scheduling and control can be achieved better in smart grid. Since it depends on precise timing information, most of the operations are equipped with GPS (global positioning system) that can give precise timing with the performance of real-time, continuity and all-day. But GPS is vulnerable to attacks because of its low power and public known data structure, so it is important to protect GPS from all kinds of jamming, which can guarantee the stability of smart grids. In this paper, a GPS anti-spoofing technology based on RELAX (relaxation) algorithm is proposed. In the case where one or more spoofing sources are present and each contains several spoofing signals or a strong one, it can set suitable number of the spoofing sources and configure the detection threshold in order to realize the spoofing detection and mitigation. The technology is very effective and validated through simulation results.","2015","7","2","2025-12-02","https://university.edu/papers/f29c8aa3-a362-4e25-b582-7fd31103f5c3.pdf");
INSERT INTO Paper VALUES ("389","Framework for Learner Assessment in Learning Games","Learner assessment in learning games (LG) is an interesting research area for both academia and industry. The play traces resulting from the learner’s activity in LGs with large state spaces and a large amount of free interactions, are hard to analyze and to interpret by teachers. In this paper, we present a framework to assist the building of an expert’s solving process that is the base of the algorithm that analyzes player’s traces and generates pedagogical labels about the learner’s behavior.","2016","15","4","2025-12-02","https://university.edu/papers/155a3492-e1ee-4afc-8693-afbd14c03c33.pdf");
INSERT INTO Paper VALUES ("390","Markov decision process formulation for managing human weight loss","We present a Markov Decision Process (MDP) approach to compute policies that can aid the management of human weight loss. We show that the problem can be formulated as a Markov Chain under a reasonable set of assumptions. The states represent the quantized weight of a participant. The transitions between the states represent nutrition and exercise actions. A policy computed using this model represents an intervention strategy for a participant. Given the participant's initial weight and target weight, we show that the computed policy is sensitive to the reward functions that are associated with the actions. In the future, such an approach can be used to offer wellness interventions to participants.","2016","4","2","2025-12-02","https://university.edu/papers/b3dc07bd-fee9-481b-ba33-2108c3b87a88.pdf");
INSERT INTO Paper VALUES ("391","Learning from textbook knowledge: a case study","One of the 'grand challenges for machine learning' is the problem of learning from textbooks. This paper addresses the problem of learning from texts including omissions and inconsistencies that are clarified by illustrative examples. To avoid problems in natural language understanding, we consider a simplification of this problem in which the text has been manually translated into a logical theory. This learning problem is solvable by a technique that we call analogical abductive explanation based learning (ANA-EBL). Formal evidence and experimental results in the domain of contract bridge show that the learning technique is both efficient and effective.","1990","16","1","2025-12-02","https://university.edu/papers/5237910a-020b-495f-a88d-a156fe3b10f7.pdf");
INSERT INTO Paper VALUES ("392","A Dynamic 3D Performance Space for Control of Virtual Musical Instruments","This work explores developing an intuitive, real-time music generation system and interface. We present a system that uses the real-time skeletal tracking provided by the Kinect to generate complex musical compositions containing up to four tracks, with instruments represented in distinct physical spaces. The performer's position and movements are translated into cues that are relayed to Ableton Live for music generation. Finally, we experiment with an interface projected in physical space to provide real-time feedback to the user.","2016","12","4","2025-12-02","https://university.edu/papers/d0c97fa5-3b1d-4b4a-bf29-6244ebd0b6b0.pdf");
INSERT INTO Paper VALUES ("393","Accuracy bounds for belief propagation","The belief propagation (BP) algorithm is widely applied to perform approximate inference on arbitrary graphical models, in part due to its excellent empirical properties and performance. However, little is known theoretically about when this algorithm will perform well. Using recent analysis of convergence and stability properties in BP and new results on approximations in binary systems, we derive a bound on the error in BP's estimates for pairwise Markov random fields over discrete-valued random variables. Our bound is relatively simple to compute, and compares favorably with a previous method of bounding the accuracy of BP.","2007","14","4","2025-12-02","https://university.edu/papers/a83042c2-d61c-49fc-85e0-b69ad183a4f7.pdf");
INSERT INTO Paper VALUES ("394","Vehicle Recognition Based on Fourier, Wavelet and Curvelet Transforms - a Comparative Study","This paper proposes the application of 3 different kinds of feature extractors to recognize & classify 5 models of vehicles. These feature extractors contain of fast Fourier transform, discrete wavelet transform & discrete curvelet transform. To justify the correct amount of each feature extractor, we perform per of the mentioned transforms to input images, precisely. The used classifier in this paper is called k nearest-neighbor. The results of this test show, that the right recognition rate of vehicle's model in this recognition system, at the time of using curvelet transform (notice, all curvelet coefficients) is 100%. For decreasing the dimension of feature vectors more & choosing the best features we've used of interclass variance criteria to intraclass variance criteria. As a result of this performance, the size of feature vectors will be extremely decreased. Then, we perform our final impact feature vectors (the best curvelet coefficients or the best wavelet coefficients or the best Fourier coefficients) to the KNN classifier. Also, the results of this test show, the right recognition rate of vehicle's model in this recognition system, at the time of using 0.1 of all curvelet coefficients is 100%.The comparison of the 3 proposed approaches for identifying the kind of vehicles showed that curvelet transform can extract better features among the proposed dataset","2007","1","3","2025-12-02","https://university.edu/papers/651a7ba5-6cba-45cb-903f-ccf992ad2a39.pdf");
INSERT INTO Paper VALUES ("395","A Linear Iteration Algorithm for a Second-Order Energy Stable Scheme for a Thin Film Model Without Slope Selection","We present a linear iteration algorithm to implement a second-order energy stable numerical scheme for a model of epitaxial thin film growth without slope selection. The PDE, which is a nonlinear, fourth-order parabolic equation, is the $$L^2$$ L 2 gradient flow of the energy $$ \int _\Omega \left( - \frac{1}{2} \ln \left( 1 + | \nabla \phi |^2 \right) + \frac{\epsilon ^2}{2}|\Delta \phi (\mathbf{x})|^2 \right) \mathrm{d}\mathbf{x}$$ ? Ω - 1 2 ln 1 + | ? ? | 2 + ∈ 2 2 | Δ ? ( x ) | 2 d x . The energy stability is preserved by a careful choice of the second-order temporal approximation for the nonlinear term, as reported in recent work (Shen et al. in SIAM J Numer Anal 50:105---125, 2012). The resulting scheme is highly nonlinear, and its implementation is non-trivial. In this paper, we propose a linear iteration algorithm to solve the resulting nonlinear system. To accomplish this we introduce an $$O(s^2)$$ O ( s 2 ) (with $$s$$ s the time step size) artificial diffusion term, a Douglas-Dupont-type regularization, that leads to a contraction mapping property. As a result, the highly nonlinear system can be decomposed as an iteration of purely linear solvers, which can be very efficiently implemented with the help of FFT in a collocation Fourier spectral setting. We present a careful analysis showing convergence for the numerical scheme in a discrete $$L^\infty (0, T; H^1) \cap L^2 (0,T; H^3)$$ L ? ( 0 , T ; H 1 ) ? L 2 ( 0 , T ; H 3 ) norm. Some numerical simulation results are presented to demonstrate the efficiency of the linear iteration solver and the convergence of the scheme as a whole.","2014","8","3","2025-12-02","https://university.edu/papers/f3d23716-4e5f-4531-8a74-837e4e328d71.pdf");
INSERT INTO Paper VALUES ("396","An Age-Based Inspection and Replacement Policy for Heterogeneous Components","This paper considers a hybrid maintenance policy for a single component from a heterogeneous population. The component is placed in a socket, and the component and socket together comprise the system. The  s -population of components consists of two sub-populations with different failure characteristics. By supposing that a component may be in a defective but operating state, so that there exists a delay time between defect arrival and component failure, we consider a novel maintenance policy that is a hybrid of inspection and replacement policies. There are similarities in this approach with the concept of ldquoburn-inrdquo maintenance. The policies are investigated in the context of traction motor bearing failures. Under certain circumstances, particularly when the mixture parameter is large, and the distribution of lifetimes for the two component types are well separated, the hybrid policy has significant cost savings over the standard age-based replacement policy, and over the pure inspection policy. In addition to the cost metric, the mean time between operational failures of the system under the hybrid policy can be used to guide decision-making. This maintenance policy metric is calculated using simulation, and using an approximation which assumes that operational failures occur according to a Poisson process with a rate that can be calculated in a straightforward way. The simulation results show good agreement with the approximation.","2009","9","3","2025-12-02","https://university.edu/papers/5e0eb428-41ef-4955-aaa9-f5dd6c01c1ef.pdf");
INSERT INTO Paper VALUES ("397","Ontology-Based Conceptual Domain Modeling for Educational Portal","The paper describes the ontological approach to the vusual knowledge structuring for the e-learning portal design and development. We will discuss why these topics are increasingly important and describe the experience of ontology developing for Knowledge Engineering courses based on educational course for both undergraduate and master students of Saint-Petersburg State Polytechnic University and Saint-Petersburg State University. We will also describe “OntolingeWiki” tool for creating ontology-based e-learning portal","2009","10","4","2025-12-02","https://university.edu/papers/50af7964-3876-4fa4-a7d7-76edea1f48c2.pdf");
INSERT INTO Paper VALUES ("398","Tracking Actual Usage: The Attention Metadata Approach","The information overload in learning and teaching scenarios is a main hindering factor for efficient and effective learning. New methods are needed to help teachers and students in dealing with the vast amount of available information and learning material. Our approach aims to utilize contextualized attention metadata to capture behavioural information of users in learning contexts that can be used to deal with the information overload in user centric ways. We introduce a schema and framework for capturing and managing such contextualized attention metadata in this paper. Schema and framework are designed to enable collecting and merging observations about the attention users give to content and their contexts. The contextualized attention metadata schema enables the correlation of the observations, thus reflects the relationships that exists between the user, her context and the content she works with. We illustrate with a simple demo application how contextualized attention metadata can be collected from several tools, the merging of the data streams into a repository and finally the correlation of the data.","2007","8","1","2025-12-02","https://university.edu/papers/f0988f00-ac70-404f-8a32-d7aaca7efe4e.pdf");
INSERT INTO Paper VALUES ("399","An integrated failure detection and fault correction model","In general, software reliability models have focused an modeling and predicting failure occurrence and have not given equal priority to modeling the fault correction process. However, there is a need for fault correction prediction, because there are important applications that fault correction modeling and prediction support. These are the following: predicting whether reliability goals have been achieved, developing stopping rules for testing, formulating test strategies, and rationally allocating test resources. Because these factors are related, we integrate them in our model. Our modeling approach involves relating fault correction to failure prediction, with a time delay estimated from a fault correction queuing model.","2002","14","1","2025-12-02","https://university.edu/papers/6721e813-8104-4233-b5c1-18ae39323ebd.pdf");
INSERT INTO Paper VALUES ("400","Development of an informatics tool for crystallography laboratory administrators","With increased demand for storage of scientific data comes a corresponding demand for efficient retrieval mechanisms necessary for analytical and reporting purposes. As is often the case, the design of databases to support scientific data is (rightly so) driven by the science. Unfortunately, this 'science-centric' view of data management does not make the subsequent reporting of information easy. The natural solution to such a problem is, of course, a data warehouse approach to scientific data management. The focus of this project is the design of a data warehousing architecture for scientific data. Our goal is to separate the science-specific aspects of the information from the reporting and analysis requirements. The problem domain we are currently investigating is crystallographic structure data, coupled with metadata concerning the structure. The paper describes ITCLA - an Informatics Tool for Crystallography Laboratory Administrators. We report on the current state of ITCLA, as well as our future plans.","2003","1","1","2025-12-02","https://university.edu/papers/b41335d8-f4bb-47a8-87db-e6be174ba22c.pdf");
INSERT INTO Paper VALUES ("401","Improving Recommendation Flow with Centrality Measure in an Evolving Social Network","The purpose of our research is to make a connection between information related to structural position of entities and individual advice selection criteria in an explicitly mentioned friendship or trust network of users. We provide a reliable mechanism in which users are able to cover most of the related information available matched with their preferences by going further to the network. We showed in our model that structural position of the network can be treated as a useful source of information by improving flow of information in the system. Finally we have implemented our model as a trust-based exchange mechanism for advice selection in Net Logo. As the results show, by embedding such information we are able to increase the utility of entities and overall utility of the system.","2012","5","3","2025-12-02","https://university.edu/papers/a706ba1f-d903-4354-b10e-7799ae76af71.pdf");
INSERT INTO Paper VALUES ("402","Segmentation by adaptive prediction and region merging","This paper presents a segmentation technique based on pre- diction and adaptive region merging. While many techniques for segmentation exist, few of them are suited for the segmentation of natural images containing regular textures defined on non-rectangular segments. In this paper, we propose a description of regions based on a deconvolution algorithm whose purpose is to remove the influence of the shape on region contents. The decoupling of shape and texture information is achieved either by adapting waveforms to the segment shape, which is a time-consuming task that needs to be repeated for each segment shape, or by the extrapolation of a signal to fit a rectangular window, which is the chosen path. The deconvolution algorithm is the key of a new segmentation technique that uses extrapolation as a prediction of neighbouring regions. When the prediction of a region fits the actual content of a connected region rea- sonably well, both regions are merged. The segmentation process starts with an over-segmented image. It progressively merges neighbouring re- gions whose extrapolations fit according to an energy criterion. After each merge, the algorithm updates the values of the merging criterion for regions connected to the merged region pair. It stops when no fur- ther gain is achieved in merging regions or when mean values of adjacent regions are too different. Simulation results indicate that, although our technique is tailored for natural images containing periodic signals and flat regions, it is in fact usable for a large set of natural images.","2003","17","3","2025-12-02","https://university.edu/papers/b25e599a-e902-498a-9762-43227c03f6f2.pdf");
INSERT INTO Paper VALUES ("403","An Evaluation of Interpolation Techniques for Reconstructing Ionospheric TEC Maps","Maps of the total electron content (TEC) of the ionosphere can be reconstructed using data extracted from global positioning system (GPS) signals. For historic and other sparse data sets, the reconstruction of TEC images is often performed using a multivariate interpolation technique. Although there are many interpolation methods available, only a limited number, for example kriging, have been applied to TEC data. This paper presents a quantitative comparison of various commonly used algorithms for scattered-data interpolation over a range of sparsi- ties. Techniques evaluated include a relatively new approach called Adaptive Normalized Convolution (ANC) that has not previously been applied to ionospheric reconstruction. The proposed evaluation scheme employs a quantitative methodology applied to both simulated and real TEC data. Results show that, although the performance of kriging is good in many cases, it is several times worse than the best performing techniques at some sparsities. Natural-neighbor interpolation has a better overall performance than kriging for both simulated and TEC data. Although its performance is a few percent worse than other methods for the simulated data, ANC produces the best performance for the TEC reconstructions.","2008","11","2","2025-12-02","https://university.edu/papers/903bead1-163d-4ef7-b3af-ab904d3fc50d.pdf");
INSERT INTO Paper VALUES ("404","On the design of optimal counter-based schemes for test set embedding","Counter-based mechanisms have been proposed for use in built-in test set embedding. A single counter or multiple counters may be used with one or multiple seeds. In addition, counters may be combined with ROM's. Each alternative design scenario introduces a difficult combinatorial optimization problem: minimization of the time required to reproduce the test patterns by an appropriate synthesis of the built-in test pattern generator. This paper presents fast synthesis techniques that result in almost optimal designs. For any given circuit, they efficiently determine whether counter-based schemes are applicable as built-in generators for a given circuit. The proposed techniques have been implemented and tested on the ISCAS'85 benchmarks. Comparative studies with a weighted random linear feedback shift register scheme show that counter-based designs may offer good hardware/time solutions.","1999","19","4","2025-12-02","https://university.edu/papers/81de7e89-3a81-42f8-b16f-46a09617608c.pdf");
INSERT INTO Paper VALUES ("405","JDeodorant: identification and application of extract class refactorings","Evolutionary changes in object-oriented systems can result in large, complex classes, known as 'God Classes'. In this paper, we present a tool, developed as part of the JDeodorant Eclipse plugin, that can recognize opportunities for extracting cohesive classes from 'God Classes' and automatically apply the refactoring chosen by the developer.","2011","8","4","2025-12-02","https://university.edu/papers/8c668446-055b-4dd4-9677-b38e924d4b7b.pdf");
INSERT INTO Paper VALUES ("406","Simulation of all-scale atmospheric dynamics on unstructured meshes","The advance of massively parallel computing in the nineteen nineties and beyond encouraged finer grid intervals in numerical weather-prediction models. This has improved resolution of weather systems and enhanced the accuracy of forecasts, while setting the trend for development of unified all-scale atmospheric models. This paper first outlines the historical background to a wide range of numerical methods advanced in the process. Next, the trend is illustrated with a technical review of a versatile nonoscillatory forward-in-time finite-volume (NFTFV) approach, proven effective in simulations of atmospheric flows from small-scale dynamics to global circulations and climate. The outlined approach exploits the synergy of two specific ingredients: the MPDATA methods for the simulation of fluid flows based on the sign-preserving properties of upstream differencing; and the flexible finite-volume median-dual unstructured-mesh discretisation of the spatial differential operators comprising PDEs of atmospheric dynamics. The paper consolidates the concepts leading to a family of generalised nonhydrostatic NFTFV flow solvers that include soundproof PDEs of incompressible Boussinesq, anelastic and pseudo-incompressible systems, common in large-eddy simulation of small- and meso-scale dynamics, as well as all-scale compressible Euler equations. Such a framework naturally extends predictive skills of large-eddy simulation to the global atmosphere, providing a bottom-up alternative to the reverse approach pursued in the weather-prediction models. Theoretical considerations are substantiated by calculations attesting to the versatility and efficacy of the NFTFV approach. Some prospective developments are also discussed.","2016","7","4","2025-12-02","https://university.edu/papers/91eb57b0-b733-452f-a473-847c2dd1903a.pdf");
INSERT INTO Paper VALUES ("407","InterVisAR: An Interactive Visualization for Association Rule Search","Association rule mining has been utilized extensively in many areas because it has the ability to discover relationships among variables in large databases. However, one main drawback of association rule mining is that it attempts to generate a large number of rules and does not guarantee that the rules are meaningful in the real world. Many visualization techniques have been proposed for association rules. These techniques were designed to provide a global overview of all rules so as to identify the most meaningful rules. However, using these visualization techniques to search for specific rules becomes challenging especially when the volume of rules is extremely large. In this study, we have developed an interactive association rule visualization technique, called InterVisAR, specifically designed for effective rule search. We conducted a user study with 24 participants, and the results demonstrated that InterVisAR provides an efficient and accurate visualization solution. We also verified that InterVisAR satisfies a non-factorial property that should be guaranteed in performing rule search. All participants also expressed high preference towards InterVisAR as it provides a more comfortable and pleasing visualization in association rule search comparing with table-based rule search.","2016","2","4","2025-12-02","https://university.edu/papers/e0e52041-798e-4a92-8d65-03c6754cf60a.pdf");
INSERT INTO Paper VALUES ("408","Understanding Newcomers to 3D Printing: Motivations, Workflows, and Barriers of Casual Makers","Interest in understanding and facilitating 3D digital fabrication is growing in the HCI research community. However, most of our insights about end-user interaction with fabrication are currently based on interactions of professional users, makers, and technology enthusiasts. We present a study of casual makers, users who have no prior experience with fabrication and mainly explore walk-up-and-use 3D printing services at public print centers, such as libraries, universities, and schools. We carried out 32 interviews with casual makers, print center operators, and fabrication experts to understand the motivations, workflows, and barriers in appropriating 3D printing technologies. Our results suggest that casual makers are deeply dependent on print center operators throughout the process from bootstrapping their 3D printing workflow, to seeking help and troubleshooting, to verifying their outputs. However, print center operators are usually not trained domain experts in fabrication and cannot always address the nuanced needs of casual makers. We discuss implications for optimizing 3D design tools and interactions that can better facilitate casual makers' workflows.","2016","5","4","2025-12-02","https://university.edu/papers/0a2b6487-d9d6-4969-84f7-15ca1760357b.pdf");
INSERT INTO Paper VALUES ("409","Addressing niche demand based on joint mobility prediction and content popularity caching","We present an efficient mobility-based proactive caching model for addressing niche mobile demand, along with popularity-based and legacy caching model extensions. Opposite to other proactive solutions which focus on popular content, we propose a distributed solution that targets less popular, personalised or dynamic content requests by prefetching data in small cells based on aggregated user mobility prediction information. According to notable studies, niche demand, particularly for video content, represents a significant 20–40% of Internet demand and follows a growing trend. Due to its novel design, our model can directly address such demand, while also make a joint use of content popularity information with the novelty of dynamically tuning the contribution of mobility prediction and content popularity on local cache actions.#R##N##R##N#Based on thorough performance evaluation simulations after exploring different demand levels, video catalogues and mobility scenarios including human walking and automobile mobility, we show that gains from mobility prediction can be high and able to adapt well to temporal locality due to the short timescale of measurements, exceeding cache gains from popularity-only caching up to  41% for low caching demand scenarios. Our model’s performance can be further improved at the cost of an added computational overhead by adapting cache replacements by, e.g. in the aforementioned scenarios,  41%. Also, we find that it is easier to benefit from requests popularity with low mobile caching demand and that mobility-based gains grow with popularity skewness, approaching close to the high and robust gains yielded with the model extensions.","2016","6","4","2025-12-02","https://university.edu/papers/3309f4e2-b4dd-473f-a7b2-4b599988fba0.pdf");
INSERT INTO Paper VALUES ("410","Decomposition—a strategy for query processing","Strategy for processing multivariable queries in the database management system INGRES is considered. The general procedure is to decompose the query into a sequence of one-variable queries by alternating between (a) reduction: breaking off components of the query which are joined to it by a single variable, and (b) tuple substitution: substituting for one of the variables a tuple at a time. Algorithms for reduction and for choosing the variable to be substituted are given. In most cases the latter decision depends on estimation of costs; heuristic procedures for making such estimates are outlined.","1976","11","2","2025-12-02","https://university.edu/papers/f504d50a-1143-414a-a378-0b249588608a.pdf");
INSERT INTO Paper VALUES ("411","Synchronization algorithm for VLC power switched baseband modulation forms","In this work, a synchronization algorithm for visible light communication power switched baseband modulation forms is elaborated. Based on the equal received signal energy content during a bit time, a dedicated convolution and summation scheme is developed, where the minimum of the summation formula indicates the start of a bit time. It is shown that the functionality of the algorithm is invariant with regard to a large range of dimming levels. The impact of noise is also considered in order to evaluate the robustness of the algorithm. Based on a limited set of Monte Carlo simulations, a rule of thumb is defined for various signal to noise ratios.","2016","14","2","2025-12-02","https://university.edu/papers/46bd0b70-e51f-43fb-bab3-5afdcc6d70e9.pdf");
INSERT INTO Paper VALUES ("412","Bayesian Multi-Object Filtering With Amplitude Feature Likelihood for Unknown Object SNR","In many tracking scenarios, the amplitude of target returns are stronger than those coming from false alarms. This information can be used to improve the multiple-target state estimation by obtaining more accurate target and false-alarm likelihoods. Target amplitude feature is well known to improve data association in conventional tracking filters, such as probabilistic data association and multiple hypothesis tracking, and results in better tracking performance of low signal-to-noise ratio (SNR) targets. The advantage of using the target amplitude approach is that targets can be identified earlier through the enhanced discrimination between target and false alarms. One of the limitations of this approach is that it is usually assumed that the SNR of the target is known. We show that the reliable estimation of the SNR requires a significant number of measurements, and so we propose an alternative approach for situations where the SNR is unknown. We illustrate this approach in the context of multiple targets for different SNRs in the framework of finite set statistics (FISST). Furthermore, we illustrate how this can be incorporated into approximate multiple-object filters derived from FISST, including probability hypothesis density (PHD) and cardinalized PHD (CPHD) filters. We present simulation results for Gaussian mixture implementations of the filters that demonstrate a significant improvement in performance over just using location measurements.","2010","4","2","2025-12-02","https://university.edu/papers/ceefa50b-18d9-4611-a2f3-a64ec19876dd.pdf");
INSERT INTO Paper VALUES ("413","A community and knowledge building model in computer education","Computer Supported Collaborative Work (CSCW) is a new information technology subject at Charles Sturt University, that develops a learning community and knowledge sharing network for a diverse range of students. By integrating course content about CSCW, students use information environments and groupware products such as e-mail, the Z Object Publishing Environment (ZOPE) and MOO to create learning artefacts. The subject immerses students into social, philosophical and psychological aspects of working in online environments as well as the technology issues associated with being a participant in a workgroup that can be applied in such fields as professional development, information technology, library science, education, teacher librarianship, health care or policing.  Students explore the principles of workgroups, various cognitive frameworks and collaborative task (eg. meetings, document generation, argument support and policy work). They learn how to select and tailor a framework appropriate to a specific collaborative situation, and guide the development of workgroup-specific infrastructure. They are also expected to evaluate the effectiveness of workflow, human interaction and knowledge management within an organisation.  This paper describes how a team-teaching approach has been structured, and how students and lecturers facilitated each other in regard to course content, methods of instruction, methods of assessment and evaluation.","2000","17","1","2025-12-02","https://university.edu/papers/ea830c7c-76a2-408a-9cdd-f89ffa6dd584.pdf");
INSERT INTO Paper VALUES ("414","Singing Voice Separation Using Spectro-Temporal Modulation Features.","A n auditory-perception inspired singing voice separation algorithm for monaural music recordings is proposed in this paper. Under the framework of computational auditory scene analysis (CASA), the music recordings are first transformed into auditory spectrograms. After extracting the spectral-temporal modulation contents of the timefrequency (T-F) units through a two-stage auditory model, we define modulation features pertaining to three categories in music audio signals: vocal, harmonic, and percussive. The T-F units are then clustered into three categories and the singing voice is synthesized from T-F units in the vocal category via time-frequency masking. The algorithm was tested using the MIR-1K dataset and demonstrated comparable results to other unsupervised masking approaches. Meanwhile, the set of novel features gives a possible explanation on how the auditory cortex analyzes and identifies singing voice in music audio mixtures.","2014","19","4","2025-12-02","https://university.edu/papers/8d4f4219-281f-4291-8394-cd6554476fe9.pdf");
INSERT INTO Paper VALUES ("415","OpenMPspy: Leveraging quality assurance for parallel software","OpenMP is widely used in practice to create parallel software, however, software quality assurance tool support is still immature. OpenMPspy introduces a new approach, with a short-term and a long-term perspective, to aid software engineers write better parallel programs in OpenMP. On the one hand, OpenMPspy acts like an online-debugger that statically detects problems with incorrect construct usage and which reports problems while programmers are typing code in Eclipse. We detect simple slips as well as more complex anti-patterns that can lead to correctness problems and performance problems. In addition, OpenMPspy can aggregate statistics about OpenMP language usage and bug patterns from many projects. Insights generated from such data help OpenMP language designers improve the usability of constructs and reduce error potential, thus enhancing parallel software quality in the long run. Using OpenMPspy, this paper presents one of the first detailed empirical studies of over 40 programs with more than 4 million lines of code, which shows how OpenMP constructs are actually used in practice. Our results reveal that constructs believed to be frequently used are actually rarely used. Our insights give OpenMP language and compiler designers a clearer picture on where to focus the efforts for future improvements.","2011","9","2","2025-12-02","https://university.edu/papers/b1e5b0e5-4be3-4712-bad0-8e40dfd7c84c.pdf");
INSERT INTO Paper VALUES ("416","Bayesian Network Model for Object Concept","This paper discusses a computational model for object concept formation. We propose a model of object concept based on the relationship between shape and function. Implementation of the proposed framework using Bayesian network is presented. At this point we need an explicit definition of object function. In the proposed model each function is defined as certain changes in a target object caused by the object. Therefore each function is represented by a feature vector which quantifies the changes in the target. Then the function is abstracted from these feature vectors using the Bayesian learning approach. The system can form object concept by observing the human tool use based on the abstract function and shape information. Furthermore, it is demonstrated that the learned model (object concept) enables the system to infer the property of unseen object. The system is evaluated using 35 hand tools, which reveals the validity of the proposed framework.","2007","11","2","2025-12-02","https://university.edu/papers/cd63d597-f28e-43d1-81d3-2f9d4b23f271.pdf");
INSERT INTO Paper VALUES ("417","MPJ Express: Towards Thread Safe Java HPC","MPJ Express is a thread-safe Java messaging library that provides a full implementation of the mpiJava 1.2 API specification. This specification defines a MPI-like bindings for the Java language. We have implemented two communication devices as part of our library, the first, called niodev is based on the Java New I/O package and the second, called mxdev is based on the Myrinet eXpress library. MPJ Express comes with an experimental runtime, which allows portable bootstrapping of Java Virtual Machines across a cluster or network of computers. In this paper we describe the implementation of MPJ Express. Also, we present a performance comparison against various other C and Java messaging systems. A beta version of MPJ Express was released in September 2005.","2006","3","1","2025-12-02","https://university.edu/papers/fe1f078a-b84f-4ac0-8073-79b57f57bdf2.pdf");
INSERT INTO Paper VALUES ("418","Multi-view variability modelling for business component reuse","Variability is defined as the ability of a software artefact to be changed or customised to be used in multiple contexts. This paper outlines variability issues through reusable component development, and in particular, in Business Component (BC) development. The main ideas of this work are (a) to address variability issues through BC development, (b) to explain variability principles in order to express variability for reuse and (c) to use an approach to represent multi-view variability for the BC development.","2007","1","4","2025-12-02","https://university.edu/papers/fe6a2cef-2340-4291-a33a-f82734bce8be.pdf");
INSERT INTO Paper VALUES ("419","Enabling Micro-level Demand-Side Grid Flexiblity in Resource Constrained Environments","The increased penetration of uncertain and variable renewable energy presents various resource and operational electric grid challenges. Micro-level (household and small commercial) demand-side grid flexibility could be a cost-effective strategy to integrate high penetrations of wind and solar energy, but literature and field deployments exploring the necessary information and communication technologies (ICTs) are scant. This paper presents an exploratory framework for enabling information driven grid flexibility through the Internet of Things (IoT), and a proof-of-concept wireless sensor gateway (FlexBox) to collect the necessary parameters for adequately monitoring and actuating the micro-level demand-side. In the summer of 2015, thirty sensor gateways were deployed in the city of Managua (Nicaragua) to develop a baseline for a near future small-scale demand response pilot implementation. FlexBox field data has begun shedding light on relationships between ambient temperature and load energy consumption, load and building envelope energy efficiency challenges, latency communication network challenges, and opportunities to engage existing demand-side user behavioral patterns. Information driven grid flexibility strategies present great opportunity to develop new technologies, system architectures, and implementation approaches that can easily scale across regions, incomes, and levels of development.","2017","1","2","2025-12-02","https://university.edu/papers/c27933c8-6461-4edd-8895-b18f5f635bcf.pdf");
INSERT INTO Paper VALUES ("420","VISTA : visualizing global DNA sequence alignments of arbitrary length","Summary: VISTA is a program for visualizing global DNA sequence alignments of arbitrary length. It has a clean output, allowing for easy identification of similarity, and is easily configurable, enabling the visualization of alignments of various lengths at different levels of resolution. It is currently available on the web, thus allowing for easy access by all researchers. Availability: VISTA server is available on the web at http: // www-gsd.lbl.gov/ vista. The source code is available upon request.","2000","1","1","2025-12-02","https://university.edu/papers/a2a5246e-5c38-4ee3-a835-00b13d679489.pdf");
INSERT INTO Paper VALUES ("421","Software Cost Modelling and Estimation Using Artificial Neural Networks Enhanced by Input Sensitivity Analysis","This paper addresses the issue of Software Cost Estimation (SCE) providing an alternative approach to modelling and prediction using Artificial Neural Networks (ANN) and Input Sensitivity Analysis (ISA). The overall aim is to identify and investigate the effect of the leading factors in SCE, through ISA. The factors identified decisively influence software effort in the models examined and their ability to provide sufficiently accurate SCEs is examined. ANN of variable topologies are trained to predict effort devoted to software development based on past (finished) projects recorded in two publicly available historical datasets. The main difference with relevant studies is that the proposed approach extracts the most influential cost drivers that describe best the effort devoted to development activities using the weights of the network connections. The approach is validated on known software cost data and the results obtained are assessed and compared. The ANN constructed generalise efficiently the knowledge acquired during training providing accurate effort predictions. The validation process included predictions with only the most highly ranked attributes among the original cost attributes of the datasets and revealed that accuracy performance was maintained at same levels. The results showed that the combination of ANN and ISA is an effective method for evaluating the contribution of cost factors, whereas the subsets of factors selected did not compromise the accuracy of the prediction results.","2012","19","4","2025-12-02","https://university.edu/papers/a8cd37ec-1f88-4449-9ca4-373248700b4e.pdf");
INSERT INTO Paper VALUES ("422","Device fingerprinting for augmenting web authentication: classification and analysis of methods","Device fingerprinting is commonly used for tracking users. We explore device fingerprinting but in the specific context of use for augmenting authentication, providing a state-of-the-art view and analysis. We summarize and classify 29 available methods and their properties; define attack models relevant to augmenting passwords for user authentication; and qualitatively compare them based on stability, repeatability, resource use, client passiveness, difficulty of spoofing, and distinguishability offered.","2016","1","2","2025-12-02","https://university.edu/papers/b6d8167a-4d75-4e1a-b939-aa0468577923.pdf");
INSERT INTO Paper VALUES ("423","A study of speaker clustering for speaker attribution in large telephone conversation datasets","Large dataset speaker clustering is more efficient using linkage clustering (O(n log(n)).Need for cluster merging and retraining is eliminated through linkage clustering.Complete-linkage speaker clustering outperforms common retraining-based clustering.Robust stopping criterion by using complete-linkage and cross-likelihood ratio.Robustness of clustering stopping criterion is evaluated on varying datasets. This paper proposes the task of speaker attribution as speaker diarization followed by speaker linking. The aim of attribution is to identify and label common speakers across multiple recordings. To do this, it is necessary to first carry out diarization to obtain speaker-homogeneous segments from each recording. Speaker linking can then be conducted to link common speaker identities across multiple inter-session recordings. This process can be extremely inefficient using the traditional agglomerative cluster merging and retraining commonly employed in diarization. We thus propose an attribution system using complete-linkage clustering (CLC) without model retraining. We show that on top of the efficiency gained through elimination of the retraining phase, greater accuracy is achieved by utilizing the farthest-neighbor criterion inherent to CLC for both diarization and linking. We first evaluate the use of CLC against an agglomerative clustering (AC) without retraining approach, traditional agglomerative clustering with retraining (ACR) and single-linkage clustering (SLC) for speaker linking. We show that CLC provides a relative improvement of 20%, 29% and 39% in attribution error rate (AER) over the three said approaches, respectively. We then propose a diarization system using CLC and show that it outperforms AC, ACR and SLC with relative improvements of 32%, 50% and 70% in diarization error rate (DER), respectively. In our work, we employ the cross-likelihood ratio (CLR) as the model comparison metric for clustering and investigate its robustness as a stopping criterion for attribution.","2016","15","3","2025-12-02","https://university.edu/papers/9a4a6b3a-9b76-4d42-8904-d0f51e7d92f0.pdf");
INSERT INTO Paper VALUES ("424","Reverse engineering with Petri nets","With the emergence of Petri nets in practical applications the need to reverse-engineer them arises. Folding based reverse-engineering techniques are crucial for Petri nets, but after a translation step they offer novel analysis capabilities for other systems. Such a translation makes Petri nets a powerful and intuitive engineering metaphor outside their traditional strength for concurrency. We present a folding-based algorithm which transforms an unstructured flat net into a coloured net. In reverse engineering terms, it recovers a high-level design, a structured specification and a data model from an existing system. Both the algorithm and the translation to Petri nets allow many variations for adaptation to different tasks. Moreover, the cost is almost linear, thus ensuring scalability.","2000","6","2","2025-12-02","https://university.edu/papers/72dd7b3c-366d-4768-b6c7-1c218835c72c.pdf");
INSERT INTO Paper VALUES ("425","Bridging Global and Local Models of Service-Oriented Systems","A service-oriented system is a collection of independent services that interact with one another through message exchanges. Languages such as the Web Services Description Language (WSDL) and the Business Process Execution Language (BPEL) allow developers to capture the interactions in which an individual service can engage, both from a structural and from a behavioral perspective. However, in large service-oriented systems, stakeholders may require a global picture of the way services interact with each other, rather than multiple small pictures focusing on individual services. Such global models are especially useful when a set of services interact in such a way that none of them sees all messages being exchanged, yet interactions between some services may affect the way other services interact. Unfortunately, global models of service interactions may sometimes capture behavioral constraints that cannot be enforced locally. In other words, some global models may not be translatable into a set of local models such that the sum of the local models equals the original global model. Starting from a previously proposed language for global modeling of service interactions, this paper defines an algorithm for determining if a global model is locally enforceable and an algorithm for generating local models from global ones. It also shows how local models are mapped into templates of BPEL process definitions.","2008","8","3","2025-12-02","https://university.edu/papers/7a9f1af5-4a90-40e3-93b3-af02523540e1.pdf");
INSERT INTO Paper VALUES ("426","iVector Fusion of Prosodic and Cepstral Features for Speaker Verification","In this paper we apply the promising iVector extraction technique followed by PLDA modeling to simple prosodic contour features. With this procedure we achieve results comparable to a system that models much more complex prosodic features using our recently proposed SMM-based iVector modeling technique. We then propose a combination of both prosodic iVectors by joint PLDA modeling that leads to significant improvements over individual systems with an EER of 5.4% on NIST SRE 2008 telephone data. Finally, we can combine these two prosodic iVector front ends with a baseline cepstral iVector system to achieve up to 21% relative reduction in new DCF. Index Terms: speaker verification, prosody, JFA, iVector, SMM, fusion","2011","7","2","2025-12-02","https://university.edu/papers/767a4812-839a-4b3e-abca-dddea98c84b1.pdf");
INSERT INTO Paper VALUES ("427","A Distributed Framework for Carbon and Cost Aware Geographical Job Scheduling in a Hybrid Data Center Infrastructure","To mitigate the growing carbon footprints of data centers, many large IT organizations (e.g., Apple) have installed on-site renewables in their self-managed data centers. Meanwhile, to achieve low-cost global presence, these organizations often lease space and house their servers in geo-distributed colocation data centers, where they share the power (including renewables) with other tenants. Such sharing of renewable energy creates new challenges: how can an organization minimize its carbon footprint in colocations? While numerous studies have investigated geographic load balancing to minimize carbon emissions of data centers, these studies have primarily focused on self-managed data centers where all the renewables are solely dedicated to the data center operator. In this paper, we consider a practical hybrid data center infrastructure (including both self-managed and colocation data centers) and propose a novel resource management algorithm based on alternating direction method of multipliers, called CAGE (Carbon and cost Aware GEographical job scheduling) to reduce carbon footprints. CAGE dynamically distributes incoming workloads to geo-distributed data centers based on local renewable availability, carbon efficiency, electricity price, and also the energy usage of other tenants that share the colocation data centers. Our comprehensive simulation study and system experiment show the benefits of CAGE in terms of carbon footprint reduction: up to 36% compared to the state of the arts.","2016","13","3","2025-12-02","https://university.edu/papers/8416aea7-da42-4765-a006-1ed210e10ee9.pdf");
INSERT INTO Paper VALUES ("428","Navigable voronoi diagram : a local path planner for mobile robots using sonar sensors","As robotics research is directed towards intelligent robot behavior, mobile robots need a capability to explore known / unknown environments autonomously. The ability of the autonomous navigation begins with a path planner : local and global. In this paper, we address a new local path planner using a navigable Voronoi diagram(NVD) which comes from the Voronoi diagram(VD). The characteristics of the NVD are safety, smoothness, fast reaction and so on. The NVD is constructed from sonar sensor readings and is integrated with a cost function. Another important advantages of the NVD is that it can drastically reduce the uncertainty of cheap sonar sensor readings due to its nature. The proposed local path planner based on the NVD has been successfully implemented on a Pioneer 3 equipped with 12 sonar sensors and its advantages were verified by 2 experiments in different indoor environments.","2007","2","3","2025-12-02","https://university.edu/papers/96b4f210-0203-46ea-86d0-2a5f128acb6d.pdf");
INSERT INTO Paper VALUES ("429","Track Routing and Optimization for Yield","In this paper, we propose track routing and optimization for yield (TROY), the first track router for the optimization of yield loss due to random defects. As the probability of failure (POF), which is an integral of the critical area and the defect size distribution, strongly depends on wire ordering, sizing, and spacing, track routing can play a key role in effective wire planning for yield optimization. However, a straightforward formulation of yield-driven track routing can be shown to be integer nonlinear programming, which is a nondeterministic polynomial-time complete problem. TROY overcomes the computational complexity by combining two effective techniques, i.e., the minimum Hamiltonian path (MHP) from graph theory and the second-order cone programming (SOCP) from mathematical optimization. First, TROY performs wire ordering to minimize the critical area for short defects by finding an MHP. Then, TROY carries out optimal wire sizing/spacing through SOCP optimization based on the given wire order. Since the SOCP can be optimally solved in near linear time, TROY efficiently achieves globally optimal wire sizing/spacing for the minimal POF.","2008","3","2","2025-12-02","https://university.edu/papers/c3f45717-3c42-4e1d-a6d0-3aa7d6564d34.pdf");
INSERT INTO Paper VALUES ("430","Optimizing TCP loss recovery performance over mobile data networks","Recent advances in high-speed mobile networks have revealed new bottlenecks in ubiquitous TCP protocol deployed in the Internet. In addition to differentiating non-congestive loss from congestive loss, our experiments revealed two significant performance bottlenecks during loss recovery phase: flow control bottleneck and application stall, resulting in degradation in QoS performance. To tackle these two problems we firstly develop a novel opportunistic retransmission algorithm to eliminate the flow control bottleneck, which enables TCP sender to transmit new packets even if receiver's receiving window is exhausted. Secondly, the application stall can be significantly alleviated by carefully monitoring and tuning the TCP send buffer growth mechanism. We implemented and modularized the proposed algorithms in the Linux kernel thus they can plug-and-play with the existing TCP loss recovery algorithms easily. Using emulated experiments we showed that with the proposed optimization techniques the existing loss recovery algorithms can at most achieve 98.3% bandwidth utilization during loss recovery phase, and reduce RTT by at most 80% after loss recovery phase.","2015","1","1","2025-12-02","https://university.edu/papers/d45ae5e7-f03a-4442-924d-854df0aa91e8.pdf");
INSERT INTO Paper VALUES ("431","The Bubble Box: Towards an Automated Visual Sensor for 3D Analysis and Characterization of Marine Gas Release Sites","Several acoustic and optical techniques have been used for characterizing natural and anthropogenic gas leaks (carbon dioxide, methane) from the ocean floor. Here, single-camera based methods for bubble stream observation have become an important tool, as they help estimating flux and bubble sizes under certain assumptions. However, they record only a projection of a bubble into the camera and therefore cannot capture the full 3D shape, which is particularly important for larger, non-spherical bubbles. The unknown distance of the bubble to the camera (making it appear larger or smaller than expected) as well as refraction at the camera interface introduce extra uncertainties. In this article, we introduce our wide baseline stereo-camera deep-sea sensor bubble box that overcomes these limitations, as it observes bubbles from two orthogonal directions using calibrated cameras. Besides the setup and the hardware of the system, we discuss appropriate calibration and the different automated processing steps deblurring, detection, tracking, and 3D fitting that are crucial to arrive at a 3D ellipsoidal shape and rise speed of each bubble. The obtained values for single bubbles can be aggregated into statistical bubble size distributions or fluxes for extrapolation based on diffusion and dissolution models and large scale acoustic surveys. We demonstrate and evaluate the wide baseline stereo measurement model using a controlled test setup with ground truth information.","2015","4","4","2025-12-02","https://university.edu/papers/2f2cf382-8f99-48ce-82f9-aaccafa910e3.pdf");
INSERT INTO Paper VALUES ("432","A Class of Explicitly Solvable Vehicle Motion Problems","A small but interesting result of Brockett is extended to the Euclidean group SE(3) and is illustrated by several examples. The result concerns the explicit solution of an optimal control problem on Lie groups, where the control belongs to a Lie triple system in the Lie algebra. The extension allows for an objective function based on an indefinite quadratic form. Applying the result requires explicit knowledge of the Lie triple systems of the Lie algebra se(3). Hence, a complete classification of the Lie triple systems of this Lie algebra is derived. Examples are considered for optimal trajectories in three cases. The first case concerns cars moving in the plane. The second looks at motions that rigidly follow the Bishop frame to a space curve. The final example does not have a particular name as it does not seem to have been studied before. The appendix gives a brief introduction to Screw theory. This is essentially the study of the Lie algebra se(3).","2015","20","1","2025-12-02","https://university.edu/papers/fdbe1153-f3bd-4684-bc8f-7c54c047de72.pdf");
INSERT INTO Paper VALUES ("433","Breast tomosynthesis imaging configuration optimization based on computer simulation","Digital tomosynthesis is an innovative imaging technology for early breast cancer detection by pro- viding three-dimensional anatomical information with fast image acquisition and low-dose radiation. Most of cur- rent breast tomosynthesis systems utilize a design where a single x-ray tube moves along an arc above objects over a certain angular range. The mechanical movement and patient motion during the scan may degrade image quality. With a carbon nanotube-based multibeam x-ray source, a new breast tomosynthesis modality is inno- vated, which will potentially produce better image quality with stationary beam sources and faster scan and it enables a variety of beam distributions. In this study, several beam distributions, such as beam sources span- ning along a one-dimensional (1-D) parallel configuration and sources over a two-dimensional (2-D) rectangle shape are investigated based on computer simulations. Preliminary results show that 2-D rectangle shapes outperform 1-D parallel shapes by providing better Z-resolution, enhanced image contrast, reduced out-of- plane blur and artifacts and lower reconstruction noise. These benefits may expand tomosynthesis applications to diagnostic and interventional procedures. © 2014 SPIE and IS&T (DOI: 10.1117/1.JEI.23.1.013017)","2014","4","2","2025-12-02","https://university.edu/papers/74a96f67-a257-49f7-9366-b00a1621a24f.pdf");
INSERT INTO Paper VALUES ("434","A combinatorial coordinate system for the body-centered cubic grid","A new compact combinatorial coordinate system is presented to address not only the voxels (truncated octahedra) of the body-centered cubic grid but also the lower-dimensional cells - faces, edges and vertices. Almost all integer triples address some cell in the grid, and incidence and adjacency relations between cells can easily be captured by the coordinate values. The new coordinate system can effectively and efficiently be applied in topological shape analysis and modeling, image processing and computer graphics applications.","2016","10","3","2025-12-02","https://university.edu/papers/00b002c8-d235-4c86-965c-07b5d17cba92.pdf");
INSERT INTO Paper VALUES ("435","Establishment of a maintenance plan based on quantitative analysis in the context of RCM in a JIT production scenario","This paper presents a quantitative method for supporting the preparation or review of an equipment maintenance plan in a Just-in-time production scenario. The proposed method includes the following steps: (i) identifying the parts that influence reliability; (ii) surveying the failure rates and times to repair the parts; (iii) classification of parts according to the effect of their failures; (iv) surveying the line occupation parameters; (v) identifying the probability distributions for time to failure, time to repair, and line occupation; (vi) simulating the production and maintenance using the Monte Carlo approach; (vii) conducting a sensitivity analysis concerning variations in demand,  MTTF , and  MTTR ; and (viii) establishing optimized intervals for preventive maintenance. The method is illustrated through an application in a labeling and filling gallons line at a paints and dyes production company. This method allowed the identification of critical parts as it relates to the productive scenario in question. The results can support companies in their decision making regarding the need and/or type of maintenance investment that would best fit an expected demand scenario.","2014","6","1","2025-12-02","https://university.edu/papers/72eb387a-fac6-4b70-ae7e-de44dfa38e4b.pdf");
INSERT INTO Paper VALUES ("436","Dimension of Marginals of Kronecker Product Models","A Kronecker product model is an exponential family whose sufficient statistics matrix factorizes as a Kronecker product of two matrices, one assigned to a visible set of variables and the other to a hidden set of variables. We estimate the dimension of the set of visible marginal probability distributions by the maximum rank of the Jacobian in the limit of large parameters. The limit is described by the tropical morphism: a piecewise linear map with pieces corresponding to slicings of the visible matrix by the normal fan of the hidden matrix. We obtain combinatorial conditions under which the model has the expected dimension, equal to the minimum of the number of natural parameters and the dimension of the ambient probability simplex. Furthermore, we prove that the binary restricted Boltzmann machine always has the expected dimension.","2017","3","4","2025-12-02","https://university.edu/papers/01d1499e-1667-4c3c-8ebe-dda3f47da528.pdf");
INSERT INTO Paper VALUES ("437","Band control policy of playout scheduling for voice over IP","We study adaptive-playout scheduling for VoIP using the framework of stochastic impulse control theory. A Wiener process is introduced to model the fluctuation of the buffer length in the absence of control. In this context, the control signal consists of length units that correspond to inserting or dropping a pitch cycle. We define an optimality criterion that has an adjustable trade-off between average buffing delay and average control length (the length of the pitch cycles added plus the length of the pitch cycles dropped). The clock-drift effect is treated in a unified manner within this framework. A band control policy is shown to be optimal. The algorithm does not require knowledge of the clock drift. It maintains the buffer length within a band region by imposing impulse control (inserted or dropped pitch cycles) whenever the bounds of the band are reached. Our experiments show that the proposed method outperforms a popular reference method.","2008","12","2","2025-12-02","https://university.edu/papers/4db7234b-f497-4275-9da1-18dd3bcbde57.pdf");
INSERT INTO Paper VALUES ("438","General Melting Point Prediction Based on a Diverse Compound Data Set and Artificial Neural Networks","We report the development of a robust and general model for the prediction of melting points. It is based on a diverse data set of 4173 compounds and employs a large number of 2D and 3D descriptors to capture molecular physicochemical and other graph-based properties. Dimensionality reduction is performed by principal component analysis, while a fully connected feed-forward back-propagation artificial neural network is employed for model generation. The melting point is a fundamental physicochemical property of a molecule that is controlled by both single-molecule properties and intermolecular interactions due to packing in the solid state. Thus, it is difficult to predict, and previously only melting point models for clearly defined and smaller compound sets have been developed. Here we derive the first general model that covers a comparatively large and relevant part of organic chemical space. The final model is based on 2D descriptors, which are found to contain more relevant information than the 3D de...","2005","13","1","2025-12-02","https://university.edu/papers/36f2d545-3243-469c-9704-1650f38f78fb.pdf");
INSERT INTO Paper VALUES ("439","Correlative monitoring for detection of false data injection attacks in smart grids","The overarching objective of the modernized electric grid, the smart grid, is to integrate two-way communication technologies across power generation, transmission and distribution to deliver electricity efficiently, securely and cost-effectively. However, real-time messaging exposes the entire grid to security threats ranging from attacks that disable information exchange between smart meters and data fusion centers to spurious payload content that would lead to incorrect assessment of actual demand. Such nefarious activities can compromise grid stability and efficiency. Hence, it is important to ensure secure communications and quickly detect malicious activity; this article proposes a framework for detection of false data injection attacks in smart grids. We present a measurement-based situation awareness framework that combines evidence from sensors at home-area networks, and aims to infer anomalies that signify a coordinated, well-orchestrated attack on residential smart meters at increasing spatial scales. By leveraging multi-view sensor readings, we present a Bayesian-based correlative monitoring approach that quickly detects power shifts to anomalous regimes. We evaluate our algorithms using real-world power traces.","2015","16","1","2025-12-02","https://university.edu/papers/e6f51aab-27c4-41b3-a25b-6ce4dadb16e3.pdf");
INSERT INTO Paper VALUES ("440","Kinematic modelling of tracked vehicles by experimental identification","The paper proposes a kinematic approach for tracked vehicles in order to improve motion control and pose estimation. Complex dynamics due to slippage and soil shearing make it difficult to predict the exact motion of the vehicle from the velocity of the two tracks. Nevertheless, reliable geometric approximations are necessary to perform onboard real-time computations for autonomous navigation. The presented solution is based on the kinematic similarities between tracked vehicles and wheeled differential drive vehicles. Particularly, the approximate position of wheel contact points for an equivalent vehicle can be optimized for a particular terrain at moderate speeds. This is achieved off-line by feeding a genetic algorithm with raw trajectory data and reliable localization estimations based on external sensors. The method has been successfully tested for online odometric computations and low-level motion control with the Auriga-/spl alpha/ mobile robot. Moreover, the identified parameters are similar to those obtained from the simulated stationary response of a complex dynamic model of this vehicle.","2004","14","1","2025-12-02","https://university.edu/papers/57bf0ed6-8a11-4f68-9d61-68eeae166ce8.pdf");
INSERT INTO Paper VALUES ("441","Simulating Topographic Effects on Spaceborne Radiometric Observations Between L and X Frequency Bands","A numerical simulator of satellite microwave-radiometric observations of orographically complex scenes, at various frequencies and observation angles, has been developed. The Simulator of Topographic Artefacts in MIcrowave RAdiometry (STAMIRA) exploits the information on the relief, extracted from a digital elevation model, and has been applied to a test case concerning a mountainous area in the Alps by assuming a simplified land-cover scenario consisting of bare terrain with two kinds of roughness (smooth and rough soils). The 1-10-GHz range has been considered to determine scattering and emission of soil and a nonscattering atmosphere has been supposed. The simulations have shown the large impact of the rotation of the polarization plane and of the brightness-temperature enhancement occurring for facets illuminated by radiation from the surrounding elevated terrain with respect to flat surfaces which scatter atmospheric downward radiation only. By considering also the antenna-pattern integration and the dependence of surface emissivity on the local observation angle, we have found that, for our case study, the brightness temperature is larger than that measured observing a flat terrain at horizontal polarization. At vertical polarization, the opposite occurs. These differences are analyzed and quantified.","2010","16","1","2025-12-02","https://university.edu/papers/bfba7810-e931-4164-a83f-eaad31bab51a.pdf");
INSERT INTO Paper VALUES ("442","An integrated voltage-mode PWM controlled buck converter with active compensation","Integrated step down DC to DC converters (buck converter) are widely used for battery powered devices. This paper presents an integrated voltage-mode PWM controlled buck converter for low power applications. A novel active compensation stage is implemented inside the buck converter to increase the loop control stability and to reduce stability dependence on the equivalent series resistance (ESR) of the output capacitor. The simulated phase margin of the control loop is 50 degree with 50mΩ ESR. A test chip is designed and fabricated in a 0.25 µm BiCMOS process. The measured peak efficiency of this buck converter with 30 mA load current is more than 87 percent and the measured output voltage ripple is less than 6 mV in steady-state.","2010","7","4","2025-12-02","https://university.edu/papers/da7a725e-9563-47bc-bd73-07c8505770e0.pdf");
INSERT INTO Paper VALUES ("443","Correlation-based user scheduling and multi-planar parallelogram array for Massive antenna systems","This paper proposes a simplified user scheduling method suitable for our proposed antenna arrangement and an antenna configuration with multi-planar antennas, for Massive MIMO. Massive MIMO has two key problems: the heavy overhead of feeding back the channel state information (CSI) for the very large number of transmission/reception antenna element pairs and the huge computation complexity imposed by the very large scale matrices. We previously proposed a parallelogram planar array (PPA) arrangement for Massive MIMO to realize channel spatial correlation reduction in LOS environments. Assuming that the proposed array is to cover omnidirectional areas, this paper proposes a user scheduling method that can easily enhance outage capacity performance in a simple manner and an antenna configuration that offers more efficient user accommodation. Simulations show that the proposed method can quadruple the system capacity over the uniform circular array antenna system.","2016","13","3","2025-12-02","https://university.edu/papers/a422c53b-5d11-4431-8c13-cc177a4f5a5d.pdf");
INSERT INTO Paper VALUES ("444","EasyApp: A Cross-platform Mobile Applications Development Environment Based on OSGi","*** The rapid development of mobile internet abstracts many non-professional persons to creating mobile applications. Traditional development process cannot meet their needs. In this paper, we present a cross-platform mobile development environment based on OSGi framework, EasyApp. It provides a highly-integrated, UI-friendly and easily-operating environment. Applications are comprehensively developed with web techniques. Users could create mobile applications with draggable widgets. Native APIs of mobile phone can be invoked with abundant plugins. After designing, users could package and download applications of multiple platforms. ***","2016","15","2","2025-12-02","https://university.edu/papers/73a57265-6bab-4dbb-969b-de635125f62b.pdf");
INSERT INTO Paper VALUES ("445","Intelligent tutoring system: Approaches, researches and e-learning solution","Passing the university entrance examination is a crucial step in student's life because it opens the vistas of higher education in professional development. It is very competitive to a certain degree so students try their luck with necessary preparation. Those who not prepared well, they fail it. Kankor is one such university entrance examination in Afghanistan. However, majority of talented students could not pass it, not because they do not deserve higher education; but because they do not have any guideline, training facilities physical or online, and capabilities. In this paper we analyze the research methods, approaches and the result of an intelligent tutoring system called e-Kankor which has been developed to tackle the aforementioned issues. The system offers a variety of practice materials, students' progress reports, teacher assessments, Integrative design, feedbacks including teacher-to-student and peer-assessments. The system rationale are firmly rooted in the learning theories and learner centered design approaches. To measure the success, we have rigorously tested our system on 3-scales: Lab testing, Expert-walk through and Field testing. The research methods are predominantly quantitative-cum-qualitative. Data analysis is performed with the help of SPSS. The outcome of the results indicates positive developments in terms of motivation, pedagogy and usability.","2015","6","3","2025-12-02","https://university.edu/papers/1fdea6ae-e2f4-4658-ac17-6a1a5efad30d.pdf");
INSERT INTO Paper VALUES ("446","Feature space trajectory methods for active computer vision","We advance new active object recognition algorithms that classify rigid objects and estimate their pose from intensity images. Our algorithms automatically detect if the class or pose of an object is ambiguous in a given image, reposition the sensor as needed, and incorporate data from multiple object views in determining the final object class and pose estimate. A probabilistic feature space trajectory (FST) in a global eigenspace is used to represent 3D distorted views of an object and to estimate the class and pose of an input object. Confidence measures for the class and pose estimates, derived using the probabilistic FST object representation, determine when additional observations are required as well as where the sensor should be positioned to provide the most useful information. We demonstrate the ability to use FSTs constructed from images rendered from computer-aided design models to recognize real objects in real images and present test results for a set of metal machined parts.","2002","1","2","2025-12-02","https://university.edu/papers/63f94dc0-7f12-420c-97e2-6ec26613b372.pdf");
INSERT INTO Paper VALUES ("447","EXPLORING THE CUSTOMER PERSPECTIVE OF AGILE DEVELOPMENT : ACCEPTANCE FACTORS AND ON-SITE CUSTOMER PERCEPTIONS IN SCRUM PROJECTS","In recent years, agile development methodologies have attracted great attention. Although the success of agile development projects depends considerably on the willingness of customers to actively participate, little research has examined which factors of such methodologies customers perceive as benefits or drawbacks. Employing an exploratory, primarily qualitative study design and the Diffusion of Innovations Theory as theoretical lens, we identify several acceptance factors of Scrum as a specific methodology and describe how customers perceive them. As basis for our examination, we use empirical data that was collected at a world-wide leading insurance company and a mixed-method approach that combines qualitative with quantitative data analyses. The results suggest that customers found Scrum to deliver relative advantages. Furthermore, they indicate that Scrum is perceived as more compatible to the way customers prefer to work in development projects. Factors that characterize the perceived complexity of Scrum were viewed as potential acceptance barriers, however.","2013","19","1","2025-12-02","https://university.edu/papers/5d748d72-5aaf-43aa-950d-f3feb973f1f3.pdf");
INSERT INTO Paper VALUES ("448","Group Association: Assisting Re-identification by Visual Context","In a crowded public space, people often walk in groups, either with people they know or with strangers. Associating a group of people over space and time can assist understanding an individual's behaviours as it provides vital visual context for matching individuals within the group. This seems to be an 'easier' task com- pared with person re-identification due to the availability of more and richer visual content in associating a group; however, solving this problem turns out to be rather challenging because a group of people can be highly non-rigid with changing rel- ative position of people within the group and severe self-occlusions. In this work, the problem of matching/associating groups of people over large space and time gaps captured in multiple non-overlapping camera views is addressed. Specifically, a novel people group representation and a group matching algorithm are proposed. The former addresses changes in the relative positions of people in a group and the latter uses the proposed group descriptors for measuring the similarity between two candidate images. Based on group matching, we further formulate a method for matching individual person using the group description as visual context. These methods are validated using the 2008 i-LIDS Multiple-Camera Tracking Scenario (MCTS) dataset on multiple camera views from a busy airport arrival hall.","2014","4","3","2025-12-02","https://university.edu/papers/f900881e-e57e-4b63-8977-025a761f7a19.pdf");
INSERT INTO Paper VALUES ("449","Analysis of Types of Self-Improving Software","Software capable of improving itself has been a dream of computer scientists since the inception of the field. In this work we provide definitions for Recursively Self-Improving software, survey different types of self-improving software, and provide a review of the relevant literature. Finally, we address security implications from self-improving intelligent software.","2015","12","4","2025-12-02","https://university.edu/papers/622f530e-7a92-4d2e-83cb-d80a990efb37.pdf");
INSERT INTO Paper VALUES ("450","ROS-DMA: A DMA Double Buffering Method for Embedded Image Processing with Resource Optimized Slicing","Image processing on a Digital Signal Processor (DSP) often requires image data to be stored in external memory, because the amount of fast on-chip memory is usually very limited. Processing images in external memory causes significant performance drawbacks. This paper presents a double buffering method using Direct Memory Access (DMA), called Resource Optimized Slicing (ROS-DMA), which is intended to be used instead of a Level 2 (L2) data cache. The idea of ROS-DMA is to transfer image slices into small intermediate buffers of fast internal memory, where the processing can be completed utilizing the full processing power. Use of DMA enables the data transfers and the processing to be accomplished in parallel. The proposed method has the advantage of a modular implementation, making it easy to re-use components for various image processing operations. The sequence of transfers is organized in such a way that use of processor resources is optimized to achieve the shortest possible execution time. ROS-DMA can yield substantially better performance compared to using L2 cache. Furthermore, we expect that with ROS-DMA it will be easier to obtain reliable and tight Worst Case Execution Times (WCETs). Test runs achieved up to six times faster execution with ROS-DMA compared to using the L2 cache on a C6416 DSP from Texas Instruments.","2006","20","1","2025-12-02","https://university.edu/papers/8b75fdb9-64ed-43ac-bfbc-04ad7f6cdc05.pdf");
INSERT INTO Paper VALUES ("451","Detection statistics and error performance of SPAD-based optical receivers","This paper presents the characterization of single photon avalanche diodes (SPADs) for optical communication applications. SPAD-based optical receivers can provide a significantly improved single-photon detection sensitivity compared with conventional photodiodes. However, an undesirable dead time introduced by the quenching circuit decreases the performance of these receivers. Using a precise analysis, we show that in the presence of dead time, the photon arrival process does not follow a Poisson process. Also, the effective count rate is evaluated and shown to depend critically on dead time. The effect of SPAD dead time on the error performance of an on-off keying (OOK) modulation optical communication system is also investigated. It is shown that, when background counts due to dark current and afterpulsing are small, the performance degradation of the SPAD-based receiver due to dead time losses is negligible. However, for systems with considerable background counts, the bit error rate (BER) degrades rapidly with increasing dead time.","2015","6","3","2025-12-02","https://university.edu/papers/f10d3b48-5156-4823-afb1-1f0ed59d456d.pdf");
INSERT INTO Paper VALUES ("452","Using MLP to Determine Abiotic Factors In uencing the Establishment of Insect Pest Species","The use of multi-layer perceptrons (MLP) to determine the significance of climatic variables to the establishment of insect pest species is described. Results show that the MLP are able to learn to accurately predict the establishment of a pest species within a specific geographic region. Analysis of the MLP yielded insights into the contribution of the individual input variables and allowed for the identification of those variables that were most significant in either encouraging or inhibiting establishment.","2006","4","2","2025-12-02","https://university.edu/papers/c2f3fe85-a0cf-447d-8c10-492f1e03be4a.pdf");
INSERT INTO Paper VALUES ("453","Interactive and Extensible Framework for Execution and Monitoring of Wireless Sensor Networks","As sensor networks become more prevalent in complex and sophisticated application domains, there is need for a simple execution and monitoring environment for repeatable experimentation and for easy transfer to in-situ real world environments. We have developed an environment for the execution and monitoring of sensor network services. It supports the requirements for the verification and testing of sensor network services, whether simulated, emulated, or real. The running of simulated, emulated, and real sensor networks allows different levels of abstraction and virtualization necessary for the verification and performance evaluation of sensor network applications and protocols. ISEE is an interactive sensor network execution environment that allows for control and access to simulated, emulated, and real sensor networks. The control and access environment provides remote execution, logging, interaction, and analysis facilities independent of the implementation of the sensor network. This framework allows for extensibility, scenario creation, and experiment repeatability. This provides visibility and repeatability to sensor network experimentation that may not be otherwise available. The combination of our framework with our distributed service framework allows for reactive and language independent user and developer interaction to a sensor networks","2006","20","1","2025-12-02","https://university.edu/papers/b55dd217-c23a-47e2-b311-18f333f29253.pdf");
INSERT INTO Paper VALUES ("454","Automatic Extraction of Causal Relations from Natural Language Texts: A Comprehensive Survey","Automatic extraction of cause-effect relationships from natural language texts is a challenging open problem in Artificial Intelligence. Most of the early attempts at its solution used manually constructed linguistic and syntactic rules on small and domain-specific data sets. However, with the advent of big data, the availability of affordable computing power and the recent popularization of machine learning, the paradigm to tackle this problem has slowly shifted. Machines are now expected to learn generic causal extraction rules from labelled data with minimal supervision, in a domain independent-manner. In this paper, we provide a comprehensive survey of causal relation extraction techniques from both paradigms, and analyse their relative strengths and weaknesses, with recommendations for future work.","2016","18","1","2025-12-02","https://university.edu/papers/9c3eb3bf-e35b-4d2e-8edb-b41f1284e06e.pdf");
INSERT INTO Paper VALUES ("455","Sensitivity analysis for multi-attribute system selection problems in onshore Environmentally Friendly Drilling (EFD)","Input data used in Multi-Attribute Decision Making (MADM) problems are often perceived to be imprecise by decision-makers because they are based on expert assessments. As a result, an important step in many applications of MADM is to perform a sensitivity analysis on the input data to help decision-makers understand how in which regions of the input data space they can be most confident in the recommended decisions and where improved input information is most needed. This paper describes sensitivity analysis procedures which will help decision-makers examine the robustness of the optimal solution to changes in input parameters in system selection decisions, where the system is made up of components (drilling technologies) that can be combined in many different ways. This paper presents two different sensitivity analysis methodologies. One is a sensitivity analysis for weighting factors of each attribute, and the other is a sensitivity analysis for uncertainty of overall attribute inputs. An application case study of the proposed approach is described to select optimal onshore Environmentally Friendly Drilling (EFD) systems at Green Lake near McFaddin, TX. © 2011 Wiley Periodicals, Inc. © 2012 Wiley Periodicals, Inc.","2012","17","2","2025-12-02","https://university.edu/papers/70ecb3b4-e853-477a-a5c5-9bbdfd16dfae.pdf");
INSERT INTO Paper VALUES ("456","A drift compensated reversible watermarking scheme for H.265/HEVC","In this paper, a compressed domain drift compensated reversible watermarking scheme is proposed with a high embedding capacity and the least amount of visual quality degradation for H.265/HEVC videos. Using compressed domain syntax elements, such as motion vector and transformed residual, a set of 4 × 4 Transform Blocks (TB) of similar texture are chosen from consecutive I Frames for watermark embedding. Due to texture similarity of these selected TBs, the differences between the transformed coefficients are equal or close to zero. Utilizing this difference statistics, a multilevel watermarking is inserted in the compressed video by altering near zeros values in the difference transformed coefficients. A comprehensive set of experiments have been carried out to justify the efficacy of the proposed scheme over existing literature.","2016","7","3","2025-12-02","https://university.edu/papers/a731f720-f9fe-430b-ad8b-7c54db8709bf.pdf");
INSERT INTO Paper VALUES ("457","Accurate and efficient runtime detection of atomicity errors in concurrent programs","Atomicity is an important correctness condition for concurrent systems. Informally, atomicity is the property that every concurrent execution of a set of transactions is equivalent to some serial execution of the same transactions. In multi-threaded programs, executions of procedures (or methods) can be regarded as transactions. Correctness in the presence of concurrency often requires atomicity of these transactions. Tools that automatically detect atomicity violations can uncover subtle errors that are hard to find with traditional debugging and testing techniques.This paper presents new algorithms for runtime (dynamic) detection of violations of conflict-atomicity and view-atomicity, which are analogous to conflict-serializability and view-serializability in database systems. In these algorithms, the recorded events are formed into a graph with edges representing the synchronization within each transaction and possible interactions between transactions. We give conditions on the graph that imply conflict-atomicity and view-atomicity. Experiments show that these new algorithms are more efficient in most experiments and are more accurate than previous algorithms with comparable asymptotic complexity.","2006","4","2","2025-12-02","https://university.edu/papers/fbea6404-0894-473a-930d-3028063df5f7.pdf");
INSERT INTO Paper VALUES ("458","Frame-based bit allocation for spatial scalability in H.264/SVC","The spatial scalability of H.264/SVC is achieved by a multi-layer approach, where an enhancement layer is dependent on its preceding layers. To address this dependent issue, we propose a modelbased spatial layer bit allocation algorithm for H.264/SVC in this work. The inter-layer dependency is decoupled by analyzing the signal flow in the H.264/SVC encoder. We show that the rate and the distortion (R-D) characteristics of a dependent layer with a frame as a basic coding unit. Finally, a low complexity spatial layer bit allocation scheme is developed using the proposed frame-based R-D models. It is shown by experimental results that our proposed bit allocation algorithm can achieve the coding performance close to the optimal R-D performance of full search and is highly improved from current reference codec JSVM.","2009","1","3","2025-12-02","https://university.edu/papers/ed64ff96-de6c-4c68-93a4-7201329f6ba4.pdf");
INSERT INTO Paper VALUES ("459","Where Can I Buy a Boulder?: Searching for Offline Retail Locations","People commonly need to purchase things in person, from large garden supplies to home decor. Although modern search systems are very effective at finding online products, little research attention has been paid to helping users find places that sell a specific product offline. For instance, users searching for an apron are not typically directed to a nearby kitchen store by a standard search engine. In this paper, we investigate 'where can I buy'-style queries related to in-person purchases of products and services. Answering these queries is challenging since little is known about the range of products sold in many stores, especially those which are smaller in size. To better understand this class of queries, we first present an in-depth analysis of typical offline purchase needs as observed by a major search engine, producing an ontology of such needs. We then propose ranking features for this new problem, and learn a ranking function that returns stores most likely to sell a queried item or service, even if there is very little information available online about some of the stores. Our final contribution is a new evaluation framework that combines distance with store relevance in measuring the effectiveness of such a search system. We evaluate our method using this approach and show that it outperforms a modern web search engine.","2016","5","2","2025-12-02","https://university.edu/papers/451ab45e-a857-4744-a866-994bae28798a.pdf");
INSERT INTO Paper VALUES ("460","Mitigating Global Warming: A Real Options Approach","Mitigation and adaptation represent two solutions to the issue of global warming. While mitigation aims at reducing CO2 emissions and preventing climate change, adaptation encompasses a broad scope of techniques used to reduce the impacts of climate change once they have occurred. Both have direct costs on a country’s Gross Domestic Product, but costs also arise from temperature increases due to inaction. This paper introduces a tipping point in a real options model and analyzes optimal investment choices in mitigation and their timing.","2016","3","2","2025-12-02","https://university.edu/papers/105f4fb4-922c-47e1-ade6-31ba5a4291c1.pdf");
INSERT INTO Paper VALUES ("461","A-3: An Architectural Style for Coordinating Distributed Components","Distributed systems comprise a significant number of entities that must be properly coordinated to reach a goal. These systems present high turnover of elements, and demand for solutions that keep their coordination as decentralized as possible to avoid bottlenecks. The paper discusses why it is important to address these characteristics from a system's conception and proposes A-3, an innovative architectural solution that adopts the concept of group as an abstraction for organizing an application into semi-independent slices, providing a single and coherent view of these aggregates, and coordinating the interactions inside and among groups. The paper presents the A-3 model and defines it as an innovative architectural style, describes a Java-based framework that supports A-3 and provides users with the proper means to exploit the style, and exemplifies all the main concepts on a simple scenario where autonomous robotic vacuum cleaners are coordinated to properly clean a museum.","2011","9","3","2025-12-02","https://university.edu/papers/641cb900-5d78-4955-9040-f9dd0ab9513c.pdf");
INSERT INTO Paper VALUES ("462","An Approach to Automated Design of Security Protocols","This paper deals with a formal specification approach that supports the design of security protocols. After introduction to communication protocols and description of the current problems in the design process, the subsequent section of the paper reviews a framework that is based on the genetic-programming approach. The original contribution consists of presentation of automated system to demonstrate the utilization of this approach for designing protocols that can establish secure communication. Moreover, this paper compares analytical and automated technique that might be used in the design process.","2006","16","2","2025-12-02","https://university.edu/papers/58e63ca7-6404-4a24-9a5d-784644f930b0.pdf");
INSERT INTO Paper VALUES ("463","Intelligent heartsound diagnostics on a cellphone using a hands-free kit","In resource-constrained environments, supply chains for consumables, repairs and calibration of diagnostic equipment are generally poor. To obviate this issue, we propose the use of widely available hardware with a strong supply chain: a cellphone with a hands-free kit. In particular, we focus on the use of the audio channel to determine heart rate (HR) and heart rate variability (HRV) in order to provide a first level screening system for infection. This article presents preliminary work performed on a gold standard database and a cellphone platform. Results indicate that HR and HRV can be accurately assessed from acoustic recordings of heart sounds using only a cellphone and hands-free kit. Heart sound analysis software, which can run on a standard cellphone in real time, has been developed that detects S1 heart sounds with a sensitivity of 92.1% and a positive predictivity of 88.4%. Evaluation of data recorded from cellphones demonstrates that the low-frequency response (<100 Hz) is key to the success of heart sound analysis on cellphones. Noise rejection is also shown to be important.","2010","3","3","2025-12-02","https://university.edu/papers/fdafe802-236c-44ec-89de-e918bfa9ec23.pdf");
INSERT INTO Paper VALUES ("464","Hidden Markov Models for the Prediction of Impending Faults","Reliability and safety are two important concepts in industrial applications. Thus, the development of monitoring tools, which are able to ensure the continuity of service by predicting faults, should improve competitiveness. This paper presents two probabilistic methods based on hidden Markov models (HMMs) for the prediction of impending faults. This paper shows that a prediction of faults is not limited to the estimation of the remaining useful life but is also extended to the estimation of the risk of an imminent appearance of faults in the future. The first method consists in modeling the degradation process of the studied system by a single HMM. A probabilistic model is proposed to predict an imminent appearance of a fault. The second method consists in modeling the degradation states by a set of HMMs. Another probabilistic model is proposed to predict an imminent appearance of a fault. An experimental application is proposed to demonstrate their applicability. The obtained results show their effectiveness to predict the imminent appearance of faults.","2016","18","3","2025-12-02","https://university.edu/papers/a4c7dda3-e2a9-48b8-9f30-11aacb94fcef.pdf");
INSERT INTO Paper VALUES ("465","Visual pattern weighting for near-duplicate image retrieval","Recently, there has been growing interest in mining co-location visual patterns from a collection of images. To find a proper usage of visual patterns in near-duplicate image retrieval systems, we study a TF-IDF weighting function for visual patterns. We show usage of TF and IDF respectively in this weighting function. Experiments demonstrate that 1) visual patterns and words should be weighted separately; 2) visual patterns consist of more frequent visual words would be more important; 3) visual patterns should be given lower weight values than visual words in near-duplicate image retrieval tasks.","2008","15","4","2025-12-02","https://university.edu/papers/c0fd0e12-be01-4c76-b4e8-69eac736715c.pdf");
INSERT INTO Paper VALUES ("466","A Local Algorithm to Learn Trajectories with Stochastic Neural Networks","This paper presents a simple algorithm to learn trajectories with a continuous time, continuous activation version of the Boltzmann machine. The algorithm takes advantage of intrinsic Brownian noise in the network to easily compute gradients using entirely local computations. The algorithm may be ideal for parallel hardware implementations.","1994","14","4","2025-12-02","https://university.edu/papers/da0162de-3c9e-4d51-a08c-1e0f18191070.pdf");
INSERT INTO Paper VALUES ("467","A Novel Geographic Partitioning System for Anonymizing Health Care Data","With large volumes of detailed health care data being collected, there is a high demand for the release of this data for research purposes. Hospitals and organizations are faced with conicting interests of releasing","2015","7","3","2025-12-02","https://university.edu/papers/88c10200-f07f-4cc4-a024-959aa379f9e6.pdf");
INSERT INTO Paper VALUES ("468","Analysis of User Behavior for Web Search Success Using Eye Tracker Data","Web log data has been the basis for analyzing user query session behavior for a number of years, but it has several important shortcomings. The main one being that we do not really know what the user is doing -- is s/he looking at the screen or doing something else? We have conducted an Eye-Tracking study to analyze user behavior when searching the web and looking for specific information on results and content pages. The goal is to obtain more precise information about the search strategy of the user. Which characteristics make the difference between successful and unsuccessful searches? This research presents results focusing on the number of formulated queries by session, documents clicked, the fixation durations on the documents, and the distribution of the attention in the different areas of the screen, among other aspects.","2012","6","2","2025-12-02","https://university.edu/papers/7379d7ec-0d88-4038-9fcc-d1a2c1545874.pdf");
INSERT INTO Paper VALUES ("469","Textured occupancy grids for monocular localization without features","A textured occupancy grid map is an extremely versatile data structure. It can be used to render human-readable views and for laser rangefinder localization algorithms. For camera-based localization, landmark or feature-based maps tend to be favored in current research. This may be because of a tacit assumption that working with a textured occupancy grid with a camera would be impractical. We demonstrate that a textured occupancy grid can be combined with an extremely simple monocular localization algorithm to produce a viable localization solution. Our approach is simple, efficient, and produces localization results comparable to laser localization results. A consequence of this result is that a single map representation, the textured occupancy grid, can now be used for humans, robots with laser rangefinders, and robots with just a single camera.","2011","9","4","2025-12-02","https://university.edu/papers/63ffb33f-16f9-42e5-b24e-7aabf44d7418.pdf");
INSERT INTO Paper VALUES ("470","Hardware-based parallel firefly algorithm for embedded applications","The firefly algorithm (FA) is a new population-based metaheuristic bioinspired on the behavior of the flashing characteristics of fireflies. As a population-based algorithm, the FA suffers from large execution times specifically for embedded optimization problems with computational limitations. For reducing execution times we propose a hardware parallel architecture of the FA algorithm that facilitates the implementation in Field Programmable Gate Arrays (FPGAs). In addition, this work proposes the application of the opposition-based learning (OBL) approach to the FA algorithm. The respective hardware implementation (HPOFA) was mapped into a Virtex5 FPGA device and numerical experiments using four well-known benchmark problems demonstrate that the opposition-based approach allows the FA algorithm to improve its functionality, preserving the swarm diversity and avoiding the premature convergence problem. Synthesis results point out that the HPOFA architecture is effectively mapped in hardware and is suitable for embedded applications.","2013","4","3","2025-12-02","https://university.edu/papers/7c163332-ea89-4ad5-bf38-de70eae36821.pdf");
INSERT INTO Paper VALUES ("471","Representing Independence Models with Elementary Triplets","In an independence model, the triplets that represent conditional independences between singletons are called elementary. It is known that the elementary triplets represent the independence model unambiguously under some conditions. In this paper, we show how this representation helps performing some operations with independence models, such as finding the dominant triplets or a minimal independence map of an independence model, or computing the union or intersection of a pair of independence models, or performing causal reasoning. For the latter, we rephrase in terms of conditional independences some of Pearl's results for computing causal effects.","2016","6","2","2025-12-02","https://university.edu/papers/73588e3d-3de9-4d7a-a008-0cb2c0b77405.pdf");
INSERT INTO Paper VALUES ("472","A New Approach to Hindi Text Steganography by Shifting Matra","Steganography is the means of storing information inside another message in such a way that hides informations existence. A number of steganography algorithms have been introduced using text, image, audio, video files as the cover media. Among these, text documents have been widely used for a very long time. This paper presents a new approach for steganography in Hindi texts. Considering the structure of Hindi alphabet/words, in this approach, by shifting the specific matra towards left or right, we hide the secret message in the text. This approach can be categorized under feature coding methods. The approach shows good result on the sample collected from different Hindi newspaper.","2009","16","4","2025-12-02","https://university.edu/papers/94d844b9-9120-4bde-9cb2-9a3296354ba2.pdf");
INSERT INTO Paper VALUES ("473","Semi-analytical techniques for substrate characterization in the design of mixed-signal ICs","A number of methods are presented for highly efficient calculation of substrate current transport. A three-dimensional Green's Function based substrate representation, in combination with the use of the Fast Fourier Transform, significantly speeds up the computation of sensitivities with respect to all parameters associated with a given architecture. Substrate sensitivity analysis is used in a number of physical optimization tools, such as placement and trend analysis for the estimation of the impact of technology migration and/or layout re-design.","1996","15","4","2025-12-02","https://university.edu/papers/d7f8bef2-8b37-4722-8e56-8e0d815c5c85.pdf");
INSERT INTO Paper VALUES ("474","Binaural speaker localization and separation based on a joint ITD/ILD model and head movement tracking","In this paper we present a novel algorithm to localize and separate simultaneous speakers using hearing aids when the head is subject to rotational movement. Most of the algorithms used in hearing aids are able to extract target signals that are in the look direction of the user and suffer from a reduced performance in localizing sounds received from other directions. Moreover, head-shadowing as well as variations like head movements may lead to significant distortions. The proposed binaural GSC beamformer includes an MMSE-based localization algorithm using an ITD/ILD model and is controlled by an inertial measurement unit. The localization algorithm can effectively localize multiple speakers in the presence of reverberation. The estimated source locations are used to adapt the GSC beamformer which extracts the desired speaker. Experimental results demonstrate the performance of the new system and especially the benefits of ILD information.","2016","20","3","2025-12-02","https://university.edu/papers/87dbdbe2-a0c8-4bfb-93dd-c6baf46eb258.pdf");
INSERT INTO Paper VALUES ("475","Mining for Tree-Query Associations in a Graph","New applications of data mining, such as in biology, bioinformatics, or sociology, are faced with large datasets structured as graphs. We present an efficient algorithm for mining associations between tree queries in a large graph. Tree queries are powerful tree-shaped patterns featuring existential variables and data constants. Our algorithm applies the theory of conjunctive database queries to make the generation of association rules efficient. We propose a practical, database-oriented implementation in SQL, and show that the approach works in practice through experiments on data about food webs, protein interactions, and citation analysis.","2006","11","1","2025-12-02","https://university.edu/papers/fd50c7c8-4195-480e-8c8e-a24960cb2050.pdf");
INSERT INTO Paper VALUES ("476","Real-time distributed computing","This position paper concerns itself with real-time safety critical distributed systems. It presents a computational model that is appropriate for this type of application and architecture. It then defines a resource allocations scheme based upon fixed priority scheduling. Such a scheme has the advantage (over purely static schedules) of supporting greater levels of flexibility and non-determinism, whilst still providing static guarantees of necessary timing behaviour (i.e. end-to-end deadlines through the systems). Priority based communication protocols are investigated, with possible future techniques reviewed.","1995","20","4","2025-12-02","https://university.edu/papers/4ab5585e-6a6a-4c92-b37c-e4dbb67fe72e.pdf");
INSERT INTO Paper VALUES ("477","The semi-smooth Newton method for variationally discretized control constrained elliptic optimal control problems; implementation, convergence and globalization","Combining the numerical concept of variational discretization and semi-smooth Newton methods for the numerical solution of pde-constrained optimization with control constraints, we place special emphasis on the implementation and globalization of the numerical algorithm. We prove fast local convergence of a globalized algorithm and illustrate our analytical and algorithmical findings by numerical experiments.","2012","14","2","2025-12-02","https://university.edu/papers/5ebf5609-f0ec-43b3-8aa7-43d48e9a3fc5.pdf");
INSERT INTO Paper VALUES ("478","Cartesian control of robots without dynamic model and observer design","Most control algorithms for rigid robots are given in joint coordinates. However, since the task to be accomplished is expressed in Cartesian coordinates, inverse kinematics has to be computed in order to implement the control law. Alternatively, one can develop the necessary theory directly in workspace coordinates. This has the disadvantage of a more complex robot model. In this paper, a control-observer scheme is given to achieve exact Cartesian tracking without the knowledge of the manipulator dynamics nor computing inverse kinematics. Also, only joint measurements are used.","2006","19","3","2025-12-02","https://university.edu/papers/d36c09b0-0f46-474c-834c-d92a84ef9917.pdf");
INSERT INTO Paper VALUES ("479","LASSO: a grid-enabled simulation optimization framework","In this paper, we report our experiences developing a grid-enabled framework for solving environmental inverse problems. The solution approach taken here couples environmental simulation models with global search methods and requires the readily available computational resources of the grid for computational tractability. We present a set of results for a ground water release history reconstruction problem, and report significant performance improvements observed for a deployment of the application on the TeraGrid.","2005","12","1","2025-12-02","https://university.edu/papers/9ab3bd2c-b2df-4177-8128-795317a0a3c2.pdf");
INSERT INTO Paper VALUES ("480","Power control in cognitive radio networks: how to cross a multi-lane highway","We consider power control in cognitive radio networks where secondary users identify and exploit instantaneous and local spectrum opportunities without causing unacceptable interference to primary users. We qualitatively characterize the impacts of the transmission power of secondary users on the occurrence of spectrum opportunities and the reliability of opportunity detection. Based on a Poisson model of the primary network, we quantify these impacts by showing that (i) the probability of spectrum opportunity decreases exponentially with the transmission power of secondary users, where the exponential decay constant is given by the traffic load of primary users; (ii) reliable opportunity detection is achieved in the two extreme regimes in terms of the ratio between the transmission power of secondary users and that of primary users. Such analytical characterizations allow us to study power control for optimal transport throughput under constraints on the interference to primary users. Furthermore, we reveal the difference between detecting primary signals and detecting spectrum opportunities, and demonstrate the complex relationship between physical layer spectrum sensing and MAC layer throughput. The dependency of this PHY-MAC interaction on the application type and the use of handshake signaling such as RTS/CTS is also illustrated.","2009","15","2","2025-12-02","https://university.edu/papers/fa01ed14-fad6-4b49-9f55-802ae9dc09c6.pdf");
INSERT INTO Paper VALUES ("481","Bedeutung von Zugehörigkeitsgraden in der Fuzzy-Technologie","Der Begriff der Fuzzy-Menge erweitert den klassischen Begriff der Menge, sodass man fur betrachtete Objekte nicht nur (in einer Menge) ,,enthalten“ und ,,nicht enthalten“ angeben, sondern Grade der Zugehorigkeit unterscheiden kann. Wahrend das nur zweiwertige (Nicht-)Enthaltensein unmittelbar verstandlich ist, stellt sich bei dazwischenliegenden Zugehorigkeitsgraden die Frage, was sie bedeuten. Wir geben daher in diesem Aufsatz einen kurzen Uberblick uber die vier am weitesten verbreiteten Ansatze, Fuzzy-Zugehorigkeitsgraden eine (prazise) Bedeutung zuzuordnen: 1. als Ahnlichkeit zu Referenzwerten, 2. als Ausdruck von Praferenz, 3. als bedingte Wahrscheinlichkeit (likelihood) und 4. als Moglichkeitsgrad (degree of possibility). Wir diskutieren die Voraussetzungen und Ausdrucksmoglichkeiten dieser vier Interpretationen und untersuchen, in welchen Anwendungsbereichen sie jeweils am nutzlichsten sind, wobei wir in einigen Fallen Beispielanwendungen erwahnen.","2015","2","3","2025-12-02","https://university.edu/papers/5411d619-3ccd-4d3f-995d-915dbf77c10b.pdf");
INSERT INTO Paper VALUES ("482","Decentralized Clustering and Linking by Networked Agents","We consider the problem of decentralized clustering and estimation over multitask networks, where agents infer and track different models of interest. The agents do not know beforehand which model is generating their own data. They also do not know which agents in their neighborhood belong to the same cluster. We propose a decentralized clustering algorithm aimed at identifying and forming clusters of agents of similar objectives, and at guiding cooperation to enhance the inference performance. One key feature of the proposed technique is the integration of the learning and clustering tasks into a single strategy. We analyze the performance of the procedure and show that the error probabilities of types I and II decay exponentially to zero with the step-size parameter. While links between agents following different objectives are ignored in the clustering process, we nevertheless show how to exploit these links to relay critical information across the network for enhanced performance. Simulation results illustrate the performance of the proposed method in comparison to other useful techniques.","2017","19","4","2025-12-02","https://university.edu/papers/786df88e-b845-45a4-9a69-9811d0ba5e9f.pdf");
INSERT INTO Paper VALUES ("483","Specific graph models and their mappings to a common model","Software engineering applications, like integrated development environments or CASE tools, often work on complex documents with graph-like structures. Modifications of these documents can be realized by graph transformations. Many graph transformation systems operate only in volatile memory and thus suffer from a couple of drawbacks. In this paper, we present the graph model of the Gras/GXL database management system. Gras/GXL enables graph based applications to store their graphs persistently in commercial databases. Because these applications usually have their own graph model, a mapping from this graph model to the Gras/GXL graph model has to be realized. We will present mappings for the PROGRES, DIAGEN, and DIAPLAN graph models in this paper. For the PROGRES graph model we will also show its realization.","2004","10","3","2025-12-02","https://university.edu/papers/6bf8cf41-daaf-4aaf-9c71-0bbb79512823.pdf");
INSERT INTO Paper VALUES ("484","Magnetic resonance and computed tomography image fusion using bidimensional empirical mode decomposition","Image Fusion has been widely used for medical images to improve diagnosis accuracy and time by providing medical personnel with more comprehensive picture of the patient condition, where a single modality cannot provide. In this work, we explore image fusion using Empirical Mode Decomposition (EMD) for medical imaging purposes. In particular, we use Bidimensional Empirical Mode Decomposition (BEMD) to analyze Magnetic Resonance (MRI) and Computed Tomography (CT) Images and fuse the generated Bidimensional Intrinsic Mode Functions (BIMFs) using simple fusion rules. BEMD is particularly useful for medical images since the fused images are, in general, anatomically consistent. Thus, BEMD is more likely to yield homogeneous BIMFs, which in turn are easy to fuse computationally. Results of BEMD-based fusion are reported and compared with two other fusion techniques: Curvelet Fusion and Wavelet Fusion. Performance of BEMD is evaluated using perceived quality as well as using three popular image fusion quality metrics; namely, Peak Signal-to-noise Ratio (PSNR), Structure Similarity Index Metric (SSIM), and Mutual Information parameter (MI).","2015","13","1","2025-12-02","https://university.edu/papers/ff28ccbb-3003-432b-ad1f-e967cc39c118.pdf");
INSERT INTO Paper VALUES ("485","Scrutinizing pseudo haptic feedback of surface roughness in virtual environments","Operators in virtual environments have to mostly rely on visual feedback when exploring virtual scenes and objects. If no additional haptic actuators are available then information about surface roughness will not be communicable and thus the degree of immersion will suffer. To compensate for this shortcome the usage of pseudo haptic feedback (Control/ Display ratio = visual cues encoding haptic object properties) is discussed and two psychophysical experiments are conducted. The first experiment deals with the perceptual scaling of different Control/ Display ratios while the second experiment examines the way, how human subjects assign suitable Control/ Display ratios to different real surfaces. It turns out that human operators can reliably perceive differences in Control/ Display ratios and a psychophysic function is established. The allocation of specific Control/ Display values to real materials does not give any generalizable results; only a global trend is observable.","2008","4","2","2025-12-02","https://university.edu/papers/f0289637-bc9d-410b-bdf3-e14fba2e7288.pdf");
INSERT INTO Paper VALUES ("486","The Current State of Understanding of the Energy Efficiency of Cloud Computing","Cloud computing has been hailed as the achievement of the long-held dream of computing as a utility and has the potential to transform a large part of the Information and Communication Technology (ICT) industry. Cloud computing is both a business and an economic model which has been gaining popularity since 2006 and it is currently the most talked about technology in the ICT industry. Because it views hardware and software as commodities, the cloud is an example of a disruptive technology. It offers enterprises the opportunity to reduce hardware and software cost and the potential reduction of maintenance and support staff. Data centers and cloud computing services providers hope that the widespread adoption of the cloud will bring them more profit and they are actively promoting the technology. The cloud has had its share of controversy; ranging from the definition of cloud computing to its energy efficiency. This paper discusses one area of controversy; the energy efficiency of cloud computing. We outline previous contributions to the discussion of energy efficiency of cloud computing, provide a working definition of cloud computing and discuss its importance, which will grow as the technology matures and becomes well known.","2012","11","4","2025-12-02","https://university.edu/papers/84785475-92c5-4cec-bdd0-0a74b88faefe.pdf");
INSERT INTO Paper VALUES ("487","Audio-visual conference through the ionosphere at 4 kbps","Unlike in data communications, multimedia communications through heterogeneous networks is still far from being achieved due to a lack of solutions at all protocol layers. We are evaluating the performance of a high frequency (HF) wireless network for transporting multimedia services. Beyond allowing civil/amateur communications, HF bands are also used for long distance wireless military communications. Therefore, our research work is based on NATO link and physical layer standards, STANAG 5066 and STANAG 4539 respectively. A typical transmission bandwidth is of about 3 kHz with a throughput bit rate up to 12800 bps, resulting in a very low channel capacity and therefore imposing serious challenges for reliable real time multimedia communications. The paper describes a complete video conference system designed to allow end-to-end communication and discusses the quality of service in terms of packet loss and delay","2004","6","3","2025-12-02","https://university.edu/papers/98bae9ef-b068-426e-a21c-c7337cf652cf.pdf");
INSERT INTO Paper VALUES ("488","Power Supply Noise in Delay Testing","Excessive power supply noise can affect path delay and cause overkill during delay test. This paper presents low-cost noise models for fast power supply noise analysis and timing analysis considering noise impact. Our prior work only considered array-bond chips. This work proposes a noise analysis methodology that can be applied to wire-bond chips as well as array-bond chips. Experiments were performed on an industrial design. Silicon results show as much as a 15% delay variation due to different don't care fill approaches. The power supply noise impact on delay must be taken into account when delay tests are applied.","2006","8","1","2025-12-02","https://university.edu/papers/df7200d1-e88d-4090-9160-096eb1972ff3.pdf");
INSERT INTO Paper VALUES ("489","Dictionary learning with the cosparse analysis model based on summation of blocked determinants as the sparseness measure","Dictionary learning is crucially important for sparse representation of signals. Most existing methods are based on the so called synthesis model, in which the dictionary is column redundant. This paper addresses the dictionary learning and sparse representation with the so-called analysis model. In this model, the analysis dictionary multiplying the signal can lead to a sparse outcome. Though it has been studied in the literature, there is still not an investigation in the context of dictionary learning for nonnegative signal representation, while the algorithms designed for general signal are found not sufficient when applied to the nonnegative signals. In this paper, for a more efficient dictionary learning, we propose a novel cost function that is termed as the summation of blocked determinants measure of sparseness (SBDMS). Based on this measure, a new analysis sparse model is derived, and an iterative sparseness maximization scheme is proposed to solve this model. In the scheme, the analysis sparse representation problem can be cast into row-to-row optimizations with respect to the analysis dictionary, and then the quadratic programming (QP) technique is used to optimize each row. Therefore, we present an algorithm for the dictionary learning and sparse representation for nonnegative signals. Numerical experiments on recovery of analysis dictionary show the effectiveness of the proposed method.","2016","7","3","2025-12-02","https://university.edu/papers/6aee550c-3009-4674-897d-615a02144d29.pdf");
INSERT INTO Paper VALUES ("490","Random Walks and Neural Network Language Models on Knowledge Bases","Random walks over large knowledge bases like WordNet have been successfully used in word similarity, relatedness and disambiguation tasks. Unfortunately, those algorithms are relatively slow for large repositories, with significant memory footprints. In this paper we present a novel algorithm which encodes the structure of a knowledge base in a continuous vector space, combining random walks and neural net language models in order to produce novel word representations. Evaluation in word relatedness and similarity datasets yields equal or better results than those of a random walk algorithm, using a dense representation (300 dimensions instead of 117K). Furthermore, the word representations are complementary to those of the random walk algorithm and to corpus-based continuous representations, improving the stateof-the-art in the similarity dataset. Our technique opens up exciting opportunities to combine distributional and knowledge-based word representations.","2015","12","2","2025-12-02","https://university.edu/papers/6234cc66-6a66-447b-9134-e4ee1a382b13.pdf");
INSERT INTO Paper VALUES ("491","An automatic intelligent system for diagnosis and confirmation of Johne's disease","Johne's disease is one of the most widespread bacterial diseases of domestic animals. It causes yearly losses of billions of dollars worldwide. In this paper an automatic intelligent computer-aided system is proposed for the diagnosis of Johne's disease, the system uses image analysis and computer vision techniques to extract features from two different microscopic images, then those features are classified using neural networks and K-nearest neighbour K-NN techniques to diagnose Johne's disease. The proposed system employs histopathological examination to extract 192 different texture features. The features are then reduced into only 8 features and classified using artificial neural networks ANN. The acid fast stain test is used to confirm the positive cases. The construction and testing of both models are carried out using a total of 294 microscopic images, 194 images for the histopathological examination test which produces an overall accuracy of 98.33%. The other 100 images are used for the acid fast stain test, and it achieves an accuracy of 96.97%.","2015","11","1","2025-12-02","https://university.edu/papers/61cfff3d-a009-4dd8-a7ca-f9085e5409f0.pdf");
INSERT INTO Paper VALUES ("492","Interference in Learning Internal Models of Inverse Dynamics in Humans","Experiments were performed to reveal some of the computational properties of the human motor memory system. We show that as humans practice reaching movements while interacting with a novel mechanical environment, they learn an internal model of the inverse dynamics of that environment. Subjects show recall of this model at testing sessions 24 hours after the initial practice. The representation of the internal model in memory is such that there is interference when there is an attempt to learn a new inverse dynamics map immediately after an anticorrelated mapping was learned. We suggest that this interference is an indication that the same computational elements used to encode the first inverse dynamics map are being used to learn the second mapping. We predict that this leads to a forgetting of the initially learned skill.","1995","1","3","2025-12-02","https://university.edu/papers/6fa13467-86cd-4486-b06f-31b5934b6c8c.pdf");
INSERT INTO Paper VALUES ("493","Robust model for speaker verification against session-dependent utterance variation","This paper investigates a new method for creating speaker models that are robust against utterance variation in continuous distribution hidden Markov model-based speaker verification. In this method, the distribution of the session-independent features for each speaker is estimated by separately modeling the session-to-session utterance variation as two distinct variations: one session-dependent and the other session-independent. In practice, joint normalization of the session-dependent utterance variation and estimation of the parameters of speaker models is performed based on a speaker adaptive training algorithm. The resulting speaker models more accurately represent session-independent speaker characteristics, and the discriminatory capabilities of these models increases. In text-independent speaker verification experiments using data uttered by 20 speakers in 7 sessions over 16 months, we show that the proposed method achieves a 15% reduction in the error rate.","1998","1","3","2025-12-02","https://university.edu/papers/5c74a01a-ec5b-4716-aee8-a608f42075a5.pdf");
INSERT INTO Paper VALUES ("494","Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes","This paper presents hHDP, a hierarchical algorithm for representing a document collection as a hierarchy of latent topics, based on Dirichlet process priors. The hierarchical nature of the algorithm refers to the Bayesian hierarchy that it comprises, as well as to the hierarchy of the latent topics. hHDP relies on nonparametric Bayesian priors and it is able to infer a hierarchy of topics, without making any assumption about the depth of the learned hierarchy and the branching factor at each level. We evaluate the proposed method on real-world data sets in document modeling, as well as in ontology learning, and provide qualitative and quantitative evaluation results, showing that the model is robust, it models accurately the training data set and is able to generalize on held-out data.","2011","7","4","2025-12-02","https://university.edu/papers/af662dd7-c767-4be5-b195-f76a17e0f408.pdf");
INSERT INTO Paper VALUES ("495","Learning from Binary Labels with Instance-Dependent Corruption","Suppose we have a sample of instances paired with binary labels corrupted by arbitrary instance- and label-dependent noise. With sufficiently many such samples, can we optimally classify and rank instances with respect to the noise-free distribution? We provide a theoretical analysis of this question, with three main contributions. First, we prove that for instance-dependent noise, any algorithm that is consistent for classification on the noisy distribution is also consistent on the clean distribution. Second, we prove that for a broad class of instance- and label-dependent noise, a similar consistency result holds for the area under the ROC curve. Third, for the latter noise model, when the noise-free class-probability function belongs to the generalised linear model family, we show that the Isotron can efficiently and provably learn from the corrupted sample.","2016","19","3","2025-12-02","https://university.edu/papers/bf223924-5a23-423d-b1c8-200a6ca277cd.pdf");
INSERT INTO Paper VALUES ("496","A Novel Unsupervised 2-Stage k-NN Re-Ranking Algorithm for Image Retrieval","In many image retrieval systems, re-ranking is an important final step to improve the retrieval accuracy given an initial ranking list. K-Nearest Neighbors (k-NN) re-ranking algorithms are the class of algorithms that re-rank an initial ranked list by comparing the similarity between a query image's k-NN and the k-NN of candidate database images, e.g. the initially high ranked images. In this paper, we present a novel 2-stage k-NN re-ranking algorithm. In stage one, we generate an expanded list of candidate database images for re-ranking so that some lower ranked ground truth images will be included for the next stage. In stage two, we re-rank the list of candidate images using a confidence score which is calculated based on both the ranking consistency and reciprocal k-NN properties. Our experimental results on two popular benchmark datasets along with a large-scale 1 million distraction dataset show improved performance over existing k-NN re-ranking methods.","2015","8","1","2025-12-02","https://university.edu/papers/0076ec25-0b68-4b9f-9ae5-a973a0a1bd83.pdf");
INSERT INTO Paper VALUES ("497","How Events Affect Trust: A Baseline Information Processing Model with Three Extensions","This article addresses how trust changes over time. We introduce a social psychology-based Information Processing Model (IPM) that explains how trust changes over time based on three cognitive mechanisms: attention, attribution, and judgment. This model is contrasted with the traditional incre- mental progression model of trust change. We also explain three extensions of the model. These models are then simulated and the results suggest that incre- mental progression may be inconsistent with established psychological theory.","2012","13","3","2025-12-02","https://university.edu/papers/8c6dd5d7-8a75-4b18-b4fd-bae73918d51f.pdf");
INSERT INTO Paper VALUES ("498","On Improving the Performance of Hybrid Wired-Wireless Network-on-Chip Architectures","Recently, hybrid wired-wireless Network-on-Chip (WiNoC) have been proposed to meet the performance and scalability demands of modern System-on-Chip (SoC) design. However, due to the presence of wirelines with multi-hop nodes in the hybrid architecture, WiNoCs have reduced performance efficiency. In this paper, we propose a low-complexity single-cycle bypassing mechanism to alleviate the performance degradation in such emerging hybrid NoCs. The proposed router employs both dimension-ordered routing (DoR) and a deadlock free adaptive routing to transmit flits at low-loads and high traffic loads, respectively, to efficiently balance traffic in WiNoCs. By reducing the latency between the wired nodes and the wireless nodes, the proposed router can improve performance efficiency in terms of average packet delay by an average of 50% in WiNoCs.","2016","20","2","2025-12-02","https://university.edu/papers/30f243fe-402a-4c7a-bf40-0e8a2d4377cf.pdf");
INSERT INTO Paper VALUES ("499","A document retrieval method from handwritten characters based on OCR and character shape information","It is a difficult task to create a large database of electronic documents from paper documents. In order to search the database for an image document, it is necessary for general electronic filing systems to convert the document into texts using OCR. However, the system cannot retrieve documents that do not contain correct character codes. We (1999) had previously proposed a document retrieval method that reduces false drops and false alarms by using the 'shape-feature' technique that describes the outline of the character's shape. We now apply this method to handwritten Japanese documents. Experimental results reveal that our method has a high recall rate of 88.8% compared to the conventional methods (69.2%: text matching, 78.3%: candidate matching).","2001","17","2","2025-12-02","https://university.edu/papers/80426614-0caf-460f-8ede-696620eec7ad.pdf");
INSERT INTO Paper VALUES ("500","System Identification and Fault Diagnosis of an Electromagnetic Actuator","The electromagnetic actuators are widely used in the industry due to their simple structure, force characteristics, and low manufacturing costs. However, from control point of view, they are nonlinear systems. In this brief, clustering-based system identification experiments as well as a piecewise mathematical model are described. Furthermore, a model-based fault detection and isolation of the actuator is presented, when the armature movement is sensed indirectly, by sensing only the armature current.","2017","4","3","2025-12-02","https://university.edu/papers/f5300c08-feb7-4ab4-be29-1f0633822b75.pdf");
INSERT INTO Paper VALUES ("501","Understanding function behaviors through program slicing","We present conditioned slicing as a general slicing framework for program comprehension. A conditioned slice consists of a subset of program statements which preserves the behavior of the original program with respect to a set of program executions. The set of initial states of the program that characterize these executions is specified in terms of a first order logic formula on the input variables of the program. Conditioned slicing allows a better decomposition of the program giving the maintainer the possibility to analyze code fragments with respect to different perspectives. We also show how slices produced with traditional slicing methods can be reduced to conditioned slices. Conditioned slices can be identified by using symbolic execution techniques and dependence graphs.","1996","20","1","2025-12-02","https://university.edu/papers/9ed0b2ae-bcc7-4f84-8b7d-3d442e94db7e.pdf");
INSERT INTO Paper VALUES ("502","A Perceptual Image Sharpness Metric Based on Local Edge Gradient Analysis","In this letter, a no-reference perceptual sharpness metric based on a statistical analysis of local edge gradients is presented. The method takes properties of the human visual system into account. Based on perceptual properties, a relationship between the extracted statistical features and the metric score is established to form a Perceptual Sharpness Index (PSI). A comparison with state-of-the-art metrics shows that the proposed method correlates highly with human perception and exhibits low computational complexity. In contrast to existing metrics, the PSI performs well for a wide range of blurriness and shows a high degree of invariance for different image contents.","2013","19","4","2025-12-02","https://university.edu/papers/7be11360-7f50-4358-8339-0821a749fd46.pdf");
INSERT INTO Paper VALUES ("503","Video Stabilization Using Scale-Invariant Features","Video Stabilization is one of those important video processing techniques to remove the unwanted camera vibration in a video sequence. In this paper, we present a practical method to remove the annoying shaky motion and reconstruct a stabilized video sequence with good visual quality. Here, the scale invariant (SIFT) features, proved to be invariant to image scale and rotation, is applied to estimate the camera motion. The unwanted vibrations are separated from the intentional camera motion with the combination of Gaussian kernel filtering and parabolic fitting. It is demonstrated that our method effectively removes the high frequency 'noise' motion, but also minimize the missing area as much as possible. To reconstruct the undefined areas, resulting from motion compensation, we adopt the mosaicing method with Dynamic Programming. The proposed method has been confirmed to be effective over a widely variety of videos.","2007","14","3","2025-12-02","https://university.edu/papers/92dfb911-878a-415f-a058-b81533b8e4cc.pdf");
INSERT INTO Paper VALUES ("504","A tactile feeling display based on selective stimulation to skin receptors","People can feel various tactile feelings by touching and rubbing objects. In this paper, we propose a method to display such tactile feeling of fine texture with reality. We create the feeling by selective stimulation to each kind of mechanoreceptor using the elastic transfer property of the skin. Our system is composed of four small magnet tips attached on the hand in a line, which are controlled with precise force. The two driving modes, the common phase mode and the reversed phase mode, stimulate the deep receptors and shallow receptors in the skin, respectively. The system could give several types of tactile feeling with reality. The principle and experimental results are shown.","1998","11","2","2025-12-02","https://university.edu/papers/29cfe59a-60ea-41e5-a3e8-cec0bed29a63.pdf");
INSERT INTO Paper VALUES ("505","WiFi localization and navigation for autonomous indoor mobile robots","Building upon previous work that demonstrates the effectiveness of WiFi localization information per se, in this paper we contribute a mobile robot that autonomously navigates in indoor environments using WiFi sensory data. We model the world as a WiFi signature map with geometric constraints and introduce a continuous perceptual model of the environment generated from the discrete graph-based WiFi signal strength sampling. We contribute our WiFi localization algorithm which continuously uses the perceptual model to update the robot location in conjunction with its odometry data. We then briefly introduce a navigation approach that robustly uses the WiFi location estimates. We present the results of our exhaustive tests of the WiFi localization independently and in conjunction with the navigation of our custom-built mobile robot in extensive long autonomous runs.","2010","7","1","2025-12-02","https://university.edu/papers/ebb5c1bf-369e-44ac-a264-63b4c2541aae.pdf");
INSERT INTO Paper VALUES ("506","Kernel Fukunaga-Koontz Transform Subspaces For Enhanced Face Recognition","Traditional linear Fukunaga-Koontz transform (FKT) (F. Fukunaga and W. Koontz, 1970) is a powerful discriminative subspaces building approach. Previous work has successfully extended FKT to be able to deal with small-sample-size. In this paper, we extend traditional linear FKT to enable it to work in multi-class problem and also in higher dimensional (kernel) subspaces and therefore provide enhanced discrimination ability. We verify the effectiveness of the proposed kernel Fukunaga-Koontz transform by demonstrating its effectiveness in face recognition applications; however the proposed non-linear generalization can be applied to any other domain specific problems.","2007","16","4","2025-12-02","https://university.edu/papers/b07d57cb-9242-4f08-9aac-026504bd651e.pdf");
INSERT INTO Paper VALUES ("507","A comparison of wavelet transform features for texture image annotation","A comparison of different wavelet transform based texture features for content based search and retrieval is made. These include the conventional orthogonal and bi-orthogonal wavelet transforms, tree-structured decompositions, and the Gabor wavelet transforms. Issues discussed include image processing complexity, texture classification and discrimination, and suitability for developing indexing techniques.","1995","2","3","2025-12-02","https://university.edu/papers/894eb91a-ca79-4ae3-bd62-14e51d135de1.pdf");
INSERT INTO Paper VALUES ("508","Scheduling hard sporadic tasks by means of finite automata and generating functions","In a previous work, we propose a technique to decide feasability of periodic hard real-time systems based on finite automata. Here, associating generating functions (whose role is to predict the future) to a finite automaton, we extend this technique to hard sporadic tasks, independent or interdependent with the periodic tasks.","2002","14","1","2025-12-02","https://university.edu/papers/7a14fbbf-214f-487f-ad85-e3f5d349f668.pdf");
INSERT INTO Paper VALUES ("509","The UAB Proteomics Database","Summary: The University of Alabama at Birmingham (UAB) Proteomics Database (UPD) (http://www.uab.edu/ proteinmenu) was created to provide a repository for the storage and linkage of two-dimensional (2D) gel images and the associated information obtained through mass spectrometry analysis of the proteins excised from the 2D gels in a manner similar to the SWISS-2DPAGE database and the Stanford Microarray Database. This was accomplished through the development of a web interface, a relational database, image maps and hyperlinks stored in the database. In addition to the internally generated data, UPD provides links to the National Center for Biotechnology Information via accession number hyperlinks. UPD currently contains information on 44 individual proteins derived from four experiments conducted by four UAB faculty members. Images of the gels from which each of these proteins was isolated are accessed by hyperlinks embedded in the database. Availability: The UAB Proteomics Database can be accessed at http://www.uab.edu/proteinmenu","2003","4","4","2025-12-02","https://university.edu/papers/b5bb29d6-a578-4f41-aaec-f9f7587ccb94.pdf");
INSERT INTO Paper VALUES ("510","Aspect extraction in sentiment analysis: comparative analysis and survey","Sentiment analysis (SA) has become one of the most active and progressively popular areas in information retrieval and text mining due to the expansion of the World Wide Web (WWW). SA deals with the computational treatment or the classification of user's sentiments, opinions and emotions hidden within the text. Aspect extraction is the most vital and extensively explored phase of SA to carry out the classification of sentiments in precise manners. During the last decade, enormous number of research has focused on identifying and extracting aspects. Therefore, in this survey, a comprehensive overview has been attempted for different aspect extraction techniques and approaches. These techniques have been categorized in accordance with the adopted approach. Despite being a traditional survey, a comprehensive comparative analysis is conducted among different approaches of aspect extraction, which not only elaborates the performance of any technique but also guides the reader to compare the accuracy with other state-of-the-art and most recent approaches.","2016","6","3","2025-12-02","https://university.edu/papers/180ad78f-2405-4d53-9868-86f83a22265a.pdf");
INSERT INTO Paper VALUES ("511","Most salient region tracking","In this paper, we introduce a cognitive approach for object tracking from a mobile platform. The approach is based on a biologically motivated attention system which is able to detect regions of interest in images based on concepts of the human visual system. A top-down guided visual search module of the system enables to especially favor features which fit to a previously learned target object. Here, the appearance of an object is learned online within the first image in which it is detected. In subsequent images, the attention system searches for the target features and builds a top-down, target-related saliency map. This enables to focus on the most relevant features of especially this object in especially this scene without knowing anything about a particular object model or scene in advance. The system is able to operate in real-time and to cope with the requirements of real-world tasks such as illumination variations and other moving objects.","2009","19","4","2025-12-02","https://university.edu/papers/897f3a63-0456-4732-b9d9-4127b34f9b26.pdf");
INSERT INTO Paper VALUES ("512","Performance Analysis of Gradient Neural Network Exploited for Online Time-Varying Matrix Inversion","This technical note presents theoretical analysis and simulation results on the performance of a classic gradient neural network (GNN), which was designed originally for constant matrix inversion but is now exploited for time-varying matrix inversion. Compared to the constant matrix-inversion case, the gradient neural network inverting a time-varying matrix could only approximately approach its time-varying theoretical inverse, instead of converging exactly. In other words, the steady-state error between the GNN solution and the theoretical/exact inverse does not vanish to zero. In this technical note, the upper bound of such an error is estimated firstly. The global exponential convergence rate is then analyzed for such a Hopfield-type neural network when approaching the bound error. Computer-simulation results finally substantiate the performance analysis of this gradient neural network exploited to invert online time-varying matrices.","2009","8","1","2025-12-02","https://university.edu/papers/8f873ed0-f7fd-4dbe-aa82-43b859c21941.pdf");
INSERT INTO Paper VALUES ("513","08393 Manifest -- The Role of Law in an Electronic World Dominated by Web 2.0","Recently, almost everything seems to have become '2.0', be it music, gadgets,#R##N#health, entertainment, business, Silicon Valley, countries such as India, the family, and, most notably, the Web. 10GB of 'user-generated content' is created in the World-Wide Web daily (see Ramakrishnan and Tomkins, 2007), that is, more than five times the amount of content created by professional Web editors. Web 2.0 has rapidly become a label that everybody using the Internet and doing business through it seems to be able to relate to; what it primarily stands for is the transition of the Web from a medium where people just read information to a medium where people both read and write; in other words, the Web meanwhile heavily benefits from user contributions and user-generated content (UGC) in a variety of media forms. This has been enabled by technological advances that nowadays make it possible for users to easily employ services offered on the Web and to embark on tasks that have previously been reserved for specialists.","2008","10","1","2025-12-02","https://university.edu/papers/0fadd81c-a9cf-42e0-bb46-ac9cd44b3e3f.pdf");
INSERT INTO Paper VALUES ("514","Explaining Your Design","Have you ever tried to explain some aspect of your design and not known where to start? Perhaps you had to present how you solved a problem or justify your chosen design among several alternatives, and you weren't sure how to highlight key design aspects critical in achieving a certain requirement. Design decisions with widespread impact or design nuances that might confuse new team members can benefit from good definitions and narrative explanations. When fellow designers repeatedly ask, 'why did you do it that way?' It's good to have an effective presentation that explains the tricky parts of your design without losing people in the details","2006","19","1","2025-12-02","https://university.edu/papers/e9bf884b-bb8c-4f5a-a435-396ca728c006.pdf");
INSERT INTO Paper VALUES ("515","CAE: Collusion Attack Emulator for Privacy-Preserving Data Aggregation Schemes","In a number of networking applications, preserving the privacy of user-related data in data aggregation schemes is a fundamental issue. As a fact, many privacy-preserving protocols can be guaranteed with security against individual attacks, but they may be threatened by collusion between participants. Therefore, security analysis, especially for collusion attack analysis, plays an essential role in privacy-preserving data aggregation protocols. There do exist a few collusion attack schemes on data aggregation protocols, but none study the internal security mechanism of these protocols. In this paper, to our best knowledge, we are the first to propose a new kind of collusion attack analysis tool, which is named CAE (Collusion Attack Emulator). We employ it to check and judge the security of several existing privacy-preserving data aggregation schemes. We first show that for an aggregation scheme which has been known to be vulnerable under collusion attack, we can use CAE to explain why it is insecure. Then we demonstrate the blind detection function of CAE, i.e., we do not know whether an aggregation protocol is secure beforehand, and employ CAE to check its security and (if the protocol cannot pass the CAE test and thus to be insecure) to find its loophole.","2016","15","3","2025-12-02","https://university.edu/papers/405e2ae6-db82-4f2d-a69b-4c129ac4c2a7.pdf");
INSERT INTO Paper VALUES ("516","Improving End-User Satisfaction through Techno-Stress Prevention: Some Empirical Evidences","Emerging information and communication technologies (ICTs) make it possible for many business end-users to get connected anytime, anywhere. While the pervasive new ICTs have the potential to offer significant end-user performance gains, they also bring some negative side effects such as technostress: a cognitive reaction that an individual experiences when he or she is unable to cope with or adapt to new ICT. Given the importance of end-user satisfaction (EUS) to system success, this paper attempts to explore the impact of a set of technostress creators on EUS, and the effect of some technostress inhibiting mechanisms (e.g. end-user training, end-user help-desk and end-user involvement) on alleviating the negative impact of technostress on EUS. Empirical data were collected through questionnaire survey to help answer the research question.","2008","5","4","2025-12-02","https://university.edu/papers/c26bc36a-e71d-491b-93de-696ffb16f628.pdf");
INSERT INTO Paper VALUES ("517","Generating Realistic Labelled, Weighted Random Graphs","Generative algorithms for random graphs have yielded insights into the structure and evolution of real-world networks. Most networks exhibit a well-known set of properties, such as heavy-tailed degree distributions, clustering and community formation. Usually, random graph models consider only structural information, but many real-world networks also have labelled vertices and weighted edges. In this paper, we present a generative model for random graphs with discrete vertex labels and numeric edge weights. The weights are represented as a set of Beta Mixture Models (BMMs) with an arbitrary number of mixtures, which are learned from real-world networks. We propose a Bayesian Variational Inference (VI) approach, which yields an accurate estimation while keeping computation times tractable. We compare our approach to state-of-the-art random labelled graph generators and an earlier approach based on Gaussian Mixture Models (GMMs). Our results allow us to draw conclusions about the contribution of vertex labels and edge weights to graph structure.","2015","2","1","2025-12-02","https://university.edu/papers/0c51bbb2-cc88-4742-b8bc-4e9f7565d6e9.pdf");
INSERT INTO Paper VALUES ("518","Students as service champions: a success story","University helpdesk staff have a daunting job description: work all hours of the day and night, support an impossibly diverse population using an array of software and services, and keep up with an ever-changing university environment, all without getting burned out on service altogether. While many campuses have assumed that FTEs are the only answer, Northwestern University has had tremendous success with an all-student staff for over 30 years. We'll share how we've used a team of students and student managers to:  provide comprehensive first level support for all major software packages and services, and fulfill the role of second-level support,  log over 90-95% of customer contacts, allowing for collection of detailed metrics,  work seamlessly with full-time staff in other areas of IT; handle tricky service issues and day-to-day helpdesk operations after full timers have gone home for the day...     ...all while maintaining a customer service satisfaction rating of over 90%!","2004","11","1","2025-12-02","https://university.edu/papers/c4db9f43-f4ec-4f92-ac29-90696957240c.pdf");
INSERT INTO Paper VALUES ("519","Transistor Fault Coverage for Self-Testing CMOS Checkers","Several realistic transistor fault models were applied to circuit-level simulation models of code checkers in order to investigate the run-time fault testing capability. Various implementations of checkers designed for the detection of stuck-at faults were examined. A coverage varying from 99% to 100% was obtained for transistor terminal short faults and from 40% to 85% for open faults. A minimum set of four fault models for simulation-based evaluation of the self-testing property is proposed.","1992","3","4","2025-12-02","https://university.edu/papers/ef3c92dc-f663-4c2d-aacc-f3a6bb32a1d4.pdf");
INSERT INTO Paper VALUES ("520","A Biologically Inspired Architecture for an Autonomous and Social Robot","Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.","2011","4","4","2025-12-02","https://university.edu/papers/bb5039d2-9f2d-4584-bad9-6cdcae29ee6b.pdf");
INSERT INTO Paper VALUES ("521","Implicit Volterra Series Interpolation for Model Reduction of Bilinear Systems","We propose a new interpolatory framework for model reduction of large-scale bilinear systems. The input–output representation of a bilinear system in frequency domain involves a series of multivariate transfer functions, each representing a subsystem of the bilinear system. If a weighted sum of these multivariate transfer functions associated with a reduced bilinear system interpolates a weighted sum of the original multivariate transfer functions, we say that the reduced system satisfies a Volterra series interpolation (Flagg and Gugercin, 2015). These interpolatory conditions can also ensure the necessary conditions for H2H2-optimal model reduction (Flagg and Gugercin, 2015; Benner and Breiten, 2012). We observe that, by carefully selecting the weights of the series, the Volterra series interpolatory conditions are transformed to the problem of interpolating a linear system with an affine parameter dependence. Such linear parametric systems can then be reduced by some method for parametric model order reduction.#R##N##R##N#Linear systems where the affine parameter dependence is given as low-rank variation in the state matrix can be mapped into a non-parameterized multi-input multi-output linear system. This allows us to utilize the standard (non-parametric) linear IRKA (Gugercin et al., 2008) for the problem of parameterized/bilinear interpolation. Numerical results show that the approximations are of comparable accuracy to those obtained from the bilinear iterative rational Krylov algorithm (Benner and Breiten, 2012). The proposed approach, however, has the advantage that it reduces the computational costs as it involves computations associated with solving linear systems only.","2017","10","3","2025-12-02","https://university.edu/papers/ae13a2b0-41b4-4ff0-b5cb-85a0cb063cea.pdf");
INSERT INTO Paper VALUES ("522","Design of silicon-based suspended inductors for UHF applications","We present technological procedures to obtain suspended inductors for UHF applications, where the dominant element is the so-called planar inductor. This element does not have, up to now, a high quality factor, Q, because, in the IC silicon approach, inductors suffer losses due to the conductive substrate. Therefore, the performance of a planar inductor is improved by eliminating the silicon substrate below the planar spiral (named bulkless inductor). Thus, in order to minimize photolithographic steps, we propose a suitable silicon etching procedure to increase the quality factor of planar inductors by using just 4 photolithographic steps. From simulation results, we obtained an inductance of 23 nH (5.85 nH per turn) that represents an augmentation of 750% when it is compared with a conventional planar inductor.","2004","11","3","2025-12-02","https://university.edu/papers/d90550f5-5057-4faa-a809-4f3257a1af81.pdf");
INSERT INTO Paper VALUES ("523","Face detection in color images using wavelet packet analysis","We propose a novel scheme for automatic and fast detection of human faces in color images where the number, the location, the orientation and the size of the faces are unknown, under unconstrained scene conditions such as complex background and uncontrolled illumination. First, each frame is segmented using skin chrominance values, providing face area candidates. Then, shape analysis and wavelet packet decomposition are performed on the face area candidates in order to detect human faces. Each face area candidate is described by a subset of band filtered images containing wavelet coefficients. These coefficients characterize the face texture and a set of simple statistical data is extracted in order to form compact and meaningful feature vectors. Then, an efficient and reliable probabilistic metric derived from the Bhattacharrya distance is used in order to classify the face area candidate feature vectors into face or non-face areas.","1999","13","1","2025-12-02","https://university.edu/papers/e06248c8-aa9f-4243-824b-ff43d30ddb84.pdf");
INSERT INTO Paper VALUES ("524","Toward power consumption in partitioned Wireless Sensors Networks routing technique","The increasing research in the areas of Wireless Sensors Networks (WSNs) have a positive impact in the world and have gained increasing attention from both the research community and actual users. A wireless sensor network compromises of a large number of diffuse independent sensors; these sensors is to be used to control an event range in scale from large national environmental pollution monitoring networks, to small scale body-worn medical monitoring systems. The sensor node consists of a wireless radio, processor and a variety of sensors. The sensors are operated with restricted capacity batteries, which of course have a lifetime, so to preserve power; the transmission/reception by the sensor radio should be decreased as much as possible. The potential contribution of this paper is to propose a theoretical model toward power consumption technique based on the idea of partitioning wireless network and we will use heinzelman equations using realistic variables for example, the initial power for each node, the distance between nodes, and the message size.","2015","18","3","2025-12-02","https://university.edu/papers/344e1416-415b-4cf6-9b09-1355f25a4a80.pdf");
INSERT INTO Paper VALUES ("525","Identifying Proper Scales on Digital Maps for In-Vehicle Navigation Systems","Current commercial mobile navigation systems often use a pre-determined scale selection schema without considering differences in spatial complexity of locations. To identify what map scales people may need and what spatial features make relevant maps stand out, we conducted an experiment on subjective map selection in a route planning task between two cities in the United States. Our results suggest that the distribution of selected maps is fairly concentrated on those maps that contain spatial information about both the origin and the destination, the current location and the destination, and the transition between different important roads in a route. These results suggest that the choice of map scales should not follow a preset scale rule for diverse locations, and instead, it should be adaptive to the complexity of local roads and decision-making processes.","2009","16","1","2025-12-02","https://university.edu/papers/d0139c4a-4618-49b5-a9fd-c41246e5ca3c.pdf");
INSERT INTO Paper VALUES ("526","Obtaining an object position using multimodal interaction for a service robot","Gestures are useful factor in communication. A gesture has different meanings depending on related objects, situation and so on. Authors aim that a robot recognizes gesture meanings and provides a service considering related objects. Object position is one of the important factors for a robot to recognize a gesture. This paper focused on multimodal interaction between human and a robot to obtain object positions. Proposed system combines gesture recognition and speech recognition as multimodal interaction, and manages the database with object position information through the interaction. The system expects improvement of infrastructure to support cognitive ability of robots.","2009","13","3","2025-12-02","https://university.edu/papers/bb569d15-cf99-4241-a80f-a25935c37a1e.pdf");
INSERT INTO Paper VALUES ("527","Non-linear mapping for multi-channel speech separation and robust overlapping spech recognition","This paper investigates a non-linear mapping approach to extract robust features for ASR and speech separation of overlapping speech. Based on our previous studies, we continue to use two additional sound sources, namely from the target and interfering speakers. The focuses of this work are: 1) We investigate the feature mapping between different domains with the consideration of MMSE criterion and regression optimizations, demonstrating the mapping of log melfilterbank energies to MFCC can be exploited to improve the effectiveness of the regression; 2) We investigate the data-driven filtering for the speech separation by using the mapping method, which can be viewed as a generalized log spectral subtraction and results in better separation performance. We demonstrate the effectiveness of the proposed approach through extensive evaluations on the MONC corpus, which includes both non-overlapping single speaker and overlapping multi-speaker conditions.","2009","15","4","2025-12-02","https://university.edu/papers/a8d099ad-a475-48da-bf01-76b333f77406.pdf");
INSERT INTO Paper VALUES ("528","A discrete event simulation for the logistics of Hamad's container terminal of Qatar","A discrete even simulation is developed for the first container terminal of Hamad's new port of Qatar which is anticipated to start its operations by the end of 2016. The model is based on the operational knowledge of experts from the current port of Doha and Qatar's port authority (Mwani). The challenge in this paper is validating a simulation for a system that has not started its operation. Nonetheless, data and configuration of the current port has been utilized to partially validate the output of the simulation. The preliminary analysis shows promising results and indicate the validity of the model.","2016","4","3","2025-12-02","https://university.edu/papers/d8ec0b45-70d3-4108-9938-26a63d312a8f.pdf");
INSERT INTO Paper VALUES ("529","Integrated design of robust fault estimation and fault-tolerant control for linear systems","In the fault tolerant control (FTC) problem based on fault compensation a bi-directional uncertainty coupling exists between the controller and the joint state/fault estimation. This coupling arises from (a) the model mismatch between the system dynamics and the observer model as well as (b) the uncertainty arising from imperfect fault estimation. Hence, this paper deals with an approach to integrate together the designs of the observer and controller for a linear system subject to bounded actuator and sensor faults as well as disturbance. The fault estimation is achieved by using an augmented state form of an unknown input observer (UIO) which relaxes the well-known UIO rank restriction in terms the system coefficient matrices. The integrated design problem with fault compensation is an observer-based robust control system solved via H∞ optimization using single-step LMI formulation. The closed-loop system time response is improved using LMI regional pole placement. The FTC performance is illustrated using an example with both sensor and actuator faults as well as disturbance and uncertainty.","2015","20","1","2025-12-02","https://university.edu/papers/9bfa2532-80eb-46c8-8ca2-0bab03a91f12.pdf");
INSERT INTO Paper VALUES ("530","An Adaptive Process Model to Support Product Development Project Management","Projects are temporary allocations of resources commissioned to achieve a desired result. Since each project is unique, the landscape between the current state (the start of the project) and the desired state (the successful end of the project) is often dynamic, uncertain, and ambiguous. Conventional project plans define a set of related activities (a work breakdown structure and activity network) with the assumptions that this set is necessary and sufficient to reach the project's desired result. Popular models for project planning (scheduling, budgeting, etc.) and control are also based on a set of project activities that are specified and scheduled  a priori . However, these assumptions often do not hold, because, as an attempt to do something novel, the actual path to a project's desired result is often revealed only by the additional light provided once the work is underway. In this paper, we model a product development process as a complex adaptive system. Rather than prespecifying which activities will be done and when, we set up: 1) a superset of general classes of activities, each with modes that vary in terms of inputs, duration, cost, and expected benefits; and 2) simple rules for activity mode combination. Thus, instead of rigidly dictating a specific project schedule  a priori , we provide a ldquoprimordial souprdquo of activities and simple rules through which the activities can self-organize. Instead of attempting to prescribe an optimal process, we simulate thousands of adaptive cases and let the highest-value process emerge. Analyzing these cases leads to insights regarding the most likely paths (processes) across the project landscape, the patterns of iteration along the paths, and the paths' costs, durations, risks, and values. The model also provides a decision support capability for managers. For researchers, this way of viewing projects and the modeling framework provide a new basis for future studies of agile and adaptive processes.","2009","1","2","2025-12-02","https://university.edu/papers/df0238f7-14bb-40ad-bb39-2af0b60cf924.pdf");
INSERT INTO Paper VALUES ("531","Domination game: effect of edge- and vertex-removal","The domination game is played on a graph   G     G        by two players, named Dominator and Staller. They alternatively select vertices of   G     G        such that each chosen vertex enlarges the set of vertices dominated before the move on it. Dominator’s goal is that the game is finished as soon as possible, while Staller wants the game to last as long as possible. It is assumed that both play optimally. Game 1 and Game 2 are variants of the game in which Dominator and Staller has the first move, respectively. The game domination number   γ g (G)       γ    g     (  G  )         and the Staller-start game domination number   γ ′ (G)       γ    ′     (  G  )         are the number of vertices chosen in Game 1 and Game 2, respectively. It is proved that if   e∈E(G)     e  ∈  E   (  G  )        , then   |γ g (G)−γ g (G−e)|≤2     |    γ    g     (  G  )   −    γ    g     (  G  −  e  )   |  ≤  2        and   |γ ′ (G)−γ ′ (G−e)|≤2     |    γ    ′     (  G  )   −    γ    ′     (  G  −  e  )   |  ≤  2       , and that each of the possibilities here is realizable by connected graphs   G     G        for all values of   γ g (G)       γ    g     (  G  )         and   γ ′ (G)       γ    ′     (  G  )         larger than 5. For the remaining small values it is either proved that realizations are not possible or realizing examples are provided. It is also proved that if   v∈V(G)     v  ∈  V   (  G  )        , then   γ g (G)−γ g (G−v)≤2       γ    g     (  G  )   −    γ    g     (  G  −  v  )   ≤  2        and   γ ′ (G)−γ ′ (G−v)≤2       γ    ′     (  G  )   −    γ    ′     (  G  −  v  )   ≤  2       . Possibilities here are again realizable by connected graphs   G     G        in almost all the cases, the exceptional values are treated similarly as in the edge-removal case.","2014","2","1","2025-12-02","https://university.edu/papers/95c864f7-b81e-4037-96a6-85821782dfcd.pdf");
INSERT INTO Paper VALUES ("532","Sensitivity to noise and performance of HRR-based ATR using the Maximum Position alignment method","This paper studies the alignment of noisy high resolution radar signals using the Maximum Position method in automatic target recognition. The relationship between the shift estimation, the performance of the classifier and the signal to noise ratio is analyzed. Several experiments are carried out in order to study the influence of the alignment in the performance of a classification system. These experiments allow us to improve the understanding of the sensitivity to noise of the Maximum Position alignment method.","2008","5","1","2025-12-02","https://university.edu/papers/a5799a27-1431-4757-abba-86ccbcd222a6.pdf");
INSERT INTO Paper VALUES ("533","Variational Bayesian Matching","Matching of samples refers to the problem of inferring unknown co-occurrence or alignment between observations in two data sets. Given two sets of equally many samples, the task is to nd for each sample a representative sample in the other set, without prior knowledge on a distance measure between the sets. Recently a few alternative solutions have been suggested, based on maximization of joint likelihood or various measures of between-data statistical dependency. In this work we present an variational Bayesian solution for the problem, learning a Bayesian canonical correlation analysis model with a permutation parameter for re-ordering the samples in one of the sets. We approximate the posterior over the permutations, and demonstrate that the resulting matching algorithm clearly outperforms all of the earlier solutions.","2012","11","4","2025-12-02","https://university.edu/papers/8db24ca3-0b28-468b-bf88-3cfbf4ac9350.pdf");
INSERT INTO Paper VALUES ("534","Integration with Stochastic Point Processes","We present a novel comprehensive approach for studying error in integral estimation with point distributions based on point process statistics. We derive exact formulae for bias and variance of integral estimates in terms of the spatial or spectral characteristics of integrands and first- and-second order product density measures of general point patterns. The formulae allow us to study and design sampling schemes adapted to different classes of integrands by analyzing the effect of sampling density, weighting, and correlations among point locations separately. We then focus on non-adaptive correlated stratified sampling patterns and specialize the formulae to derive closed-form and easy-to-analyze expressions of bias and variance for various stratified sampling strategies. Based on these expressions, we perform a theoretical error analysis for integrands involving the discontinuous visibility function. We show that significant reductions in error can be obtained by considering alternative sampling strategies instead of the commonly used random jittering or low discrepancy patterns. Our theoretical results agree with and extend various previous results, provide a unified analytic treatment of point patterns, and lead to novel insights. We validate the results with extensive experiments on benchmark integrands as well as real scenes with soft shadows.","2016","8","2","2025-12-02","https://university.edu/papers/bc0ea11c-c0c5-452e-a89e-df39675f6521.pdf");
INSERT INTO Paper VALUES ("535","Improved Log-MAP decoding algorithm for turbo-like codes","In this letter, a new method for decoding turbo-like codes is proposed to simplify the hardware implementation of Log-MAP algorithm. In our method, the multivariable Jacobian logarithm in Log-MAP algorithm is actually concatenated by recursive 1D Jacobian logarithm units. Two new approximations of Log-MAP algorithm based on these 1D units are then presented, which have good approximated accuracy and is simple for hardware implementation. We further suggest a novel decoding scheme that its complexity is near the Max-Log-MAP while the performance is close to the Log-MAP algorithm.","2006","3","2","2025-12-02","https://university.edu/papers/60680b6c-b3f6-413e-a95a-67fd1bc0abf5.pdf");
INSERT INTO Paper VALUES ("536","Ultra-fast tracking based on zero-shift points","A novel tracker of so called zero-shift points (ZSPs) is presented. ZSPs are points where a dot product with a single period of a sinusoidal wave, both in horizontal and vertical directions, is equal to zero. Very efficient tracking and localization of ZSPs is possible as a consequence of the existence of the field of 2D shift vectors pointing toward them. A single point is tracked on average in less than 10@ms on a standard notebook. When organized in a Multi-scale Flock (MSF), the ZSPs become a core of a robust, fast and accurate tracker. We demonstrated the applicability of the combination of MSF-ZSP with RANSAC based homography estimation on standard sequences reporting good tracking results.","2012","12","1","2025-12-02","https://university.edu/papers/87ec7cab-dac1-4544-9f89-3ee58d981464.pdf");
INSERT INTO Paper VALUES ("537","Wireless real-time processing and visualization of EMG data","Existing wireless electromyography (EMG) solutions utilize proprietary hard- and software components for transmitting and analyzing sensor data. In this paper, we present a setup for transmission and visualization of EMG data on a tablet PC. The system relies on standard hard- and software components and offers both real-time visualization and analysis of myoelectric signals (MES). In this contribution, two hardware setups are presented, a system with a medical-grade EMG amplifier and an alternative system based on a low-cost EMG Arduino shield. Next to the basic RMS feature, the presented iPad application also offers several other common EMG feature calculation methods, like zero crossings (ZC) or the Willison amplitude (WAMP). Direct actuation of a prosthesis through the received EMG signal is possible through the integration of a modern Bluetooth-enabled prosthesis. For medical staff and orthopedic mechanics, this allows easy adjustment of sensor position and measurement of key parameters.","2014","2","3","2025-12-02","https://university.edu/papers/646b9162-06ee-449b-a0f8-82fda1bba097.pdf");
INSERT INTO Paper VALUES ("538","On the engineering value of spectrum in dense mobile network deployment scenarios","The continuing growth in the mobile data traffic magnifies the challenges for the design and deployment of scalable high-capacity mobile networks that can meet the future demand at reasonable cost levels. In order to meet the future traffic demand, an operator should invest on both infrastructure, i.e. densification of base stations, and more radio spectrum. Knowing the effectiveness of each element is thus of utmost importance for minimizing the investment cost. In this paper, we study the economic substitutability between spectrum and densification. For this, we measure the engineering value of spectrum, which refers to the potential saving in the total cost of ownership (TCO) as result of acquiring additional spectrum resources. Two countries are considered to represent different market situations: India with dense population and high spectrum price and Sweden with moderate population density and low spectrum fee. Numerical results indicate that additional amount of spectrum substantially relieves the need for densifying radio base stations, particularly for providing high user data rate in dense India. Nonetheless, the engineering value of spectrum is low in India (i.e. spectrum acquisition has less cost benefit) under the high spectrum price of today, whereas spectrum is instrumental in lowering the total cost of ownership in Sweden. Our finding highlights the importance of affordable and sufficient spectrum resources for future mobile broadband provisioning.","2015","2","1","2025-12-02","https://university.edu/papers/e0741d3b-eb69-4ab9-8775-8f171d3e1b50.pdf");
INSERT INTO Paper VALUES ("539","Detection of ophthalmic artery stenosis by least-mean squares backpropagation neural network","Doppler ultrasound is a noninvasive technique that allows the examination of the direction, velocity, and volume of blood flow. In this study, ophthalmic artery Doppler signals were obtained from 105 subjects, 48 of whom had suffered from ophthalmic artery stenosis. A least-mean squares backpropagation neural network was used to detect the presence or absence of ophthalmic artery stenosis. Spectral analysis of ophthalmic artery Doppler signals was done by the Welch method for determining the neural network inputs. The network was trained, cross validated and tested with subject records from the database. Performance indicators and statistical measures were used for evaluating the neural network. Ophthalmic artery Doppler signals were classified with the accuracy varying from 88.9% to 90.6%.","2003","2","3","2025-12-02","https://university.edu/papers/907cc95d-1821-42df-a3e7-1239058c3673.pdf");
INSERT INTO Paper VALUES ("540","Simultaneous Semi-Coupled Dictionary Learning for Matching RGBD Data","Matching with hidden information which is available only during training and not during testing has recently become an important research problem. Matching data from two different modalities, known as cross-modal matching is another challenging problem due to the large variations in the data coming from different modalities. Often, these are treated as two independent problems. But for applications like matching RGBD data, when only one modality is available during testing, it can reduce to either of the two problems. In this work, we propose a framework which can handle both these scenarios seamlessly with applications to matching RGBD data of Lambertian objects. The proposed approach jointly uses the RGB and depth data to learn an illumination invariant canonical version of the objects. Dictionaries are learnt for the RGB, depth and the canonical data, such that the transformed sparse coefficients of the RGB and the depth data is equal to that of the canonical data. Given RGB or depth data, their sparse coefficients corresponding to their canonical version is computed which can be directly used for matching using a Mahalanobis metric. Extensive experiments on three datasets, EURECOM, VAP RGB-D-T and Texas 3D Face Recognition database show the effectiveness of the proposed framework.","2016","3","3","2025-12-02","https://university.edu/papers/1382ee1c-e5cf-4c06-9bae-b62df6cdc2f8.pdf");
INSERT INTO Paper VALUES ("541","The Statistical Mechanics of Complex Product Development: Empirical and Analytical Results","In recent years, understanding the structure and function of complex networks has become the foundation for explaining many different real-world complex biological, technological, and informal social phenomena. Techniques from statistical physics have been successfully applied to the analysis of these networks, and have uncovered surprising statistical structural properties that have also been shown to have a major effect on their functionality, dynamics, robustness, and fragility. This paper examines, for the first time, the statistical properties of strategically important organizational networks---networks of people engaged in distributed product development (PD)---and discusses the significance of these properties in providing insight into ways of improving the strategic and operational decision making of the organization. We show that the structure of information flow networks that are at the heart of large-scale product development efforts have properties that are similar to those displayed by other social, biological, and technological networks. In this context, we also identify novel properties that may be characteristic of other information-carrying networks. We further present a detailed model and analysis of PD dynamics on complex networks, and show how the underlying network topologies provide direct information about the characteristics of these dynamics. We believe that our new analysis methodology and empirical results are also relevant to other organizational information-carrying networks.","2007","11","4","2025-12-02","https://university.edu/papers/7c623514-4bf4-4e75-be94-df5dc0876b1b.pdf");
INSERT INTO Paper VALUES ("542","Equipping Students to Reduce Lead Times: The Role of Queuing-Theory-Based Modeling","Time is power. A company that gets products to its customers faster than its competitors strengthens its market position; therefore management students should learn how to reduce lead times. The counterintuitive mathematical principles that drive lead time and the complex system dynamics of operations management make the skills of reducing lead times difficult to teach. Mathematical modeling (queuing-theory or simulation-based) is an effective tool for teaching these skills. In evaluating modeling approaches in the classroom, it is important to consider model quality and student affective outcomes, such as motivation and empowerment. Queuing-theory-based models increase students abilities to reduce lead times more than simulation-based models. Using a classic teaching case, we compare the two approaches.","2006","9","2","2025-12-02","https://university.edu/papers/ba0430c6-85c7-4c8c-a878-a96ac15ac942.pdf");
INSERT INTO Paper VALUES ("543","A Comparison of Different Approaches to Nonlinear Shift Estimation for Object Tracking","This paper presents a corner based voting method for estimating the object shift in video image frames. Information about the corners distribution around a reference point is used to represent the object shape and then to find the most probable target position in the next frame. Tracking is done through using a voting space obtained by matching corners information. A motion vector for the reference point is nonlinearly estimated with three different strategies by using the global information of the matched corners. The results show a comparison between three considered strategies for estimating the object shift.","2007","5","4","2025-12-02","https://university.edu/papers/b3068027-d22f-4398-8b63-4f57b76cd5c2.pdf");
INSERT INTO Paper VALUES ("544","Electron Dynamics Simulation with Time-Dependent Density Functional Theory on Large Scale Symmetric Mode Xeon Phi Cluster","Many-core architecture processors such as the Intel Xeon Phi provide new solutions for high performance computing (HPC) systems that require high computing performance combined with low power consumption. However, this computing efficiency is difficult to achieve due to its characteristics as the 'throughput core' which differs from the ordinary 'latency core' characteristic of advanced processors such as Intel Xeon. In this study, we implement a real scientific code named Ab-initio Real-time Electron Dynamics simulator (ARTED), which is an electron dynamics simulator on (Time-Dependent Density Functional Theory (TDDFT). ARTED runs on an Intel Xeon Phi cluster using the Symmetric mode, where all CPU and Intel Xeon Phi resources contribute to the computation. A kernel of stencil computation that dominates the total computation time is optimized in a single-thread (single-core) level with various techniques such as explicit vectorization with 512-bit SIMD instructions. Consequently, the Native mode operation of the Intel Xeon Phi achieves approximately twice the level of performance of the Intel E5-2670v2 CPU (Ivy-Bridge, 1 socket, 10 cores) for the stencil computation with double-precision complex value: 212.2 GFLOPS with Xeon Phi and 106.9 GFLOPS with CPU. Moreover, the entire code achieves 1.45 times better performance compared with the CPU. For the Symmetric mode operation, we need to balance the load among different types of processors. We control the number of processes in the wave space for each processor to balance their loads. Consequently, the Symmetric mode operation achieves 2.16 times better performance compared with the CPU-only utilization on each node with strong scaling.","2016","4","2","2025-12-02","https://university.edu/papers/0062c39d-d58a-41c9-8328-13318dc5fbe7.pdf");
INSERT INTO Paper VALUES ("545","System level evaluation of LTE networks with semidistributed intercell interference coordination","3GPP LTE is the evolution of UMTS which will make possible to deliver high quality multimedia services with an improved user experience. Since Radio Resource Management (RRM) has been recognized as a key point to successfully accomplish this target, the performance evaluation of a multi-cell resource allocation scheme applied to LTE downlink (DL) is presented in this paper. A semi-distributed RRM framework is discussed and evaluated from a system level viewpoint. Detailed link level simulations have also been carried out to properly back up the results.","2009","11","2","2025-12-02","https://university.edu/papers/533c0a26-e267-49d9-9fe2-0e1bbe1dc2f3.pdf");
INSERT INTO Paper VALUES ("546","Variation-tolerant hierarchical voltage monitoring circuit for soft error detection","As device feature size continues to scale down to the nanometer regime, the decreasing critical charge fundamentally reduces noise margins of devices and in turn increases the susceptibility of the ICs to external noise sources such as particle strikes. While protection techniques for memory such as ECC are mature and effective, protections for logic errors remain imperfect. Full-blown redundancy solutions for microprocessors such as mirrored cores and triple-modular redundancy incur significant overhead and are clearly limited to the niche market of mission-critical servers. The fundamental inefficiency of such redundancy lies in the repetition of all operations to detect the discrepancy caused by events much rarer than cycle-to-cycle activities. Clearly, for the vast majority of general-purpose systems, a detection mechanism that has low standby energy consumption is called for. In this paper, we propose a circuit-level solution to detect errors by monitoring the supply rail disturbance caused by a particle strike. Combined with checkpointing and rollback support, such a circuit can provide a high level of protection against particle-strike induced soft errors. At 17%, the power overhead of the design is reasonable and much lower than prior art. The design is also tolerant to process, voltage, and temperature (PVT) variations.","2009","19","4","2025-12-02","https://university.edu/papers/e46719a3-8a72-4daa-8b3a-921b7ac7b955.pdf");
INSERT INTO Paper VALUES ("547","AI Methods for Smart Environments A Case Study on Team Assistance in Smart Meeting Rooms","Ubiquitous computing aims for the realisation of environ- ments that assist users autonomously and proactively in a non-distractive manner. Therefore smart environment infrastructures need to be able to identify users needs (intention recognition) and to plan an appropriate assisting strategy (strategy generation) without explicit user interaction. In our two-stage approach we address inferring the intention of a team of users during a meeting within a smart multiple display environment and the system decision process - what information to present on which display - on the strategy generation level.","2007","15","1","2025-12-02","https://university.edu/papers/390b3bbe-ef37-4835-8fe8-69f3d7e86264.pdf");
INSERT INTO Paper VALUES ("548","An Empirical Comparison of Search Approaches for Moving Agents","Computational Intelligence#R##N#Early View (Online Version of Record published before inclusion in an issue)","2016","17","2","2025-12-02","https://university.edu/papers/2bab65ea-5d42-4f57-b668-ff64a8376194.pdf");
INSERT INTO Paper VALUES ("549","Performance analysis of envelope tracking power amplifier's envelope shaping methods for LTE mobile terminal application","Envelope tracking (ET) is a significant technique to improve the efficiency of power amplifier (PA) in the power back-off region, especially in modern mobile communication system with a high peak-to-average power ratio (PAPR). Different ET implementation solutions, especially the way of choosing shaping table, have a great impact on the performance of ET system. In this paper, a transistor-level PA and a behavior-level supply modulator are introduced to analyze the performance of ET PA system. The power-added efficiency (PAE), AM-to-AM distortion, AM-to-PM distortion and Adjacent Channel Leakage Ratio (ACLR) are investigated to explain the impacts of different commonly-used shaping methods. Simulation results indicate that adopting ET technology increases the efficiency of RF PA largely, and the shaping methods applied in supply modulation will affect a lot in efficiency and linearity. Consequently, a new dualmode ET shaping method is proposed in this paper to guarantee high efficiency as far as possible without introducing too much distortions. Besides, it also improves the linearity where the PAE is at a lower level.","2014","19","4","2025-12-02","https://university.edu/papers/06752435-41bc-4423-96f9-252098ff4e40.pdf");
INSERT INTO Paper VALUES ("550","Odd components of co-trees and graph embeddings","In this paper we investigate the relation between odd components of co-trees and graph embeddings. We show that any graph G must share one of the following two conditions: (a)?for each integer h such that G may be embedded on Sh, the sphere with h handles, there is a spanning tree T in G such that h = 1 2 ( β ( G ) - ω ( T ) ) , where β(G) and ω(T) are, respectively, the Betti number of G and the number of components of G - E ( T ) having odd number of edges; (b)???for every spanning tree T of G, there is an orientable embedding of G with exact ω ( T ) + 1 faces. This extends Xuong and Liu's theorem 9,13 to some other (possible) genera. Infinitely many examples show that there are graphs which satisfy (a) but (b). Those make a correction of a result of Archdeacon 2, Theorem?1.","2016","16","3","2025-12-02","https://university.edu/papers/6169c722-8e88-4b79-a795-8b123178af19.pdf");
INSERT INTO Paper VALUES ("551","Multi-instance genetic programming for web index recommendation","This article introduces the use of a multi-instance genetic programming algorithm for modelling user preferences in web index recommendation systems. The developed algorithm learns user interest by means of rules which add comprehensibility and clarity to the discovered models and increase the quality of the recommendations. This new model, called G3P-MI algorithm, is evaluated and compared with other available algorithms. Computational experiments show that our methodology achieves competitive results and provide high-quality user models which improve the accuracy of recommendations.","2009","11","4","2025-12-02","https://university.edu/papers/7a5267f8-55ae-4ac0-a31b-329cb6aeaf9b.pdf");
INSERT INTO Paper VALUES ("552","Processor-efficient FFT Implementation Scheme for Active Noise Control Applications","Most of the frequency-domain (FD)-based active noise control (ANC) applications involve the computation of several discrete Fourier transforms (DFTs). Conventionally, an N-point DFT of a sequentially arriving data is computed only after the arrival of the N th sample. For applications involving ANC, such an approach will overload the processor. In this paper, an alternative method to compute the DFT is proposed, which distributes the computations over a span of several sampling instants. As an example to prove the efficiency of the proposed algorithm, it is applied to the reduced delay-less frequency-domain block filtered-x least-mean-square (RD-FBFXLMS) algorithm, wherein about 24% (for a block length of 1024 samples) of the multiplications and about 29% of additions (which were supposed to have been done at the last sampling instant of each block) are shifted to earlier sampling instants during which the processor is idle. The percentage of computational redistribution will be higher for multi channel non-linear systems.","2010","8","1","2025-12-02","https://university.edu/papers/5a2e60d9-4371-45ac-a2d4-f5a3066c9410.pdf");
INSERT INTO Paper VALUES ("553","Delegating classifiers","A sensible use of classifiers must be based on the estimated reliability of their predictions. A cautious classifier would delegate the difficult or uncertain predictions to other, possibly more specialised, classifiers. In this paper we analyse and develop this idea of delegating classifiers in a systematic way. First, we design a two-step scenario where a first classifier chooses which examples to classify and delegates the difficult examples to train a second classifier. Secondly, we present an iterated scenario involving an arbitrary number of chained classifiers. We compare these scenarios to classical ensemble methods, such as bagging and boosting. We show experimentally that our approach is not far behind these methods in terms of accuracy, but with several advantages: (i) improved efficiency, since each classifier learns from fewer examples than the previous one; (ii) improved comprehensibility, since each classification derives from a single classifier; and (iii) the possibility to simplify the overall multi-classifier by removing the parts that lead to delegation.","2004","9","3","2025-12-02","https://university.edu/papers/bb844411-c2b3-45b3-8f6e-14537c26a164.pdf");
INSERT INTO Paper VALUES ("554","A Generalized Dynamic Composition Algorithm of Weighted Finite State Transducers for Large Vocabulary Speech Recognition","We propose a generalized dynamic composition algorithm of weighted finite state transducers (WFST), which avoids the creation of noncoaccessible paths, performs weight look-ahead and does not impose any constraints to the topology of the WFSTs. Experimental results on Wall Street Journal (WSJ1) 20k-word trigram task show that at 17% WER (moderately-wide beam width), the decoding time of the proposed approach is about 48% and 65% of the other two dynamic composition approaches. In comparison with static composition, at the same level of 17% WER, we observe a reduction of about 60% in memory requirement, with an increase of about 60% in decoding time due to extra overheads for dynamic composition.","2007","3","3","2025-12-02","https://university.edu/papers/c3938d83-e2c8-4674-9e7f-06cf72d9d359.pdf");
INSERT INTO Paper VALUES ("555","Predicting clinical variable from MRI features: application to MMSE in MCI","The ability to predict a clinical variable from automated analysis of single, cross-sectional T1-weighted (T1w) MR scans stands to improve the management of patients with neurological diseases. We present a methodology for predicting yearly Mini-Mental Score Examination (MMSE) changes in Mild Cognitive Impairment (MCI) patients. We begin by generating a non-pathological, multidimensional reference space from a group of 152 healthy volunteers by Principal Component Analyses of (i) T1w MR intensity of linearly registered Volumes of Interest (VOI); and (ii) trace of the deformation fields of nonlinearly registered VOIs. We use multiple regression to build linear models from eigenvectors where the projection eigencoordinates of patient data in the reference space are highly correlated with the clinical variable of interest. In our cohort of 47 MCI patients, composed of 16 decliners, 26 stable and 5 improvers (based on MMSE at 1 yr follow-up), there was a significant difference (P = 0.0003) for baseline MMSE scores between decliners and improvers, but no other differences based on age or sex. First, we classified our three groups using leave-one-out, forward stepwise linear discriminant analyses of the projection eigencoordinates with 100% accuracy. Next, we compared various linear models by computing F-statistics on the residuals of predicted vs actual values. The best model was based on 10 eigenvectors + baseline MMSE, with predicted yearly changes highly correlated (r = 0.6955) with actual data. Prospective study of an independent cohort of patients is the next logical step towards establishing this promising technique for clinical use.","2005","18","2","2025-12-02","https://university.edu/papers/ede249cd-d8b0-4d60-9876-ce84d3846ba6.pdf");
INSERT INTO Paper VALUES ("556","Constraint nondegeneracy in variational analysis","This paper studies the sensitivity analysis of variational conditions defined over perturbed systems of finitely many nonlinear inequalities or equations, subject to additional fixed polyhedral constraints. If the system of constraints obeys a certain property called nondegeneracy, we show how to construct a local diffeomorphism of the feasible set to its tangent cone. Moreover, this diffeomorphism varies smoothly as the perturbation parameter changes.The original variational condition is then locally equivalent to a variational inequality defined over this (polyhedral convex) tangent cone. This extends stability results already known for variational inequalities over polyhedral convex sets to a substantially more general case. We also show that existence, local uniqueness, and Lipschitz continuity, as well as B-differentiability of the solution, can all be predicted from a single affine variational inequality that is easily computable in terms of the data of the unperturbed problem at the point in question.","2003","7","1","2025-12-02","https://university.edu/papers/d06a684c-0eda-4dc1-bdc1-f100b7d1c22c.pdf");
INSERT INTO Paper VALUES ("557","Multiclass sparse Bayesian regression for fMRI-based prediction","Inverse inference has recently become a popular approach for analyzing neuroimaging data, by quantifying the amount of information contained in brain images on perceptual, cognitive, and behavioral parameters. As it outlines brain regions that convey information for an accurate prediction of the parameter of interest, it allows to understand how the corresponding information is encoded in the brain. However, it relies on a prediction function that is plagued by the curse of dimensionality, as there are far more features (voxels) than samples (images), and dimension reduction is thus a mandatory step. We introduce in this paper a new model, called Multiclass Sparse Bayesian Regression (MCBR), that, unlike classical alternatives, automatically adapts the amount of regularization to the available data. MCBR consists in grouping features into several classes and then regularizing each class differently in order to apply an adaptive and efficient regularization. We detail these framework and validate our algorithm on simulated and real neuroimaging data sets, showing that it performs better than reference methods while yielding interpretable clusters of features.","2011","3","4","2025-12-02","https://university.edu/papers/7131a12f-8b59-4c45-8cd8-ef03d05fdab4.pdf");
INSERT INTO Paper VALUES ("558","Supporting Community-Driven Evolution of Model-Driven Development Knowledge Using ReMoDD","Research on model-driven development (MDD) tackles the problem of developing complex, critical software systems by providing support for systematically transforming ab- stract models of software systems to dependable implementations. A problem that significantly impedes MDD research productivity and hampers efforts to effectively teach MDD concepts is the lack of accessible models and other artifacts produced in MDD projects. MDD researchers exert significant effort developing convincing exemplar models, transformations, and other artifacts that are used to validate or demonstrate the capabilities of their research products. Educators also spend significant time developing suitable MDD artifacts for use in the classroom. The Repository for Model Driven Development (ReMoDD) is a National Science Foundation funded project that aims to develop and maintain a repository infrastructure that MDD researchers can use to share artifacts that can significantly improve MDD research productivity, improve MDD practice, and enhance the learning experience of students studying MDD technology. In this talk I will discuss how use of ReMoDD can help researchers tackle challenging MDD problems and give an update on the project's progress. Dr. Robert France is a Full Professor in the Department of Computer Science at Colorado State University. His research interests are in the area of Software Engineering, in particular formal spec- ification techniques, software modeling techniques, and domain-specific modeling languages. He is an editor-in-chief of the Springer journal on Software and System Modeling (SoSyM), a Software Area Editor for IEEE Computer, and is a past Steering Committee Chair of the MoDELS/UML conference series. He was also a member of the revision task forces for the UML 1.x standards. He was awarded the Ten Year Most Influential Paper award at MODELS in 2008.","2011","2","2","2025-12-02","https://university.edu/papers/e28b42b4-e3c8-40b5-9bac-69f0aac748eb.pdf");
INSERT INTO Paper VALUES ("559","Sleep Apnea Screening by Autoregressive Models From a Single ECG Lead","This paper presents a method for obstructive sleep apnea (OSA) screening based on the electrocardiogram (ECG) recording during sleep. OSA is a common sleep disorder produced by repetitive occlusions in the upper airways and this phenomenon can usually be observed also in other peripheral systems such as the cardiovascular system. Then the extraction of ECG characteristics, such as the RR intervals and the area of the QRS complex, is useful to evaluate the sleep apnea in noninvasive way. In the presented analysis, 50 recordings coming from the apnea Physionet database were used; data were split into two sets, the training and the testing set, each of which was composed of 25 recordings. A bivariate time-varying autoregressive model (TVAM) was used to evaluate beat-by-beat power spectral densities for both the RR intervals and the QRS complex areas. Temporal and spectral features were changed on a minute-by-minute basis since apnea annotations where given with this resolution. The training set consisted of 4950 apneic and 7127 nonapneic minutes while the testing set had 4428 apneic and 7927 nonapneic minutes. The K-nearest neighbor (KNN) and neural networks (NN) supervised learning classifiers were employed to classify apnea and non apnea minutes. A sequential forward selection was used to select the best feature subset in a wrapper setting. With ten features the KNN algorithm reached an accuracy of 88%, sensitivity equal to 85%, and specificity up to 90%, while NN reached accuracy equal to 88%, sensitivity equal to 89% and specificity equal to 86%. In addition to the minute-by-minute classification, the results showed that the two classifiers are able to separate entirely (100%) the normal recordings from the apneic recordings. Finally, an additional database with eight recordings annotated as normal or apneic was used to test again the classifiers. Also in this new dataset, the results showed a complete separation between apneic and normal recordings.","2009","1","2","2025-12-02","https://university.edu/papers/d78c1f87-39c0-4c7b-a76c-a1a276b0d501.pdf");
INSERT INTO Paper VALUES ("560","Orthogonal graphs over finite commutative rings of odd characteristic","Let ( V , β ) be an orthogonal space over a finite commutative ring R of odd characteristic. We determine the structure of Vwhen R is a finite local ring. We define a graph for V called an orthogonal graph. We show that our graph is vertex and arc transitive and determine the chromatic number. If R is a finite local ring, we can classify if it is a strongly regular or quasi-strongly regular graph and we obtain its automorphism group. Moreover, we work on subconstituents of the graph.","2016","15","4","2025-12-02","https://university.edu/papers/5c5eb6a6-d0e6-415d-bc4f-b217dc52aa91.pdf");
INSERT INTO Paper VALUES ("561","A model of the relationship between psychological characteristics, mobile phone addiction and use of mobile phones by Taiwanese university female students","While many researches have analyzed the psychological antecedents of mobile phone addiction and mobile phone usage behavior, their relationship with psychological characteristics remains mixed. We investigated the relationship between psychological characteristics, mobile phone addiction and use of mobile phones for 269 Taiwanese female university students who were administered Rosenberg's self-esteem scale, Lai's personality inventory, and a mobile phone usage questionnaire and mobile phone addiction scale. The result showing that: (1) social extraversion and anxiety have positive effects on mobile phone addiction, and self-esteem has negative effects on mobile phone addiction. (2) Mobile phone addiction has a positive predictive effect on mobile phone usage behavior. The results of this study identify personal psychological characteristics of Taiwanese female university students which can significantly predict mobile phone addiction; female university students with mobile phone addiction will make more phone calls and send more text messages. These results are discussed and suggestions for future research for school and university students are provided.","2012","7","4","2025-12-02","https://university.edu/papers/dc1f5e00-e36c-4aef-aa9e-de16a31a0781.pdf");
INSERT INTO Paper VALUES ("562","A component-based approach for service distribution in sensor networks","The increasing number of distributed applications over  Wireless Sensor Networks  (WSNs) in ubiquitous environments raises the need for high-level mechanisms to distribute sensor services and integrate them in modern IT systems. Existing work in this area mostly focuses on low-level networking issues, and fails to provide high-level and off-the-shelf programming abstractions for this purpose. In this paper, we therefore consider WSN programming models and service distribution as two interrelated factors and we present a new  component-based  abstraction for integrating WSNs within existing IT systems. Our approach emphasizes on reifying distribution strategies at the software architecture level, thus allowing remote invocation of component services, and facilitating interoperability of sensor services with the Internet through  Web service-enabled  components. The latter is efficiently provided by incorporating the REST architectural style---emphasizing on abstraction of high-level services as resources---to our component-based framework. The preliminary evaluation results show that the proposed framework has an acceptable memory overhead on a TelosB sensor platform.","2010","4","3","2025-12-02","https://university.edu/papers/f38132c8-9503-4a66-842f-19939a746a65.pdf");
INSERT INTO Paper VALUES ("563","Stabilization of polytopic delay difference inclusions: Time-varying control Lyapunov functions","This paper deals with stabilization of polytopic delay difference inclusions (DDIs) via the Razumikhin approach. As not every DDI that is globally exponentially stable (GES) admits a standard Lyapunov-Razumikhin function (LRF), time-varying Lyapunov functions are proposed as a tool for stability analysis and stabilizing controller synthesis for polytopic DDIs. It is shown that any polytopic DDI that is GES admits a quadratic time-varying Lyapunov-Krasovskii function and, under an additional mild assumption, it also admits a quadratic time-varying LRF. These results are further exploited to derive a stabilizing receding horizon control scheme that does not suffer from an exponential increase in complexity when the size of the delay increases. The proposed control scheme requires solving on-line a low-dimensional semi-definite program.","2010","7","3","2025-12-02","https://university.edu/papers/74c0f9e5-bb2d-48ae-b737-620470b386ce.pdf");
INSERT INTO Paper VALUES ("564","On Multiplicative Linear Logic, Modality and Quantum Circuits","A logical system derived from linear logic and called QMLL is introduced and shown able to capture all unitary quantum circuits. Conversely, any proof is shown to compute, through a concrete GoI interpretation, some quantum circuits. The system QMLL, which enjoys cut-elimination, is obtained by endowing multiplicative linear logic with a quantum modality","2012","10","4","2025-12-02","https://university.edu/papers/32d99eff-606e-4c1d-9274-ea29cc801ed2.pdf");
INSERT INTO Paper VALUES ("565","Comparison of Cluster Representations from Partial Second- to Full Fourth-Order Cross Moments for Data Stream Clustering","Under seven external clustering evaluation measures, a comparison is made for cluster representations from the partial second order to the fourth order in data stream clustering. Two external clustering evaluation measures, purity and cross entropy, adopted for data stream clustering performance evaluation in the past, penalize the performance of an algorithm when each hypothesized cluster contains points in different target classes or true clusters, while ignoring the issue of points in a target class falling into different hypothesized clusters. The seven measures will address both sides of the clustering performance. The represented geometry by the partial second-order statistics of a cluster is non-oblique ellipsoidal and cannot describe the orientation, asymmetry, or peakedness of a cluster. The higher-order cluster representation presented in this paper introduces the third and fourth cross moments, enabling the cluster geometry to be beyond an ellipsoid. The higher-order statistics allow two clusters with different representations to merge into a multivariate normal cluster, using normality tests based on multivariate skewness and kurtosis. The clustering performance under the seven external clustering evaluation measures with a synthetic and two real data streams demonstrates the effectiveness of the higher-order cluster representations.","2008","5","1","2025-12-02","https://university.edu/papers/d8cdbf77-d33b-40fc-9299-be880519e192.pdf");
INSERT INTO Paper VALUES ("566","A Joint Optimization Technique for Multi-Edge Type LDPC Codes","This paper considers the optimization of multi-edge type low-density parity-check (METLDPC) codes to maximize the decoding threshold. We propose an algorithm to jointly optimize the node degree distribution and the multi-edge structure of MET-LDPC codes for given values of the maximum number of edge-types and maximum node degrees. This joint optimization is particularly important for MET-LDPC codes as it is not clear a priori which structures will be good. Using several examples, we demonstrate that the MET-LDPC codes designed by the proposed joint optimization algorithm exhibit improved decoding thresholds compared to previously reported MET-LDPC codes.","2016","5","2","2025-12-02","https://university.edu/papers/3b5fd0c7-e204-4ef8-9dca-17c2fb021672.pdf");
INSERT INTO Paper VALUES ("567","Adaptive areal elimination (AAE): A transparent way of disclosing protected spatial datasets","Geographical masking is the conventional solution to protect the privacy of individuals involved in confidential spatial point datasets. The masking process displaces confidential locations to protect individual privacy while maintaining a fine level of spatial resolution. The adaptive form of this process aims to further minimize the displacement error by taking into account the underlying population density. We describe an alternative adaptive geomasking method, referred to as Adaptive Areal Elimination (AAE). AAE creates areas of a minimum K-anonymity and then original points are either randomly perturbed within the areas or aggregated to the median centers of the areas. In addition to the masked points, K-anonymized areas can be safely disclosed as well without increasing the risk of re-identification. Using a burglary dataset from Vienna, AAE is compared with an existing adaptive geographical mask, the donut mask. The masking methods are evaluated for preserving a predefined K-anonymity and the spatial characteristics of the original points. The spatial characteristics are assessed with four measures of spatial error: displaced distance, correlation coefficient of density surfaces, hotspots' divergence, and clusters' specificity. Masked points from point aggregation of AAE have the highest spatial error in all the measures but the displaced distance. In contrast, masked points from the donut mask are displaced the least, preserve the original spatial clusters better, have the highest clusters' specificity and correlation coefficient of density surfaces. However, when the donut mask is adapted to achieve an actual K-anonymity, the random perturbation of AAE introduces less spatial error than the donut mask for all the measures of spatial error.","2016","12","4","2025-12-02","https://university.edu/papers/e1739bdf-9046-43f5-80a5-d8ad12ff3b62.pdf");
INSERT INTO Paper VALUES ("568","A linguistic framework for querying dimensional data","This paper deals with dimensional data. Examples of dimensions are space and time. Thus, temporal, spatial, spatiotemporal values are examples of dimensional data. We define the notion of dimensional object, extending an object-oriented ODMG-like type system to include dimensional types. We then address the problem of querying dimensional objects. Linguistic constructs are introduced that allow objects with different dimensions to be mixed in the same phrases. This allows the user to formulate both associative and navigational accesses seamlessly without having to worry about the dimensions of the various data elements involved.","2001","15","2","2025-12-02","https://university.edu/papers/a0868c94-e8b2-4fe4-b93e-1569df17894d.pdf");
INSERT INTO Paper VALUES ("569","Intelligent control algorithms for optimal reconfiguration of microgrid distribution system","The distribution power system in ship is very similar to a microgrid and supplies energy to navigation and operation system as well as sophisticated systems of weapons and communications. After a fault is encountered, reconfiguration refers to changing the topology of the microgrid distribution network in order to isolate system damage and/or optimize certain characteristics of the system. Reconfiguration problem in microgrid is nonlinear with numerous discrete variables and additional constraints. Traditional optimization methods are not the best solution due to tendency of getting stuck to a suboptimal solution. In this work, intelligent methods such as genetic algorithm (GA) and particle swarm optimization (PSO) have been applied for microgrid reconfiguration with shipboard power system (SPS) as an example. Proposed methods are capable to satisfy the operational constraints and consider load priorities. Graph theory is utilized to represent the microgrid network topology. Proposed intelligent reconfiguration algorithms were implemented using MATLAB and tested on 8-BUS and 13-BUS SPS models including distributed generations (DGs) and islands. Test systems were reconfigured in three different possible scenarios by considering load priority, load magnitude, and by combining these two simultaneously. Developed reconfiguration algorithm was also implemented in real time using controller-in-the-loop with real time digital simulator. Simulation results show satisfactory performance for several test case operating scenarios.","2015","13","2","2025-12-02","https://university.edu/papers/eb791fa6-9a5a-41b9-9cf7-1d7792bba5c3.pdf");
INSERT INTO Paper VALUES ("570","Maximum likelihood estimation of multiple frequencies with constraints to guarantee unit circle roots","An approximate maximum-likelihood estimator (MLE) of multiple exponentials converts the frequency estimation problem into a problem of estimating the coefficients of a z-polynomial with roots at the desired frequencies. Theoretically, the roots of the estimated polynomial should fall on the unit circle, but MLE, as originally proposed, does not guarantee unit circle roots. This drawback sometimes causes merged frequency estimates, especially at low SNR. If all the sufficient conditions for the z-polynomial to have unit circle roots are incorporated, the optimization problem becomes too nonlinear and it loses the desirable weighted-quadratic structure of MLE. In the present paper, the exact constraints are imposed on each of the first-order factors corresponding to individual frequencies for ensuring unit circle roots. The constraints are applied during optimization alternately for each frequency. In the absence of any merged frequency estimates, the RMS values more closely approach the theoretical Cramer-Rao (CR) bound at low SNR levels. >","1995","3","3","2025-12-02","https://university.edu/papers/f59a1660-2494-4a32-8322-0f620a3bb43e.pdf");
INSERT INTO Paper VALUES ("571","A secure distributed search system","This paper presents the design, implementation and evaluation of Mingle, a secure distributed search system. Each participating host runs a Mingle server, which maintains an inverted index of the local file system. Users initiate peer-to-peer keyword searches by typing keywords to lightweight Mingle clients. Central to Mingle are its access control mechanisms and its insistence on user convenience. For access control, we introduce the idea of access-right mapping, which provides a convenient way for file owners to specify access permissions. Access control is supported through a single sign-on mechanism that allows users to conveniently establish their identity to Mingle servers, such that subsequent authentication occurs automatically, with minimal manual involvement. Preliminary performance evaluation suggests that Mingle is both feasible and scalable.","2002","14","2","2025-12-02","https://university.edu/papers/aaee588b-5dc4-4ab8-841b-2ca51342e165.pdf");
INSERT INTO Paper VALUES ("572","A reliability window for flexible and scalable multicast services","This paper proposes a simple mechanism to allow reliability to be traded off against performance and scalability in a reliable multicast transport protocol. A reliability window is used in the data packet header to indicate which packets are useful to recover if lost. In addition, we describe a simple API that allows applications to set the reliability window in a way meaningful to the application. The usefulness of the trade-off is demonstrated using experimental results from a test network. We expect this mechanism to be useful for large-scale content distribution where the content ages over time.","2002","10","1","2025-12-02","https://university.edu/papers/612218ec-25db-4c03-a4c5-ddb1bdb7192f.pdf");
INSERT INTO Paper VALUES ("573","A structured approach to handling on-line interface upgrades","The integration of complex systems out of existing systems is an active area of research and development. There are many practical situations in which the interfaces of the component systems, for example belonging to separate organisations, are changed dynamically and without notification. In this paper we propose an approach to handling such upgrades in a structured and disciplined fashion. All interface changes are viewed as abnormal events and general fault tolerance mechanisms (exception handling, in particular) are applied to dealing with them. The paper outlines general ways of detecting such interface upgrades and recovering after them. An Internet Travel Agency is used as a case study.","2002","5","4","2025-12-02","https://university.edu/papers/6268f980-7dfb-48dc-978d-a9a401a83c9f.pdf");
INSERT INTO Paper VALUES ("574","Low-complexity digital encoding strategies for wireless sensor networks","Low-complexity schemes for digital encoding of a noise-corrupted signal and associated signal estimators are presented. This problem arises in wireless distributed sensor networks where an environmental signal of interest is to be estimated at a central site from low-bandwidth digitized information received from collections of remote sensors. We show that the use of a properly designed and often easily implemented additive control input before signal quantization can significantly enhance overall system performance. In particular, efficient estimators can be constructed and used with optimized pseudo-noise, deterministic, and feedback-based control inputs, resulting in a hierarchy of practical systems with very attractive performance-complexity characteristics.","1998","4","1","2025-12-02","https://university.edu/papers/51fcbc4b-746a-46ad-88a4-fa5012060a98.pdf");
INSERT INTO Paper VALUES ("575","Investigating Gene and MicroRNA Expression in Glioblastoma","Glioblastoma is the most common primary brain tumor in adults. Here we present an integrated analysis of microRNA expression and gene expression in 237 tumor tissues and 10 normal tissues. We indentified 1,236 genes, and 131 pathways significantly differentially expressed between tumor and normal tissues. We also indentified 98 differentially expressed microRNAs, 22 of which have been reported to affect glioblastoma and 73 of which to affect cancers and brain diseases. We found one experimentally validated microRNA target gene and 1,094 miRNA-target gene pairs in our datasets which were predicted by miRanda algorithm, 16 of the 661 target genes are tumor suppressor genes and 5 are oncogenes. These findings gave important clues to study of the carcinogenic process in glioblastomas.","2009","8","1","2025-12-02","https://university.edu/papers/f791fbde-3b4b-4f5b-a6c2-291bac2fafa7.pdf");
INSERT INTO Paper VALUES ("576","Energy conservation in sensor networks through selective node activation","This work presents a novel algorithm to improve energy conservation in sensor networks. The algorithm is based upon selective activation of sensor nodes using thresholding (SAT). The sensor continuously monitors the received signal and makes a binary decision to join the network if the average received signal power falls within the specified minimum and maximum threshold range. Thus, SAT divides all the receivers within the coverage range of the transmitter into sets of active and inactive nodes realizing a saving in power consumption proportional to the number of inactive nodes. The sensor life-time is enhanced by allowing the node to transmit at a power that is a constant fraction of the total residual energy. For two cases of linear and hexagonal networks considered in this work, it is shown that for each transmission, the fraction of inactive nodes may exceed by over 30% of the total number of nodes present within maximum one-hop distance of the transmitter. The cost associated with energy conservation through SAT is (a) increased sensor node density or (b) increased transmission power requirement.","2006","15","2","2025-12-02","https://university.edu/papers/ac5980a4-ee3c-42e3-b264-f9d90ebef1c1.pdf");
INSERT INTO Paper VALUES ("577","The effect of tine geometry during vertical movement on soil penetration resistance using finite element analysis","New tillage and planting tools causing low soil disturbance and minimizing vegetation deterioration are desired in the conservation tillage technology development. This paper attempted to study the effect of tine geometry in its vertical movement on penetration resistance. Four kinds of tines were defined (i.e. rectangle, triangle, crescent and mososeries) based on the geometry of the cutting edge. The effects of tine geometry, thickness, and penetration depth on soil penetration resistance were investigated and side soil disturbance evaluated. Finite element method with a Drucker–Prager elasto-plastic model was introduced to simulate the material behavior of sandy loam soil taken from Hebei province in China. Each tine was considered as a discrete rigid body with a reference point at the top-midpoint of the central plane, at which the vertical force (penetration resistance) was calculated. Results indicated that the rectangle tine obtained the highest penetration resistance as compared to the others. Penetration resistances of all the tines increased with the attack surface area with a power function, nonlinear tendency with thickness and a quadratic function with penetration depth. A crescent soil deformation area existed through the penetration process. It can be concluded that the FEM can maximize the understanding of tine geometry effects on penetration resistance and soil deformation area.","2016","9","1","2025-12-02","https://university.edu/papers/abd76ca2-6bc2-4d81-a740-3bb49dc500ed.pdf");
INSERT INTO Paper VALUES ("578","Development of leader-follower system for field work","Two robot tractors were used in a leader-follower system for agricultural field work. Each of the robots was fully independent and could conduct field work alone. They could also work together to form a certain spatial arrangement during the operation. During the headland turn, each robot was simplified as a rectangular zone, and the two robots cooperated and coordinated to turn to next path without collision. This system was designed for practical application, and the system gains the ability to tolerate most of the disturbances in a real field. Fault tolerant methods in accordance with agricultural work were illustrated to solve the common disturbances from the GPS and the IMU. Field experiments were conducted to determine the effectiveness of the system. The results of the experiments showed that the two robot tractors can work safely together to complete the field work. The average lateral error of the navigation system of the robots was less than 0.04 m, and the efficiency of the leader-follower system was improved by 84.3 percent compared with that of a conventional single robot.","2015","16","4","2025-12-02","https://university.edu/papers/42604c85-1def-4bc9-95e4-96fb01aba988.pdf");
INSERT INTO Paper VALUES ("579","A trajectory clustering approach to crowd flow segmentation in videos","This work proposes a trajectory clustering-based approach for segmenting flow patterns in high density crowd videos. The goal is to produce a pixel-wise segmentation of a video sequence (static camera), where each segment corresponds to a different motion pattern. Unlike previous studies that use only motion vectors, we extract full trajectories so as to capture the complete temporal evolution of each region (block) in a video sequence. The extracted trajectories are dense, complex and often overlapping. A novel clustering algorithm is developed to group these trajectories that takes into account the information about the trajectories' shape, location, and the density of trajectory patterns in a spatial neighborhood. Once the trajectories are clustered, final motion segments are obtained by grouping of the resulting trajectory clusters on the basis of their area of overlap, and average flow direction. The proposed method is validated on a set of crowd videos that are commonly used in this field. On comparison with several state-of-the-art techniques, our method achieves better overall accuracy.","2016","12","3","2025-12-02","https://university.edu/papers/e9652a9b-7e3c-4595-a8e4-f0055c4f8ec4.pdf");
INSERT INTO Paper VALUES ("580","Extraction Error Modeling and Automated Model Debugging in High-Performance Low Power Custom Designs","Test model generation is common in the design cycle of custom made high performance low power designs targeted for high volume production. Logic extraction is a key step in test model generation to produce a logic level netlist from the transistor level representation. This is a semi-automated process which is error prone. The paper analyzes typical extraction errors applicable to clocking schemes seen in high-performance designs today. An automated debugging solution for these errors in designs with no state equivalence information is also presented. A suite of experiments on circuits with similar architectures to those found in the industry confirm the fitness and practicality of the solution.","2005","4","1","2025-12-02","https://university.edu/papers/ce9d6dd7-73f8-49b8-aac1-f26352ae19d3.pdf");
INSERT INTO Paper VALUES ("581","GAME: an object-oriented approach to computer animation in flexible manufacturing system modelling","Graphically animating results from a simulation is typically a tedious programming task. GAME (graphic animator for modelling and evaluation) is a graphical editor and animator dedicated to discrete flow manufacturing system which authorizes both the building of a manufacturing system topology with graphical objects and the animation of these objects via discrete event simulation results. The object-oriented design of GAME allowed other domain tackling (computer systems, networks, administrative systems, . . .). GAME is independent of the simulator used upstream and was mainly designed for communication, decision-making, simulation model validation and debugging. An implementation of GAME was achieved with C++. The current version has been validated on many industrial sites with the QNAP2, and SIMAN simulation software. >","1991","12","4","2025-12-02","https://university.edu/papers/7261093b-f837-43e2-a292-0e2902b282ae.pdf");
INSERT INTO Paper VALUES ("582","Effectiveness of hybrid recovery techniques on parametric failures","Modern day microprocessors effectively utilise supply voltage scaling for tremendous power reduction. The minimum voltage beyond which a processor cannot operate reliably is defined as V dd min . On-chip memories like caches are the most susceptible to voltage-noise induced failures because of process variations and reduced noise-margins thereby arbitrating whole processor's V dd min . In this paper, we evaluate the effectiveness of a new class of hybrid techniques in improving cache yield through failure prevention and correction. Proactive read/write assist techniques like body-biasing (BB) and wordline boosting (WLB) when combined with reactive techniques like ECC and redundancy are shown to offer better quality-energy-area trade offs when compared to their standalone configurations. Proactive techniques can help lower V dd min  (improving functional margin) for significant power savings and reactive techniques ensure that the resulting large number of failures are corrected (improving functional yield). Our results in 22nm technology indicate that at scaled supply voltages, hybrid techniques can improve parametric yield by atleast 28% when considering worst-case process variations.","2013","7","2","2025-12-02","https://university.edu/papers/c45898ff-4d75-41a3-aefa-a3336b4e3ba0.pdf");
INSERT INTO Paper VALUES ("583","The dropout learning algorithm","Dropout is a recently introduced algorithm for training neural networks by randomly dropping units during training to prevent their co-adaptation. A mathematical analysis of some of the static and dynamic properties of dropout is provided using Bernoulli gating variables, general enough to accommodate dropout on units or connections, and with variable rates. The framework allows a complete analysis of the ensemble averaging properties of dropout in linear networks, which is useful to understand the non-linear case. The ensemble averaging properties of dropout in non-linear logistic networks result from three fundamental equations: (1) the approximation of the expectations of logistic functions by normalized geometric means, for which bounds and estimates are derived; (2) the algebraic equality between normalized geometric means of logistic functions with the logistic of the means, which mathematically characterizes logistic functions; and (3) the linearity of the means with respect to sums, as well as products of independent variables. The results are also extended to other classes of transfer functions, including rectified linear functions. Approximation errors tend to cancel each other and do not accumulate. Dropout can also be connected to stochastic neurons and used to predict firing rates, and to backpropagation by viewing the backward propagation as ensemble averaging in a dropout linear network. Moreover, the convergence properties of dropout can be understood in terms of stochastic gradient descent. Finally, for the regularization properties of dropout, the expectation of the dropout gradient is the gradient of the corresponding approximation ensemble, regularized by an adaptive weight decay term with a propensity for self-consistent variance minimization and sparse representations.","2014","13","4","2025-12-02","https://university.edu/papers/e5871a3b-d677-47d7-9850-44f0ccf0d0b2.pdf");
INSERT INTO Paper VALUES ("584","Unveiling anomalies in large-scale networks via sparsity and low rank","In the backbone of large-scale networks, traffic flows experience abrupt unusual changes which can result in congestion, and limit the extent to which end-user quality of service requirements are met. Diagnosing such traffic volume anomalies is a crucial task towards engineering the traffic in the network. This is challenging however, since the available data are the superposition of unobservable origin-to-destination (OD) flows per link. Leveraging the low intrinsic-dimensionality of OD flows and the sparse nature of anomalies, a convex program is formulated to unveil anomalies across flows and time. A centralized solver is developed using the proximal gradient algorithm, which offers provable iteration complexity guarantees. An equivalent nonconvex but separable criterion enables in-network processing of link-load measurements, when optimized via the alternating-direction method of multipliers. The novel distributed iterations entail reduced-complexity local tasks, and affordable message passing between neighboring nodes. Interestingly, under mild conditions the distributed algorithm approaches its centralized counterpart. Numerical tests with synthetic and real network data corroborate the effectiveness of the novel scheme.","2011","17","3","2025-12-02","https://university.edu/papers/2aa090a4-11aa-46ba-ac53-8b5f0c90aa42.pdf");
INSERT INTO Paper VALUES ("585","Répondre à des requêtes cliniques PICO.","Dans cet article, nous nous interessons a l’evaluation de requetes cliniques exprimees avec les facettes PICO (Population/Problem (P), Intervention (I), Comparaison (C) et Outcome (O)). Nous proposons l’application d’un operateur d’agregation prioritaire des scores qui permet : (1) d’agreger les scores de pertinence partiels issus de l’evaluation de representations semantiques associees aux sous-requetes facettes et (2) contextualiser le score d’importance des facettes au document et requete en cours d’evaluation. Les experimentations menees sur la collection standard CLIREC, comprenant 423 requetes cliniques et plus de 1.2millions de documents PubMed, mettent en evidence l’efﬁcacite de notre approche comparativement aux autres modeles de l’etat de l’art.","2016","2","4","2025-12-02","https://university.edu/papers/3d8c96df-604f-4304-acc9-1650a332b956.pdf");
INSERT INTO Paper VALUES ("586","Interactivity and Multimodality in the IMIX Demonstrator","It is generally acknowledged that many experts and almost all laypersons have difficulty in formulating requests for information in such a manner that conventional off-line information extraction systems can find optimal answers. Therefore, it is increasingly evident that there is a need for an interactive dialog between information seekers and information extraction systems. In this paper, we describe the demonstrator of an interactive and multimodal information extraction system that is under construction in the NWO funded research program IMIX","2005","9","3","2025-12-02","https://university.edu/papers/8facc85e-69c1-4c9d-800a-ee478097e509.pdf");
INSERT INTO Paper VALUES ("587","Locally weighted total variation denoising for ringing artifact suppression in pet reconstruction using PSF modeling","Iterative reconstruction with point spread function (PSF) modeling improves contrast recovery in positron emission tomography (PET) images, but also introduces ringing artifacts and over enhancement that is contrast and object size dependent. Mitigation of these artifacts is crucial for clinical and research purposes. In this work we introduce a new iterative regularized reconstruction method that incorporates locally-weighted total variation denoising designed to suppress artifacts induced by PSF modeling. The reconstruction method is evaluated on a simulated cylindrical phantom and preliminary results show that ringing artifacts are suppressed while contrast recovery is maintained.","2013","4","1","2025-12-02","https://university.edu/papers/a417466c-ac00-4279-b7d6-e2a82d455e77.pdf");
INSERT INTO Paper VALUES ("588","Enabling next generation small cells through femtorelays","Today’s society is driven by ever-growing information needs, which cause increased demand for ubiquitous and very high speed wireless communications. In search for the urgent need of improved coverage and capacity, cellular networks are currently undergoing a major transformation from an architecture comprised of thoroughly planned macrocell base stations (MBSs) to a much more heterogeneous architecture where the macrocell network is underlaid by one or several tiers of unevenly deployed small cells. However, this new set of technologies is not exempt of several challenges. Backhaul is still an unresolved issue, i.e. which is the best technology for the small cell to reach the core network. In the case of uncoordinated co-channel deployments where the macrocell and small cell tier share the spectrum (e.g. femtocells or metrocells), the interference is also a major problem. In this paper, a new concept and architecture called femtorelays is introduced as a novel solution for next generation small cell problems. A femtorelay is a small cell access point that enables improved cellular coverage within indoor environments while increasing the overall system capacity through spatial frequency reuse. Working as an open-access small cell, it provides dual-backhaul connectivity to the core network for registered and unregistered users. One of the backhaul connections is the internet-based, and the second one is the relay-based operating on the spectrum owned by the wireless carrier. The radio interference between the macrocell and the small cell is overcome by servicing the macrocell interfering users at the femtorelay. Unlike the traffic from subscribers, this traffic will be forwarded to the network through the relay-based backhaul. The internal architecture, the approach employed to make the technology fit in existing networks, and future evolution of the basic femtorelays for larger scenarios are also presented. Finally, performance results show the potential of this technology to outperform other existing solutions.","2013","13","4","2025-12-02","https://university.edu/papers/d6aca038-6b3a-4302-ab71-0fa5729b037e.pdf");
INSERT INTO Paper VALUES ("589","WikiTable: a new tool for collaborative authoring and data management","Tables are an efficient tool for organizing complex data. Even though they are pervasively used in all kinds of documentation, current implementations of tables often limit the power of data management because generally they do not support concurrent collaborative authoring; they only allow keyword search, which typically yields poor search performance; and transporting tables among different applications is cumbersome. We present a new table tool, WikiTable, which permits multiple users to work on the same table simultaneously. The content of each table is stored in a database, which enables accurate data inquiry. More importantly, WikiTable is highly portable, permitting easy integration with other applications, such as Wikis or Blogs. An effort to apply the WikiTable in a global collaboration project of software development is also discussed.","2007","7","3","2025-12-02","https://university.edu/papers/e2b82d1d-c5db-4c8f-a403-c73cbdfee4dc.pdf");
INSERT INTO Paper VALUES ("590","Linked Dataset description papers at the Semantic Web journal: A critical assessment","Since 2012, the Semantic Web journal has been accepting papers in a novel Linked Dataset description track. Here we motivate the track and provide some analysis of the papers accepted thus far. We look at the ratio of accepted papers in this time-frame that fall under this track, the relative impact of these papers in terms of citations, and we perform a technical analysis of the datasets they describe to see what sorts of resources they provide and to see if the datasets have remained available since publication. Based on a variety of such analyses, we present some lessons learnt and discuss some potential changes we could apply to the track in order to improve the overall quality of papers accepted.","2016","7","4","2025-12-02","https://university.edu/papers/691f8de1-9dbc-4bdf-94ab-44a3a4b0479e.pdf");
INSERT INTO Paper VALUES ("591","Context-aware characterisation of energy consumption in data centres","Carbon emissions are receiving increased attention and scrutiny in all walks of life and the ICT sector is no exception. With the increase in on-demand applications and services together with on-demand compute/storage facilities in server farms or data centres there are self-evident increases in the power requirements to maintain such systems. Proponents of the impact of increased carbon emissions when powering electrical systems in general however, regularly impress negative side-effects such as influence on climate change. Action is subsequently being encouraged to halt further environmental damage. The problem is explored in this paper from the point of view of carbon emissions from data centre operations and the development of energy-aware management and energy-efficient networking solutions. Data centre energy consumption costs drive the evaluation process within a Data Centre Energy-Efficient Context-Aware Broker (DCe-CAB) algorithm designed as an original solution to this significant carbon-contributing network scenario. In this paper, performance requirements and objectives of the DCe-CAB are defined, along with case study demonstration of the way in which it optimises selection and operation of data centres using context-awareness.","2011","6","3","2025-12-02","https://university.edu/papers/ac8faf21-f23d-4450-8f09-3816138fb001.pdf");
INSERT INTO Paper VALUES ("592","193 MOPS/mW @ 162 MOPS, 0.32V to 1.15V voltage range multi-core accelerator for energy efficient parallel and sequential digital processing","Low power (mW) and high performance (GOPS) are strong requirements for compute-intensive signal processing in E-health, Internet-of-Things, and wearable applications. This work presents a building block for programmable Ultra-Low Power accelerators, namely a tightly-coupled computing cluster that supports parallel and sequential execution at high energy efficiency over a wide range of workload requirements. The cluster, implemented in 28nm UTBB FD-SOI technology, achieves peak energy efficiency in the near-threshold (NVT) operating region: 193 MOPS/mW at 162 MOPS for parallel workloads, and 90 MOPS/mW at 68 MOPS for sequential workloads at 0.46V and 0.5V, respectively. The energy efficient operating range is wide (0.32V to 1.15V), also meeting the design goal of 1 GOPS within a 10 mW power envelope (at 0.66V).","2016","17","4","2025-12-02","https://university.edu/papers/826fdd9a-9055-458b-8bc9-52886c3e3ea7.pdf");
INSERT INTO Paper VALUES ("593","Electric Field Servoing for robotic manipulation","This paper presents two experiments with electric field servoing for robotic manipulation. In the first, a robot hand pre-shapes to the geometry and pose of objects to be grasped, by servoing each finger according to the values on EF sensors built in to each finger. In the second, a 7 degree of freedom arm aligns itself in 2 dimensions with a target object using electric field measurements as the error signal. This system also allows the end effector to dynamically track the target object as it is moved.","2008","17","4","2025-12-02","https://university.edu/papers/665a1488-fada-45c6-998f-28874a420798.pdf");
INSERT INTO Paper VALUES ("594","Segment-based streaming media proxy: modeling and optimization","Researchers often use segment-based proxy caching strategies to deliver streaming media by partially caching media objects. The existing strategies mainly consider increasing the byte hit ratio and/or reducing the client perceived startup latency (denoted by the metric delayed startup ratio). However, these efforts do not guarantee continuous media delivery because the to-be-viewed object segments may not be cached in the proxy when they are demanded. The potential consequence is playback jitter at the client side due to proxy delay in fetching the uncached segments, which we call proxy jitter. Thus, for the best interests of clients, a correct model for streaming proxy system design should aim to minimize proxy jitter subject to reducing the delayed startup ratio and increasing the byte hit ratio. However, we have observed two major pairs of conflicting interests inherent in this model: (1) one between improving the byte hit ratio and reducing proxy jitter, and (2) the other between improving the byte hit ratio and reducing the delayed startup ratio. In this study, we first propose and analyze prefetching methods for in-time prefetching of uncached segments, which provides insights into the first pair of conflicting interests. Second, to address the second pair of the conflicting interests, we build a general model to analyze the performance tradeoff between the second pair of conflicting performance objectives. Finally, considering our main objective of minimizing proxy jitter and optimizing the two tradeoffs, we propose a new streaming proxy system called Hyper Proxy. Synthetic and real workloads are used to evaluate our system. The performance results show that Hyper Proxy generates minimum proxy jitter with a low delayed startup ratio and a small decrease of byte hit ratio compared with existing schemes.","2006","4","1","2025-12-02","https://university.edu/papers/67446d57-17d5-41fc-a667-4d171ce5654d.pdf");
INSERT INTO Paper VALUES ("595","An open-loop cyclostationarity-based timing recovery algorithm for accelerated timing acquisition in frequency-selective channels","We propose an open-loop symbol period estimation algorithm that can be used alone or to speed up symbol timing recovery loops. The proposed algorithm is effective in frequency selective channels, does not require the resampling of the digital received signal while estimating the symbol period, and does not require estimation of the transmitted symbols. The algorithm is performed in a computationally efficient manner. Included is a simple method of finding a DFT value for subsequent overlapping blocks of data using only one complex multiply. Simulations of the proposed algorithm show significant improvements in estimation time and reduction of jitter when compared to a Gardner timing recovery loop.","2002","8","1","2025-12-02","https://university.edu/papers/75ea191c-ac57-433e-a840-7cf20da5436a.pdf");
INSERT INTO Paper VALUES ("596","From MAP to DIST: The Evolution of a Large-Scale WLAN Monitoring System","The edge of the Internet is increasingly becoming wireless. Therefore, monitoring the wireless edge is important to understanding the security and performance aspects of the Internet experience. We designed and implemented a large-scale WLAN monitoring system, the Dartmouth Internet security testbed (DIST), at Dartmouth College. It is equipped with distributed arrays of 'sniffers' that cover 210 diverse campus locations and more than 5,000 users. In this paper, we describe our approach, designs, and solutions for addressing the technical challenges that have resulted from efficiency, scalability, security, and management perspectives. We also present extensive evaluation results on a production network, and summarize the lessons learned.","2014","8","1","2025-12-02","https://university.edu/papers/f129f3f2-f791-4de4-9b50-805c2b83883f.pdf");
INSERT INTO Paper VALUES ("597","Texture analysis and retrieval using fractal signature and B-spline wavelet transform with second order derivative","In the paper, we proposed a novel over-complete B-spline wavelet transform and fractal signature for texture image analysis and retrieval. Traditionally, discrete wavelet frame took the first order derivative of smoothing function into account, which is equivalent to Canny edge detection. The second order derivative spline wavelet has the ability to detect the variation of the edge width, and the finite impulse response is conducted in the paper. Additionally, statistical features in wavelet domain and fractal signature are utilized in the retrieval. Experimental results have shown that the proposed method is reasonable to describe the essences of the textures and can reach the highest retrieval rate (76.54%) comparing with Gabor Filter and first order derivative over-complete wavelet transform.","2005","2","1","2025-12-02","https://university.edu/papers/60c63dcc-d7d6-452e-86de-eca7a3865db2.pdf");
INSERT INTO Paper VALUES ("598","Delay Performance of Direct Reads in Distributed Storage Systems with Coding","Delay performance is crucial in distributed storage systems and it can greatly impact user experience. Both direct and k-access reads are common in storage systems. However, much of previous research only considers k-access reads and many schemes, such as Redundant Scheme, are only shown to reduce delay for k-access reads. We have no idea whether those existing schemes can also work for direct reads. The study regarding the characteristics of the delay performance ofdirect reads, and the appropriate schemes for direct reads to reduce delay is still lacking. In this paper, we study the delay performance of direct reads and its correlation with degraded reads. We illustrate the relationship between degraded reads and bandwidth cost and answer important questions like when degraded reads can help reduce delay. Then we propose a scheme DRALB to reduce delay for direct reads. DRALB can be easily added to existing schemes and can greatly reduce the delay of hot data. We also conduct trace-driven simulations to verify that DRALB significantly outperforms existing schemes, in terms of delay performance of direct reads.","2015","19","3","2025-12-02","https://university.edu/papers/c7633e2e-9949-4e53-8a1a-c7b55ecf4d0b.pdf");
INSERT INTO Paper VALUES ("599","Tracking Salient Keypoints for Human Action Recognition","It plays an important role to recognize human actions from realistic videos in multimedia event detection and understanding. To this aim, a novel human tracking approach is proposed in this paper. Firstly, salient key points trajectories are generated to track human actions at multiple spatial scales. Then, camera motion elimination is utilized to further improve the robustness of motion trajectories. To depict human motions accurately and efficiently, the Histogram of Oriented Gradient (HOG), Histogram of Optical Flow (HOF) and Motion Boundary Histogram (MBH) are employed with the Fisher vector model being utilized to aggregate these three features. Extensive experimental results on four challenging human action video datasets demonstrate that the proposed approach is able to achieve better recognition performances in a more computationally efficient manner as compared with a number of state-of-the-art approaches.","2015","8","1","2025-12-02","https://university.edu/papers/2b17a0b4-fea9-4fc3-a598-e554a554723a.pdf");
INSERT INTO Paper VALUES ("600","Social community detection based on node distance and interest","Nowadays, social network sites, such as Facebook and Twitter, have tremendous number of users in their repositories. Having this huge amount of data requires analyzing them to get statistics about the users and their interests. In this paper, we propose a new algorithm that clusters the nodes in social networks into communities based on their geodesic location and the similarity between their interests. The algorithm is examined thoroughly to test its performance. The experiments show that the algorithm achieves a high community detection accuracy.","2016","18","1","2025-12-02","https://university.edu/papers/4a645a9a-6b45-4951-900a-a6398c9b34a1.pdf");
INSERT INTO Paper VALUES ("601","Multicriteria 3D PET image segmentation","The analysis of images acquired with Positron Emission Tomography (PET) is challenging. In particular, there is no consensus on the best criterion to quantify the metabolic activity for lesion detection and segmentation purposes. Based on this consideration, we propose a versatile knowledge-based segmentation methodology for 3D PET imaging. In contrast to previous methods, an arbitrary number of quantitative criteria can be involved and the experts behaviour learned and reproduced in order to guide the segmentation process. The classification part of the scheme relies on example-based learning strategies, allowing interactive example definition and more generally incremental refinement. The image processing part relies on hierarchical segmentation, allowing vectorial attribute handling. Preliminary results on synthetic and real images confirm the relevance of this methodology, both as a segmentation approach and as an experimental framework for criteria evaluation.","2015","9","2","2025-12-02","https://university.edu/papers/bac4f995-5c89-4f46-93fb-fa5a4fd44b2d.pdf");
INSERT INTO Paper VALUES ("602","Frequency down-conversion with complementary-MOS inverters","This paper focuses on the frequency-down-conversion realized with a proposed Mixer topology using 4 CMOS inverters only. From simulation and using typical 0.35µm CMOS process parameters, the proposed Mixer exhibits at 900MHz under 2.5 supply voltage, the following performances: a 16.8dB conversion gain, a 23dBc-IM3 with 200mVpeak-to-peak input sinusoidal waves. The corresponding IIP3 is 10dBm for a total power consumption of 1.4mW.","2010","20","4","2025-12-02","https://university.edu/papers/b04dbe0b-5c36-4316-8e08-93089c7c5b9d.pdf");
INSERT INTO Paper VALUES ("603","Planar PØP: Feature-less pose estimation with applications in UAV localization","We present a featureless pose estimation method that, in contrast to current Perspective-n-Point (PnP) approaches, it does not require n point correspondences to obtain the camera pose, allowing for pose estimation from natural shapes that do not necessarily have distinguished features like corners or intersecting edges. Instead of using n correspondences (e.g. extracted with a feature detector) we will use the raw polygonal representation of the observed shape and directly estimate the pose in the pose-space of the camera. This method compared with a general PnP method, does not require n point correspondences neither a priori knowledge of the object model (except the scale), which is registered with a picture taken from a known robot pose. Moreover, we achieve higher precision because all the information of the shape contour is used to minimize the area between the projected and the observed shape contours. To emphasize the non-use of n point correspondences between the projected template and observed contour shape, we call the method Planar P0P. The method is shown both in simulation and in a real application consisting on a UAV localization where comparisons with a precise ground-truth are provided.","2016","13","4","2025-12-02","https://university.edu/papers/50ccf7af-b96b-4490-8d71-45d5456200ff.pdf");
INSERT INTO Paper VALUES ("604","Practical Deadlock-Free Fault-Tolerant Routing in Meshes Based on the Planar Network Fault Model","The number of virtual channels required for deadlock-free routing is important for cost-effective and high-performance system design. The planar adaptive routing scheme is an effective deadlock avoidance technique using only three virtual channels for each physical channel in 3D or higher dimensional mesh networks with a very simple deadlock avoidance scheme. However, there exist one idle virtual channel for all physical channels along the first dimension and two idle virtual channels for channels along the last dimension in a mesh network based on the planar adaptive routing algorithm. A new deadlock avoidance technique is proposed for 3D meshes using only two virtual channels by making full use of the idle channels. The deadlock-free adaptive routing scheme is then modified to a deadlock-free adaptive fault-tolerant routing scheme based on a planar network (PN) fault model. The proposed deadlock-free adaptive routing scheme is also extended to n-dimensional meshes still using two virtual channels. Sufficient simulation results are presented to demonstrate the effectiveness of the proposed algorithm.","2009","4","2","2025-12-02","https://university.edu/papers/c0b0b13b-cd95-4e9e-830f-4b89ad1e85c9.pdf");
INSERT INTO Paper VALUES ("605","The meta-object facility typed","The Object Managment Group's Meta-Object Facility (MOF) [9] is a semiformal approach to writing models and metamodels (models of models). The MOF was developed to enable systematic model/metamodel interchange and integration. The approach is problematic, unless metamodels are correctly specified: an error in a metamodel specification will propagate throughout instantiating models and final model implementations. An important open question is how to develop provably correct metamodels. This paper outlines a solution to the question, in which the MOF meta-modelling approach is formalized within constructive type theory.","2006","9","4","2025-12-02","https://university.edu/papers/fba5bd70-6158-4fa8-b91c-765ffcbe9d4d.pdf");
INSERT INTO Paper VALUES ("606","Meta Change Queue: Tracking Changes to People, Places, and Things","Managing information flow between different parts of the enterprise information infrastructure can be a daunting task. We have grown too large to send the complete lists around anymore, instead we need to send just the changes of interest to the systems that want them. In addition, we wanted to eliminate 'sneaker net' and have the systems communicate directly without human intervention. Some of our applications required real time updates, and for all cases, we needed to respect the 'business rules' of the destination systems when entering information. This paper describes a general method for propagating changes of information while respecting the needs of the target systems.","2004","7","2","2025-12-02","https://university.edu/papers/abb4faac-fc80-4403-a294-1eb1e64af904.pdf");
INSERT INTO Paper VALUES ("607","Implementation of neuroidentifiers trained by PSO on a PLC platform for a multimachine power system","Power systems are nonlinear with fast changing dynamics. In order to design a nonlinear adaptive controller for damping power system oscillations, it becomes necessary to identify the dynamics of the system. This paper demonstrates the implementation of a neural network based system identifier, referred to as a neuroidentifier, on a programmable logic controller (PLC) platform. Two separate neuroidentifiers are trained using the particle swarm optimization (PSO) algorithm to identify the dynamics in a two-area four machine power system, one neuroidentifier for Area 1 and the other for Area 2. The power system is simulated in real time on the Real Time Digital Simulator (RTDS). The PLC implementing two neural networks and the PSO training algorithm is interfaced in a real time to the RTDS. Typical results are presented showing that PLC platform is able to implement the neuroidentifiers to sufficiently identify the dynamics of the two-area four machine power system.","2008","7","3","2025-12-02","https://university.edu/papers/5f236085-543c-4aec-b172-5b60c5b59e19.pdf");
INSERT INTO Paper VALUES ("608","Unified Modeling of Complex Real-Time Control Systems","The complex real-time control system is a software dense and algorithm dense system, which needs modern software engineering techniques to design. UML is an object-oriented industrial standard modeling language, used more and more in the real-time domain. This paper first analyses the advantages and problems of using UML for real-time control systems design. Then, it proposes an extension of UML-RT to support time-continuous subsystems modeling. So we can unify modeling of complex real-time control systems on a UML-RT platform, from requirement analysis, model design, simulation, through to code generation.","2005","10","3","2025-12-02","https://university.edu/papers/825ea892-8358-4431-ab5b-4f6dd8f4701a.pdf");
INSERT INTO Paper VALUES ("609","Reliability estimation during prototyping of knowledge-based systems","Many knowledge based systems are designed and built with little attention paid to the reliability of the output. In this paper, we present an approach, using partitioning of both the knowledge base and the input space, that allows for the measurement of the reliability during any program increment in a rapid prototyping development cycle. Before presenting the approach, we formalize the problem using concepts from general systems theory and then describe our three objectives: 1) measurement of the reliability of the knowledge-based system at the current program increment, 2) prediction of the reliability of the future system, and 3) support for design decisions. Finally, we apply our approach to a design-aiding knowledge-based system for the selection of materials under various climatic conditions. The design-aiding knowledge-based system is used by U.S. Army personnel in the development of equipment to be used by the U.S. Army in various regions of the world. We find that the current system, containing 40 rules, has a reliability of approximately 0.85. However, more importantly, we have discovered the rules that led to many of the failures. >","1995","1","1","2025-12-02","https://university.edu/papers/7cf43d50-0012-4f42-81b7-88634ce2257d.pdf");
INSERT INTO Paper VALUES ("610","Improving Parallel Write by Node-Level Request Scheduling","In a cluster of multiple processors or cpu-cores, many processes may run on each compute node. Each process tends to issue contiguous I/O requests for snapshot, checkpointing or so, however, if large number of processes enter the I/O phase at the same time, the requests from the same process may be interrupted by the requests of other processes. Then, the I/O nodes receive these requests as non-contiguous way. This interleaved access pattern causes performance degradation in parallel file systems. In order to overcome the problem, we have designed the Gather-Arrange-Scatter (GAS) I/O architecture, for optimizing the parallel write performance. The GAS is an architecture for capturing write operations, buffering them in the memory, and scheduling them to reduce I/O cost at I/O nodes. The scheduling is done per compute node, and the requests are sent to the remote disks in parallel. In this paper, after introducing the GAS architecture in detail, its efficiency and scalability are evaluated using the NAS Parallel Benchmark BTIO. GAS is 5.2%faster than ROMIO collective I/O on PVFS2 in BTIO with 16 nodes/64 processes, and 34.9% faster than MPI noncollective I/O in the same configuration.","2009","6","4","2025-12-02","https://university.edu/papers/76f4094f-a5a4-4175-ab48-9558b937ddb5.pdf");
INSERT INTO Paper VALUES ("611","Class-proximity SOM and its applications in classification","In this study, we propose a model of self-organizing map (SOM) capable of mapping high dimensional data into a low dimension space by preserving not only the feature-proximity of the original data but also their class-proximity. A conventional SOM is known to map original high dimensional data with similar features into points located close to each other in the low dimensional map in a so called competitive layer. In addition to this feature, the proposed SOM is also able to map high dimensional data belonging to a same class in each other's proximities. These characteristics retains the ability of the map to be used as a visualization tool of high dimensional data while also support the execution of high quality pattern classifications in the low dimensional map. In the experiments the classification performance of the proposed SOM is compared to that of MLP with regards to wide varieties of problems.","2008","10","2","2025-12-02","https://university.edu/papers/562aae86-c91b-42f1-8160-5c9c08181203.pdf");
INSERT INTO Paper VALUES ("612","Confident Interpretation of Bayesian Decision Tree Ensembles for Clinical Applications","Bayesian averaging (BA) over ensembles of decision models allows evaluation of the uncertainty of decisions that is of crucial importance for safety-critical applications such as medical diagnostics. The interpretability of the ensemble can also give useful information for experts responsible for making reliable decisions. For this reason, decision trees (DTs) are attractive decision models for experts. However, BA over such models makes an ensemble of DTs uninterpretable. In this paper, we present a new approach to probabilistic interpretation of Bayesian DT ensembles. This approach is based on the quantitative evaluation of uncertainty of the DTs, and allows experts to find a DT that provides a high predictive accuracy and confident outcomes. To make the BA over DTs feasible in our experiments, we use a Markov Chain Monte Carlo technique with a reversible jump extension. The results obtained from clinical data show that in terms of predictive accuracy, the proposed method outperforms the maximum a posteriori (MAP) method that has been suggested for interpretation of DT ensembles","2007","6","3","2025-12-02","https://university.edu/papers/aeea07e1-1357-4382-8787-9bc99c7d9f3c.pdf");
INSERT INTO Paper VALUES ("613","Local Identification of Prototypes for Genetic Learning of Accurate TSK Fuzzy Rule-Based Systems","This work presents the use of local fuzzy prototypes as a new idea to obtain accurate local semantics-based Takagi–Sugeno–Kang ~TSK! rules. This allow us to start from prototypes considering the interaction between input and output variables and taking into account the fuzzy nature of the TSK rules. To do so, a two-stage evolutionary algorithm based on MOGUL ~a methodology to obtain Genetic Fuzzy Rule-Based Systems under the Iterative Rule Learning approach! has been developed to consider the interaction between input and output variables. The first stage performs a local identification of prototypes to obtain a set of initial local semantics-based TSK rules, following the Iterative Rule Learning approach and based on an evolutionary generation process within MOGUL ~taking as a base some initial linguistic fuzzy partitions!. Because this generation method induces competition among the fuzzy rules, a postprocessing stage to improve the global system performance is needed. Two different processes are considered at this stage, agenetic niching-based selection process to remove redundant rules and a genetic tuning process to refine the fuzzy model parameters. The proposal has been tested with two real-world problems, achieving good results. © 2007 Wiley Periodicals, Inc.","2007","3","2","2025-12-02","https://university.edu/papers/66732fbe-d3fe-422e-a4d0-cb8f7ce48544.pdf");
INSERT INTO Paper VALUES ("614","Numerical Local Irreducible Decomposition","Globally, the solution set of a system of polynomial equations with complex coefficients can be decomposed into irreducible components. Using numerical algebraic geometry, each irreducible component is represented using a witness set thereby yielding a numerical irreducible decomposition of the solution set. Locally, the irreducible decomposition can be refined to produce a local irreducible decomposition. We define local witness sets and describe a numerical algebraic geometric approach for computing a numerical local irreducible decomposition for polynomial systems. Several examples are presented.","2015","6","3","2025-12-02","https://university.edu/papers/41b99387-577b-4d55-8054-34d36921d0a1.pdf");
INSERT INTO Paper VALUES ("615","Mapping Wetlands in Zambia Using Seasonal Backscatter Signatures Derived from ENVISAT ASAR Time Series","Wetlands are considered a challenging environment for mapping approaches based on Synthetic Aperture Radar (SAR) data due to their often complex internal structures and the diverse backscattering mechanisms caused by vegetation, soil moisture and flood dynamics contributing to the resulting imagery. In this study, a time series of >100 SAR images acquired by ENVISAT during a time period of ca. two years over the Kafue River basin in Zambia was compared to water heights derived from radar altimetry and surface soil moisture from a reanalysis dataset. The backscatter time series were analyzed using a harmonic model to characterize the seasonality in C-band backscatter caused by the interaction of flood and soil moisture dynamics. As a result, characteristic seasonal signatures could be derived for permanent water bodies, seasonal open water, persistently flooded vegetation and seasonally flooded vegetation. Furthermore, the analysis showed that the influence of local incidence angle could be accounted for by a linear shift in backscatter averaged over time, even in wetland areas where the dominant scattering mechanism can change depending on the season. The retrieved harmonic model parameters were then used in an unsupervised classification to detect wetland backscattering classes at the regional scale. A total area of 7800 km2 corresponding to 7.6% of the study area was classified as either one of the wetland backscattering classes. The results demonstrate the value of seasonality parameters extracted from C-band SAR time series for wetland mapping.","2016","15","2","2025-12-02","https://university.edu/papers/6e06bc30-c0e1-4976-8e77-ece09fee8dff.pdf");
INSERT INTO Paper VALUES ("616","Embryonics+immunotronics: a bio-inspired approach to fault tolerance","Fault tolerance has always been a standard feature of electronic systems intended for long-term missions. However, the high complexity of modern systems makes the incorporation of fault tolerance a difficult task. Novel approaches to fault tolerance can be achieved by drawing inspiration from nature. Biological organisms possess characteristics such as healing and learning that can be applied to the design of fault-tolerant systems. This paper extends the work on bio-inspired fault-tolerant systems at the University of York. It is proposed that by combining embryonic arrays with an immune inspired network, it is possible to achieve systems with higher reliability.","2000","1","4","2025-12-02","https://university.edu/papers/5e24eac2-ef21-4bf8-a609-18ffd2e40eed.pdf");
INSERT INTO Paper VALUES ("617","Towards validation of SMAP: SMAPEX-4 & -5","The L-band (1 – 2 GHz) microwave remote sensing has been widely acknowledged as the most promising method to monitor regional to global soil moisture. Consequently, the Soil Moisture Active Passive (SMAP) satellite applied this technique to provide global soil moisture every 2 to 3 days. To verify the performance of SMAP, the fourth and fifth campaign of SMAP Experiments (SMAPEx-4 & -5) were carried out at the beginning of the SMAP operational phase in the Murrumbidgee River catchment, southeast Australia. The airborne radar and radiometer observations together with ground sampling on soil moisture, vegetation water content, and surface roughness were collected in coincidence with SMAP overpasses. The SMAPEx-4 & -5 data sets will benefit to SMAP post-launch calibration and validation under Australian land surface conditions.","2016","14","3","2025-12-02","https://university.edu/papers/633121fe-dee9-4d47-89bc-50182595feb4.pdf");
INSERT INTO Paper VALUES ("618","Graph notation for arrays","A graph-theoretical notation for array concatenation represents arrays as bubbles with arms sticking out, each arm with a specified number of ''fingers'. Bubbles with one arm are vectors, with two arms matrices, etc. Arrays can only hold hands, i.e., 'contract' along a given pair of arms, if the arms have the same number of fingers. There are three array concatenations: outer product, contraction, and direct sum. Special arrays are the unit vectors and the diagonal array, which is the branching point of several arms. Outer products and contractions are independent of the order in which they are performed and distributive with respect to the direct sum. Examples are given where this notation clarifies mathematical proofs.","2001","1","2","2025-12-02","https://university.edu/papers/78ffd167-538e-46d6-8c44-7b5aa007a9c4.pdf");
INSERT INTO Paper VALUES ("619","Credit Risk Evaluation Based on Text Analysis","The main difficulty of credit risk evaluation is to evaluate borrowers' willingness of repayment, which is a subjective factor depending on the thoughts and ideas of borrowers. Text description is a kind of human behavior which reflects the mental process of writers. The authors identify the characteristics of borrowers from their text descriptions and further use them to evaluate the credit risk of loans. Experimental results show that: 1 textual information is a good choice when traditional financial information is missing. The authors can achieve similar accuracy using only textual information as traditional methods which use financial information and credit information from the third party. 2 Textual information is a good complementary information source to traditional financial information sources. Using textual information can improve the performance of credit risk evaluation system when combined with traditional financial information.","2016","9","1","2025-12-02","https://university.edu/papers/5c7673a9-b488-42a0-8c5d-30d3353be7ea.pdf");
INSERT INTO Paper VALUES ("620","Adaptive MLSE equalizers with parametric tracking for multipath fast-fading channels","We use the parametric channel identification algorithm proposed by Chen and Paulraj (see Proc. IEEE Vehicular Technology Conf., p.710-14, 1997) and by Chen, Kim and Liang (see IEEE Trans. Veh. Technol., p.1923-35, 1999) to adaptively track the fast-fading channels for the multichannel maximum likelihood sequence estimation (MLSE) equalizer using multiple antennas. Several commonly-used channel tracking schemes, decision-directed recursive least square (DD/RLS), per-survivor processing recursive least square (PSP/RLS) and other reduced-complexity MLSE algorithms are considered. An analytic lower bound for the multichannel MLSE equalizer with no channel mismatch in the time-varying specular multipath Rayleigh-fading channels is derived. Simulation results that illustrate the performance of the proposed algorithms working with various channel tracking schemes are presented, and then these results are compared with the analytic bit error rate (BER) lower bound and with the conventional MLSE equalizers directly tracking the finite impulse response (FIR) channel tap coefficients. We found that the proposed algorithm always performs better than the conventional adaptive MLSE algorithm, no matter what channel tracking scheme is used. However, which is the best tracking scheme to use depends on the scenario of the system.","2001","6","1","2025-12-02","https://university.edu/papers/cfddaa8b-b367-4eba-8a3d-f5c92c2afb3d.pdf");
INSERT INTO Paper VALUES ("621","Finding essential features for tracking starfish in a video sequence","The paper introduces a software system for detecting and tracking starfish in an underwater video sequence. The target of such a system is to help biologists in giving an estimate of the number of starfish present in a particular area of the sea-bottom. The nature of the input images is characterised by a low signal/noise ratio and by the presence of noisy background represented by pebbles; this makes the detection a non-trivial task. The procedure we use is a chain of several steps that starts from the extraction of the area of interest and ends with a classifier and a tracker providing the necessary information for counting the starfish present in the scene.","2003","20","3","2025-12-02","https://university.edu/papers/c96a037f-674b-44fd-8333-8f38cb91c117.pdf");
INSERT INTO Paper VALUES ("622","Reconfiguring Ordered Bases of a Matroid","For a matroid with an ordered (or 'labelled') basis, a basis exchange step removes one element with label $l$ and replaces it by a new element that results in a new basis, and with the new element assigned label $l$. We prove that one labelled basis can be reconfigured to another if and only if for every label, the initial and final elements with that label lie in the same connected component of the matroid. Furthermore, we prove that when the reconfiguration is possible, the number of basis exchange steps required is $O(r^{1.5})$ for a rank $r$ matroid. For a graphic matroid we improve the bound to $O(r \log r)$.","2016","16","1","2025-12-02","https://university.edu/papers/90ca7c71-a732-4591-820c-2fd6c2982297.pdf");
INSERT INTO Paper VALUES ("623","A novel approach based on Support Vector Machines for automatic speaker identification","Over the past decade, the field of automatic speaker recognition has been the subject of extensive research looking for an efficient determination of a person's identity. Despite the essential role played by acoustic characteristics in order to discriminate between speakers. The research of discriminative information about a person remains a major challenge. The main objective of this paper is to present a new approach employing additional information which is dialect detection with a novel parameterization of the speech to improve the task of speaker identification. The superiority of the proposed system has been demonstrated by different kernels function of Support Vector Machines (SVM) with speakers taken from TIMIT database.","2015","16","2","2025-12-02","https://university.edu/papers/a3d0575c-17c4-4523-8e7b-bf708c0cbb5f.pdf");
INSERT INTO Paper VALUES ("624","A single-electron-transistor logic gate family and its application - Part I: basic components for binary, multiple-valued and mixed-mode logic","This paper presents a model-based study of an SET (single-electron-transistor) logic gate family for synthesizing binary and MV (multiple-valued) logic circuits. The use of SETs combined with MOS transistors allows a compact realization of basic logic functions that exhibit periodic transfer characteristics. These basic SET logic gates are useful for implementing binary logic circuits, MV logic circuits and binary-MV-mixed logic circuits in a highly flexible manner. As an example, this paper describes the design of various parallel counters for carry-propagation-free arithmetic, where MV signals are effectively used to achieve higher functionality with lower hardware complexity.","2004","16","1","2025-12-02","https://university.edu/papers/972ab446-ab89-40c1-b3c9-813b4dd85982.pdf");
INSERT INTO Paper VALUES ("625","Skill grouping method: Mining and clustering skill differences from body movement BigData","Capturing human movement has become available in detail due to the advancement of motion sensor technology integrated by micro-machine and also due to the one of optical recording by high speed and high resolution image sensors. Therefore, we can easily record the human activity as the body movement BigData and analyze it to quest skill to become an expert of a target body movement. Especially, in the sports activity, the quest for becoming an expert athlete has been tried by using a mathematical model of an ideal body movement experienced from the biomechanics approach. The skill is discussed by comparing the differences from the predicted coordinates of body parts captured during the target performance. However, the approach potentially includes difficulties such as modeling the body control from the dynamics system for all human movements. And also the approach needs for adjusting jitters of the individual characteristics. Therefore, when applying the conventional approach, we must discuss a huge number of combinations of mathematical models and then we would find a model for the ideal body movement. To overcome the difficulty, this paper proposes an approach to visualize skill differences among experts and beginners from the BigData called the skill grouping method. It exploits the skill groups clustered by machine learning approach based on a kernel method. This paper shows applications of the skill grouping method from sports activities. Those show validities for finding the skill differences comparing to the BigData of skillful athletes, and also the one for managing skill transition of an athlete in a timeline.","2015","2","1","2025-12-02","https://university.edu/papers/ee91b093-60cd-47e8-a073-a8eebcba634a.pdf");
INSERT INTO Paper VALUES ("626","Self-noise free second-order carrier phase synchronization of MSK-type signals","In this paper we study from a theoretical and practical perspective the problem of nondata-aided (NDA) carrier phase recovery with MSK-type modulations. As suggested in previous works, the optimal ML estimator for low SNRs is quadratic on the received data. However, self-noise limits its performance in the medium-to-high SNR interval. To overcome this limitation, we have deduced optimal second-order schemes for the whole SNR range. The proposed estimator is asymptotically efficient when the SNR is low and cancels out the self-noise at high SNRs. Closed-form expressions are obtained for the high-SNR asymptotic case and a complete discussion is provided on its applicability in closed-loop and feed-forward schemes.","2004","19","3","2025-12-02","https://university.edu/papers/4f41d642-2174-45e9-9e51-06eaf11c567c.pdf");
INSERT INTO Paper VALUES ("627","Theoretical approach to characterize the non-Markovianity and diffusion through the influx of the information","In this paper, we study the Fisher information for a quantum system consisting of two identical qubits, each of them locally interacting with a bosonic reservoir in the same environment for non-Markovian open, dissipative quantum system. Based on the influx of the information, we propose an information-theoretical approach for characterizing the time-dependent memory effect of environment and diffusion function under the effect of the physical parameters. More precisely, an interesting monotonic relation between the time derivative of quantum Fisher information (QFI) and diffusion function behavior is observed during the time evolution. The phenomenon is that the QFI, namely the precision of estimation, changes dramatically with the environment structure. The dependence of the physical parameters shows that the increasing in the temperature will damage the amount of the QFI with respect of the ratio between the reservoir cutoff frequency and the system oscillation frequency.","2016","8","2","2025-12-02","https://university.edu/papers/a4eeb77d-8f98-49b6-8b37-9b66a1bd101b.pdf");
INSERT INTO Paper VALUES ("628","Coordinated Interference Mitigation Precoding in Unsynchronized Small Cell LTE Networks","Next generation long term evolution (LTE) systems evolve towards small cell networks (SCNs) to enable the tremendous data growth through extreme frequency reuse. However, shrinking the cell size to boost the spectral efficiency comes at the expense of increased co-channel interference (CCI) and is the dominant limiting factor from achieving higher network capacities. Consequently, downlink (DL) scenarios in the cell edge become particularly crucial, as the user equipment (UE) is typically surrounded with multiple interfering small cells. To overcome this limitation, in this paper we focus on cooperative interference mitigation schemes where UEs in good channel condition empower the cell edge UE to mitigate the CCI through linear precoding schemes. We provide a practical realization of the cooperative interference mitigation precoding scheme and determine the set of reference signal configuration to enable the promised performance in unsynchronized SCNs with varying timing offsets (TOs) among the receive signals. With simulation results at the link level, we show that estimating and compensating the TO reliable channel state information (CSI) can be achieved for the non- colliding CSI mapping scheme and as a result near optimum DL transmission can be achieved at the cell edge UE in practical SCNs.","2014","5","1","2025-12-02","https://university.edu/papers/177e39c5-73bc-494f-96bf-fffd162063d0.pdf");
INSERT INTO Paper VALUES ("629","Meaning of dataflow diagram and entity life history-a systems theoretic foundation for information systems analysis. II","For part I see ibid., p.1-10. Dataflow diagrams and entity life histories are widely-used tools in information systems methodologies. The tools are far more effective than natural language, though their meanings have not yet been clarified. This paper shows how the model developed in part I enables formal characterization of information systems methodologies. That is, it elaborates the meaning of DFDs and ELHs by providing a concrete example throughout. The characterization of DFDs establishes an explicit correspondence between the static structure of a business transaction system and a DFD. This correspondence illustrates the necessary components in designing the file structure of a business system. The ELH of a business system is described as the set of sequences of the system's transactions. Black hole and franchise business systems can be characterized by sequences, while the ELH of a general business system partially defines its dynamic structure.","1997","4","3","2025-12-02","https://university.edu/papers/8506e1da-8e14-4b6b-8fb0-42d734d1fdb6.pdf");
INSERT INTO Paper VALUES ("630","Implementing linked widgets: lessons learned for linked data developers","Seven years after Linked Data has been introduced as a concept to publish data on the web, an abundant cloud of Linked Open Data (LOD) built upon standard web technologies has emerged. To facilitate and encourage widespread use of that data, a critical step is now to streamline the process for creating applications on top of LOD. This paper discusses lessons learned while developing an open standards-based platform that aims to achieve that by means of Linked Widgets. Whereas resources are already connected in the LOD cloud, Linked Widgets in a similar vein aim to alleviate LOD application development in an open and interlinked fashion. Through reuse, we aim to foster both users' and developers' productivity and creativity.","2014","11","4","2025-12-02","https://university.edu/papers/f43b0a59-b25a-45c7-864e-77c0eb16b35b.pdf");
INSERT INTO Paper VALUES ("631","Logical Information Systems: from Taxonomies to Logics","Dynamic taxonomies have been proposed as a solution for combining querying and navigation, offering both expressivity and interactivity. Navigation is based on the filtering of a multidimensional taxonomy w.r.t. query answers, which helps users to focus their search. We show that properties that are commonly used only in queries can be integrated in taxonomies, and hence in navigation, by the use of so-called logics. Hand-designed taxonomies and concrete domains (e.g., dates, strings) can be combined so as to form complex taxonomies. For instance, valued attributes can be handled, and different roles between documents and locations can be distinguished. Logical Information Systems (LIS) are characterized by the combination of querying and navigation, and the systematic use of logics.","2007","16","3","2025-12-02","https://university.edu/papers/ff58e571-ceb5-4905-9600-11b2ba0ec9c6.pdf");
INSERT INTO Paper VALUES ("632","A Graph-Based Approach to String Regeneration","The string regeneration problem is the problem of generating a fluent sentence from a bag of words. We explore the Ngram language model approach to string regeneration. The approach computes the highest probability permutation of the input bag of words under an N-gram language model. We describe a graph-based approach for finding the optimal permutation. The evaluation of the approach on a number of datasets yielded promising results, which were confirmed by conducting a manual evaluation study.","2014","18","3","2025-12-02","https://university.edu/papers/781ad5f0-8c36-4173-8970-7bb381ea5bdd.pdf");
INSERT INTO Paper VALUES ("633","Transient performance of a CSMA system under temporary overload conditions","Effects of impulsive arrivals of packets on the performance of carrier-sense multiple-access (CSMA) protocols are studied. A deterministic dynamic system is proposed to approximate the imbedded Markovian chain model of the CSMA system. Based on this approximation, the probability of overloading of the CSMA system due to impulsive input can be estimated, and the trajectory of the system states can be calculated. For engineering application purposes, a relaxation time is defined. Simulations are carried out which support the above-mentioned approaches. >","1990","16","3","2025-12-02","https://university.edu/papers/8a094dc9-d6e0-49fb-bba4-335287f22a85.pdf");
INSERT INTO Paper VALUES ("634","UAV Attitude estimation by vanishing points in catadioptric images","Unmanned aerial vehicles (UAV) are the subject of an increasing interest in many applications and a key requirement is the stabilization of the vehicle. Some previous works have suggested using catadioptric vision, instead of traditional perspective cameras, in order to gather much more information from the environment and therefore improve the robustness of the UAV attitude estimation. This paper belongs to a series of recent publications of our research group concerning catadioptric vision for UAVs. Currently, we focus on the estimation of the complete attitude of a UAV flying in urban environment. In order to avoid the limitations of horizon-based approaches, the difficulties of traditional epipolar methods (such as rotation-translation ambiguity, lack of features, retrieving motion parameters from matrix decomposition, etc..) and improve UAV dynamic control, we suggest computing infinite homography. We show how catadioptric vision plays a key role to: first, extract a large number of lines, second robustly estimate the associated vanishing points and third, track them even during long video sequences. Therefore it is not only possible to estimate the relative rotation between consecutive frames but also compute the absolute rotation between two distant frames without error accumulation. Finally, we present some experimental results with ground truth data to demonstrate the accuracy and the robustness of our method.","2008","12","4","2025-12-02","https://university.edu/papers/a7dd0055-6032-4b7c-abc9-1cb350143ae0.pdf");
INSERT INTO Paper VALUES ("635","Revealing Hidden 3-D Reflection Symmetry","Reflection symmetry is present in most of the man-made or naturally formed objects. In computer vision, real-world scenes are represented by dense 3-D models or by 2-D projections, such as images captured by cameras. Most of the existing methods either detect reflection symmetry from dense 3-D models or 2-D projections. However, generating a dense 3-D model is a computationally expensive process and reflection symmetry may not be evident in any of the 2-D views obtained through projections. In this letter, we propose an energy minimizationbased approach to detect the reflection symmetry present in the object from its multiple 2-D projections captured from different viewpoints and the sparse 3-D model obtained using these projections. The proposed approach only estimates the sparse 3-D model and utilizes content of the images in terms of local scale invariant features. The energy minimization problem reduces to the problem of finding the eigenvector corresponding to the smallest eigenvalue of a small matrix, thereby leading to reduction in computations.","2016","1","3","2025-12-02","https://university.edu/papers/6f0baab2-c1a8-4fae-80ac-5ef17dfa6e37.pdf");
INSERT INTO Paper VALUES ("636","Knowledge management of cyber security expertise: an ontological approach to talent discovery","Cyber security is a dynamic knowledge environment, where attracting talented people is paramount. However, current initiatives do not always use mechanisms able to search for suited individuals. Approaching cyber security as an organisation can help to manage capabilities and improve domain-oriented talent discovery. This paper presents an ontological approach to support talent discovery as a means of improving allocation of expertise for cyber security projects. A case study is conducted among experts in a cyber security community. Our method is capable of selecting, ranking and evaluating experts given a set of criteria specified in a project profile. The approach combines values of quantitative and qualitative nature provided by the profile owner and derived from external appraisals. Further, the ontology model delivers a systematic integration of talent practices, which embeds a feedback loop that favours ongoing continuous improvement. The model was successfully experimented and further appraised in terms of acceptance by a board of experts.","2016","10","3","2025-12-02","https://university.edu/papers/2a98b17d-119a-42fc-ab32-d5c401738e5a.pdf");
INSERT INTO Paper VALUES ("637","Robust Quadratic-Optimal Control of TS-Fuzzy-Model-Based Dynamic Systems With Both Elemental Parametric Uncertainties and Norm-Bounded Approximation Error","This paper considers the design problem of the robust quadratic-optimal parallel-distributed-compensation (PDC) controllers for Takagi-Sugeno (TS) fuzzy-model-based control systems with both elemental parametric uncertainties and norm-bounded approximation error. By complementarily fusing the robust stabilizability condition, the orthogonal functions approach (OFA), and the hybrid Taguchi genetic algorithm (HTGA), an integrative method is presented in this paper to design the robust quadratic-optimal PDC controllers such that 1) the uncertain TS-fuzzy-model-based control systems can be robustly stabilized, and 2) a quadratic integral performance index for the nominal TS-fuzzy-model-based control systems can be minimized. In this paper, the robust stabilizability condition is proposed in terms of linear matrix inequalities (LMIs). By using the OFA and the LMI-based robust stabilizability condition, the robust quadratic-optimal PDC control problem for the uncertain TS-fuzzy-model-based dynamic systems is transformed into a static constrained-optimization problem represented by the algebraic equations with constraint of LMI-based robust stabilizability condition, thus greatly simplifying the robust optimal PDC control design problem. Then, for the static constrained-optimization problem, the HTGA is employed to find the robust quadratic-optimal PDC controllers of the uncertain TS-fuzzy-model-based control systems. Two design examples of the robust quadratic-optimal PDC controllers for an uncertain inverted pendulum system and an uncertain nonlinear mass-spring-damper mechanical system are given to demonstrate the applicability of the proposed integrative approach.","2009","17","4","2025-12-02","https://university.edu/papers/652378ea-4ebb-4777-8c89-e66ba02583a1.pdf");
INSERT INTO Paper VALUES ("638","Free Gait — An architecture for the versatile control of legged robots","This paper introduces Free Gait, a software framework for the control of robust, versatile, and task-oriented control of legged robots. In contrast to common hardware abstraction layers, this work focusses on the description and execution of generic whole-body motions (whole-body abstraction layer). The motion generation and motion execution algorithms are connected through the Free Gait API. This facilitates the development and execution of higher level behaviors and motion planning algorithms. The API is structured to accommodate a variety of task-space control commands. With these, the framework is applicable to intuitive tele-operation of the robot, scripting of user defined behaviors, and fully autonomous operation with motion planners. The defined motion plans are tracked with a feedback whole-body controller to ensure accurate and robust motion execution. We use Free Gait with our quadrupedal robot ANYmal and present results for rough terrain climbing, whole-body stair scaling, and special motions such as push-ups and squad jumps. Free Gait is available open-source and compatible with any type of legged robot, independent of the number of legs and joints.","2016","4","3","2025-12-02","https://university.edu/papers/e94627e3-bbe3-482b-8e62-3ec24c86658b.pdf");
INSERT INTO Paper VALUES ("639","Admittance Design for Assembly of Polyhedral Parts with Modeling Errors","This paper describes a new method of designing admittance for robotic assembly involving polyhedral parts with geometrical modeling errors as well as finite positioning errors and friction between the parts. First, an approach to de signing admittance is illustrated. Then, the detailed procedure for designing admittance robust to the errors is presented. Finally, the design method is applied to a mating task to show the effectiveness of the proposed method.","2005","17","1","2025-12-02","https://university.edu/papers/9812c0a5-c981-4d71-bcc8-bf2e66a72f9f.pdf");
INSERT INTO Paper VALUES ("640","Exposing library holdings metadata in RDF using schema.org semantics","Libraries have been busy transforming and publishing their data as linked open data by testing already existing semantics and developing new sets of semantics. So far, most of the efforts have focused on the bibliographic data, not the holdings and item related data that are unique to individual libraries and that help users access the information resources they need. The University of Illinois at Urbana-Champaign Library experimented with a subset of its bibliographic records (5.4 million) describing print resources and associated holdings data to examine options and best practices so far identified for expressing library holdings data using schema.org semantics. The experimentation suggests that the mappings for holdings data recommended by the BibExtend Community Group are in some ways incomplete and that some proposed uses of schema.org types and properties to describe library holdings go beyond current schema.org definitions. Existing schema.org enumerations should be extended (e.g., regarding availability) to better describe library use cases, and some extensions to schema.org are needed to fully describe library holdings data and to maximize their utility. This paper highlights issues, suggests potential extensions identified during the transformation to schema.org semantics, and discusses options to make essential library holdings data fully visible as linked open data.","2015","5","4","2025-12-02","https://university.edu/papers/e5302a5d-bdcb-495a-ae69-84170f38a226.pdf");
INSERT INTO Paper VALUES ("641","Marketing and MIS during times of resource scarcity","MIS managers generally have not stressed the marketing aspects of their operations. A more widespread concern is with the shortage of systems analyst and programmer resources. In an effort to learn how one group of MIS managers views their marketing responsibilities and practices in a shortage era, a study was conducted and the results were used to describe both short term and long term MIS marketing plans. These plans are developed by identifying critical areas in the organization in light of corporate objectives, user needs, and MIS resources.","1982","8","2","2025-12-02","https://university.edu/papers/cdfa275a-69a3-4a41-910c-03610fa23cff.pdf");
INSERT INTO Paper VALUES ("642","Quality-Aware and Fine-Grained Incentive Mechanisms for Mobile Crowdsensing","Limited research efforts have been made for Mobile CrowdSensing (MCS) to address quality of the recruited crowd, i.e., quality of services/data each individual mobile user and the whole crowd are potentially capable of providing, which is the main focus of the paper. Moreover, to improve flexibility and effectiveness, we consider fine-grained MCS, in which each sensing task is divided into multiple subtasks and a mobile user may make contributions to multiple subtasks. In this paper, we first introduce mathematical models for characterizing the quality of a recruited crowd for different sensing applications. Based on these models, we present a novel auction formulation for quality-aware and fine-grained MCS, which minimizes the expected expenditure subject to the quality requirement of each subtask. Then we discuss how to achieve the optimal expected expenditure, and present a practical incentive mechanism to solve the auction problem, which is shown to have the desirable properties of truthfulness, individual rationality and computational efficiency. We conducted trace-driven simulation using the mobility dataset of San Francisco taxies. Extensive simulation results show the proposed incentive mechanism achieves noticeable expenditure savings compared to two well-designed baseline methods, and moreover, it produces close-to-optimal solutions.","2016","12","4","2025-12-02","https://university.edu/papers/e29e60ad-d799-4c38-940f-90ea76784973.pdf");
INSERT INTO Paper VALUES ("643","Interval-Based Linear Hybrid Dynamical System for Modeling Cross-Media Timing Structures in Multimedia Signals","In this paper, we propose a computational scheme named an interval-based linear hybrid dynamical system (ILHDS) to represent complex dynamic events based on temporal intervals, each of which is characterized by linear dynamics and its duration. We then propose a cross-media timing-structure model to represent dynamic structures among multiple media signals based on the relation of temporal intervals described by multiple ILHDSs. To evaluate the proposed scheme, we conducted experiments on media conversion that generates lip video from an input audio signal.","2007","1","2","2025-12-02","https://university.edu/papers/9f8fd8f6-2f1c-40fb-abef-ca7c1417e6ce.pdf");
INSERT INTO Paper VALUES ("644","Achievable throughput in two-scale wireless networks","We propose a new model of wireless networks which we refer to as 'two-scale networks.' At a local scale, characterised by nodes being within a distance r, channel strengths are drawn independently and identically from a distance-independent distribution. At a global scale, characterised by nodes being further apart from each other than a distance r, channel connections are governed by a Rayleigh distribution, with the power satisfying a distance-based decay law. Thus, at a local scale, channel strengths are determined primarily by random effects such as obstacles and scatterers whereas at the global scale channel strengths depend on distance. For such networks, we propose a hybrid communications scheme, combining elements of distance-dependent networks and random networks. For particular classes of two-scale networks with N nodes, we show that an aggregate throughput that is slightly sublinear in N, for instance, of the form N/ log 4  N is achievable. This offers a significant improvement over a throughput scaling behaviour of O(radic(N)) that is obtained in other work.","2009","19","4","2025-12-02","https://university.edu/papers/4de3edfd-ab34-4395-9547-64c16ff81315.pdf");
INSERT INTO Paper VALUES ("645","Rule-based data-driven analytics for Wide-Area fault detection using synchrophasor data","Synchrophasor technology, also known as Wide-Area Monitoring System (WAMS) technology, utilizes Phasor Measurement Unit (PMU) to monitor real-time system data, which can provide unique insights into the operation of a power grid. In this paper, a rule-based data-driven analytics method for wide-area fault detection in a power system using synchrophasor data is proposed. As a data-driven approach, this method relies on rules created using PMU measurement data, and does not require knowledge of the power system's topology and model. It can detect fault location (bus and line) and fault type for a particular fault event. Three common types of short circuit faults in a power grid, single-line-to-ground (SLG), line-to-line (LL), and three phase faults, can be identified using the proposed method. Fault thresholds used in rules are determined based on theoretical values and recorded PMU data during fault events in Bonneville Power Administration (BPA)'s large power grid. The proposed method is validated by comparing with the recorded field data for fault events provided by BPA. It is found that it can effectively detect most faults with a great accuracy. It has been developed into a software program, and can be readily used by utility companies.","2016","12","2","2025-12-02","https://university.edu/papers/c1dacc98-85bc-4f6c-af88-6160bbae58f4.pdf");
INSERT INTO Paper VALUES ("646","Hidden heterogeneity in manpower systems: A Markov-switching model approach","In modeling manpower systems, it is of crucial importance to deal with heterogeneity. Until recently, manpower models are dealing with heterogeneity due to observable sources, neglecting heterogeneity due to latent sources. In this paper a two-step procedure is introduced. In the first step personnel groups homogeneous with respect to the transition probabilities are determined in a classical way by taking into account the observable sources of heterogeneity. In the second step heterogeneity caused by latent sources is handled. A multinomial Markov-switching manpower model is introduced that deals with heterogeneity due to latent sources for the internal flows as well as for the wastage flows. The model incorporates the mover-stayer principle. A re-estimation algorithm is presented to estimate the parameters of the Markov-switching manpower model. The switching approach offers a methodology to build a Markov model with personnel groups as states that are more homogeneous, and therefore can contribute to a better validity of the manpower model.","2011","3","2","2025-12-02","https://university.edu/papers/a7e088ad-5514-459d-8caf-dafcd11a85fc.pdf");
INSERT INTO Paper VALUES ("647","Land surface emissivity retrieval from HJ-1B satellite data using a combined method","Land surface emissivity (LSE) is an essential parameter in deriving land surface temperature form remote sensing data. According to the single channel characteristics of HJ-1B Infrared Scanner (IRS), a combined method for estimating LSE was proposed based on the vegetation cover method and classification-based method. The proposed method requires inputs such as static land cover product, vegetation and ground emissivity for each land cover and vegetation cover product. The sensitivity analysis indicates that this method could achieve good accuracy with LSE relative errors vary from 0.4% to 2%.","2011","13","1","2025-12-02","https://university.edu/papers/e3d44053-eaaa-4175-a654-8ccd7dd09533.pdf");
INSERT INTO Paper VALUES ("648","GPU-accelerated scene categorization under multiscale category-specific visual word strategy","We utilize GPU to accelerate an essential component for computer vision and multimedia information retrieval, i.e. scene categorization. To construct bag of word models, we modify calculation of Euclidean distance so that feature clustering and visual word quantization can be processed in a parallel manner. We provide details of GPU implementations and conduct comprehensive experiments to verify the efficiency of GPU on multimedia analysis.","2012","9","4","2025-12-02","https://university.edu/papers/ce13bc06-7572-49e6-a3b0-935062031d3c.pdf");
INSERT INTO Paper VALUES ("649","Towards packet-less ultrasonic sensor networks for energy-harvesting structures","This paper proposes and evaluates an energy-aware pulse switching architecture for a through-substrate ultrasonic sensor network. The network is run from vibration energy harvested on an airplane stabilizer structure, whose health is monitored using the through-substrate network. Pulse- switching-based protocols use single pulses instead of multi-bit packets for information delivery with ultra-high energy-efficiency. Pulse switching using ultrasound is particularly well suited for event reporting through metal / composite substrates used in structures such as bridges, aircraft wings, etc. This can eliminate the need for out-of-substrate radio or wired links. This paper presents a large-scale simulation model in which structural vibration modeling using finite element methods, energy harvesting modeling from such vibrations, and energy-aware pulse networking models are integrated for end-to-end architecture level performance evaluation. Simulation results are used for demonstrating the sensitivity of network performance to key system parameters, namely, structural vibration intensity, energy harvesting efficiency of the used piezoelectric material, and the energy storage capacity at the pulse switching sensor nodes. In addition to event reporting delay, the impacts of pulse loss have been thoroughly characterized using the integrated simulator.","2017","17","2","2025-12-02","https://university.edu/papers/e43e3888-f08c-4838-8746-719567ae9e6d.pdf");
INSERT INTO Paper VALUES ("650","Self-aligned double patterning aware pin access and standard cell layout co-optimization","Self-Aligned Double Patterning (SADP) is being considered for use at the 10$nm$ technology node and below for routing layers with pitches down to ~50nm because it has better LER and overlay control compared to other multiple patterning candidates. To date, most of the SADP-related literature has focused on enabling SADP-legal routing in physical design tools while few attempts have been made to address the impact SADP routing has on local, standard cell (SC) I/O pin access. In this paper, we present the first study on SADP-aware pin access and layout optimization at the SC level. Accounting for SADP-specific design rules, we propose a coherent framework that uses Mixed Integer Linear Programming (MILP) and branch and bound method to simultaneously optimize SADP-based local pin access and within-cell connections. Our experimental results show that, compared with the conventional approach, our framework effectively improves pin access of the standard cells and maximizes the pin access flexibility for routing.","2014","9","3","2025-12-02","https://university.edu/papers/d5a613cc-4e67-4e6b-9ef7-1d2e08f58c9b.pdf");
INSERT INTO Paper VALUES ("651","Integration-Enhanced Zhang Neural Network for Real-Time-Varying Matrix Inversion in the Presence of Various Kinds of Noises","Matrix inversion often arises in the fields of science and engineering. Many models for matrix inversion usually assume that the solving process is free of noises or that the denoising has been conducted before the computation. However, time is precious for the real-time-varying matrix inversion in practice, and any preprocessing for noise reduction may consume extra time, possibly violating the requirement of real-time computation. Therefore, a new model for time-varying matrix inversion that is able to handle simultaneously the noises is urgently needed. In this paper, an integration-enhanced Zhang neural network (IEZNN) model is first proposed and investigated for real-time-varying matrix inversion. Then, the conventional ZNN model and the gradient neural network model are presented and employed for comparison. In addition, theoretical analyses show that the proposed IEZNN model has the global exponential convergence property. Moreover, in the presence of various kinds of noises, the proposed IEZNN model is proven to have an improved performance. That is, the proposed IEZNN model converges to the theoretical solution of the time-varying matrix inversion problem no matter how large the matrix-form constant noise is, and the residual errors of the proposed IEZNN model can be arbitrarily small for time-varying noises and random noises. Finally, three illustrative simulation examples, including an application to the inverse kinematic motion planning of a robot manipulator, are provided and analyzed to substantiate the efficacy and superiority of the proposed IEZNN model for real-time-varying matrix inversion.","2016","11","4","2025-12-02","https://university.edu/papers/de216232-6d34-4f9c-8138-a2edd6fc7bd1.pdf");
INSERT INTO Paper VALUES ("652","Incremental augmented complex adaptive IIR algorithm for training widely linear ARMA model","In this paper, we propose a distributed adaptive learning algorithm to train the coefficients of a widely linear autoregressive moving average model by measurements collected by the nodes of a network. We assume that each node uses the augmented complex adaptive infinite impulse response (ACA-IIR) filter as the learning rule, and nodes interact with each other under an incremental mode of cooperation. To derive the proposed algorithm, called the incremental ACAIIR (IACA-IIR), we firstly formulate the distributed adaptive learning problem as an unconstrained minimization problem. Then, we apply stochastic gradient optimization argument to solve it and derive the proposed algorithm. We further find the step size range where the stability of the proposed algorithm is guaranteed. We also introduce a reduced-complexity version of the IACA-IIR algorithm. Since the proposed algorithm relies on the augmented complex statistics, it can be used to model both types of complex-valued signals (proper and improper signals). To evaluate the performance of the proposed algorithm, we use both synthetic and real-world complex signals in our simulations. The results exhibit superior performance of the proposed algorithm over the non-cooperative ACA-IIR algorithm.","2017","19","4","2025-12-02","https://university.edu/papers/564cf28a-45f1-4a93-84f1-2b8eaf50ff68.pdf");
INSERT INTO Paper VALUES ("653","Interpretable Prediction of Protein Stability Changes upon Mutation by Using Decision Tree","For protein stability changes upon mutation, an accurate predictor with linguistic interpretability is beneficial to protein designs. Traditional analysis based on linear correlation between predicted and experimental data reveals their primitive relationships. Recently, some machine learning techniques such as artificial neural network (ANN)-based methods were applied to find an accurate predictor. However, the ANN-predictor without interpretability is insufficient in knowledge discovery. This paper proposes an interpretable predictor using a rule-based decision tree method (named iPTREE) for accurately predicting protein stability changes upon single point mutations. Besides being a sign predictor, iPTREE can be used both as a model for verifying attributes effect, and as a rules miner in the protein stability change study. iPTREE is depending on features including mutation type (deleted and introduced residues), the relative solvent accessibility value (RSA), the experimental conditions (pH and temperature) and the local spatial environment. To evaluate the performance of iPTREE, a thermodynamic dataset consisting of 1615 mutations generated from ProTherm is used. The computer simulation shows that iPTREE has an accurate prediction for the direction of stability changes as high as 87%, which is significantly better than the ANN-predictor for the same features.","2005","9","3","2025-12-02","https://university.edu/papers/60af9c8c-882a-407c-8397-91f19a43c471.pdf");
INSERT INTO Paper VALUES ("654","Genetic algorithms and grid technologies in clustering, an example: Clustering of images","Abstract#R##N##R##N#In this paper we describe the development of an image retrieval system that is able to browse, cluster and classify large digital image databases. This work was motivated by the projects of the Visualization Centre of the Eotvos Lorand University, where such problems are to be solved. The system's functions are based on a Gaussian mixture model (GMM) representation of the images. Image matching is done by the distance measure of the representations, based on the approximation of the Kullback–Leibler divergence of the GMMs. The GMMs are estimated with an improved expectation maximization (EM) algorithm that avoids convergence to the boundary of the parameter space. These form the basis of the clustering, where a variant of a genetic algorithm is used. The suggested algorithm is able to work with a large number of images or objects, the grid technology is a useful tool for generating several runs simultaneously. Copyright © 2008 John Wiley & Sons, Ltd.","2008","7","1","2025-12-02","https://university.edu/papers/f64ebd49-bea6-4492-9859-8097e8518aae.pdf");
INSERT INTO Paper VALUES ("655","Fast affinity propagation clustering based on incomplete similarity matrix","Affinity propagation (AP) is a recently proposed clustering algorithm, which has been successful used in a lot of practical problems. Although effective in finding meaningful clustering solutions, a key disadvantage of AP is its efficiency, which has become the bottleneck when applying AP for large-scale problems. In the literature, most of the methods proposed to improve the efficiency of AP are based on implementing the message-passing on a sparse similarity matrix, while neither the decline in effectiveness nor the improvement in efficiency is theoretically analyzed. In this paper, we propose a two-stage fast affinity propagation (FastAP) algorithm. Different from previous work, the scale of the similarity matrix is first compressed by selecting only potential exemplars, then further reduced by sparseness according to k nearest neighbors. More importantly, we provide theoretical analysis, based on which the improvement of efficiency in our method is controllable with guaranteed clustering performance. In experiments, two synthetic data sets, seven publicly available data sets, and two real-world streaming data sets are used to evaluate the proposed method. The results demonstrate that FastAP can achieve comparable clustering performances with the original AP algorithm, while the computational efficiency has been improved with a several-fold speed-up on small data sets and a dozens-of-fold on larger-scale data sets.","2017","19","3","2025-12-02","https://university.edu/papers/58bf20cf-491b-418b-8b9e-33c8ccbfa9f1.pdf");
INSERT INTO Paper VALUES ("656","Multi-sensor multi-object tracking of vehicles using high-resolution radars","Recent advances in automotive radar technology have led to increasing sensor resolution and hence a more detailed image of the environment with multiple measurements per object. This poses several challenges for tracking systems: new algorithms are necessary to fully exploit the additional information and algorithms need to resolve measurement-to-object association ambiguities in cluttered multi-object scenarios. Also, the information has to be fused if multi-sensor setups are used to obtain redundancy and increased fields of view. In this paper, a Labeled Multi-Bernoulli filter for tracking multiple vehicles using multiple high-resolution radars is presented. This finite-set-statistics-based filter tackles all three challenges in a fully probabilistic fashion and is the first Monte Carlo implementation of its kind. The filter performance is evaluated using radar data from an experimental vehicle.","2016","20","1","2025-12-02","https://university.edu/papers/2871278a-c8be-4c83-8a72-9e770a997096.pdf");
INSERT INTO Paper VALUES ("657","Minimizing Co-location Potential of Moving Entities","We study the problem of maintaining knowledge of the locations of $n$ entities that are moving, each with some, possibly different, upper bound on their speed. We assume a setting where we can query the current location of any one entity, but this query takes a unit of time, during which we cannot query any other entities. In this model, we can never know the exact locations of all entities at any one time. Instead, we wish to minimize uncertainty concerning the locations of all entities at some target time that is t units in the future. We measure uncertainty by the ply of the potential locations: the maximum over all points $x$ of the number of entities that could potentially be at $x$. Since the ply could be large for every query strategy, we analyze the performance of our query strategy in a competitive framework: we consider the worst-case ratio of the ply achieved by our strategy to the intrinsic ply (the smallest ply achievable by any strategy, even one that knows in advance the full trajectories o...","2016","14","4","2025-12-02","https://university.edu/papers/bf761a5a-514d-4aa5-9415-3cfbe7ddadbf.pdf");
INSERT INTO Paper VALUES ("658","Wireless/mobile connected entertainment [Guest editors' introduction]","New communication technologies have given rise to novel services and business models for consumer electronic devices, while low-cost wireless connectivity means have enabled ambient connectivity among mainstream consumer electronic devices. In the years to come, it is expected that new lifestyle solutions targeting mobile connected entertainment will be extended well beyond the home environment to cover in-vehicle services. Recent market forecasts validate this momentum, expecting revenues from in-car connected services to top $152 billion by 2020 [1]. As a result, automakers are pursuing innovative applications for car safety, driver assistance, and in-car well being and infotainment by directly connecting the car with the cloud (Fig. 1).","2016","19","3","2025-12-02","https://university.edu/papers/10b65872-8064-4b56-8ffb-6bcef91ef02d.pdf");
INSERT INTO Paper VALUES ("659","Istanbul Technical University at TRECVID2008.","ITU MSPR Group participates the TREC Video Retrieval Evaluation (TRECVID) in Content Based Copy Detection (CBCD) task. The system proposed by ITU MSPR consists of two main modules: Extraction of video fingerprints and search/retrieval. We propose a feature extraction scheme based on the Nonnegative Matrix Factorization(NMF)[1], which is an efficient dimension reduction technique in video processing[2]. Video fingerprint generation module takes the factorization matrices generated by NMF as its input and converts them to binary hashes by differencial coding. Extracted hashes are indexed into a database. Searching module first applies a hash matching procedure to locate potential matching points. It is followed by temporal merging that eliminates false alarms while combining subsegments. Initial results are promising for insertion of pattern, reencoding, blurring, change of gamma and noise addition. Future work will include impoving the current results and searching for robustness to geometric transformations such as shift, crop, flip and picture-in-picture.","2008","10","1","2025-12-02","https://university.edu/papers/9954602b-eb7b-4f9c-83df-0540b4fff5e7.pdf");
INSERT INTO Paper VALUES ("660","Pedestrian detection using GPU-accelerated multiple cue computation","Achieving accurate pedestrian detection for practically relevant scenarios in real-time is an important problem for many applications, while representing a major scientific challenge at the same time. In this paper we present an algorithmic framework which efficiently computes pedestrian-specific shape and motion cues and combines them in a probabilistic manner to infer the location and occlusion status of pedestrians viewed by a stationary camera. The articulated pedestrian shape is represented by a set of sparse contour templates, where fast template matching against image features is carried out using integral images built along oriented scan-lines. The motion cue is obtained by employing a non-parametric background model using the YCbCr color space. Both cues are computed and evaluated on the GPU. Given the probabilistic output from the two cues the spatial configuration of hypothesized human body locations is obtained by an iterative optimization scheme taking into account the depth ordering and occlusion status of individual hypotheses. The method achieves fast computation times even in complex scenarios with a high pedestrian density. Employed computational schemes are described in detail and the validity of the approach is demonstrated on three PETS2009 datasets depicting increasing pedestrian density. Evaluation results and comparison with state of the art are presented.","2011","1","4","2025-12-02","https://university.edu/papers/9bbb73f0-f3f0-48f9-b84f-e341aa2e3584.pdf");
INSERT INTO Paper VALUES ("661","Virtual synchronization technique with OS modeling for fast and time-accurate cosimulation","Hardware/Software cosimulation is the key process to shorten the design turn around time. We have proposed a novel technique, called virtual synchronization, for fast and time accurate cosimulation that involves interacting component simulators. In this paper, we further extend the virtual synchronization technique with OS modeling for the case where multiple software tasks are executed under the supervision of a real-time operating system. The OS modeler models the RTOS overheads of context switching and tick interrupt handling as well as preemption behavior. While maintaining the timing accuracy to an acceptable level below a few percents, we could reduce the simulation time drastically compared with existent conservative approach by removing the need of time synchronization between simulators. It is confirmed with a preliminary experiment with a multimedia example that consists of four real-life tasks.","2003","5","4","2025-12-02","https://university.edu/papers/ff7e71b0-fec7-4671-88b5-b5d64eba1e69.pdf");
INSERT INTO Paper VALUES ("662","Manipulation of 3D enveloped object","This paper discusses the manipulation of 3D enveloped object. By assigning all fingers as either the position controlled finger (P-finger) or the torque controlled finger (T-finger), we propose a method for letting the object to move in the desired direction along the surface of the P-fingers. For this purpose, we obtain the joint torque command for the T-fingers. The formulation of the total force/moment set can be applied to general 3D enveloping grasp. Also, we newly provide a sufficient condition for the total force/moment set of the object moving toward the desired direction, where it can be applied to general 3D contact configurations between the object and the P-fingers.","2002","5","3","2025-12-02","https://university.edu/papers/f6243c47-8efb-4517-bc45-784fd6345acf.pdf");
INSERT INTO Paper VALUES ("663","Fuzzy Inference Modeling with the Help of Fuzzy Clustering for Predicting the Occurrence of Adverse Events in an Active Theater of War","This study investigated the relationship between adverse events and infrastructure development projects in an active theater of war using fuzzy inference systems FIS with the help of fuzzy clustering that directly benefits from its prediction accuracy. Fourteen developmental and economic improvement projects were selected as independent variables. These were based on allocated budgets and included a number of projects from different time periods, urban and rural population density, and total number of adverse events during the previous month. A total of four outputs reflecting the adverse events in terms of the number of people killed, wounded, or hijacked and the total number of adverse events has been estimated. The performance of each model was investigated and compared to all other models with calculated mean absolute error MAE values. Prediction accuracy was also tested within ±1 difference between actual and predicted value with values around 90%. Based on the results, it was concluded that FIS is a useful modeling technique for predicting the number of adverse events based on historical development or economic project data.","2015","20","2","2025-12-02","https://university.edu/papers/3672b170-400d-4d57-81a9-8c92ededd09d.pdf");
INSERT INTO Paper VALUES ("664","Joint channel estimation and symbol detection for SFBC-OFDM systems via the EM algorithm","Joint channel estimation and symbol detection for space-frequency block coded OFDM (SFBC-OFDM) systems is considered. The expectation-maximization (EM) algorithm is employed to devise both soft-in-hard-out (SIHO) maximum likelihood (ML) iterative receivers and soft-in-soft-out (SISO) maximum a posteriori (MAP) iterative receivers for SFBC-OFDM systems. Besides the low computational complexity and fast convergence, the EM-based iterative receivers also have the ability of tracing the variation of fast fading channels, and thus provide quite satisfying performance and bandwidth efficiency even in high-vehicular-speed environment. Numerical results are provided to corroborate the theoretical designs.","2004","10","4","2025-12-02","https://university.edu/papers/a6825256-b650-4bcf-8680-bd36068ab991.pdf");
INSERT INTO Paper VALUES ("665","Measurement of grasp position by human hands and grasp criterion for two soft-fingered robot hands","In this study, grasp positions of human hands are measured for planar objects for development of a reasonable grasp criterion for a two-soft-fingered robotic hand. We first propose a grasp criterion that yields the best grasping position for a robot hand with two soft fingers. To examine the properties of this criterion with respect to some weighting coefficients included in the criterion, a grasping experiment is performed by humans for planar objects with various sizes and shapes. Results show that many observed grasping positions used by humans correspond to a set of weighting coefficients that equally weigh all the factors in the criterion. A grasping experiment using a robot has also been conducted using a set of coefficients corresponding to the equal weight; the effectiveness of the criterion was confirmed.","2009","10","1","2025-12-02","https://university.edu/papers/e24d7c23-b71e-49f8-be86-5028f026d4d6.pdf");
INSERT INTO Paper VALUES ("666","Sentential semantics for propositional attitudes","The sentential theory of propositional attitudes is very attractive to AI workers, but it is difficult to use such a theory to assign semantics to English sentences about attitudes. The problem is that a compositional semantics cannot easily build the logical forms that the theory requires. We present a new notation for a sentential theory, and a unification grammar that builds logical forms in our notation. The grammar is implemented using the standard implementation of definite clause grammars in Prolog.","1990","10","1","2025-12-02","https://university.edu/papers/7b3247ed-0203-4cff-a5ea-0e2ac36f0bff.pdf");
INSERT INTO Paper VALUES ("667","Training Two-Layered Feedforward Networks With Variable Projection Method","The variable projection (VP) method for separable nonlinear least squares (SNLLS) is presented and incorporated into the Levenberg-Marquardt optimization algorithm for training two-layered feedforward neural networks. It is shown that the Jacobian of variable projected networks can be computed by simple modification of the backpropagation algorithm. The suggested algorithm is efficient compared to conventional techniques such as conventional Levenberg-Marquardt algorithm (LMA), hybrid gradient algorithm (HGA), and extreme learning machine (ELM).","2008","15","1","2025-12-02","https://university.edu/papers/6ec91f13-8e71-4ab7-b715-7cee8303458b.pdf");
INSERT INTO Paper VALUES ("668","Orbital Angular Momentum-Based Communications With Partial Arc Sampling Receiving","A generalized signal model for multiple orbital angular momentum (OAM) mode-based radio communication combined with a novel partial arc sampling receiving (PASR) scheme for compactly receiving is proposed and mathematically analyzed. Furthermore, a near-field line-of-sight PASR radio data link using four OAM modes is experimentally demonstrated to quadruple the spectral efficiency without adding signal processing complexity at the receiving end. Experiment results show that all the four OAM channels are recovered with bit-error rates below    $ {3.8\times 10^{-3}}$   , indicating the robustness of the four-OAM-mode-PASR data link.","2016","7","3","2025-12-02","https://university.edu/papers/655b985c-ef34-41b1-a3fb-eed18a074f80.pdf");
INSERT INTO Paper VALUES ("669","Multi-objective optimization involving cost and control properties in reactive distillation processes to produce diphenyl carbonate","Polycarbonate has a very extensive commercial application thanks to its multiple physical properties. The environmental problems associated with the conventional process to obtain polycarbonate by the phosgene route has stimulated the research of intensified schemes as is the case of the reactive distillation for the synthesis of Diphenyl Carbonate (DPC). These intensified processes are complex in their structure because of the several degrees of freedom and are subject to be optimized in terms of crucial criteria such as the cost and the control properties. This work presents the multi-objective optimization involving cost and control properties of four intensified systems configurations to produce DPC: a conventional reactive distillation (CRD), a thermally coupled reactive distillation (TCRD), and two novel configurations which uses vapor recompression technology, a reactive distillation with heat integration (RDHI) through vapor recompression, and a reactive distillation with thermally coupling and heat integration (THRD) through vapor recompression. The results of the multi-objective optimization show that the tray holdups and diameter values of the columns strongly influence the control properties; thus, for large values of the tray holdups and diameters, the control properties were better. The control properties also were influenced by the presence of the interlinking streams in the reactive and separation columns, in particular, the presence of one interlinking stream tend to favor the control properties of a configuration. To close it is important to remark that the TCRD configuration was the most attractive arrangement to be implemented to produce DPC, mainly because the optimized designs showed the best control properties, and also the optimized designs achieved significant energy savings because they did not require electric power.","2016","19","1","2025-12-02","https://university.edu/papers/c3f2add7-3309-42d8-8602-16f426c6717e.pdf");
INSERT INTO Paper VALUES ("670","A productivity metric based on statistical pattern recognition","The generally accepted calculation to measure the productivity of a software engineer is based on economic theory and is borrowed from traditional product manufacturing environments. Managers often measure the productivity of a worker to determine merit-based raises or to provide feedback to workers with poor productivity. The assumption is that this calculation of a worker's productivity is directly proportional to a worker's value to the company. The motivation for the approach proposed here is that such relationship may not be algebraically captured with respect to the productivity of software engineers. To better capture the productivity of a software engineer and his value to a company, the productivity problem is reformulated here as a pattern recognition problem and solved using clustering. By defining a general productivity operator, clustering has been used to map the domain of the productivity operator to a range of productivity classes. This new approach has been successfully applied to randomly generated project data and actual project data from the NASA SATC software metric database.","2005","2","4","2025-12-02","https://university.edu/papers/64923c4a-83d0-4f0a-a6f0-de3d3d5dd419.pdf");
INSERT INTO Paper VALUES ("671","A parallel distributed algorithm for feature extraction and disparity analysis of computer images","A parallel distributed processing method for extracting features in stereo images is presented. The algorithm is edge-based and employs the epipolar constraint. First edges are detected in a multilayered network using two methods of locating the magnitude of directional first derivatives and the zero-crossing of second derivatives of smoothed images. The combined edge detection process helps to eliminate 'phantom' edges. Then features that are likely to be detectable in both images are selected. These features are edge intervals and edge orientation, that is, the intersection of image edges with the epipolar line and the corresponding slope of the edges at those points. The feature extraction process is implemented in a two-layered parallel distributed processing model. The first layer provides edge interval representations. The second layer computes a similarity of measure for each pair of primitive matches which are then forwarded to the second stage of the algorithm. The purpose of the second stage is to turn the difficult pixel correspondence problem into a constraint satisfaction problem by imposing relational constraints. This constraint satisfaction is then solved using a neural network. The results of computer simulations are presented to demonstrate the effectiveness of the approach. >","1990","10","1","2025-12-02","https://university.edu/papers/c8c9c529-ac67-4c04-a1b2-2a23eda00652.pdf");
INSERT INTO Paper VALUES ("672","First Fit bin packing: A tight analysis.","In the bin packing problem we are given an instance consisting of a sequence of items with sizes between 0 and 1. The objective is to pack these items into the smallest possible number of bins of unit size. FirstFit algorithm packs each item into the first bin where it fits, possibly opening a new bin if the item cannot fit into any currently open bin. In early seventies it was shown that the asymptotic approximation ratio of FirstFit bin packing is equal to 1.7.#R##N##R##N#We prove that also the absolute approximation ratio for FirstFit bin packing is exactly 1.7. This means that if the optimum needs OPT bins, FirstFit always uses at most \lfloor 1.7 OPT \rfloor bins.#R##N##R##N#Furthermore we show matching lower bounds for a majority of values of OPT, i.e., we give instances on which FirstFit uses exactly \lfloor 1.7 OPT \rfloor bins. #R##N##R##N#Such matching upper and lower bounds were previously known only for finitely many small values of OPT. The previous published bound on the absolute approximation ratio of FirstFit was 12/7 \approx 1.7143. Recently a bound of 101/59 \approx 1.7119 was claimed.","2013","14","3","2025-12-02","https://university.edu/papers/bdcd2a52-33de-4112-8e81-32b5759a63a0.pdf");
INSERT INTO Paper VALUES ("673","Enhancing a glossectomy patient's speech via GMM-based voice conversion","In this paper, we describe the use of a voice conversion algorithm for improving the intelligibility of speech by patients with articulation disorders caused by a wide glossectomy and/or segmental mandibulectomy. As a first trial, to demonstrate the difficulty of the task at hand, we implemented a conventional Gaussian mixture model (GMM)-based algorithm using a frame-by-frame approach. We compared voice conversion performance among normal speakers and one with an articulation disorder by measuring the number of training sentences, the number of GMM mixtures, and the variety of speaking styles of training speech. According to our experiment results, the mel-cepstrum (MC) distance was decreased by 40% in all pairs of speakers as compared with that of pre-conversion measures; however, at post-conversion, the MC distance between a pair of a glossectomy speaker and a normal speaker was 28% larger than that between pairs of normal speakers. The analysis of resulting spectrograms showed that the voice conversion algorithm successfully reconstructed high-frequency spectra in phonemes /h/, /t/, /k/, /ts/, and /ch/; we also confirmed improvements of speech intelligibility via informal listening tests.","2016","1","1","2025-12-02","https://university.edu/papers/a837a7e5-a06a-4c2a-8679-815858fc2252.pdf");
INSERT INTO Paper VALUES ("674","Accuracy Improvement of Extremum Seeking Control","In this work, we present a modification for the classic and phasor extremum seeking control algorithms in order to improve the accuracy by removing or reducing the convergence error. The modulation signals were replaced by a sum of sinusoids in order to remove the equilibrium shift in the controlled variable of the averaged system. The convergence error is calculated as a function of the number of sinusoids used in the modulation signal. A simulation example is presented to illustrate the improvement.","2017","9","2","2025-12-02","https://university.edu/papers/fbd70953-60db-49ba-8a0b-c660e7dfdf20.pdf");
INSERT INTO Paper VALUES ("675","Hardware task migration module for improved fault tolerance and predictability","Task migration has been applied as an efficient mechanism to handle faulty processing elements (PEs) in Multi-processor Systems-on-Chip (MPSoCs). However, current task migration solutions are either implemented or emulated in software, compromising intrinsically the predictability and degrading the system robustness. Moreover, the initial placement and mapping of the tasks in the MPSoC plays an important role in minimising the task migration overhead and overall system energy. This paper proposes a hardware-based task migration scheme for MPSoC systems, offering better predictability as well as an improved method of fault tolerance. The proposed scheme intelligently generates an initial placement for the tasks with improved fault tolerance and stores these mappings on a hash map, which is looked up at run-time as and when faults occur. Compared with the state-of-the-art, our scheme performs up to 1500× faster task migration without any significant overheads.","2015","12","3","2025-12-02","https://university.edu/papers/0b73a357-35c9-4a3d-a27b-bf4a087c192a.pdf");
INSERT INTO Paper VALUES ("676","Measuring the Usage of Repositories via a National Standards-based Aggregation Service: IRUS-UK","Many educational institutions have repositories for research outputs. The number of items available through institutional repositories is growing, and is expected to continue to do so due to requirements for outputs from public-funded research to be open access. But how much usage are institutional repositories and their individual items getting? The Jisc-funded service IRUS-UK is designed to help institutions understand more about the usage of their institutional repositories. IRUS-UK collects raw usage data from participating repositories and processes these into COUNTER-compliant statistics. This provides repositories with comparable, authoritative, standards-based data and opportunities for profiling and benchmarking. It enables institutions to run reports at both repository level (e.g. total download figures) and at item level. IRUS-UK utilises a robust, multistage ingest process, validating data, stripping out robot and unusual accesses, and filtering out double clicks, to transform raw usage data into COUNTER-compliant statistics. IRUS-UK currently has data from 83 UK institutional repositories (using Eprints, DSpace and Fedora software) and has recorded over 35 million downloads since July 2012. The data from IRUS-UK can be used to provide information for management reporting, for usage monitoring, and for external reporting. Data can be viewed within the online portal, downloaded for further analysis, or harvested using the SUSHI service (NISO Z39.93). IRUS-UK is also working with and contributing to other groups and initiatives involved in a range of activities relating to usage statistics. These include: the Distributed Usage Logging/CrossRef DOI Event Tracker Working Group, OpenAIRE2020 and COAR Working Group.","2015","17","2","2025-12-02","https://university.edu/papers/0691afeb-79ab-44d6-af74-6ce1887ca0fb.pdf");
INSERT INTO Paper VALUES ("677","Partitioning a graph of bounded tree-width to connected subgraphs of almost uniform size","Assume that each vertex of a graph G is assigned a nonnegative integer weight and that l and u are nonnegative integers. One wishes to partition G into connected components by deleting edges from G so that the total weight of each component is at least l and at most u. Such an “almost uniform” partition is called an (l, u)-partition. We deal with three problems to find an (l, u)-partition of a given graph; the minimum partition problem is to find an (l, u)-partition with the minimum number of components; the maximum partition problem is defined analogously; and the p-partition problem is to find an (l, u)-partition with a fixed number p of components. All these problems are NP-complete or NP-hard, respectively, even for series-parallel graphs. In this paper we show that both the minimum partition problem and the maximum partition problem can be solved in time O(u 4 n) and the p-partition problem can be solved in time O(p 2 u 4 n) for any series-parallel graph with n vertices. The algorithms can be extended for partial k-trees, that is, graphs with bounded tree-width. © 2005 Elsevier B.V. All rights reserved.","2006","3","3","2025-12-02","https://university.edu/papers/ba54dee9-4896-4b97-a027-e6ddd0c9b959.pdf");
INSERT INTO Paper VALUES ("678","Instantaneous accounting for leaf water in X-ray fluorescence spectra of corn grown in manure- and fertilizer-amended soils","Manure-amended soils have shown a high degree of temporal and geographic variability in labile phosphorus (P). Real time information and practical ways for determining foliar composition are needed to obtain direct evidence of plant uptake, and the supplying capacity of the soil. Field and laboratory experiments were conducted to determine leaf water content effects on spectral characteristics of corn (Zea mays) uppermost leaves when grown in mineral P fertilizers- (0–250 mg P kg−1) or manure-amended soils (0, 15, and 30 kg P ha−1). In situ X-ray fluorescence scans of fresh green leaves yielded foliar P concentrations that paralleled those obtained using oven-dried harvested leaf samples. Leaf structure and size of seedlings can cause significant variations in leaf-to-spectrometer contact, inter-element interference, and leaf water content and its attenuating effects on the yield of weak fluorescence radiation of low Z-elements (<19). Intensities of scattered radiation associated with the X-ray tube anode were significantly correlated with leaf water content (θw), which was used to (i) assess crop water status and (ii) normalize fluorescence intensities of P to a common basis. The θw − P reduced concentration relationship was best-described by a sigmoidal function #R##N##R##N#y=0.12+0.94/(1+exp(-(θw-0.37)/-0.17))y=0.12+0.94/(1+exp(-(θw-0.37)/-0.17))#R##N##R##N#with r2 = 0.938 and RMSE = 0.02. Therefore, we proposed its use to obtain P concentration on a dry weight basis and unbiased estimates of crop P status. The in situ fluorescence sensing system presents a new paradigm in nutrient management to insure the sustainability of agroecosystems and development of field-specific nutrient management practices.","2016","5","2","2025-12-02","https://university.edu/papers/7a0a2554-3d18-488f-b7a9-089a4dd59483.pdf");
INSERT INTO Paper VALUES ("679","Ad-hoc wireless network coverage with networked robots that cannot localize","We study a fully distributed, reactive algorithm for deployment and maintenance of a mobile communication backbone that provides an area around a network gateway with wireless network access for higher-level agents. Possible applications of such a network are distributed sensor networks as well as communication support for disaster or military operations. The algorithm has minimalist requirements on the individual robotic node and does not require any localization. This makes the proposed solution suitable for deployment of large numbers of comparably cheap mobile communication nodes and as a backup solution for more capable systems in GPS-denied environments. Robots keep exploring the configuration space by random walk and stop only if their current location satisfies user-specified constraints on connectivity (number of neighbors). Resulting deployments are robust and convergence is analyzed using both kinematic simulation with a simplified collision and communication model as well as a probabilistic macroscopic model. The approach is validated on a team of 9 iRobot Create robots carrying wireless access points in an indoor environment.","2009","14","1","2025-12-02","https://university.edu/papers/f8232080-740b-4550-af4b-2d26fd0702bb.pdf");
INSERT INTO Paper VALUES ("680","Profiling users with tag networks in diffusion-based personalized recommendation","This study explores new ways of tag-based personalized recommendation by relieving the assumption that tags assigned by a user occur independently of each other. The new methods profile users using tag co-occurrence networks, upon which link-based node weighting methods (e.g. PageRank and HITS) are applied to refine the weights of tags. A diffusion process is then performed upon the tag-item bipartite graph to transform the weights of tags into recommendation scores for items. Experiments on three datasets showed improvements of the proposed method over the tag-based collaborative filtering in terms of precision and recall in the datasets with dense user-tag networks and in terms of inter-diversity in all datasets. In addition, the user-tag network is found to be a necessary instrument for the improvements. The findings of this study contribute to more accurate user profiling and personalized recommendations using network theory and have practical implications for tag-based recommendation systems.","2016","10","2","2025-12-02","https://university.edu/papers/c7292f68-98f5-4c6b-b291-0cf4986c737b.pdf");
INSERT INTO Paper VALUES ("681","Mantra 2.0: An online collaborative resource for drug mode of action and repurposing by network analysis","Summary: Elucidation of molecular targets of a compound [mode of action (MoA)] and its off-targets is a crucial step in drug development. We developed an online collaborative resource (MANTRA 2.0) that supports this process by exploiting similarities between drug-induced transcriptional profiles. Drugs are organized in a network of nodes (drugs) and edges (similarities) highlighting ‘communities’ of drugs sharing a similar MoA. A user can upload gene expression profiles before and after drug treatment in one or multiple cell types. An automated processing pipeline transforms the gene expression profiles into a unique drug ‘node’ embedded in the drug-network. Visual inspection of the neighbouring drugs and communities helps in revealing its MoA and to suggest new applications of known drugs (drug repurposing). MANTRA 2.0 allows storing and sharing user-generated network nodes, thus making MANTRA 2.0 a collaborative ever-growing resource. Availability and implementation: The web tool is freely available for academic use at http://mantra.tigem.it. Contact: dibernardo@tigem.it","2014","2","4","2025-12-02","https://university.edu/papers/f431485e-6262-4008-8158-52960a70b816.pdf");
INSERT INTO Paper VALUES ("682","Devising a conflict detection method for multi-party contracts","The notion of contracts play an important role since the beginning of humankind. Technological advances and the globalization have increased the use of contracts in electronic transactions. Therefore, verification of contracts has become extremely important to guarantee properties and agreements. Some formalisms are used as the basis to represent electronic contracts such as deontic and dynamic logics. Formal models and computational support allow to attain more precise results on checking electronic contracts. This work proposes an approach to represent appropriately multi-party contracts by means of suitable formalisms and also to automatically verify properties in contracts of this nature.","2015","12","2","2025-12-02","https://university.edu/papers/1b910ad2-17c7-44be-8b0d-7e3a04c39fd3.pdf");
INSERT INTO Paper VALUES ("683","A stitch in time saves nine: Early improving code-first Web Services discoverability","Web Services represent a number of standard technologies and methodologies that allow developers to build applications under the Service-Oriented Computing paradigm. Within these, the WSDL language is used for representing Web Service interfaces, while code-first remains the de facto standard for building such interfaces. Previous studies with contract-first Web Services have shown that avoiding a specific catalog of bad WSDL specification practices, or anti-patterns, can reward Web Service publishers as service understandability and discoverability are considerably improved. In this paper, we study a number of simple and well-known code service refactorings that early reduce anti-pattern occurrences in WSDL documents. This relationship relies upon a statistical correlation between common OO metrics taken on a service's code and the anti-pattern occurrences in the generated WSDL document. We quantify the effects of the refactorings — which directly modify OO metric values and indirectly alter anti-pattern...","2015","13","4","2025-12-02","https://university.edu/papers/f75aeb3e-85d5-4002-bb72-a03eea7e9aae.pdf");
INSERT INTO Paper VALUES ("684","Observing Architectural Design: Improving the Development of Collaborative Design Environments","The physical environments in which design collaborations take place provide many affordances, which enable interactions to occur both seamlessly and (in most cases) successfully. Physical collaboration is also facilitated through many aspects of the design process. Virtual design collaboration on the other hand, while successful at achieving the direct repre-sentation of activity around the artefacts being manipulated, lacks many of the physical affordances which make collaboration in the physical realm successful. The aim of this paper is to present the physical affordances of design interaction, isolate those which aid the success of physical design and identify which factors are potentially beneficial to improve the affordances of virtual collaborative design environments","2004","13","1","2025-12-02","https://university.edu/papers/a84cb5a9-19c2-4b94-96f4-764590e6ac81.pdf");
INSERT INTO Paper VALUES ("685","Penalized weighted low-rank approximation for robust recovery of recurrent copy number variations.","Background#R##N#Copy number variation (CNV) analysis has become one of the most important research areas for understanding complex disease. With increasing resolution of array-based comparative genomic hybridization (aCGH) arrays, more and more raw copy number data are collected for multiple arrays. It is natural to realize the co-existence of both recurrent and individual-specific CNVs, together with the possible data contamination during the data generation process. Therefore, there is a great need for an efficient and robust statistical model for simultaneous recovery of both recurrent and individual-specific CNVs.","2015","9","3","2025-12-02","https://university.edu/papers/ec15521d-23a1-47a6-ba39-bc828743c000.pdf");
INSERT INTO Paper VALUES ("686","SPRAT: Runtime processor selection for energy-aware computing","A commodity personal computer (PC) can be seen as a hybrid computing system equipped with two different kinds of processors, i.e. CPU and a graphics processing unit (GPU). Since the superiorities of GPUs in the performance and the power efficiency strongly depend on the system configuration and the data size determined at the runtime, a programmer cannot always know which processor should be used to execute a certain kernel. Therefore, this paper presents a runtime environment that dynamically selects an appropriate processor so as to improve the energy efficiency. The evaluation results clearly indicate that the runtime processor selection at executing each kernel with given data streams is promising for energy-aware computing on a hybrid computing system.","2008","20","3","2025-12-02","https://university.edu/papers/81740483-9647-47cb-96f0-7db5d0376c68.pdf");
INSERT INTO Paper VALUES ("687","A recursive SVD-based self-constructing rule generation for neuro-fuzzy system modeling","We propose a recursive SVD-based self-constructing rule generation (RSVD-SCRG) approach for structure identification in neuro-fuzzy system modeling. Fuzzy clusters are generated incrementally, with none at the beginning, by presenting the training data one by one. For each presented data, we evaluate its input similarities and output similarities to existing clusters. If the data is not similar enough to any of existing clusters, a new fuzzy cluster is created and its corresponding Gaussian input membership functions and TSK-type linear output function are initialized. Otherwise, we combine the data into the most similar existing cluster and update the corresponding membership functions and output function with statistical calculations and a recursive SVD-based least squares estimator. Therefore, our approach solves the parameter estimation problem encountered in processes of cluster generation and updating. Besides, experimental results have shown that our approach generates more precise initial fuzzy rules and produces lower approximation errors than other approaches.","2011","6","4","2025-12-02","https://university.edu/papers/e7142bf0-93c8-480b-8756-c8f028d06ec5.pdf");
INSERT INTO Paper VALUES ("688","Federal Funds Rate Prediction: A Comparison between the Robust RBF Neural Network and Economic Models","Neural network forecasting models have been widely used in the analyses of financial time series during the last decade. This paper attempts to fill this gap in the literature by examining a variety of univariate and multivariate, linear, nonlinear Economics empirical modes and neural network. In this paper, we construct an M-estimator based RBF (MRBF) neural network with growing and pruning techniques. Then we compare the forecasting performances of MRBF with six other time-series forecasting models for daily U.S. effective federal funds rate. The results show that the proposed MRBF network can produce the lowest root mean square errors in one-day-ahead forecasting for the federal funds rate. It implies that MRBF can be one good method for the predictions of some financial time series data.","2009","11","2","2025-12-02","https://university.edu/papers/8188b296-92f0-4a38-8a90-0afe29b00288.pdf");
INSERT INTO Paper VALUES ("689","Dealing with Precise and Imprecise Decisions with a Dempster-Shafer Theory Based Algorithm in the Context of Handwritten Word Recognition","The classification process in handwriting recognition is designed to provide lists of results rather than single results, so that context models can be used as post-processing. Most of the time, the length of the list is determined once and for all the items to classify. Here, we present a method based on Dempster-Shafer theory that allows a different length list for each item, depending on the precision of the information involved in the decision process. As it is difficult to compare the results of such an algorithm to classical accuracy rates, we also propose a generic evaluation methodology. Finally, this algorithm is evaluated on Latin and Arabic handwritten isolated word datasets.","2010","7","3","2025-12-02","https://university.edu/papers/ebe033f2-cfef-455a-b4d5-559e41993cf9.pdf");
INSERT INTO Paper VALUES ("690","Building Virtual Worlds Carrying on the Legacy of Randy Pausch's 'Head Fake'","The Carnegie Mellon Building Virtual Worlds course fosters interdisciplinary collaboration and invention. It helps provide students with a solid foundation by challenging them to create innovative, future-oriented experiences through a series of critiqued rapid prototypes. This process, combined with carefully designed peer evaluation, has led to a system that hundreds of alumni credit with setting them on the road to inventing the future of entertainment technology.","2013","5","4","2025-12-02","https://university.edu/papers/c82ad2d1-a3f5-418f-970e-09f9b991830d.pdf");
INSERT INTO Paper VALUES ("691","Estimation of Continuous Urban Sky View Factor from Landsat Data Using Shadow Detection","Sky View Factor (SVF, a dimensionless value between 0 and 1 representing obstructed and unobstructed sky, respectively) has an important influence on urban energy balance, and is a key contributor to the Urban Heat Island (UHI) effect experienced by heavily built up regions. Continuous urban SVF maps used in modeling the spatial distribution of UHI can be derived analytically using Lidar data; however, Lidar data are costly to obtain and often lack complete coverage of large cities or metropolitan areas. This study develops and validates a method for estimating continuous urban SVF from globally available Landsat TM data, based on the presence of shadows cast by SVF-reducing urban features. SVF and per-pixel shadow proportion (SP) were first calculated for synthetic grid cities to confirm a logarithmic relationship between the two properties; then Lidar data from four US cities were used to determine an empirical regression relating SP to SVF. Spectral Mixture Analysis was then used to estimate per-pixel SP in a Landsat 5 TM image covering the Greater Vancouver Area, Canada, and the empirical regression was used to calculate SVF from per-pixel SP. The accuracy of the resulting SVF map was validated using independent Lidar-derived SVF data (R2 = 0.78; RMSE = 0.056).","2016","18","2","2025-12-02","https://university.edu/papers/f07f8c37-5692-49ec-a1ad-8173f89f0b36.pdf");
INSERT INTO Paper VALUES ("692","High-Efficiency Wireless Power Transfer for Biomedical Implants by Optimal Resonant Load Transformation","Wireless power transfer provides a safe and robust way for powering biomedical implants, where high efficiency is of great importance. A new wireless power transfer technique using optimal resonant load transformation is presented with significantly improved efficiency at the cost of only one additional chip inductor component. The optimal resonant load condition for the maximized power transfer efficiency is explained. The proposed technique is implemented using printed spiral coils with discrete surface mount components at 13.56 MHz power carrier frequency. With an implantable coil having an area of 25 mm × 10 mm and a thickness of 0.5 mm, the power transfer efficiency of 58% is achieved in the tissue environment at 10-mm distance from the external coil. Compared to previous works, the power efficiency is much higher and the structure is compact with planar integration, easy to tune, and suitable for batch production, as well as biocompatible owing to no incorporation of ferromagnetic core.","2013","10","3","2025-12-02","https://university.edu/papers/863dd2f1-152a-4a1b-94a4-8eb9fa78a142.pdf");
INSERT INTO Paper VALUES ("693","Usable gestures for blind people: understanding preference and performance","Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces.","2011","3","3","2025-12-02","https://university.edu/papers/892a980e-72eb-416c-9b2d-fc56083869cb.pdf");
INSERT INTO Paper VALUES ("694","Modeling and robust Body Freedom Flutter Analysis of flexible aircraft configurations","Body Freedom Flutter (BFF) is a dynamic instability concerning coupling between rigid-body and elastic modes of the aircraft. Flexible configurations with adverse geometric properties have been found susceptible to this phenomena. In this work a simple model, based on the typical section framework and incorporating basic features of the problem, is proposed. A sensitivity study of the role played by two meaningful parameters (wing bending stiffness and tail horizontal distance) is performed both with classical (p-k method) and robust (μ technique) tools. The analyses performed showcase the potential and prowess of the latter, not only in inferring critical features of BFF but also in its capability for more complete and complex robust parametric analysis.","2016","19","4","2025-12-02","https://university.edu/papers/a965c463-5796-4230-bcbb-6fea0c711389.pdf");
INSERT INTO Paper VALUES ("695","Internal Computability","We extend the notion of (TTE-)computability to nonstandard universes by the traditional method of enlarging universes through ultrafilters. In this way a nonstandard notion of effectivity is obtained.","2007","18","2","2025-12-02","https://university.edu/papers/04140ed4-d9c6-4bba-a898-9b9f12451c10.pdf");
INSERT INTO Paper VALUES ("696","Memory Efficient Max Flow for Multi-label Submodular MRFs","Multi-label submodular Markov Random Fields (MRFs) have been shown to be solvable using max-flow based on an encoding of the labels proposed by Ishikawa, in which each variable Xi is represented by l nodes (where l is the number of labels) arranged in a column. However, this method in general requires 2 l2 edges for each pair of neighbouring variables. This makes it inapplicable to realistic problems with many variables and labels, due to excessive memory requirement. In this paper, we introduce a variant of the max-flow algorithm that requires much less storage. Consequently, our algorithm makes it possible to optimally solve multi-label submodular problems involving large numbers of variables and labels on a standard computer.","2016","13","4","2025-12-02","https://university.edu/papers/a4ecf97a-f43f-40f8-93aa-40ab3f07560c.pdf");
INSERT INTO Paper VALUES ("697","Computation of Zames-Falb multipliers revisited","The convex approach to the absolute stability problem is considered. Gapski and Geromel's algorithm for computing Zames-Falb multipliers, used in determining stability, treats the problem as an optimization problem. It is found that their algorithm may terminate prematurely in some cases, failing to find the optimal multiplier. We propose an improvement that always finds an ascent direction and a multiplier that improves the objective function whenever one exists.","2010","4","2","2025-12-02","https://university.edu/papers/81b50eb3-3f6e-4fa8-80ef-2aec8013bb32.pdf");
INSERT INTO Paper VALUES ("698","Comparative performance analysis of multi dynamic time quantum Round Robin(MDTQRR) algorithm with arrival time","CPU being considered a primary computer resource, its scheduling is central to operating-system design. A thorough performance evaluation of various scheduling algorithms manifests that Round Robin Algorithm is considered as optimal in time shared environment because the static time is equally shared among the processes. We have proposed an efficient technique in the process scheduling algorithm by using dynamic time quantum in Round Robin. Our approach is based on the calculation of time quantum twice in single round robin cycle. Taking into consideration the arrival time, we implement the algorithm. Experimental analysis shows better performance of this improved algorithm over the Round Robin algorithm and the Shortest Remaining Burst Round Robin algorithm. It minimizes the overall number of context switches, average waiting time and average turn-around time. Consequently the throughput and CPU utilization is better.","2011","17","4","2025-12-02","https://university.edu/papers/4e6e2335-3c9f-4220-a113-91892ecec174.pdf");
INSERT INTO Paper VALUES ("699","Robot arm force control through system linearization by nonlinear feedback","Based on a differential geometric feedback linearization technique for nonlinear time-varying systems, a dynamic force control method for robot arms is developed. It uses active force-moment measurements at the robot wrist. The controller design fully incorporates the robot-arm dynamics and is so general that it can be reduced to pure position control, hybrid position/force control, and pure force control. The controller design is independent of the tasks to be performed. Computer simulations show that the controller improves the position error by a factor of ten in cases in which position errors generate force measurements. A theorem on linearization of time-varying system is also presented. >","1988","11","3","2025-12-02","https://university.edu/papers/b7216fc6-3c2f-4deb-8fa6-339e9dee96d7.pdf");
INSERT INTO Paper VALUES ("700","Learning robot in-hand manipulation with tactile features","Dexterous manipulation enables repositioning of objects and tools within a robot's hand. When applying dexterous manipulation to unknown objects, exact object models are not available. Instead of relying on models, compliance and tactile feedback can be exploited to adapt to unknown objects. However, compliant hands and tactile sensors add complexity and are themselves difficult to model. Hence, we propose acquiring in-hand manipulation skills through reinforcement learning, which does not require analytic dynamics or kinematics models. In this paper, we show that this approach successfully acquires a tactile manipulation skill using a passively compliant hand. Additionally, we show that the learned tactile skill generalizes to novel objects.","2015","15","3","2025-12-02","https://university.edu/papers/8bba7bfe-98a3-4ab0-acbb-887843b9f267.pdf");
INSERT INTO Paper VALUES ("701","QueryScope: visualizing queries for repeatable database tuning","Reading and perceiving complex SQL queries has been a time consuming task in traditional database applications for decades. When it comes to decision support systems with automatically generated and sometimes highly nested SQL queries, human understanding or tuning of these workloads becomes even more challenging. This demonstration explores visualization methods to represent queries as graphs. We developed the QueryScope tool to help visualize and understand critical elements of a query, thereby cutting down the learning curve. We show how the tool allows the user to drill down on particular queries or to find similarly structured queries that may exhibit similar tuning opportunities. The queries shown in the demonstration are taken from real tuning engagements.","2008","14","4","2025-12-02","https://university.edu/papers/d2e9b18d-4bec-4a9b-b5e4-4aacc5d1494b.pdf");
INSERT INTO Paper VALUES ("702","Context-based global multi-class semantic image segmentation by wireless multimedia sensor networks","Using context to aid object detection is becoming more popular among computer vision researchers. Our physical world is structured, and our perception as human beings does not neglect contextual information. In this paper, we propose a framework that is able to simultaneously detect and segment objects of different classes under context. Context is incorporated into our model as long-range pairwise interactions between pixels, which impose a prior on the labeling. Long-range interactions have seen seldom use in the computer vision literature, and we show how to use them to encode contextual information in our segmentation. Our framework formulates the multi-class image segmentation task as an energy minimization problem and finds a globally optimal solution under certain conditions using a single graph cut. We experimentally evaluate performance of our model on two publicly available datasets: the MSRC-1 and the CorelB datasets. Our results show the applicability of our model to the multi-class segmentation problem.","2015","14","4","2025-12-02","https://university.edu/papers/630cf35a-8dbc-492d-9e21-33909f5b9451.pdf");
INSERT INTO Paper VALUES ("703","Reduced RBF centers based multi-user detection in DS-CDMA systems","The major goal of this paper is to develop a practically implemental radial basis function neural network based multi-user detector for direct sequence code division in multiple access systems. This work is expected to provide an efficient solution by quickly setting up the proper number of radial basis function centers and their locations required in training. The basic idea in this research is to select all the possible radial basis function centers by using supervised k-means clustering technique, select the only centers which locate near seemingly decision boundary, and reduce them further by grouping some of the centers adjacent to each other. Therefore, it reduces the computational burden for finding the proper number of radial basis function centers and their locations in the existing radial basis function based multi-user detector, and ultimately, make its implementation practical.","2006","15","1","2025-12-02","https://university.edu/papers/cc931acb-6ad6-4930-95cc-8cf27e38dc2f.pdf");
INSERT INTO Paper VALUES ("704","Efficient digitizing of sculptured surfaces using wavelet transform","Surface digitization is an approach to obtain three-dimensional measurement of an unknown sculptured surface. The quality and the efficiency of surface digitization are two main concerns which have drawn much attention in the manufacturing industries. A cost-effective digitizing approach can not only reduce the measuring time, but also improve the accuracy of measurement. In the past, the digitizing methods were performed in such a way that the digitizing points were chosen at intervals with a constant distance. However, many local areas of a sculptured surface can be well-represented by fewer points. Therefore dense digitizing of conventional digitizing schemes is not efficient. In this paper, a new irregular digitizing scheme based on the wavelet transform is proposed. First an initial depth map of sculptured surface is obtained by using computer vision. From the initial depth map, the wavelet transform is used to select the necessary digitizing points for further digitization by highly accurate measuring equipment. Once the digitizing points are re-measured, the surface can be reconstructed by wavelet synthesis technique.","1997","18","1","2025-12-02","https://university.edu/papers/91be3654-15ac-4dfa-b559-b7c7ea97855c.pdf");
INSERT INTO Paper VALUES ("705","Nonlinear Predictive Control of processes with variable time delay. A temperature control case study","Material or fluid transportation is a commonly encountered phenomenon in industrial applications, generating variable time delay that makes the design of feedback control loops more difficult. This paper investigates the applicability of MPC (Model Predictive Control) strategies to this type of processes. The experimental setup consists of a heated tank, of which the outlet temperature (measured at a certain distance from the tank) is controlled by manipulating the outlet flow. The nonlinear EPSAC (Extended Prediction Self-Adaptive Control) approach is used, which reduces the complexity of nonlinear optimization to iterative quadratic programming. It is shown that developing a process model in which dynamics are decoupled from the variable time delay leads to a Smith predictor-like control structure, that allows the proper operation of the control loop with fixed control parameters. The performance of the predictive controller is compared on the pilot plant to the performance of classic control approaches for systems with time delay.","2008","14","1","2025-12-02","https://university.edu/papers/7935a4c1-767d-4a04-bf06-faf9cb367b24.pdf");
INSERT INTO Paper VALUES ("706","Situation assessment for human-robot interactive object manipulation","In daily human interactions spatial reasoning occupies an important place. With this ability we can build relations between objects and people, and we can predict the capabilities and the knowledge of the people around us. An interactive robot is also expected to have these abilities in order to establish an efficient and natural interaction. In this paper we present a situation assessment reasoner, based on spatial reasoning and perspective taking, which generates on-line relations between objects and agents in the environment. Being fully integrated to a complete architecture, this reasoner sends the generated symbolic knowledge to a fact data base which is built on the basis on an ontology and which is accessible to the entire system. This work is also part of a broader effort to develop a complete decisional framework for human-robot interactive task achievement.","2011","5","3","2025-12-02","https://university.edu/papers/4ff4a212-85b4-4883-9d23-adcc9fdc70b1.pdf");
INSERT INTO Paper VALUES ("707","Neighbors Investment Geographic Routing Algorithm in Wireless Sensor Networks","Geographic routing is widely used in wireless sensor networks. The problem that most of the geographic routing algorithms, which adopt greedy algorithm as their basic routing strategies, have to face is the “local minimal phenomena”. In this paper, we propose a Neighbors Investment Geographic Routing Algorithm (NIGRA), which is based on the geographic information of 2-hop neighbors. NIGRA adopts NIR (Neighbors Investment Routing) algorithm as basic routing strategy, which makes nodes be aware of the existence of voids, so that the packet can bypass the dead-end nodes ahead of time to reduce the occurrence rate of local minimal phenomena. Furthermore, PATN, a Planarization Algorithm based on 2-hop Neighbors, is also introduced. When NIGRA resorts to perimeter routing as recovery strategy, PATN ensures the success of perimeter routing through the planarization without extra overhead, and guarantees the delivery in UDG networks. Extensive simulations further show that NIR algorithm can significantly decrease the local minimal phenomena and NIGRA has better routing performance than GPSR.","2009","8","3","2025-12-02","https://university.edu/papers/9e9036f2-9ae3-4fda-8b1f-26c9a7f73c32.pdf");
INSERT INTO Paper VALUES ("708","Model of Problematic Internet Use in People with a Sexual Interest in Children","Agencies working with sex offenders are starting to see the emergence of people with a sexual interest in children who meet some of their needs through the use of child pornography, or the seduction of children, through the Internet. While CBT models dominate our understanding of sex offenders, there has been little research into the role that such new technologies may play in offending behavior. Data from the COPINE project has been used to generate a model of such offending behavior that emphasizes the role of cognitions in both the etiology, engagement with and problematic use of the Internet for those with a sexual interest in children. Such a model seeks to incorporate contemporary thinking about the role of cognitions in Pathological Internet Use, but applies this from a nonpathological perspective. This model is a first step towards providing a conceptual framework for such offending that will help inform both assessment and therapy.","2003","5","3","2025-12-02","https://university.edu/papers/d09dd87f-2b21-4c88-87e0-542452e1b387.pdf");
INSERT INTO Paper VALUES ("709","Finding Relevant Relations in Relevant Documents","This work studies the combination of a document retrieval and a relation extraction system for the purpose of identifying query-relevant relational facts. On the TREC Web collection, we assess extracted facts separately for correctness and relevance. Despite some TREC topics not being covered by the relation schema, we find that this approach reveals relevant facts, and in particular those not yet known in the knowledge base DBpedia. The study confirms that mention frequency, document relevance, and entity relevance are useful indicators for fact relevance. Still, the task remains an open research problem.","2016","2","4","2025-12-02","https://university.edu/papers/fdcde2cd-952a-4baa-b51f-fd7a60fed6ba.pdf");
INSERT INTO Paper VALUES ("710","Hardware requirements for neural network pattern classifiers: a case study and implementation","A special-purpose chip, optimized for computational needs of neural networks and performing over 2000 multiplications and additions simultaneously, is described. Its data path is particularly suitable for the convolutional architectures typical in pattern classification networks but can also be configured for fully connected or feedback topologies. A development system permits rapid prototyping of new applications and analysis of the impact of the specialized hardware on system performance. The power and flexibility of the processor are demonstrated with a neural network for handwritten character recognition containing over 133000 connections. >","1992","5","4","2025-12-02","https://university.edu/papers/b508d24c-4034-40c1-a464-74a4aea619a2.pdf");
INSERT INTO Paper VALUES ("711","Reducing Sampling Clock Jitter to Improve SNR Measurement of A/D Converters in Production Test","Random jitter, present in the clock that is used for sampling the input signal, applied to the A/D converter results in noise that is added to the output of the device. For high-resolution A/D converters (low quantization noise), a very low-jitter clock is needed to measure accurate signal-to-noise ratio. Low jitter constraints on the clock signal increases with the test stimulus frequency. This paper implements a board-level, low-cost, phase-locked-loop (PLL) based approach to reduce the jitter present in the sampling clock provided by a low-cost tester. A small loop bandwidth PLL, a low-noise voltage controlled crystal oscillator (VCXO) and a low-cost (higher jitter) reference clock are used to synthesize a low-jitter clock. The proposed approach was simulated using Simulink and validated using hardware measurements. The results show significant improvement in RMS jitter that improves the SNR measurement of the A/D converter by 3dB","2006","1","4","2025-12-02","https://university.edu/papers/568851f3-d03c-4d4a-86db-867701abf9f3.pdf");
INSERT INTO Paper VALUES ("712","Inductive Complexity of P versus NP Problem Extended Abstract","Using the complexity measure developed in (7,3,4) and the extensions obtained by using inductive register machines of various or- ders in (1,2), we determine an upper bound on the inductive complexity of second order of the P versus NP problem. From this point of view, the P versus NP problem is more complex than the Riemann hypothesis.","2012","17","4","2025-12-02","https://university.edu/papers/d355b4c9-5e41-4983-8b63-502cecea12a1.pdf");
INSERT INTO Paper VALUES ("713","Routing in the frequency domain","The design of single transceiver based multi-channel multi-hop wireless mesh networks focuses on the trade-off between rapid neighbor synchronization and maximizing the usage of all available channels. Existing designs are confined to the MAC layer and scale poorly as the network grows in coverage and density. We recently proposed Dominion as a cross-layer architecture that includes both medium access control and routing. Dominion eliminates the need for neighbor synchronization at the MAC layer and pushes the intelligence up the network stack. At the MAC layer, a node switches channels according to a deterministic schedule which guarantees that a node converges with each of its neighbors periodically. At the network layer, the channel-hopping aware routing substrate routes traffic along the frequency domain, i.e., packets along a multi-hop route generally traverse via multiple channels. In this paper, we present the complete design, analysis and evaluation of Dominion and make four new contributions. Firstly, we extend Dominion to support goal-oriented routing: source nodes can locally choose to maximize throughput or minimize end-to-end latency without requiring any changes in the network. Secondly, we describe a technique that eliminates intra-flow interference. In absence of extrinsic interference, Dominion now allows network flows to maintain constant throughput and deterministic end-to-end latencies irrespective of distance. Thirdly, via theoretical modeling and analysis, we provide expected throughput and end-to-end latencies for network flows. Finally, via extensive QualNet simulations we show that Dominion achieves 1064% higher throughput than IEEE 802.11 while being 299% fairer.","2010","2","1","2025-12-02","https://university.edu/papers/6ff55377-f87f-4e1d-a73a-9f13c9f4ae28.pdf");
INSERT INTO Paper VALUES ("714","North Corridor Economic Region: Bio Ecosystem Analysis","Under the Ninth Malaysian Plan (9MP), various development schemes according to geographical regions have been planned for implementation. The North Corridor Economic Region (NCER) is envisaged to promote economic development in the northern corridor region, which includes Penang and Kedah. Significant economic development is expected to be implemented in the state of Penang, in which the Universiti Sains Malaysia (USM) is located. Coastal reclamation and development, including the Penang Outer Ring Road PORR, the Second Link and the Penang Global City Center PGCC, will be implemented in several parts of the Penang state. These developments may incur negative bioenvironmental impacts, for which an Environmental Impact Assessment (EIA) is needed for mitigation. This paper presents a brief exposition of these EIA studies, with particular reference to model simulations on hydrodynamic regimes and suspended sediment SS in the Straits of Penang. The impacts of SS on marine ecosystems are discussed.","2008","2","3","2025-12-02","https://university.edu/papers/88c5b440-3ec9-4b9f-8fb8-24901b2cd18f.pdf");
INSERT INTO Paper VALUES ("715","Trust with Private and Common Property: Effects of Stronger Property Right Entitlements","Is mutually beneficial cooperation in trust games more prevalent with private property or common property? Does the strength of property right entitlement affect the answer? Cox, Ostrom, Walker, et al. [1] report little difference between cooperation in private and common property trust games. We assign stronger property right entitlements by requiring subjects to meet a performance quota in a real effort task to earn their endowments. We find that cooperation is lower in common property trust games than in private property trust games, which is an idiosyncratic prediction of revealed altruism theory [2].","2010","4","3","2025-12-02","https://university.edu/papers/3a8fb585-6db3-48e8-a3c9-c654f8beca6d.pdf");
INSERT INTO Paper VALUES ("716","ViSTPro: A platform for visualization of spatiotemporal processes on Google Earth","The presentation of spatiotemporal processes is a recurring theme in learning. Such processes are part of the standard curricula in subjects like geography, history, environmental education etc., as well as in professional learning tools like serious games. Learners face several difficulties in studying learning topics without strong spatiotemporal process visualization and explanation support. This paper presents an approach to tackle these problems by providing a spatiotemporal process modeling, visualization and explanation platform on top of Google Earth. The platform is based on a generic conceptual model that adapts to various types of spatiotemporal processes and enables learners to make rich inquiries in a playful manner that resembles their experiences with digital games.","2016","20","1","2025-12-02","https://university.edu/papers/072211a4-a961-4901-a288-cb10cd74949b.pdf");
INSERT INTO Paper VALUES ("717","A genetic algorithm for scheduling tasks in a real-time distributed system","Real time systems must often handle several independent periodic macro tasks, each one represented by a general task graph, including communications and precedence constraints. The implementation of such applications on a distributed system communicating via a bus, requires task assignment and scheduling as well as the taking into account of the communication delays. As periodicity implies macro task deadlines, the problem of finding a feasible schedule is critical. The paper addresses this NP hard problem resolution, by using a genetic algorithm under offline and non preemptive scheduling assumptions. The algorithm performance is evaluated on a large simulation set, and compared to classical list based algorithms, a simulated annealing algorithm and a specific clustering algorithm.","1998","10","4","2025-12-02","https://university.edu/papers/7faf58fd-5ff6-4b9c-be3d-ce80824fbd5c.pdf");
INSERT INTO Paper VALUES ("718","Cost-based Filtering for Shorter Path Constraints","Many real world problems, e.g. personnel scheduling and transportation planning, can be modeled naturally as Constrained Shortest Path Problems (CSPPs), i.e., as Shortest Path Problems with additional constraints. A well studied problem in this class is the Resource Constrained Shortest Path Problem. Reduction techniques are vital ingredients of solvers for the CSPP, that is frequently NP-hard, depending on the nature of the additional constraints. Viewed as heuristics, these techniques have not been studied theoretically with respect to their efficiency, i.e., with respect to the relation of filtering power and running time. Using the concepts of Constraint Programming, we provide a theoretical study of cost-based filtering for shorter path constraints on acyclic, on undirected, and on directed graphs that do not contain negative cycles. We then show empirically how reasoning about path-substructures in combination with CP-based Lagrangian relaxation can help to improve significantly over previously developed problem-tailored filtering algorithms for the resource constrained shortest path problem and investigate the impact of required-edge detection, undirected versus directed filtering, and the choice of the algorithm optimizing the Lagrangian dual.","2007","11","1","2025-12-02","https://university.edu/papers/f8f9df5c-d821-41f3-8fd3-a2cd0c563802.pdf");
INSERT INTO Paper VALUES ("719","Outage Performance of Cognitive Relay Networks With Wireless Information and Power Transfer","In this paper, we consider underlay cognitive radio (CR) networks with one primary receiver, one cognitive transmitter–receiver pair, and one   energy harvesting   relay. The transmission power of the secondary source is opportunistically determined by its interference to the primary receiver, and the relay transmission is powered by the energy harvested from the radio-frequency observations at the relay. For the considered CR networks with simultaneous wireless information and power transfer (SWIPT), we derive analytical expressions for the outage probability, as well as their high signal-to-noise ratio (SNR) approximations in closed form. The developed analytical results demonstrate that the use of SWIPT will not cause any loss in diversity gain, but the outage probability achieved by the SWIPT-CR scheme asymptotically decays as    ${\log \mbox{SNR}}/\mbox{SNR}$  , whereas a decaying rate of    ${\mbox{1}}/\mbox{SNR}$   is achieved by a conventional CR network. Computer simulation results are also provided to demonstrate the accuracy of the presented analysis.","2016","4","1","2025-12-02","https://university.edu/papers/e12351e6-b3fe-42eb-a91e-a06323bb13ca.pdf");
INSERT INTO Paper VALUES ("720","Holding intruders accountable on the Internet","This paper addresses the problem of tracing intruders who obscure their identity by logging through a chain of multiple machines. After discussing previous approaches to this problem, we introduce thumbprints which are short summaries of the content of a connection. These can be compared to determine whether two connections contain the same text and are therefore likely to be part of the same connection chain. We enumerate the properties a thumbprint needs to have to work in practice, and then define a class of local thumbprints which have the desired properties. A methodology from multivariate statistics called principal component analysis is used to infer the best choice of thumbprinting parameters from data. Currently our thumbprints require 24 bytes per minute per connection. We develop an algorithm to compare these thumbprints which allows for the possibility that data may leak from one time-interval to the next. We present experimental data showing that our scheme works on a local area network. >","1995","7","2","2025-12-02","https://university.edu/papers/6f50aef6-f0a6-4e03-98a8-937941fa3f04.pdf");
INSERT INTO Paper VALUES ("721","Semantic web in enterprise: an agile startup perspective","Since the Agile Manifesto was first published, uptake in enterprise of agile methods such as Scrum has been significant. In this keynote speech, the speaker explored how, for data-intensive projects that aim to be agile, a Semantic Web technology stack can have several important benefits over other approaches.","2013","18","4","2025-12-02","https://university.edu/papers/59f70ef0-f6c6-41ae-9862-fd06dcbdf9f5.pdf");
INSERT INTO Paper VALUES ("722","Minimum Energy coding in CDMA Wireless Sensor Networks","A theoretical framework is proposed for accurate comparison of minimum energy coding in coded division multiple access (CDMA) wireless sensor networks (WSNs). Energy consumption and reliability are analyzed for two coding schemes: minimum energy coding (ME), and modified minimum energy coding (MME). A detailed model of consumed energy is described as function of the coding, radio transmit power, the characteristics of the transceivers, and the dynamics of the wireless channel. Since CDMA is strongly limited by multi-access interference, the system model includes all the relevant characteristics of wireless propagation. A distributed and asynchronous algorithm, which minimizes the total energy consumption by controlling the radio power, is developed. Numerical results are presented to validate the theoretical analysis and show under which conditions MME outperforms ME with respect to energy consumption and bit error rate. It is concluded that MME is more energy efficient than ME only for short codewords.","2009","5","2","2025-12-02","https://university.edu/papers/69b11843-a403-4bdf-8810-8291ee67f607.pdf");
INSERT INTO Paper VALUES ("723","Domain ontology concept extraction method based on text","This paper propose a new method to extract ontology concepts from multiple text of the same type. This method uses mutual information and document frequency. According to the mutual information tend to choose the low frequency words, combining mutual information and document frequency to avoid this problem. In this paper, a number of financial and economic reports are reported as the corpus. First of all, do the text preprocessing, and then based on the N-gram algorithm to generate a set of candidate phrases, and finally use the statistics and the rules to screen for the concept of ontology from candidate phrases.","2016","5","3","2025-12-02","https://university.edu/papers/640f40a3-9132-4e56-812a-fbb352fc8f27.pdf");
INSERT INTO Paper VALUES ("724","Real-time implementation of panoramic mosaic camera based on FPGA","With regard to Automated Guided Vehicles (AGVs) and autonomous navigation of Micro Aerial Vehicles (MAVs) in complicated environments, it is vital to detect not only in the direction of ongoing but also the entire environment. It is very significant for obtaining a broader view of a scene than the current single view which has been used in a wide range of applications such as satellite imaging, medical imaging and so on. As the conventional omnidirectional camera based on PC is cumbersome and power consuming, then a novel light-weight structure comprising of four cameras to detect targets in all directions based on FPGA is presented in our design. We will discuss the implementation of image mosaic algorithm which is comprised of image registration and image fusion and some other image preprocessing algorithms for better effect such as median filter algorithm, color filter algorithm, image enhancement algorithm, etc., on the Xilinx Zynq-7020 FPGA device using Vivado Design Suite and Software Development Kit which is embedded on ZedBoard developed board. The system is able to handle more than 60 frames per second (fps) freely and still in a low power consuming.","2016","10","1","2025-12-02","https://university.edu/papers/59f23645-8518-4c3d-9d2e-f022f7a3b68d.pdf");
INSERT INTO Paper VALUES ("725","Using Memory Access Traces to Map Threads and Data on Hierarchical Multi-core Platforms","In parallel programs, the tasks of a given application must cooperate in order to accomplish the required computation. However, the communication time between the tasks may be different depending on which core they are executing and how the memory hierarchy and interconnection are used. The problem is even more important in multi-core machines with NUMA characteristics, since the remote access imposes high overhead, making them more sensitive to thread and data mapping. In this context, process mapping is a technique that provides performance gains by improving the use of resources such as interconnections, main memory and cache memory. The problem of detecting the best mapping is considered NP-Hard. Furthermore, in shared memory environments, there is an additional difficulty of finding the communication pattern, which is implicit and occurs through memory accesses. This work aims to provide a method for static mapping for NUMA architectures which does not require any prior knowledge of the application. Different metrics were adopted and an heuristic method based on the Edmonds matching algorithm was used to obtain the mapping. In order to evaluate our proposal, we use the NAS Parallel Benchmarks (NPB) and two modern multi-core NUMA machines. Results show performance gains of up to 75% compared to the native scheduler and memory allocator of the operating system.","2011","16","2","2025-12-02","https://university.edu/papers/59a492e6-d6d9-4275-b19b-7fa08db51538.pdf");
INSERT INTO Paper VALUES ("726","Output-to-State Stability for systems on manifolds with multiple invariant sets","Output-to-State Stability (OSS) is a notion of detectability for nonlinear systems that is formulated in the ISS framework. We generalize the notion of OSS for systems evolving on manifolds and having multiple invariant sets. Building upon a recent extension of the Input-to-State Stability (ISS) theory for this very class of systems [1], the paper provides equivalent characterizations of the OSS property in terms of asymptotic estimates of the state trajectories and, in particular, in terms of existence of Lyapunov-like functions.","2016","4","1","2025-12-02","https://university.edu/papers/92712158-372d-415a-941b-3b9f99cc5959.pdf");
INSERT INTO Paper VALUES ("727","Browsing mixed structured and unstructured data","Both structured and unstructured data, as well as structured data representing several different types of tuples, may be integrated into a single list for browsing or retrieval. Data may be arranged in the Gray code order of the features and metadata, producing optimal ordering for browsing. We provide several metrics for evaluating the performance of systems supporting browsing, given some constraints. Metadata and indexing terms are used for sorting keys and attributes for structured data, as well as for semi-structured or unstructured documents, images, media, etc. Economic and information theoretic models are suggested that enable the ordering to adapt to user preferences. Different relational structures and unstructured data may be integrated into a single, optimal ordering for browsing or for displaying tables in digital libraries, database management systems, or information retrieval systems. Adaptive displays of data are discussed.","2006","1","2","2025-12-02","https://university.edu/papers/5b34d3ed-1a24-4e5d-8bc7-819c3195489b.pdf");
INSERT INTO Paper VALUES ("728","A self-consistent Carleman linearization technique for the large signal analysis of nonlinear circuits","The analysis of nonlinear dynamic circuits is still a challenging subject since analytic solutions are rarely available. Therefore, several techniques are suggested to solve the corresponding circuit equations approximately such that qualitative as well as quantitative properties are preserved. In small signal analysis of nonlinear circuits the nonlinear part of the Taylor series around an operational point is omitted. However, this approach delivers reliable approximations only if the approximated linear dynamical system is hyperbolic. One of the few approaches for a large signal analysis is the widely known Carleman linearization technique. In this contribution, a self-consistent Carleman linearization technique is presented where even the asymptotic behavior of nonlinear circuits can be approximated in a suitable manner. We illustrate our approach with some examples and discuss also its limitations.","2016","20","1","2025-12-02","https://university.edu/papers/ce62c1ff-0055-45d3-83f5-b39728e9dd0d.pdf");
INSERT INTO Paper VALUES ("729","Interactive exploration for image retrieval","We present a new version of our content-based image retrieval system RETIN. It is based on adaptive quantization of the color space, together with new features aiming at representing the spatial relationship between colors. Color analysis is also extended to texture. Using these powerful indexes, an original interactive retrieval strategy is introduced. The process is based on two steps for handling the retrieval of very large image categories. First, a controlled exploration method of the database is presented. Second, a relevance feedback method based on statistical learning is proposed. All the steps are evaluated by experiments on a generalist database.","2005","17","1","2025-12-02","https://university.edu/papers/ab943ace-3840-4a78-bb27-f4458aaa79fb.pdf");
INSERT INTO Paper VALUES ("730","Inferential Clustering Approach for Microarray Experiments with Replicated Measurements","Cluster analysis has proven to be a useful tool for investigating the association structure among genes in a microarray data set. There is a rich literature on cluster analysis and various techniques have been developed. Such analyses heavily depend on an appropriate (dis)similarity measure. In this paper, we introduce a general clustering approach based on the confidence interval inferential methodology, which is applied to gene expression data of microarray experiments. Emphasis is placed on data with low replication (three or five replicates). The proposed method makes more efficient use of the measured data and avoids the subjective choice of a dissimilarity measure. This new methodology, when applied to real data, provides an easy-to-use bioinformatics solution for the cluster analysis of microarray experiments with replicates (see the Appendix). Even though the method is presented under the framework of microarray experiments, it is a general algorithm that can be used to identify clusters in any situation. The method's performance is evaluated using simulated and publicly available data set. Our results also clearly show that our method is not an extension of the conventional clustering method based on correlation or euclidean distance.","2009","8","2","2025-12-02","https://university.edu/papers/4b784f4d-85f9-4f60-a2a5-2a3bbde52521.pdf");
INSERT INTO Paper VALUES ("731","Rollout-based Game-tree Search Outprunes Traditional Alpha-beta","Recently, rollout-based planning and search methods have emerged as an alternative to traditional tree-search methods. The fundamental operation in rollout-based tree search is the generation of trajectories in the search tree from root to leaf. Game-playing programs based on Monte-Carlo rollouts methods such as 'UCT' have proven remarkably effective at using information from trajectories to make state-of-the-art decisions at the root. In this paper, we show that trajectories can be used to prune more aggressively than classical alpha-beta search. We modify a rollout-based method, FSSS, to allow for use in game-tree search and show it outprunes alpha-beta both empirically and formally.","2012","4","4","2025-12-02","https://university.edu/papers/ea8cf1fb-9732-465e-bc4c-dabd3023ccd0.pdf");
INSERT INTO Paper VALUES ("732","An overview of a system for automatic generation of file conversion programs","Abstract#R##N##R##N#This paper describes a processor which automatically produces file conversion programs based on non-procedural user specification. The processor accepts, as input, descriptions of a source file and a desired target file with some auxiliary descriptions of associations between the two. This is specified by a user in a Data Description Language (DDL). To specify validation criteria, complex conversions not built in to the system, security criteria or summary processes, the system also accepts specifications in a Data Manipulation Language (DML). It produces, as an output, a conversion program in PL/1 capable of converting the described source file into the desired target file. The paper describes the structure, system design, capabilities and applications of the DDL/DML language and processor, including an illustrative example.","1975","1","4","2025-12-02","https://university.edu/papers/d5f248e5-9e6f-40cd-bcef-2526d0eb318e.pdf");
INSERT INTO Paper VALUES ("733","Directed network as a chaotic dynamical system","A directed network such as the WWW can be represented by a transition matrix. Comparing this matrix to a Frobenius-Perron matrix of a chaotic piecewise-linear one-dimensional map whose domain can be divided into Markov subintervals, we are able to relate the network structure itself to chaotic dynamics. Just like various large-deviation properties of local expansion rates (finite-time Lyapunov exponents) related to chaotic dynamics, we can also discuss those properties of network structure.","2006","13","1","2025-12-02","https://university.edu/papers/94164ada-9726-4a48-b497-4f9f40c9b4d2.pdf");
INSERT INTO Paper VALUES ("734","Difference-ratio-based NDGM interpolation forecasting algorithm and its application","A difference-ratio-based imputation algorithm is proposed to tackle missing values in modeling sequence and improve prediction accuracy of non-homogenous discrete grey model (NDGM). It is proved that the classical conditions of quasi-smooth sequences are not sufficient and necessary conditions for non-homogenous sequence and a new method is put forward to judge the smoothness of sequences. Reconstruction error of missing value comes from average generation and its impacts on forecasting accuracy of NDGM are also discussed. Compared with average generation, it is also proved that the new method is more effective. Unbiased imputation and prediction of non-homogenous sequence can be realized under this algorithm. Furthermore, two cases are employed to demonstrate that the algorithmic approach is suitable for short-term prediction of sequences characterized by high increasing tendency, insufficient information and outlier value inclusion.","2011","4","3","2025-12-02","https://university.edu/papers/ad53b888-852f-4e75-b70f-ea493c5e8d2a.pdf");
INSERT INTO Paper VALUES ("735","Neuromorphic walking gait control","We present a neuromorphic pattern generator for controlling the walking gaits of four-legged robots which is inspired by central pattern generators found in the nervous system and which is implemented as a very large scale integrated (VLSI) chip. The chip contains oscillator circuits that mimic the output of motor neurons in a strongly simplified way. We show that four coupled oscillators can produce rhythmic patterns with phase relationships that are appropriate to generate all four-legged animal walking gaits. These phase relationships together with frequency and duty cycle of the oscillators determine the walking behavior of a robot driven by the chip, and they depend on a small set of stationary bias voltages. We give analytic expressions for these dependencies. This chip reduces the complex, dynamic inter-leg control problem associated with walking gait generation to the problem of setting a few stationary parameters. It provides a compact and low power solution for walking gait control in robots.","2006","13","4","2025-12-02","https://university.edu/papers/ddda8c98-ba4a-4cd6-a980-3f8a6c53d57d.pdf");
INSERT INTO Paper VALUES ("736","GATA: a graphic alignment tool for comparative sequence analysis","Background#R##N#Several problems exist with current methods used to align DNA sequences for comparative sequence analysis. Most dynamic programming algorithms assume that conserved sequence elements are collinear. This assumption appears valid when comparing orthologous protein coding sequences. Functional constraints on proteins provide strong selective pressure against sequence inversions, and minimize sequence duplications and feature shuffling. For non-coding sequences this collinearity assumption is often invalid. For example, enhancers contain clusters of transcription factor binding sites that change in number, orientation, and spacing during evolution yet the enhancer retains its activity. Dot plot analysis is often used to estimate non-coding sequence relatedness. Yet dot plots do not actually align sequences and thus cannot account well for base insertions or deletions. Moreover, they lack an adequate statistical framework for comparing sequence relatedness and are limited to pairwise comparisons. Lastly, dot plots and dynamic programming text outputs fail to provide an intuitive means for visualizing DNA alignments.","2005","6","2","2025-12-02","https://university.edu/papers/730d26d5-813a-4260-a4fa-a397f42746a1.pdf");
INSERT INTO Paper VALUES ("737","Computing in the Dark Silicon Era: Current Trends and Research Challenges","Power density has become the major constraint for many on-chip designs. As an introduction to the Special Issue on Dark Silicon, the authors provide the newest trends and a survey on the topic that has valuable information for novices and experts alike.","2017","18","3","2025-12-02","https://university.edu/papers/e05dcb6e-01b3-43eb-8b90-ae5b2e519dd7.pdf");
INSERT INTO Paper VALUES ("738","An automatic correction tool that can learn","The majority of Computer Based Assessment (CBA) environments have been designed for fixed-response questions. This feature is not enough for the university context since not all the skills can be reduced to this typology of questions and free response exercises are required. In this paper, we present a web-based tool designed to automatically correct exercises that require a diagram or a graph to be solved. The main novelty of this tool is the strategy used for the correction. The tool starts without the knowledge about correct and incorrect solutions and then learns about the solutions provided by teachers and students. It automatically records the information of all entered solutions, the teacher correction and the corresponding feedback in a system database. When a new student solution is entered the information of the database is used for correction. The main components of the tool are the graph editor module, designed to support diagram drawing, and the correction module, which corrects the solutions entered by the students. These modules are integrated in a more general e-learning platform denoted ACME. ACME provides teachers all functionalities required for student work tracking, assessment, personalized attention, etc. The proposed tool has been evaluated on experimental group.","2011","20","4","2025-12-02","https://university.edu/papers/be5299e3-62b5-413b-a2c2-4d5129af063e.pdf");
INSERT INTO Paper VALUES ("739","STRONGLY CONSISTENT SOLUTIONS TO BALANCED TU GAMES","Consistency properties of game solutions connect between themselves the solution sets of games with different sets of players. In the paper, the strongly consistent solutions with respect to the Davis–Maschler definition of the reduced games to the class of balanced cooperative TU games with finite sets of players are considered. A cooperative game solution σ to a class of a TU cooperative game is called strongly consistent if for any and , where is the reduced game of Γ on the player set S and with respect to x. Evidently, all consistent single-valued solutions are strongly consistent. In the paper, we characterise anonymous, covariant bounded and strongly consistent to the class of balanced games. The core, its relative interior and the prenucleolus are among them. However, they are not unique solutions satisfying these axioms. Thus, more axioms are necessary in order to characterise these solutions with strong consistency. One of such axioms is the definition of a solution for the class of balanced two-person games. It is sufficient for the axiomatisation of the prenucleolus without the single-valuedness axiom. If we add the closed graph property of the solution correspondence to the given axioms, then the system characterises only the core. The two axiomatisations are the main result of the paper. An example of a strongly consistent solution different from the prenucleolus, the core and its relative interior is given.","1999","20","1","2025-12-02","https://university.edu/papers/4b3fc28d-d671-4569-9995-6eda1219401e.pdf");
INSERT INTO Paper VALUES ("740","Probabilistic Associations as a Proxy for Semantic Relatedness","Semantic relatedness computation is a well known problem with multidisciplinary applications. Existing approaches to computing semantic relatedness ignore the asymmetric associations of words. In the absence of an explicit topical context, these asymmetric associations can be effectively used to represent the relation of words in directional con- texts. Motivated by the idea of word associations, this paper presents a new approach to computing semantic relatedness using asymmetric association based probabilities of words extracted from the directional contexts of words based on the Wikipedia corpus. The performance eval- uation of the proposed approach on a variety of publicly available bench- mark datasets shows that the asymmetric association based measures outperformed not only the baseline symmetric measures but also most of the state-of-art approaches.","2014","14","2","2025-12-02","https://university.edu/papers/674dff38-7ed8-4e77-a7fc-721808ccda7c.pdf");
INSERT INTO Paper VALUES ("741","Non-scan design for testability for synchronous sequential circuits based on conflict analysis","A non-scan design for testability method is presented for synchronous sequential circuits. A testability measure called conflict based on conflict analysis in the process of synchronous sequential circuit test generation is introduced. Reconvergent fanouts with nonuniform inversion parity are still the main cause of redundancy and backtracking in the process of sequential circuit test generation. A new concept called sequential depth for testability is introduced to calculate the conflict-analysis-based testability measure. Potential conflicts between fault effect activation and fault effect propagation are also checked because they are closely related. The testability measure implies the number of potential conflicts to occur or the number of clock cycles required to detect a fault. The non-scan design for testability method based on the conflict measure can reduce many potential backtracks, make many hard-to-detect faults easy-to-detect and many redundant faults testable, therefore, can enhance fault coverage of the circuit greatly. It is believed that non-scan design for testability using the conflict measure can improve the actual testability of a circuit. Extensive experimental results are presented to demonstrate the effectiveness of the method.","2000","1","2","2025-12-02","https://university.edu/papers/6c22ab58-df72-4673-842e-a885750c3be5.pdf");
INSERT INTO Paper VALUES ("742","Estimating the number of communities in a network","Community detection, the division of a network into dense subnetworks with only sparse connections between them, has been a topic of vigorous study in recent years. However, while there exist a range of effective methods for dividing a network into a specified number of communities, it is an open question how to determine exactly how many communities one should use. Here we describe a mathematically principled approach for finding the number of communities in a network by maximizing the integrated likelihood of the observed network structure under an appropriate generative model. We demonstrate the approach on a range of benchmark networks, both real and computer generated.","2016","5","2","2025-12-02","https://university.edu/papers/96df6ece-32fb-4d52-ad11-75a82ff52ed6.pdf");
INSERT INTO Paper VALUES ("743","RST invariant video watermarking based on log-polar mapping and phase-only filtering","In this paper, we present a video watermarking algorithm based on the log-polar mapping and phase-only filtering method. The log-polar mapping (LPM) domain is obtained first from the magnitude of the Fourier spectrum of the frame. Then, the watermark pattern is embedded in the LPM domain based on the feature that rotation and scaling transformations in the spatial domain result in cyclically translational shifts in the logpolar mapping domain. A matching template is cut from the LPM domain after watermark embedding and is used for correlation matching to find the RST parameters for the watermarked video undergone geometric attacks. Our new phase-only filtering method is used and it is the only filter that can provide an acceptable discrimination while rotation or scaling or both applied to the watermarked video. A square portion from I-frame of each Group of Picture (GOP) is used for watermark embedding based on our analysis that a square image has better tolerance to rotation attack than a rectangular image. The experimental results demonstrate that this algorithm is robust against rotation, scaling, translation transform, noise addition, filtering, MPEG-2 compression, etc.","2010","6","2","2025-12-02","https://university.edu/papers/b60f23d4-bf4e-4b47-8ccc-a8ab3ab01f57.pdf");
INSERT INTO Paper VALUES ("744","Migrate or not? exploiting dynamic task migration in mobile cloud computing systems","Contemporary mobile devices generate heavy loads of computationally intensive tasks, which cannot be executed locally due to the limited processing and energy capabilities of each device. Cloud facilities enable mobile devices-clients to offload their tasks to remote cloud servers, giving birth to Mobile Cloud Computing (MCC). The challenge for the cloud is to minimize the task execution and data transfer time to the user, whose location changes due to mobility. However, providing quality of service guarantees is particularly challenging in the dynamic MCC environment, due to the time-varying bandwidth of the access links, the ever changing available processing capacity at each server and the timevarying data volume of each virtual machine. In this article, we advocate the need for novel cloud architectures and migration mechanisms that effectively bring the computing power of the cloud closer to the mobile user. We consider a cloud computing architecture that consists of a back-end cloud and a local cloud, which is attached to wireless access infrastructure (e.g. LTE base stations). We outline different classes of task migration policies, spanning fully uncoordinated ones, in which each user or server autonomously makes its migration decisions, up to the cloud-wide migration strategy of a cloud provider. We conclude with a discussion of open research problems in the area.","2013","16","4","2025-12-02","https://university.edu/papers/b36d18b7-265f-4011-b591-7e9734a16b80.pdf");
INSERT INTO Paper VALUES ("745","Leveraging Cellular Infrastructure to Improve Fraud Prevention","The relationship between physical security and critical infrastructure has traditionally been unidirectional - the former being necessary to sustain the latter. However, certain pieces of critical infrastructure hold the potential to significantly improve the security of individuals and their most sensitive information. In this paper, we develop a pair of mechanisms for cellular networks and mobile devices that augment the physical security of their users' financial credentials. In particular, we create FrauVent, a multi-modal protocol that provides users with information related to a pending questionable transaction (e.g., transaction value, location, vendor) in a way that improves the available context for approving or rejecting such exchanges. Through protocol design, formal verification and implementation of an application for the Android platform, we develop a robust tool to help reduce the costs of fraud without requiring financial institutions to significantly change their extensively deployed end systems (i.e., card readers). More critically, we provide a general framework that allows cellular infrastructure to actively improve the physical security of sensitive information.","2009","10","3","2025-12-02","https://university.edu/papers/d81ead42-c9a6-45e9-b5b9-83af597a47d6.pdf");
INSERT INTO Paper VALUES ("746","Bulletin Boards in Voting Systems: Modelling and Measuring Privacy","Transparency is crucial to ensuring fair, honest elections. Transparency is achieved by making information (e.g. election result) public. In e-voting literature, this publication is often described in terms of a bulletin board. While privacy of voting systems has been actively studied in recent years, resulting in various analysis frameworks, to date there has not been an explicit modelling of bulletin board in any such framework. Privacy implications of bulletin boards are thus understudied. In this paper, we extend the semantics of the framework of Jonker, Mauw and Pang to model a bulletin board and capture coercion-resistance. The usage of the extended framework is illustrated by an application to the Pret a Voter voting system. Moreover, we present an information-theoretical measure of privacy loss in elections.","2011","4","4","2025-12-02","https://university.edu/papers/878e1f56-a3ad-4e3c-9c26-6b1e10aa0f00.pdf");
INSERT INTO Paper VALUES ("747","Some remarks about factors of graphs","A (g, f)-factor of a graph is a subset F of E such that for all $v \in V$, $g(v)\le {\rm deg}_{F}(v)\le f(v)$. Lovasz gave a necessary and sufficient condition for the existence of a (g, f)-factor. We extend, to the case of edge-weighted graphs, a result of Kano and Saito who showed that if $g(v)< \lambda {\rm deg}_{E}(v) < f (v)$ for any $\lambda\in [0,1]$, then a (g, f)-factor always exist. In addition, we use results of Anstee to provide new necessary and sufficient conditions for the existence of a (g, f)-factor. © 2008 Wiley Periodicals, Inc. J Graph Theory 57: 265–274, 2008","2008","12","3","2025-12-02","https://university.edu/papers/e6fb073c-da9b-4d79-b5b0-12b26589213d.pdf");
INSERT INTO Paper VALUES ("748","Multidimensional wiener filtering using fourth order statistics of hyperspectral images","In this paper we propose a new multidimensional filtering method based on fourth order cumulants to denoise of data tensor impaired by correlated Gaussian noise. We overview the multidimensional Wiener filtering that overcomes the well known lower rank-(K 1 ,..., K N ) tensor approximation. But this method only exploits second order statistics. In some applications, it may be interesting to consider a correlated Gaussian noise. Then, we propose to introduce the fourth order statistics in the denoising algorithm. Indeed, the use of fourth order cumulants enables to remove the Gaussian components of an additive noise. Qualitative results of the improved multidimensional Wiener filtering are shown for the case of noise reduction in hyperspectral imagery.","2008","13","4","2025-12-02","https://university.edu/papers/b72168aa-897f-4b7b-9bb2-0bdee73a7bd4.pdf");
INSERT INTO Paper VALUES ("749","Mining basic active structures from a large-scale database","Background#R##N#The Pubchem Database is a large-scale resource for chemical information, containing millions of chemical compound activities derived by high-throughput screening (HTS). The ability to extract characteristic substructures from such enormous amounts of data is steadily growing in importance. Compounds with shared basic active structures (BASs) exhibiting G-protein coupled receptor (GPCR) activity and repeated dose toxicity have been mined from small datasets. However, the mining process employed was not applicable to large datasets owing to a large imbalance between the numbers of active and inactive compounds. In most datasets, one active compound will appear for every 1000 inactive compounds. Most mining techniques work well only when these numbers are similar.","2013","4","4","2025-12-02","https://university.edu/papers/d53cdaf4-c166-4c97-8afe-8e9fe4fa9f81.pdf");
INSERT INTO Paper VALUES ("750","A simple mathematically based framework for rule extraction using wide spectrum language","Programs use rules to dictate or constrain specific decisions or actions. These rules have typically been tested, revised, and updated continuously; therefore, they represent a substantial and valuable business or intellectual asset. These rules often are not reused because the legacy program code is the only valid source for these rules, and extraction of the rules from the legacy code is thought to be too difficult. This problem is exacerbated when a re-engineering project potentially involves rule recovery from multiple programs in multiple languages. This paper reviews the uses of mathematically formal approaches to business rule recovery and extraction. The applications of provable transformations from different programming languages to Wide Spectrum Language (WSL) are reviewed, and a simple framework for two different rule extraction approaches using WSL is presented. An example of rule extraction using each approach is presented, and the requirements, advantages, and limitations of each approach are examined.","2002","14","4","2025-12-02","https://university.edu/papers/80072006-b7c8-4bc8-91bf-abd42ee27f41.pdf");
INSERT INTO Paper VALUES ("751","Developing LHCb Grid software: experiences and advances","The LHCb Grid software has been used for two Physics Data Challenges, with the latter producing over 98 TB of data and consuming over 650 processor-years of computing power. This paper discusses the experience of developing a Grid infrastructure, interfacing to an existing Grid (LCG) and traditional computing centres simultaneously, running LHCb experiment software and jobs on the Grid, and the integration of a number of new technologies into the Grid infrastructure. Our experience and utilization of the following core technologies will be discussed: OGSI, XML-RPC, Grid services, LCG middleware and instant messaging. Specific attention will be given to analysing the behaviour of over 100 000 jobs executed through the LCG Grid environment, providing insight into the performance, failure modes and scheduling efficiency over a period of several months for a large computational Grid incorporating over 40 sites and thousands of nodes.","2007","5","1","2025-12-02","https://university.edu/papers/a24d2705-d97b-4bc2-8d98-9447ee99f6a9.pdf");
INSERT INTO Paper VALUES ("752","Liver Segmentation from CT Scans: A Survey","In this paper we describe the state of the art of the semi-automatic and automatic techniques for liver volume extraction from abdominal CT. In the recent years this research focus has gained a lot of importance in the field of medical image processing since it is the first and fundamental step of any automated technique for the automatic liver disease diagnosis, liver volume measurement, and 3D liver volume rendering from CT images.","2007","10","4","2025-12-02","https://university.edu/papers/88a676da-76c8-45a3-a5df-5a06fcb7c604.pdf");
INSERT INTO Paper VALUES ("753","Total Public Announcements","We present a dynamic epistemic logic for knowledge change of rational agents. Existing approaches only deal with partial public announcements, that means an announcement may lead to an inconsistent state. We introduce an extension of the multi-modal logic  S5   n  featuring total public announcements where an update cannot result in an inconsistency. We also study total public announcements in the context of common knowledge and relativized common knowledge.","2007","4","4","2025-12-02","https://university.edu/papers/ff6ca42c-111c-4748-a588-d4e756634da5.pdf");
INSERT INTO Paper VALUES ("754","A Distributed Energy-Efficient Flow Protocol for Mobile Ad Hoc Wireless Networks","Because of the limited node battery power, energy optimization is important for the mobile nodes in wireless ad hoc networks. Controlled node mobility is an effective approach to reduce the communication energy consumption while the movement itself consumes energy. Based on cooperative communication (CC) model, the paper takes the energy consumption of node movement and their residual energy into account, and then proposes localized algorithms to direct nodes adapt their transmission power dynamically in mobile ad hoc networks. Compared with other algorithms by simulation, our mechanism shows its efficiency in improving the system lifetime.","2008","1","3","2025-12-02","https://university.edu/papers/99124ea1-1b22-418a-bfd6-4f89efebf97c.pdf");
INSERT INTO Paper VALUES ("755","The Status of Polycyclic Group-Based Cryptography: A Survey and Open Problems","Polycyclic groups are natural generalizations of cyclic groups but with more complicated algorithmic properties. They are finitely presented and the word, conjugacy, and isomorphism decision problems are all solvable in these groups. Moreover, the non-virtually nilpotent ones exhibit an exponential growth rate. These properties make them suitable for use in group-based cryptography, which was proposed in 2004 by Eick and Kahrobaei. Since then, many cryptosystems have been created that employ polycyclic groups. These include key exchanges such as non-commutative ElGamal, authentication schemes based on the twisted conjugacy problem, and secret sharing via the word problem. In response, heuristic and deterministic methods of cryptanalysis have been developed, including the length-based and linear decomposition attacks. Despite these efforts, there are classes of infinite polycyclic groups that remain suitable for cryptography. The analysis of algorithms for search and decision problems in polycyclic groups has also been developed. In addition to results for the aforementioned problems we present those concerning polycyclic representations, group morphisms, and orbit decidability. Though much progress has been made, many algorithmic and complexity problems remain unsolved, we conclude with a number of them. Of particular interest is to show that cryptosystems using infinite polycyclic groups are resistant to cryptanalysis on a quantum computer.","2016","2","4","2025-12-02","https://university.edu/papers/d14a43f0-ded0-49c5-b277-b37e3ec54cb7.pdf");
INSERT INTO Paper VALUES ("756","Adaptive Pinning Synchronization of A General Complex Dynamical Network","This paper further investigates and answers two fundamental questions in the complex dynamical networks: i) how many nodes should a general complex dynamical network with fixed network structure and coupling strength be pinned to reach network synchronization? ii) how much coupling strength should a general complex dynamical network with fixed network structure and pinning nodes be employed to reach network synchronization? In the above framework, the coupling-configuration matrix and the inner-coupling matrix are not necessarily symmetric. Also, the pinning nodes can be randomly selected. Furthermore, our adaptive pinning controllers are rather simple compared with some traditional controllers. Finally, a BA network example is then given to show the effectiveness of the proposed synchronization criteria.","2007","2","3","2025-12-02","https://university.edu/papers/9fe2a862-4e2f-41ed-b3d5-123aad5ad723.pdf");
INSERT INTO Paper VALUES ("757","On the crossed field antenna performance","Lately, short antennas and Crossed Field Antennas (CFA) have attracted broadcast and amateur community attention. The CFA antenna has been developed in the last decade of the 20th century, trying to obtain a compact transmitting antenna for low and medium frequency AM bands. The CFA is intended to be used in order to get a low profile antenna and a supposed performance similar or better compared to a quarter-wave monopole. The CFA has a short monopole and a metallic disk close to the monopole base, both mechanical structures being fed by means of two separated generators. Thus, the CFA has two ports and can be analyzed from the Network Theory point of view. In this paper, the CFA has been studied exhaustively using the Transmission Line Method (TLM) in order to obtain an equivalent network and the antenna performance. Due to the lack of theoretical data to explain the CFA antenna behavior, the TLM has been validated by means of Moment Method simulations and some available experimental data","2006","5","4","2025-12-02","https://university.edu/papers/5da3e72b-9f4d-4b77-968f-82f8856fa92c.pdf");
INSERT INTO Paper VALUES ("758","Blind spatial signature estimation via time-varying user power loading and parallel factor analysis","In this paper, the problem of blind spatial signature estimation using the parallel factor (PARAFAC) analysis model is addressed in application to wireless communications. A time-varying user power loading in the uplink mode is proposed to make the model identifiable and to enable application of PARAFAC analysis. Then, identifiability issues are studied in detail and closed-form expressions for the corresponding modified Crame/spl acute/r-Rao bound (CRB) are obtained. Furthermore, two blind spatial signature estimation algorithms are developed. The first technique is based on the PARAFAC fitting trilinear alternating least squares (TALS) regression procedure, whereas the second one makes use of the joint approximate diagonalization algorithm. These techniques do not require any knowledge of the propagation channel and/or sensor array manifold and are applicable to a more general class of scenarios than earlier approaches to blind spatial signature estimation.","2005","15","3","2025-12-02","https://university.edu/papers/776da8b4-2700-49c7-ba2e-97b3dd7349d0.pdf");
INSERT INTO Paper VALUES ("759","Betti numbers of complexes with highly Connected links","Let Δn−1(k) denote the k  -dimensional skeleton of the (n−1)(n−1)-simplex Δn−1Δn−1 and consider a complex Δn−1(k−1)⊂X⊂Δn−1(k). Let KK be a field and let 0≤l<k0≤l<k. It is shown that if H˜k−l−2(lk(X,τ);K)=0 for all l-dimensional faces τ of X then#R##N##R##N#dim⁡H˜k−1(X;K)≤(n−1l)(n−l−2k−l)(k+1l+1)#R##N##R##N#with equality iff lk(X,τ)lk(X,τ) is a (k−l−1)(k−l−1)-hypertree for all l-dimensional simplices τ   of Δn−1Δn−1. Examples based on sum complexes show that the bound is asymptotically tight for all fixed k,lk,l as n→∞n→∞.","2017","1","2","2025-12-02","https://university.edu/papers/87c1aa36-2670-43af-b0d0-fbfca4cc96ab.pdf");
INSERT INTO Paper VALUES ("760","Wireless Power Transfer by Electric Field Resonance and Its Application in Dynamic Charging","In this paper, the electric field resonance (EFR) method, similar to the four-coil configuration of the magnetic field resonance wireless power transfer, is proposed for the capacitive coupling power transfer. The characteristics of the proposed method are derived and analyzed. With the EFR method, not only unity power factor for the power source is achieved, but also high power factor and low reactive power for the capacitive coupling stage are achieved. Effective power transfer is realized by the EFR method. Based on the proposed method, a dynamic charging concept for railway vehicles is then proposed. A prototype powering system is designed and built to prove the validity of the proposed method. Analytical, simulation, and experimental results are given and compared. A 23-cm model vehicle is put on a 150-cm track. It is shown that about 700-W power is transferred through a 24-pF coupling capacitor. The proposed method reaches 91% dc–dc overall efficiency at switching frequency 2 MHz.","2016","12","2","2025-12-02","https://university.edu/papers/9dc74dac-ee63-4d74-b871-4ea150c01e8a.pdf");
INSERT INTO Paper VALUES ("761","MOTA: engineering an operator agnostic mobile service","There are two emerging trends in the mobile data world. First, mobile data is exploding at a rapid rate with analysts predicting 25-50X growth by the year 2015. The second trend is that users are demanding greater degree of flexibility in selecting their operators at fine timescales. Across Asia, dual-SIM phones have become popular, while Apple is rumored to be designing a  Universal SIM  that will allow iPhone users to toggle between different operators. This latter trend points towards an impending disruption in wireless service models which could also be the need of the hour from the spectrum shortage perspective.   This points towards a new service model where users can choose an operator based on application needs. However, if users make this choice greedily without network assistance, it can exacerbate spectrum scarcity and degrade user experience. In this work, we consider user devices with multiple network interfaces (3G, LTE etc.) that can be simultaneously active and each running multiple applications. We propose the MOTA service model to enable users to associate each interface with the operator of choice at fine time scales. Under the MOTA service model, through concise signalling information, operators provide information about their own network, so that each user can (i) choose a suitable operator for each interface, and (ii) choose an interface for each active application. We make the following contributions in this paper. First, we propose concise network signalling that assists users to make informed choices even under mobility. Second, we develop user-choice algorithms that maximize a suitable notion of user satisfaction while using spectrum resources efficiently. Third, we perform extensive evaluation over actual base station deployment in a city coupled with real signal propagation maps. Our results with two operators show that, MOTA service model provides capacity gain in the range 2.5-4X over the current existing service model. Finally, we argue that our solution is practically implementable by combining appropriate IEEE standards and IETF proposals.","2011","12","4","2025-12-02","https://university.edu/papers/c66c8436-1704-4bb0-9062-3c11d2a9b41a.pdf");
INSERT INTO Paper VALUES ("762","An improved sentiment analysis algorithm for Chinese news","In recent years, news sentiment analysis is a hotspot in the field of natural language processing, and it is also a challenging problem. Methods based on semantic direction almost only consider polarity of emotion words of every sentence in news. We present an improved news sentiment analysis method. It divides news sentiment analysis into title sentiment analysis and text sentiment analysis. For the title, we use our rule set to process. For the text, we use an algorithm of subjective sentences recognition and an algorithm of subject word recognition to analyze the sentiment of Chinese news. We call the proposed method is Improved Sentiment Analysis (ISA). Experimental data shows that the proposed method improves the accuracy of news sentiment analysis.","2015","17","1","2025-12-02","https://university.edu/papers/ee3a10c0-dac2-43c4-adcf-9d39cb7e1b5c.pdf");
INSERT INTO Paper VALUES ("763","Service management for multi-operator heterogeneous networks","The advent of heterogeneous radio networks which combined under the 'Beyond 3G' vision can offer ubiquitous services demands an integrated management approach. We address in this paper an integrated management approach for end-to-end service management over heterogeneous networks in a multi-operator environment. We show how to integrate our solution into the larger context of Web based management, thus allowing the easy integration into already existing management platforms.","2002","6","2","2025-12-02","https://university.edu/papers/d363ae1d-2218-4705-8f24-e87e74475507.pdf");
INSERT INTO Paper VALUES ("764","A New Evolutionary Method with a Hybrid Approach Combining Particle Swarm Optimization and Genetic Algorithms using Fuzzy Logic for Decision Making","We describe in this paper a new hybrid approach for mathematical function optimization combining particle swarm optimization (PSO) and genetic algorithms (GAs) using fuzzy logic to integrate the results. The new evolutionary method combines the advantages of PSO and GA to give us an improved PSO+GA hybrid method. Fuzzy logic is used to combine the results of the PSO and GA in the best way possible. The new hybrid PSO+GA approach is compared with the PSO and GA methods with a set of benchmark mathematical functions. The new hybrid PSO+GA method is shown to be superior than the individual evolutionary methods.","2008","12","3","2025-12-02","https://university.edu/papers/cdb1913d-d521-4c63-be22-b989540eebf7.pdf");
INSERT INTO Paper VALUES ("765","More Semantics More Robust: Improving Android Malware Classifiers","Automatic malware classifiers often perform badly on the detection of new malware, i.e., their robustness is poor. We study the machine-learning-based mobile malware classifiers and reveal one reason: the input features used by these classifiers can't capture general behavioural patterns of malware instances. We extract the best-performing syntax-based features like permissions and API calls, and some semantics-based features like happen-befores and unwanted behaviours, and train classifiers using popular supervised and semi-supervised learning methods. By comparing their classification performance on industrial datasets collected across several years, we demonstrate that using semantics-based features can dramatically improve robustness of malware classifiers.","2016","15","2","2025-12-02","https://university.edu/papers/de7e671d-3fd9-437b-888c-8f85922749ae.pdf");
INSERT INTO Paper VALUES ("766","On Optimal Relay Placement for Urban Vehicular Networks","Wireless vehicular networks have received significant attention. As vehicles are increasingly equipped with onboard sensors, large-scale urban monitoring with vehicular networks becomes attractive. To facilitate better monitoring, it is highly desirable that sensory data of the vehicles can be gathered with high fidelity. Deploying wireless relays is a cost-effective approach for connection enhancement. In this paper we consider the crucial problem of optimal relay placement for maximum data collection from the vehicles. The placement is greatly impacted by vehicle distribution and mobility, which makes it difficult to determine the optimal locations. We theoretically prove that the relay placement problem (RPP) is NP-hard even when the vehicle traces are assumed as a priori knowledge. We first propose an approximate algorithm for the RPP with given vehicle traces (D-RPP). This algorithm is proved to achieve an approximation ratio of (1-1/ e), where e is the natural logarithm base. To solve the RPP without a priori knowledge about future vehicle traces (N-RPP), we first show that there is strong regularity with vehicle mobility by entropy analysis. Then, we propose an algorithm for solving the N-RPP, which exploits regularity extracted from historical traces. Extensive simulations based on real trace datasets show that the D-RPP algorithm produces performance close to the optimum.","2011","9","3","2025-12-02","https://university.edu/papers/a0b3af32-a794-40f4-b6d8-c9e27f637663.pdf");
INSERT INTO Paper VALUES ("767","From order to disorder: the role of computer-based electronics projects on fostering of higher-order cognitive skills","This research explored learning and thinking processes enhanced by integrating computers in secondary schools electronics projects. Electronics studies provide a sophisticated learning environment, where computers are simultaneously part of the subject matter learned (Technology Education), and a means for enhancing teaching and learning (Educational Technology), as seen in any other area of education. The follow-up on fifty students working on their final projects showed that students working on computer-based electronics projects tend to adopt flexible strategies, such as creating new ideas, risk-taking, improvisation, using trial and error methods for problem solving, and rapid transition from one design to another. In contrast, students working on non-computerized electronics projects are more likely to progress along a linear path: planning, construction, and troubleshooting. Computerized projects also promote the transfer of knowledge between students, and joint development of ideas. Students who exercise freedom in their project do not express the same independence in their documentation, and prepare portfolios that show how they, supposedly, developed their system in an orderly manner. It is important to educate students, and teachers, that creative design and problem solving requires a balance between openness, flexibility, and intuition, on the one hand, and systematic investigation, discipline, and hard work, on the other hand.","2005","13","1","2025-12-02","https://university.edu/papers/d5f7fd6f-7253-4db6-a9e1-dffa593c6f07.pdf");
INSERT INTO Paper VALUES ("768","A D2D communication architecture under full control using SDN","Device-to-device (D2D) communication is a potential solution to the incessant increase in data traffic on cellular networks. The greatest problem is how to control the interference between D2D users and cellular mobile users, and between D2D users themselves. This paper proposes a solution for this issue by putting the full control privilege in cellular network using the software-defined networking (SDN) concept. A software virtual switch called Open vSwitch and several components are integrated into mobile devices for data forwarding and radio resource mapping, whereas the control functions are executed in the cellular network via a SDN controller. This allows the network to assign radio resources for D2D communication directly, thus reducing interference. This solution also brings out many benefits, including resource efficiency, energy saving, topology flexibility, etc. The advantages and disadvantages of this architecture are analyzed by both a mathematical method and a simple implementation. The result shows that implementation of this solution in the next generation of cellular networks is feasible.","2016","16","4","2025-12-02","https://university.edu/papers/06ba6a79-c7a3-4309-8d1c-e22f2333a194.pdf");
INSERT INTO Paper VALUES ("769","SNet: skip graph based semantic web services discovery","This paper presents the design of SNet system, which is a P2P overlay for Semantic Web Services discovery. SNet differs from previous P2P Web Services discovery systems in that it supports complex search with its locality-preserving feature based on Skip Graph. To guarantee efficient and semantic service discovery, SNet schemes WSDL-S as Semantic Web Services description language and extracts its semantic attributes as indexing keys in Skip Graph so that similar keys are aggregated to keep the leverage between peer nodes. Our evaluation showed that the SNet system performs considerable service discovery efficiency.","2007","16","2","2025-12-02","https://university.edu/papers/e8fdd2b0-9eda-4e55-a3a8-8de50c8db12d.pdf");
INSERT INTO Paper VALUES ("770","TUIC: enabling tangible interaction on capacitive multi-touch displays","We present  TUIC , a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M's multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects:  spatial ,  frequency , and  hybrid (spatial plus frequency) . The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M's multi-touch displays.","2011","19","3","2025-12-02","https://university.edu/papers/754a20b6-4af2-4548-bb70-49cd1e3a8041.pdf");
INSERT INTO Paper VALUES ("771","Faithful performance prediction of a dynamic task‐based runtime system for heterogeneous multi‐core architectures","Summary#R##N#Multi-core architectures comprising several graphics processing units (GPUs) have become mainstream in the field of high-performance computing. However, obtaining the maximum performance of such heterogeneous machines is challenging as it requires to carefully off-load computations and manage data movements between the different processing units. The most promising and successful approaches so far build on task-based runtimes that abstract the machine and rely on opportunistic scheduling algorithms. As a consequence, the problem gets shifted to choosing the task granularity, task graph structure, and optimizing the scheduling strategies. Trying different combinations of these different alternatives is also itself a challenge. Indeed, obtaining accurate measurements requires reserving the target system for the whole duration of experiments. Furthermore, observations are limited to the few available systems at hand and may be difficult to generalize. In this article, we show how we crafted a coarse-grain hybrid simulation/emulation of StarPU, a dynamic runtime for hybrid architectures, over SimGrid, a versatile simulator of distributed systems. This approach allows to obtain performance predictions of classical dense linear algebra kernels accurate within a few percents and in a matter of seconds, which allows both runtime and application designers to quickly decide which optimization to enable or whether it is worth investing in higher-end graphics processing units or not. Additionally, it allows to conduct robust and extensive scheduling studies in a controlled environment whose characteristics are very close to real platforms while having reproducible behavior. Copyright © 2015 John Wiley & Sons, Ltd.","2015","5","3","2025-12-02","https://university.edu/papers/a13ac36c-9a3a-45db-9c79-423e411cc9d0.pdf");
INSERT INTO Paper VALUES ("772","A performance counterexample of Billor–Chatterjee–Hadi procedure and an improvement proposal for robust regression","AbstractThe BCH procedure introduced by Billor et al. for fitting linear models was found to be inefficient for y-outliers in the presence of a high perturbation level. We propose to modify the first step of the BCH procedure, so that the robust distances are computed on the matrix Z = (y, X) of the basic subset. The performance of the present note procedure (PNP), as compared to the BCH procedure and the OLS method, was studied by processing several datasets used in the literature for robust regression and by performing a Monte Carlo experiment. PNP performs better particularly with datasets having high perturbation.","2015","19","3","2025-12-02","https://university.edu/papers/9ddc5cde-b2bd-4725-80e9-b6cf477487b2.pdf");
INSERT INTO Paper VALUES ("773","Complex intuitionistic fuzzy classes","A complex fuzzy class is characterized by a pure complex fuzzy grade of membership. Pure complex fuzzy classes are paramount in providing rich semantics for cases where the fuzzy data is periodic with a fuzzy period. Often, however, the available data is contaminated by noise, opposing expert opinions, ambiguity, and false information. This opens the door for using intuitionistic fuzzy sets theory: representing the false information via a degree of non-membership. Several researchers have identified the benefits of integrating the two concepts of complex fuzzy sets and intuitionistic fuzzy sets. Nevertheless, complex fuzzy sets allow for only one component of the degree of membership to be fuzzy. In this paper, we introduce the concept of complex intuitionistic fuzzy classes, which are characterized by pure complex intuitionistic fuzzy grade of membership. We define the basic terms and operations on complex intuitionistic fuzzy classes and provide a motivating example of relevant application.","2016","19","4","2025-12-02","https://university.edu/papers/bf88adec-83a8-41b7-b65b-0b3489f9587b.pdf");
INSERT INTO Paper VALUES ("774","A new clustering algorithm applicable to multispectral and polarimetric SAR images","The authors applied a scale-space clustering algorithm to the classification of a multispectral and polarimetric SAR image of an agricultural site. After the initial polarimetric and radiometric calibration and noise cancellation, a 12-dimensional feature vector for each pixel was extracted from the scattering matrix. The clustering algorithm partitioned a set of unlabeled feature vectors from 13 selected sites, each site corresponding to a distinct crop, into 13 clusters without any supervision. The cluster parameters were then used to classify the whole image. The classification map is much less noisy and more accurate than those obtained by hierarchical rules. Starting with every point as a cluster, the algorithm works by melting the system to produce a tree of clusters in the scale space. It can cluster data in any multidimensional space and its insensitive to variability in cluster densities, sizes and ellipsoidal shapes. This algorithm, more powerful than existing ones, may be useful for remote sensing for land use. >","1993","3","1","2025-12-02","https://university.edu/papers/b0cc0ae3-ad2f-4db1-b8c5-274db7f180e5.pdf");
INSERT INTO Paper VALUES ("775","The Degree of Squares is an Atom (Extended Version)","We answer an open question in the theory of degrees of infinite sequences with respect to transducibility by finite-state transducers. An initial study of this partial order of degrees was carried out in (Endrullis, Hendriks, Klop, 2011), but many basic questions remain unanswered. One of the central questions concerns the existence of atom degrees, other than the degree of the `identity sequence' 1 0^0 1 0^1 1 0^2 1 0^3 .... A degree is called an `atom' if below it there is only the bottom degree 0, which consists of the ultimately periodic sequences. We show that also the degree of the `squares sequence' 1 0^0 1 0^1 1 0^4 1 0^9 1 0^{16} ... is an atom. As the main tool for this result we characterise the transducts of `spiralling' sequences and their degrees. We use this to show that every transduct of a `polynomial sequence' either is in 0 or can be transduced back to a polynomial sequence for a polynomial of the same order.","2015","1","2","2025-12-02","https://university.edu/papers/2c65bd4a-28f1-4feb-bb59-56ed3faaaf06.pdf");
INSERT INTO Paper VALUES ("776","Queuing network analysis for waterways with artificial neural networks","An Artificial Neural Network (ANN) model has been developed for analyzing traffic in an inland waterway network. The main purpose of this paper is to determine how well such a relatively fast model for analyzing a queuing network could substitute for far more expensive simulation. Its substitutability for simulation is judged by relative discrepancies in predicting tow delays between the ANN and simulation models. This model is developed by integrating five distinct ANN submodels that predict tow headway variances at (1) merge points, (2) branching (i.e., diverging) points, (3) lock exits, and (4) link outflow points (e.g., at ports, junctions, or lock entrances), plus (5) tow queuing delays at locks. Preliminary results are shown for those five submodels and for the integrated network analysis model. Eventually, such a network analyzer should be useful for designing, selecting, sequencing, and scheduling lock improvement projects, for controlling lock operations, for system maintenance planning, and for other applications where many combinations of network characteristics must be evaluated. More generally, this method of decomposing complex queuing networks into elements that can be analyzed with ANNs and then recombined provides a promising approach for analyzing other queuing networks (e.g., in transportation, communication, computing, and production systems).","1999","8","1","2025-12-02","https://university.edu/papers/fdce5f1f-5050-4ea2-aedb-e83ad968a428.pdf");
INSERT INTO Paper VALUES ("777","A visualization and analysis tool for NS-2 wireless simulations: iNSpect","The network simulator 2 (NS-2) is a popular and powerful simulation environment, and the number of NS-2 users has increased greatly in recent years. Although it was originally designed for wired networks, NS-2 has been extended to work with wireless networks, including wireless LANs, mobile ad hoc networks (MANETs), and sensor networks; however, the network animator (NAM) for NS-2 has not been extended for wireless visualization. In this paper, we discuss a new visualization and analysis tool for use with NS-2 wireless simulations. Visual analysis of a wireless environment is important for three areas of NS-2 based simulation research: (1) validating the accuracy of a mobility model's output and/or the node topology files used to drive the simulation; (2) validation of new versions of the NS-2 simulator itself; and-(3) analysis of the results of NS-2 simulations. Our iNSpect program handles all three of these areas quickly and accurately. We've made our iNSpect program available for other researchers in order to improve the accuracy of their simulations.","2005","4","4","2025-12-02","https://university.edu/papers/b12d0262-55aa-4143-8c7f-abdbb9ca44a3.pdf");
INSERT INTO Paper VALUES ("778","Mining paths of complex crowd scenes","The Ambient Intelligence (AmI) paradigm requires a robust interpretation of people actions and behaviour and a way for automatically generating persistent spatial-temporal models of recurring events. This paper describes a relatively inexpensive technique that does not require the use of conventional trackers to identify the main paths of highly cluttered scenes, approximating them with spline curves. An AmI system could easily make use of the generated model to identify people who do not follow prefixed paths and warn them. Security, safety, rehabilitation are potential application areas. The model is evaluated against new data of the same scene.","2005","16","3","2025-12-02","https://university.edu/papers/9844a54a-24a6-4cc8-9a50-50de58ee866a.pdf");
INSERT INTO Paper VALUES ("779","Bidirectional Decoder Networks for Attention-Based End-to-End Offline Handwriting Recognition","Recurrent neural networks that can be trained end-to-end on sequence learning tasks provide promising benefits over traditional recognition systems. In this paper, we demonstrate the application of an attention-based long short-term memory decoder network for offline handwriting recognition and analyze the segmentation, classification and decoding errors produced by the model. We further extend the decoding network by a bidirectional topology together with an integrated length estimation procedure and show that it is superior to unidirectional decoder networks. Results are presented for the word and text line recognition tasks of the RIMES handwriting recognition database. The software used in the experiments is freely available for academic research purposes.","2016","8","2","2025-12-02","https://university.edu/papers/caf4c98d-2fec-41ac-9991-ccfc6bd83d9e.pdf");
INSERT INTO Paper VALUES ("780","A modeling technique utilizing feedback control theory for performance evaluation of IoT system in real-time","Communication techniques for Internet of Things (IoT) have attracted research attention because of the increasing number and variety of connected devices. The IoT systems are able to provide a variety of applications by collecting information from various “things” using the network constructed by the things. The IoT systems are required to provide the applications in real-time. For example, the immediacy and the time restriction will be more important to the applications. Although there have been many applications of real-time IoT systems, a specific model for performance evaluation has not received adequate attention. Therefore, in this paper, we focus on the modeling aspect for evaluating the performance of real-time IoT system. Specifically, our proposed model is constructed by utilizing feedback control theory. In order to apply feedback control theory for our model, we introduce a method for representing the “things” as the controlled objects in the control theory. After that, the overall system model of the real-time IoT with the controlled objects is represented. Finally, our represented method is validated through the numerical analysis while varying the parameters.","2015","4","2","2025-12-02","https://university.edu/papers/af1b312a-8b11-4bdf-b0d8-d836926ad2b7.pdf");
INSERT INTO Paper VALUES ("781","Metabolite-based clustering and visualization of mass spectrometry data using one-dimensional self-organizing maps.","Background#R##N#One of the goals of global metabolomic analysis is to identify metabolic markers that are hidden within a large background of data originating from high-throughput analytical measurements. Metabolite-based clustering is an unsupervised approach for marker identification based on grouping similar concentration profiles of putative metabolites. A major problem of this approach is that in general there is no prior information about an adequate number of clusters.","2008","13","4","2025-12-02","https://university.edu/papers/839b88e4-f6c2-44a1-9b9d-41d9e0823368.pdf");
INSERT INTO Paper VALUES ("782","A Hadoop Use Case for Engineering Data","This paper presents the VELaSSCo project (Visualization for Extremely LArge-Scale Scientific Computing). It aims to develop a platform to manipulate scientific data used by FEM (Finite Element Method) and DEM (Discrete Element Method) simulations. The project focuses on the development of a distributed, heterogeneous and high-performance platform, enabling the scientific communities to store, process and visualize huge amounts of data. The platform is compatible with current hardware capabilities, as well as future hardware.","2015","3","1","2025-12-02","https://university.edu/papers/8d57aa27-68af-406c-b599-0c74d2b4a449.pdf");
INSERT INTO Paper VALUES ("783","2-D digital curve analysis: A regularity measure","A regularity measure for discrete line geometry is presented. This quantitative measure based on a ratio between line lengths at different scales is analyzed in the framework of Brownian motion theory. The measure at a given scale is always computed from the maximum precision image, so that it does not introduce any subresolution assumption. A scale choice determines the quantity of global information vs. local information to be measured. Its statistical behavior is studied on two extremal models of curves: the Brownian motion and the digitized straight line. It is shown that this quantitative measure leads to relevant shape information. To illustrate this fact, an image segmentation application example is discussed based essentially on geometry criteria of region boundaries. Some experimental results performed on real-scene images are presented. >","1993","20","3","2025-12-02","https://university.edu/papers/8c10a259-eaca-4162-8740-75c1df9b42f2.pdf");
INSERT INTO Paper VALUES ("784","Dealing with Unforeseen Situations in the Context of Self-Adaptive Urban Traffic Control: How to Bridge the Gap","Autonomously adapting signalling strategies to changing traffic demands in urban areas have been frequently used as application scenario for self-organising systems in general as well as for Autonomic or Organic Computing systems in particular. The Organic Traffic Control (OTC) system is one of the most prominent representatives in this domain. OTC implements a multi-layered Observer/Controller (O/C) architecture and utilises a strongly modified eXtended Classifier System (XCSO/C) for the task of self-adaptation. In this paper, we extend the algorithmic structure of XCS-O/C by a novel interpolation-based approach that incorporates existing knowledge beyond the traditional means. We demonstrate the benefit of the developed approach in terms of reduced delay times for near-to-reality simulations of realistic traffic conditions from Hamburg, Germany.","2016","4","1","2025-12-02","https://university.edu/papers/9255fae4-ada8-4839-82ab-b21c2439bfd1.pdf");
INSERT INTO Paper VALUES ("785","Relaciones morfoléxicas prefijales del español.","Resumen: En este trabajo se presenta una taxonomia de los sufijos derivativos y terminaciones usadas en espanol utiles para el establecimiento de relaciones morfolexicas deducidas a partir del un corpus de 134109 formas canonicas. Se desarrolla un sistema capaz de resolver y responder a cualquier aspecto morfologico de una palabra del espanol que abarca todo lo relacionado con la morfologia derivativa y otros aspectos cercanos. Permite el reconocimiento, la generacion y la manipulacion de las relaciones morfolexicas a partir de cualquier palabra, categoria gramatical de la base y de sus palabras relacionadas, incluye la recuperacion de toda su informacion lexicogenetica hasta llegar a una primitiva, la gestion y control de los afijos en el tratamiento de sus relaciones, asi como la regularidad en la relacion establecida. Palabras clave: morfologia, lematizacion, derivacion, sufijacion, linguistica computacional.","2004","3","4","2025-12-02","https://university.edu/papers/d661174c-8661-470e-a505-0ca5db7937a3.pdf");
INSERT INTO Paper VALUES ("786","An Empirical Analysis of the Impact of Pre-Release Movie Piracy on Box Office Revenue","Digital distribution channels raise many new challenges for managers in the media industry. This is particularly true for movie studios where high-value content can be stolen and released through illegitimate digital channels, even prior to the release of the movie in legal channels. In response to this potential threat, movie studios have spent millions of dollars to protect their content from unauthorized distribution throughout the lifecycle of films. They have focused their efforts on the pre-release period under the assumption that pre-release piracy could be particularly harmful for a movie's success.#R##N##R##N#However, surprisingly, there has been little rigorous research to analyze whether, and how much, pre-release movie piracy diminishes legitimate sales. In this paper, we analyze this question using data collected from a unique Internet file-sharing site. We find that, on average, pre-release piracy causes a 19.1% decrease in revenue compared to piracy that occurs post-release.#R##N##R##N#Our study contributes to the growing literature on piracy and digital media consumption by presenting evidence of the impact of Internet-based movie piracy on sales and by analyzing pre-release piracy, a setting that is distinct from much of the existing literature.","2014","12","1","2025-12-02","https://university.edu/papers/a0113002-2855-419e-afb5-cbb23ae8894f.pdf");
INSERT INTO Paper VALUES ("787","Illustrative visualization: interrogating triangulated surfaces","Geometrical modeling is a crucial aspect of simulations involving manufactured objects and is usually performed using free-form surfaces. However, to simulate the flow through or about a manufactured object or to simulate structural integrity, the free-form surfaces must be tessellated into triangulated surfaces. To concurrently visualize the simulation results and the quality of the surfaces, we present two novel visualization algorithms for triangulated surfaces as opposed to the traditional freeform surfaces. The proposed algorithms are for curvature estimation based on local surface fitting with cubic triangular Bezier patches and for reflection-line computation.","2009","6","3","2025-12-02","https://university.edu/papers/f1fb7e8c-1a95-4a32-b9e1-3864660109ec.pdf");
INSERT INTO Paper VALUES ("788","Automated detection of unusual events on stairs","This paper presents a method for automatically detecting unusual human events on stairs from video data. The motivation is to provide a tool for biomedical researchers to rapidly find the events of interest within large quantities of video data. Our system identifies potential sequences containing anomalies, and reduces the amount of data that needs to be searched by a human. We compute two sets of features from a video of a person descending a stairwell. The first set of features are the foot positions and velocities. We track both feet using a mixed state particle filter with an appearance model based on histograms of oriented gradients. We compute expected (most likely) foot positions given the state of the filter at each frame. The second set of features are the parameters of the mean optical flow over a foreground region. Our final classification system inputs these two sets of features into a hidden Markov model (HMM) to analyse the spatio-temporal progression of the stair descent. A single HMM is trained on sequences of normal stair use, and a threshold on sequence likelihoods is used to detect unusual events in new data. We demonstrate our system on a data set with five people descending a set of stairs in a laboratory environment. We show how our system can successfully detect nearly all anomalous events, with a low false positive rate. We discuss limitations and suggest improvements to the system.","2009","4","4","2025-12-02","https://university.edu/papers/d262fe45-d393-4c86-b709-a6114407d3ca.pdf");
INSERT INTO Paper VALUES ("789","Iterative design of Teleoperative Slit Lamp Microscopes for Telemedicine","This paper reports a design project of Teleoperative Slit lamp Microscopes for Telemedicine. The project is a case study of development and deployment of a telemedicine system using human-centered design approaches. At the beginning of the design process, we conducted field research and paper prototyping of the doctor's terminal with ophthalmologists. Later, we developed working prototypes for evaluation. We conducted ophthalmologist's fixation data collection to redesign the user interface of the latest prototype.","2010","13","2","2025-12-02","https://university.edu/papers/864bb525-09be-4c67-b1f8-385592f613c5.pdf");
INSERT INTO Paper VALUES ("790","Enabling near real-time central control for live video delivery in CDNs","User-created live video streaming is marking a fundamental shift in the workload of live video delivery. However, live-video-specific challenges and the viral nature of user-created content makes it difficult for current CDNs to deliver 1) high-quality, 2) highly-scalable, and 3) highly-responsive service. We present the design and implementation of VDN, a new control plane for CDNs designed to optimize the delivery of live streams within the CDN. VDN satisfies these requirements by using two approaches: 1) optimizing directly for video quality (not just throughput) and 2) combining centralized control with local control, allowing VDN to adapt to traffic dynamics and network failures at fine timescales.","2015","19","2","2025-12-02","https://university.edu/papers/7cb78525-be52-4694-a8e3-c3caec16d367.pdf");
INSERT INTO Paper VALUES ("791","Advanced Video Services Delivery over Heterogeneous Networks","Summary form only given. ADVISE special session aims to addresses an important issues related to Quality of Service (QoS) adaptation for the delivery of multimedia services over next generation wired/wireless networks. This session covers future multimedia communication systems that can be part of an end-to-end system by including support of the userpsilas needs and preferences and taking into consideration the terminal capabilities, the content specification and the underlying networking technologies. This session has papers presenting important results for handling QoS adaptation for multimedia content delivery.","2008","7","3","2025-12-02","https://university.edu/papers/52f3e1f0-90c1-43fc-a1f8-2b44e2a04344.pdf");
INSERT INTO Paper VALUES ("792","A novel objective function for improved phoneme recognition using time-delay neural networks","Single-speaker and multispeaker recognition results are presented for the voice-stop consonants /b,d,g/ using time-delay neural networks (TDNNs) with a number of enhancements, including a new objective function for training these networks. The new objective function, called the classification figure of merit (CFM), differs markedly from the traditional mean-squared-error (MSE) objective function and the related cross entropy (CE) objective function. Where the MSE and CE objective functions seek to minimize the difference between each output node and its ideal activation, the CFM function seeks to maximize the difference between the output activation of the node representing incorrect classifications. A simple arbitration mechanism is used with all three objective functions to achieve a median 30% reduction in the number of misclassifications when compared to TDNNs trained with the traditional MSE back-propagation objective function alone. >","1990","16","4","2025-12-02","https://university.edu/papers/da51ab33-125e-4d94-8c9b-180b72a2b535.pdf");
INSERT INTO Paper VALUES ("793","Unequal-error-protection codes in SRAMs for mobile multimedia applications","In this paper, we introduce unequal-error-protection error correcting codes (UEPECCs) to improve SRAM reliability at low supply voltages for mobile multimedia applications. The fundamental premise for our work is that in multimedia applications, different bits in the same SRAM word are usually not equally significant, and hence deserve different protection levels. The key innovation in our work includes (i) a novel metric, word mean squared error, to measure the reliability of a SRAM word when different bits are not equally significant and (ii) an optimization algorithm based on dynamic programming to construct the UEPECC that assigns different protection levels to bits according to their significance. The advantage of the UEPECC over the traditional equal-error-protection ECC is demonstrated using two representative multimedia applications. For the same area, power, and encoding/decoding latency, SRAMs with UEPECC increase the peak signal-to-noise ratio by 8 dB in image processing and incur 60% less errors on average in optical flow (motion vector) computation.","2011","10","2","2025-12-02","https://university.edu/papers/a2eeb79c-8b87-41eb-8274-f92b7e7c57ba.pdf");
INSERT INTO Paper VALUES ("794","Error rate performance of the projection code","The operation of the projection code is introduced, and the error rate performance is determined. A new combinatorial generating function technique is used to compute the weight distribution of a cylindrical projection code, which is then employed to obtain upper and lower bounds of the bit error rate of the code. We then apply a state equation technique to compute the generating function of a convolutional projection code. This new generating function technique is needed since the standard state-diagram technique cannot realistically be used to obtain the generating function of a typical convolutional projection code which can have a constraint length of 56.","1996","7","2","2025-12-02","https://university.edu/papers/d569dc01-7597-4ab3-9a57-c4edecfce6cf.pdf");
INSERT INTO Paper VALUES ("795","Outsourced private information retrieval","We propose a scheme for outsourcing Private Information Retrieval (PIR) to untrusted servers while protecting the privacy of the database owner as well as that of the database clients. We observe that by layering PIR on top of an Oblivious RAM (ORAM) data layout, we provide the ability for the database owner to perform private writes, while database clients can perform private reads from the database even while the owner is offline. Our system is compatible with existing PIR access control and pricing schemes on a per-record basis for these reads. This extends the usual ORAM model by allowing multiple database readers without requiring trusted hardware; indeed, almost all of the computation in our scheme during reads is performed by untrusted cloud servers. We make a second observation that the database owner can always conduct a private read as an ordinary database client, and the private write protocol does not have to provide a 'read' functionality as a standard ORAM protocol does. Based on the two observations, we construct an end-to-end system that privately updates a 1 MB record in a 1 TB database with an amortized end-to-end response time as low as 300 ms when the database owner has a fast network connection to the database servers, and about 1 minute over a slow ADSL connection. Private read times by the database readers are on the order of seconds in either case.","2013","14","2","2025-12-02","https://university.edu/papers/64a114f5-70e1-4f81-970f-d54661ff77fb.pdf");
INSERT INTO Paper VALUES ("796","Efficient VLSI Implementation of $2^{{n}}$ Scaling of Signed Integer in RNS ${\{2^{n}-1, 2^{n},2^{n}+1\}}$","Scaling is a problematic operation in residue number system (RNS) but a necessary evil in implementing many digital signal processing algorithms for which RNS is particularly good. Existing signed integer RNS scalers entail a dedicated sign detection circuit, which is as complex as the magnitude scaling operation preceding it. In order to correct the incorrectly scaled negative integer in residue form, substantial hardware overheads have been incurred to detect the range of the residues upon magnitude scaling. In this brief, a fast and area efficient 2 n  signed integer RNS scaler for the moduli set {2 n -1, 2 n , 2 n +1} is proposed. A complex sign detection circuit has been obviated and replaced by simple logic manipulation of some bit-level information of intermediate magnitude scaling results. Compared with the latest signed integer RNS scalers of comparable dynamic ranges, the proposed architecture achieves at least 21.6% of area saving, 28.8% of speedup, and 32.5% of total power reduction for n ranging from 5 to 8.","2013","3","1","2025-12-02","https://university.edu/papers/b349f44a-0e06-45d3-addd-86ed75abb8ca.pdf");
INSERT INTO Paper VALUES ("797","Robust Visual Tracking with Deep Convolutional Neural Network Based Object Proposals on PETS","Tracking by detection based object tracking methods encounter numerous complications including object appearance changes, size and shape deformations, partial and full occlusions, which make online adaptation of classifiers and object models a substantial challenge. In this paper, we employ an object proposal network that generates a small yet refined set of bounding box candidates to mitigate the this object model refitting problem by concentrating on hard negatives when we update the classifier. This helps improving the discriminative power as hard negatives are likely to be due to background and other distractions. Another intuition is that, in each frame, applying the classifier only on the refined set of object-like candidates would be sufficient to eliminate most of the false positives. Incorporating an object proposal makes the tracker robust against shape deformations since they are handled naturally by the proposal stage. We demonstrate evaluations on the PETS 2016 dataset and compare with the state-of-theart trackers. Our method provides the superior results.","2016","4","2","2025-12-02","https://university.edu/papers/947139f7-67d7-48ef-adb5-f8ae50d60fbe.pdf");
INSERT INTO Paper VALUES ("798","A Hensel lifting to replace factorization in list-decoding of algebraic-geometric and Reed-Solomon codes","This article presents an algorithmic improvement to Sudan's (see J. Complexity, vol.13, p.180-93, 1997) list-decoding algorithm for Reed-Solomon codes and its generalization to algebraic-geometric codes from Shokrollahi and Wasserman (see ibid., vol.45, p.432-37, 1999). Instead of completely factoring the interpolation polynomial over the function field of the curve, we compute sufficiently many coefficients of a Hensel development to reconstruct the functions that correspond to codewords. We prove that these Hensel developments can be found efficiently using Newton's method. We also describe the algorithm in the special case of Reed-Solomon codes.","2000","2","2","2025-12-02","https://university.edu/papers/b6de9156-960d-40cc-bd57-2d3783d4bc04.pdf");
INSERT INTO Paper VALUES ("799","CoreDevRec: Automatic Core Member Recommendation for Contribution Evaluation","The pull-based software development helps developers make contributions flexibly and efficiently. Core members evaluate code changes submitted by contributors, and decide whether to merge these code changes into repositories or not. Ideally, code changes are assigned to core members and evaluated within a short time after their submission. However, in reality, some popular projects receive many pull requests, and core members have difficulties in choosing pull requests which are to be evaluated. Therefore, there is a growing need for automatic core member recommendation, which improves the evaluation process. In this paper, we investigate pull requests with manual assignment. Results show that 3.2%�40.6% of pull requests are manually assigned to specific core members. To assist with the manual assignment, we propose CoreDevRec to recommend core members for contribution evaluation in GitHub. CoreDevRec uses support vector machines to analyze different kinds of features, including file paths of modified codes, relationships between contributors and core members, and activeness of core members. We evaluate CoreDevRec on 18651 pull requests of five popular projects in GitHub. Results show that CoreDevRec achieves accuracy from 72.9% to 93.5% for top 3 recommendation. In comparison with a baseline approach, CoreDevRec improves the accuracy from 18.7% to 81.3% for top 3 recommendation. Moreover, CoreDevRec even has higher accuracy than manual assignment in the project TrinityCore. We believe that CoreDevRec can improve the assignment of pull requests.","2015","1","3","2025-12-02","https://university.edu/papers/ae62d70a-95f1-4409-a2b8-38a5ff9c2b46.pdf");
INSERT INTO Paper VALUES ("800","Big data assisted customer analysis and advertising architecture for real estate","Advertising delivery is the key in the real estate industry. This paper proposes a big data assisted customer analysis and advertising (BDCAA) architecture. Its aim is to precisely seek potential users and improve the efficiency of advertisement delivery. The proposed BDCAA architecture consists of three stages, including user 360-degree portrait and users segmentation, potential customer mining, precise advertising delivery. Experiment shows the BDCAA architecture can reach high advertising arrival rate, as well as superior advertising exposure/click conversion rate.","2016","14","1","2025-12-02","https://university.edu/papers/0abcf2ca-4d75-4d22-ba34-52b6ee0ba9a5.pdf");
INSERT INTO Paper VALUES ("801","Delivering Group-based Feedback of Electricity Usage in Campus Dorms: Poster Abstract","The installation of smart meters in buildings introduces new opportunities for system and application design, to encourage energy conservation or other environmentally friendly behaviors. Delivering feedback to users is a widely-adopted approach that can potentially influence behaviors effectively. The main contribution of our work includes designing and implementing systems to deliver feedback of electricity usage in a real campus dormitory environment, as well as applying a data analytic approach to generate group-based comparative feedback. The approach divides users into groups based on actual usage data, rather than doing it statically, based on long-term patterns. We believe that the group-based feedback can encourage energy conservation more effectively.","2016","11","2","2025-12-02","https://university.edu/papers/cff7d190-56f0-417c-92bc-2319a51ec70f.pdf");
INSERT INTO Paper VALUES ("802","Multiuser private queries over encrypted databases","Searchable encryption schemes allow users to perform keyword-based searches on an encrypted database. Almost all existing such schemes only consider the scenario where a single user acts as both the data owner and the querier. However, most databases in practice do not just serve one user; instead, they support search and write operations by multiple users. In this paper, we systematically study searchable encryption in a practical multiuser setting. Our results include a set of security notions for multiuser searchable encryption as well as a construction which is provably secure under the newly introduced security notions. We also discuss how to improve query efficiency.","2009","17","4","2025-12-02","https://university.edu/papers/a612e9f2-a71b-4570-bbd5-ac6087d51d60.pdf");
INSERT INTO Paper VALUES ("803","A phonetically aware system for speech activity detection","Speech activity detection (SAD) is an essential component of most speech processing tasks and greatly influences the performance of the systems. Noise and channel distortions remain a challenge for SAD systems. In this paper, we focus on a dataset of highly degraded signals, developed under the DARPA Robust Automatic Transcription of Speech (RATS) program. On this challenging data, the best-performing systems are those based on deep neural networks (DNN) trained to predict speech/non-speech posteriors for each frame. We propose a novel two-stage approach to SAD that attempts to model phonetic information in the signal more explicitly than in current systems. In the first stage, a bottleneck DNN is trained to predict posteriors for senones. The activations at the bottleneck layer are then used as input to a second DNN, trained to predict the speech/non-speech posteriors. We test performance on two datasets, with matched and mismatched channels compared to those in the training data. On the matched channels, the proposed approach leads to gains of approximately 35% relative to our best single-stage DNN SAD system. On mismatched channels, the proposed system obtains comparable performance to our baseline, indicating more work needs to be done to improve robustness to mismatched data.","2016","7","2","2025-12-02","https://university.edu/papers/98d02fab-1cfe-49b3-861d-52d5b8a9682b.pdf");
INSERT INTO Paper VALUES ("804","FFT-based incremental refinement of suboptimal detection","In the context of FFT-based maximum-likelihood (ML) detection of a complex sinusoid in noise, we consider the result of terminating the FFT at an intermediate stage of computation and applying the ML detection strategy to its unfinished results. We show that detection performance increases monotonically with the number of FFT stages completed, converging ultimately to that of the exact ML detector. The receiver operating characteristic associated with the completion of each FFT stage is derived. This enables the calculation of the minimum number of FFT stages that must be completed in order for desired detection and false alarm probabilities to be obtained.","1996","19","4","2025-12-02","https://university.edu/papers/831a699e-2a90-4dd7-9e93-beef531bb6f3.pdf");
INSERT INTO Paper VALUES ("805","Meta objects for access control: extending capability-based security","Object-based programming is becoming more and more popular and is currently conquering the world of distributed programming models. In object-based systems, access control is often based on capabilities, as capability-based security is a well-known paradigm. It has been extended by means to restrict, revoke, and expire capabilities. On the other hand, capabilities have serious drawbacks. First, in object-based systems, programming is based on the frequent exchange of object references (i.e., capabilities). Thus, it is hard to check which parts of an application are able to gain control of a certain capability. This becomes even harder if we consider distributed object-based systems like Java RMI and CORBA. Second. a capability usually cannot prevent method invocations from leaking unprotected references as return values. Transitive access control is not possible in a transparent way, which is independent of the code describing the invocation. We present a new security paradigm based on meta objects. Meta objects can be attached to object references and control access to the corresponding objects. Meta objects offer the same functionality as capability-based security. In addition. they can be used for implicit and transitive access control of object references passed as a parameter or as a result. Such a reference can be automatically protected by the meta object by attaching itself or another meta object to the reference before passing it on. Meta objects can implement arbitrary and user-defined security policies. They help to separate security policies from application code, and thus support reuse.","1998","17","3","2025-12-02","https://university.edu/papers/60a05a09-0759-4dba-b85a-6222a2310338.pdf");
INSERT INTO Paper VALUES ("806","Migrating a library's web site to a commercial CMS within a : campus-wide implementation","Purpose – To examine the issues involved with migrating an academic library's web site to a commercial content management system (CMS) within a campus‐wide implementation.Design/methodology/approach – The old and new web sites are described in terms of their histories, technologies, and structures. Key issues relating to the migration are identified and some concerns and benefits are listed.Findings – Although proprietary systems are restrictive in some ways, the technological, organizational, and work flow advantages to the CMS which was employed are significant. An entirely different set of issues emerge when a library participates in a campus‐wide implementation as opposed to one which is librarywide.Originality/value – This may be the first case study of a CMS migration that is both campus‐wide and using a commercially available system. The current trend in academic libraries toward home‐grown systems could some day be reversed as the commercial CMS market evolves.","2006","12","2","2025-12-02","https://university.edu/papers/cb242ec0-3e72-4cd1-87b1-ffbde81c34bb.pdf");
INSERT INTO Paper VALUES ("807","A Study of Cyber Security Awareness in Educational Environment in the Middle East","Information security awareness can play an important role in facing cyber-attacks by intruders. The main goal of this paper is to analyse the information security awareness among academic staff, researchers, undergraduate students and employee within educational environments in the Middle East in an attempt to understand the level of awareness of information security, the associated risks and overall impact on the institutions. The results reveal that the participants do not have the requisite knowledge and understanding of the importance of information security principles and their practical application in their day-to-day work. This situation can however be corrected through comprehensive awareness and training programs as well as adopting all the necessary safety measures at all levels of the institution to ensure that the students, academic staff and employees are trustworthy, technology savvy and keep their data safe. Without such training programs and awareness, there will be negative consequences on IT systems and their application usage, as well as on users’ personal security now and in the future. From the weaknesses identified in this survey, some essential recommendations are put forward to remedy the situation.","2016","3","4","2025-12-02","https://university.edu/papers/c8e05240-8662-4b76-811e-d8ff3ed9e7d1.pdf");
INSERT INTO Paper VALUES ("808","SC-LDPC code design for Gaussian multiple access channel","This paper presents the design and analysis of spatially coupled low-density parity-check (SC-LDPC) codes for Gaussian multiple access channel (GMAC). For two-user GMAC, we consider that each user encodes their messages by SC-LDPC codes while joint belief propagation decoding is considered at the receiver. We present low complexity density evolution analysis of SC-LDPC GMAC codes and show simple optimisation procedure. For the asymptotic case, we observe that SC-LDPC code-based GMAC code outperforms existing irregular LDPC code-based GMAC code.","2016","14","4","2025-12-02","https://university.edu/papers/db55937e-64ad-47e3-9ae1-13c113923773.pdf");
INSERT INTO Paper VALUES ("809","Multiple instruction sets architecture (MISA)","In the computer hardware industry, there are currently two highly successful instruction set architectures (ISAs): the CISC X86 ISA which is an established standard architecture in the personal computer and server markets, and the RISC ARM ISA which is currently used in many ultra-mobile computing devices, such as smart-phones and tablets. Platforms that run one standard ISA cannot run the other ISA application binaries without recompiling the source code. We are investigating the technical feasibility of designing an energy-efficient multiple instruction sets architecture (MISA) processor that can run both X86 and ARM binaries. We propose an approach in which special decoders interpret the binary instructions of the running ISA and translates them to a native target machine ISA that executes within the processor pipeline. We discuss the completed initial stage of our work involving the design of XAM, an X86 hardware binary interpreter for a MISA processor that runs native ARM instructions, and describe our design in detail. We present performance and energy simulation results of our MISA processor design for a set of synthetic benchmarks including Dhrystone 2.1, measured using the ARM SimpleScalar microarchitecture and power simulator. We also discuss design issues of an ARM to X86 hardware interpreter we are currently developing. We expect the completed X86-to-ARM design and the current ARM-to-X86 work to lay a foundation for designing a well optimized processor having a new native ISA that can run efficiently both X86 and ARM binaries, using direct hardware interpretation.","2011","3","1","2025-12-02","https://university.edu/papers/374e733c-1664-4dd8-8625-2926a80b7a87.pdf");
INSERT INTO Paper VALUES ("810","Rule-based PI controller autotuning for drive systems","Tuning a PI controller can be quite cumbersome for the non-expert as the closed-loop control system has to meet various requirements while the influence and interaction of the two degrees of freedom are not always clear. This paper addresses the design of an iterative PI controller autotuning for drive systems with the idea of imitating a human expert. In contrast to existing concepts, a new approach with multiple tuning strategies is applied which gives a compact rule base that is easy to modify. The performance of the proposed algorithm is illustrated through motion control testbench trials.","2015","5","3","2025-12-02","https://university.edu/papers/73360c60-f98c-411b-82b3-a72a1fd2973f.pdf");
INSERT INTO Paper VALUES ("811","A Self-Repairing Prefetcher in an Event-Driven Dynamic Optimization Framework","Software prefetching has been demonstrated as a powerful technique to tolerate long load latencies. However, to be effective, prefetching must target the most critical (frequently missing) loads, and prefetch them sufficiently far in advance. This is difficult to do correctly with a static optimizer, because locality characteristics and cache latencies vary across data inputs and across different machines. This paper presents a mechanism that dynamically inserts prefetch instructions into frequently executed hot traces. Hot traces are dynamically analyzed to identify delinquent loads and the appropriate prefetch distance for those loads. Those prefetches are then inserted into the hot trace. The low overhead of the event-driven dynamic optimization system allows the optimizer to continuously monitor the performance of the software prefetches. This is done to find an accurate and stable prefetch distance and to adapt to changes in program behavior using what we call self-repairing prefetching. Relative to the baseline hardware stride prefetching, we find a total 23% improvement when we use the self-repairing mechanism to adoptively discover the best prefetch distance for each load, which is 12% better performance than dynamic prefetching techniques without adaptive repairing.","2006","4","1","2025-12-02","https://university.edu/papers/de09918d-6777-4e11-971f-77944d6aef85.pdf");
INSERT INTO Paper VALUES ("812","Feature Sensitive Label Fusion With Random Walker for Atlas-Based Image Segmentation","In this paper, a novel label fusion method is proposed for brain magnetic resonance image segmentation. This label fusion method is formulated on a graph, which embraces both label priors from atlases and anatomical priors from target image. To represent a pixel in a comprehensive way, three kinds of feature vectors are generated, including intensity, gradient, and structural signature. To select candidate atlas nodes for fusion, rather than exact searching, randomized k-d tree with spatial constraint is introduced as an efficient approximation for high-dimensional feature matching. Feature sensitive label prior (FSLP), which takes both the consistency and variety of different features into consideration, is proposed to gather atlas priors. As FSLP is a non-convex problem, one heuristic approach is further designed to solve it efficiently. Moreover, based on the anatomical knowledge, parts of the target pixels are also employed as the graph seeds to assist the label fusion process, and an iterative strategy is utilized to gradually update the label map. The comprehensive experiments carried out on two publicly available databases give results to demonstrate that the proposed method can obtain better segmentation quality.","2017","16","2","2025-12-02","https://university.edu/papers/771918a0-1669-4253-86e9-b734a49466d5.pdf");
INSERT INTO Paper VALUES ("813","An efficient routing method for pseudo-exhaustive built-in self-testing of high-speed interconnects","This paper presents a powerful routing method for pseudo-exhaustive built-in self-testing of high-speed interconnects with both capacitive and inductive crosstalk effects. Based on the concepts of test cone and cut-off locality, the routing method can generate an interconnect structure such that all nets can be tested by pseudoexhaustive patterns. The test pattern generation method is simple and efficient. Experimental results obtained by simulating a set of MCNC benchmarks demonstrate the feasibility of the proposed pseudo-exhaustive test approach and the efficiency of the proposed routing method.","2007","2","3","2025-12-02","https://university.edu/papers/9040e1d6-301a-4e1d-9b9a-821ae4326797.pdf");
INSERT INTO Paper VALUES ("814","Dynamic quantum secret sharing by using d-dimensional GHZ state","Through generating the d-dimensional GHZ state in the Z-basis and measuring it in the X-basis, a dynamic quantum secret sharing scheme is proposed. In the proposed scheme, multiple participants can be added or deleted in one update period, and the shared secret does not need to be changed. The participants can be added or deleted by themselves, and the dealer does not need to be online. Compared to the existing schemes, the proposed scheme is more efficient and more practical.","2017","1","2","2025-12-02","https://university.edu/papers/e201c160-0d05-4297-a01f-24e3f1c6c2a8.pdf");
INSERT INTO Paper VALUES ("815","Evolutionary agents for epipolar geometry estimation","This paper presents an evolutionary agent-based approach to epipolar geometry estimation. Each agent stands for a minimum subset for computing fundamental matrix, and evolves autonomously in the vast solution space to get the optimal result. In so doing, the agents rely on some reactive behaviors such as reproduction and diffusion, and collaborate with others with a subset template. Experimental results show that our approach performs better than other typical methods in terms of accuracy and computational efficiency, and is robust to noise and outliers.","2004","10","3","2025-12-02","https://university.edu/papers/4c96e9de-7daf-404b-8fc3-69e2f7580622.pdf");
INSERT INTO Paper VALUES ("816","Change impact analysis of enterprise architectures","An enterprise architecture is a high-level description intended to capture the vision of an enterprise integrating all its dimensions: organization structure, business processes, and infrastructure. Every single part of an enterprise is subject to change, and each change may have significant consequences within all domains of the enterprise. A lot of effort is therefore devoted to maintaining the integrity of an architectural description. In this paper we address the problem of mastering the ripple effects of a proposed change. This allows architects to assess the consequences of a particular change to the enterprise, in order to identify potential impacts of a change before it actually takes place.","2005","13","3","2025-12-02","https://university.edu/papers/bc89baa2-da25-4d94-a8c2-c0de1b5abe24.pdf");
INSERT INTO Paper VALUES ("817","Software specification and design for imaging systems","Although it would seem obvious that object-oriented techniques are well suited to modeling image processing systems, there is almost no research to substantiate this position. We review the unique challenges faced when modeling, that is, specifying and designing, imaging systems. First, the argument is presented that specification and design of imaging systems should be studied as a special case. Next, a subset of techniques that have been used to model practical imaging systems is surveyed. Then the use of object-oriented techniques in the specification of imaging systems is investigated more fully and compared to a widely used alternative— structured analysis and design—by way of a case study. We con- clude with some recommendations for best practices and future re- search. © 2003 SPIE and IS&T. (DOI: 10.1117/1.1557154)","2003","3","2","2025-12-02","https://university.edu/papers/775c2b45-4e19-457c-b8a4-146afd0fabbd.pdf");
INSERT INTO Paper VALUES ("818","Navigation among movable obstacles: real-time reasoning in complex environments","In this paper, we address the problem of navigation among movable obstacles (NAMO): a practical extension to navigation for humanoids and other dexterous mobile robots. The robot is permitted to reconfigure the environment by moving obstacles and clearing free space for a path. Simpler problems have been shown to be P-SPACE hard. For real-world scenarios with large numbers of movable obstacles, complete motion planning techniques are largely intractable. This paper presents a resolution complete planner for a subclass of NAMO problems. Our planner takes advantage of the navigational structure through state-space decomposition and heuristic search. The planning complexity is reduced to the difficulty of the specific navigation task, rather than the dimensionality of the multi-object domain. We demonstrate real-time results for spaces that contain large numbers of movable obstacles. We also present a practical framework for single-agent search that can be used in algorithmic reasoning about this domain.","2004","10","1","2025-12-02","https://university.edu/papers/47141cdb-3e8d-4716-9479-3510ea1d6ff1.pdf");
INSERT INTO Paper VALUES ("819","Multi-task Multi-domain Representation Learning for Sequence Tagging","Representation learning with deep models have demonstrated success in a range of NLP. In this paper we consider its use in a multi-task multi-domain setting for sequence tagging by proposing a unified framework for learning across tasks and domains. Our model learns robust representations that yield better performance in this setting. We use shared CRFs and domain projections to allow the model to learn domain specific representations that can feed a single task specific CRF. We evaluate our model on two tasks -- Chinese word segmentation and named entity recognition -- and two domains -- news and social media -- and achieve state-of-the-art results for both social media tasks.","2016","18","2","2025-12-02","https://university.edu/papers/0831d183-7c67-447f-816b-dbc89895b957.pdf");
INSERT INTO Paper VALUES ("820","How to deliver your message from/to a disaster area","This article sheds light on communication needs of evacuees in shelters during a post-disaster period and advocates that it is essential to develop a completely new communication service for those in shelters to maintain communication channels with those outside shelters as well as with those in other shelters. We then present assumptions and requirements in developing such service and show a service and system concept, termed Shelter Communication System. SCS is composed of a computer (termed Shelter Server) connected to the Internet and a set of personal computers (termed shelter PCs), one in each shelter, also connected to the Internet via an appropriate Internet access connection such as High Speed Packet Access. Shelter Server and Shelter PCs cooperatively provide a message communication service for those in shelters and those outside shelters. A prototype of SCS is presented to demonstrate feasibility of SCS. A simple evaluation shows that SCS potentially provides a message communication service for enormous number of evacuees in shelters in the case of large-scale disasters and surpasses other message communication services such as cellular phone mail and facsimile.","2011","17","3","2025-12-02","https://university.edu/papers/7947735c-e128-4df1-a62a-62311cd2b5e4.pdf");
INSERT INTO Paper VALUES ("821","A generalised label noise model for classification in the presence of annotation errors","Supervised learning from annotated data is becoming more challenging due to inherent imperfection of training labels. Previous studies of learning in the presence of label noise have been focused on label noise which occurs randomly, while the study of label noise that is influenced by input features, which is intuitively more realistic, is still lacking. In this paper, we propose a new, generalised label noise model which is able to withstand the negative effect of random label noise and a wide range of non-random label noises. Empirical studies using a battery of synthetic data and four real-world datasets with inherent annotation errors demonstrate that the proposed generalised label noise model improves, in terms of classification accuracy, upon existing label noise modelling approaches.","2016","13","1","2025-12-02","https://university.edu/papers/d585ce5e-d31c-4c62-a083-676d668b3b09.pdf");
INSERT INTO Paper VALUES ("822","Constructing low-latency overlay networks: Tree vs. mesh algorithms","Distributed interactive applications may have stringent latency requirements and dynamic user groups. These applications may benefit from a group communication system, and to improve the system support for such applications, we investigate graph algorithms that construct low-latency overlay networks for application-layer multicast. In particular, we focus on reducing the diameter and the pair-wise latencies in the overlay. The overlay construction time is also considered, as it is often time-dependent in our dynamic target applications. Here, we have implemented and experimentally analyzed spanning-tree heuristics and mesh construction heuristics, and compared their performance and applicability to distributed interactive applications. We found that trees are faster to construct and save considerable amounts of resources in the network. Meshes, on the other hand, yield lower pair-wise latencies and increases the fault tolerance, but at the expense of increased resource consumption.","2008","18","1","2025-12-02","https://university.edu/papers/cde9692c-82d9-455a-9e9d-f56726d9fba3.pdf");
INSERT INTO Paper VALUES ("823","Bayesian Modeling and Classification of Neural Signals","Signal processing and classification algorithms often have limited applicability resulting from an inaccurate model of the signal's underlying structure. We present here an efficient, Bayesian algorithm for modeling a signal composed of the superposition of brief, Poisson-distributed functions. This methodology is applied to the specific problem of modeling and classifying extracellular neural waveforms which are composed of a superposition of an unknown number of action potentials (APs). Previous approaches have had limited success due largely to the problems of determining the spike shapes, deciding how many are shapes distinct, and decomposing overlapping APs. A Bayesian solution to each of these problems is obtained by inferring a probabilistic model of the waveform. This approach quantifies the uncertainty of the form and number of the inferred AP shapes and is used to obtain an efficient method for decomposing complex overlaps. This algorithm can extract many times more information than previous methods and facilitates the extracellular investigation of neuronal classes and of interactions within neuronal circuits.","1994","19","4","2025-12-02","https://university.edu/papers/98a43b4e-df4a-4074-af18-ac9123aee697.pdf");
INSERT INTO Paper VALUES ("824","MEA: designing a multimodal email support tool for persons with Aphasia","We describe the design of an assistive email interface for persons with aphasia who have problems in reading, writing, and or speaking. The email interface was designed by consulting persons with aphasia, their therapists and partners. Writing support such as readymade sentences and recommendations of words from free hand drawing were introduced. The application is suitable to be used in smart phone/tablet pc and highly praised by the therapists and persons with aphasia. Our user studies showed that the application has potential for persons with aphasia due to its simplicity in use and alternative means of language support while composing email messages.","2014","9","1","2025-12-02","https://university.edu/papers/d8ae15eb-caf7-4771-86d8-aa4bfc7d808f.pdf");
INSERT INTO Paper VALUES ("825","Performance analysis of target parameters estimation using multiple widely separated antenna arrays","Target parameter estimation performance is investigated for a radar employing a set of widely separated transmitting and receiving antenna arrays. Cases with multiple extended targets are considered under two signal model assumptions: stochastic and deterministic. The general expressions for the corresponding Cramer-Rao lower bound (CRLB) and the asymptotic properties of the maximum-likelihood (ML) estimator are derived for a radar with Mt arrays of Lt transmitting elements and Mr arrays of Lr receiving elements for both types of signal models. It is shown that for an infinitely large product MtMr, and a finite Lr, the ML estimator is consistent and efficient under the stochastic model, while the deterministic model requires MtMr to be finite and Lr to be infinitely large in order to guarantee consistency and efficiency. Monte Carlo simulations further investigate the estimation performance of the proposed radar configuration in practical scenarios with finite MtMr and Lr, and a fixed total number of available receiving antenna elements, MrLr. The numerical results demonstrate that grouping receiving elements into properly sized arrays reduces the mean","2016","2","3","2025-12-02","https://university.edu/papers/7e869dfa-57b8-4646-9d13-7eb56063469f.pdf");
INSERT INTO Paper VALUES ("826","Optimal design of gene knockout experiments for gene regulatory network inference","Motivation: We addressed the problem of inferring gene regulatory network (GRN) from gene expression data of knockout (KO) experiments. This inference is known to be underdetermined and the GRN is not identifiable from data. Past studies have shown that suboptimal design of experiments (DOE) contributes significantly to the identifiability issue of biological networks, including GRNs. However, optimizing DOE has received much less attention than developing methods for GRN inference.#R##N##R##N#Results: We developed REDuction of UnCertain Edges (REDUCE) algorithm for finding the optimal gene KO experiment for inferring directed graphs (digraphs) of GRNs. REDUCE employed ensemble inference to define uncertain gene interactions that could not be verified by prior data. The optimal experiment corresponds to the maximum number of uncertain interactions that could be verified by the resulting data. For this purpose, we introduced the concept of edge separatoid which gave a list of nodes (genes) that upon their removal would allow the verification of a particular gene interaction. Finally, we proposed a procedure that iterates over performing KO experiments, ensemble update and optimal DOE. The case studies including the inference of Escherichia coli GRN and DREAM 4 100-gene GRNs, demonstrated the efficacy of the iterative GRN inference. In comparison to systematic KOs, REDUCE could provide much higher information return per gene KO experiment and consequently more accurate GRN estimates.#R##N##R##N#Conclusions: REDUCE represents an enabling tool for tackling the underdetermined GRN inference. Along with advances in gene deletion and automation technology, the iterative procedure brings an efficient and fully automated GRN inference closer to reality.#R##N##R##N#Availability and implementation: MATLAB and Python scripts of REDUCE are available on www.cabsel.ethz.ch/tools/REDUCE.#R##N##R##N#Contact: hc.zhte.mehc@nawanug.idur#R##N##R##N#Supplementary information: Supplementary data are available at Bioinformatics online.","2016","14","3","2025-12-02","https://university.edu/papers/5865bd5a-3359-4a2c-9b92-7d294c68be00.pdf");
INSERT INTO Paper VALUES ("827","Temperature-aware task scheduling heuristics on Network-on-Chips","Chip temperature becomes a critical design issue with technology scaling to nanometer-scale, especially for NoC systems with large number of cores and shrunken core size. To reduce peak temperature and balance spatial temperature distribution on NoC-based multi-cores chips, this paper proposes a temperature-aware task scheduling approach. The thermal profiles of tasks are first extracted by accurate temperature model. Then run-time task mapping heuristic is proposed considering transient core temperatures, thermal dissipation from adjacent cores, communication overheads and the thermal influence of physical position on chip. Voltage-frequency is also scaled down when timing constraint is met to reduce power consumption and core temperature. Experimental results show that the significant reduction of peak temperature and the temperature variance compared with the current approaches is achieved.","2016","7","3","2025-12-02","https://university.edu/papers/8c4d7b3a-f51c-491c-8e64-5ca7a0b477c0.pdf");
INSERT INTO Paper VALUES ("828","Method of NDA frequency-offset estimation for faster-than-Nyquist signaling with high-order modulation","Carrier synchoronization is an important propblem in digital communications, not only in Nyquist signaling system but also in the faster-than-Nyquist (FTN) signaling system. For filling this gap, we propose a new non-data aided (NDA) frequency-offset estimation scheme for FTN signaling system. Combining discrete Fourier transform (DFT) with chirp z-transform (CZT), the proposed scheme can realize the estimation of frequency-offset by minimizing the nonlinear least-squares (NLS) error. Moreover, our proposed estimation scheme can be also applied into high-order modulation format like Mary pulse amplitude modulation (M-PAM). From the numerical results given in the paper, the Cramer-Rao bound can be closely approached by proposed estimation scheme, even when the timing period packing becomes small.","2016","2","2","2025-12-02","https://university.edu/papers/6607fbd6-d740-439b-aa3f-7a5e239dd3e4.pdf");
INSERT INTO Paper VALUES ("829","Multiple Ground Target Tracking with a GMTI Sensor","For current GMTI trackers, one of the most common contextual information used is road network information. In this paper, we present our approach to using the road network information in tracking ground targets and in solving some ambiguities that can arise at road intersections or following a target manoeuvre of leaving the road. For this we examine the performances of an adapted algorithm for tracking manoeuvring ground targets on road and off road in a cluttered environment using the road network information.","2006","7","3","2025-12-02","https://university.edu/papers/9e6799ad-cdd9-4978-951c-d603b7f03988.pdf");
INSERT INTO Paper VALUES ("830","Implementation of a novel system for measuring the lifetime of OLED panels","This paper presents a reliable and feasible means of evaluating the lifetime of organic light emitting diode (OLED) panels. The proposed system is composed of a PC with a man-machine interface, a power supply with multiple channels and a data acquisition card to record the brightness and voltage drop across the OLED panels. A novel noise filter is also applied to yield a noise-free data acquisition system. The proposed system has the following features. The system can measure the lifetime of one to 256 OLED panels. Second, the system applies a software filter to enhance its immunity to noise. Third, the system supports two different power sources, constant voltage and constant current. The output voltage varies from zero to 25 V and the output current varies from 0.1 mA to 150 mA. Fourth, the system sets off an alarm when the brightness decayed to half of the initial luminance. Fifth, the interval between measurements can be divided into 16 periods at most, so that the user can set the data sampling rate to meet the testing requirements. It also provides a user-friendly environment and multiple-channel power to measure the lifetime of various OLED panels. Therefore, the system could be used in a mass production stage.","2003","2","2","2025-12-02","https://university.edu/papers/bc298303-52f1-4453-87b1-f8bb0bf54931.pdf");
INSERT INTO Paper VALUES ("831","Blind watermarking of 3D shapes using localized constraints","This paper develops a digital watermarking methodology for 3D graphical objects defined by polygonal meshes. In watermarking or fingerprinting the aim is to embed a code in a given media without producing identifiable changes to it. One should be able to retrieve the embedded information even after the shape had suffered various modifications. Two blind watermarking techniques applying perturbations onto the local geometry for selected vertices are described in this paper. The proposed methods produce localized changes of vertex locations that do not alter the mesh topology. A study of the effects caused by vertex location modification is provided for a general class of surfaces. The robustness of the proposed algorithms is tested at noise perturbation and object cropping.","2004","16","1","2025-12-02","https://university.edu/papers/acd4abc8-1922-45ce-9dad-986636ae77d4.pdf");
INSERT INTO Paper VALUES ("832","Searching for interpretable rules for disease mutations: a simulated annealing bump hunting strategy","Background: Understanding how amino acid substitutions affect protein functions is critical for the study of proteins and their implications in diseases. Although methods have been developed for predicting potential effects of amino acid substitutions using sequence, three-dimensional structural, and evolutionary properties of proteins, the applications are limited by the complication of the features and the availability of protein structural information. Another limitation is that the prediction results are hard to be interpreted with physicochemical principles and biological knowledge. Results: To overcome these limitations, we proposed a novel feature set using physicochemical properties of amino acids, evolutionary profiles of proteins, and protein sequence information. We applied the support vector machine and the random forest with the feature set to experimental amino acid substitutions occurring in the E. coli lac repressor and the bacteriophage T4 lysozyme, as well as to annotated amino acid substitutions occurring in a wide range of human proteins. The results showed that the proposed feature set was superior to the existing ones. To explore physicochemical principles behind amino acid substitutions, we designed a simulated annealing bump hunting strategy to automatically extract interpretable rules for amino acid substitutions. We applied the strategy to annotated human amino acid substitutions and successfully extracted several rules which were either consistent with current biological knowledge or providing new insights for the understanding of amino acid substitutions. When applied to unclassified data, these rules could cover a large portion of samples, and most of the covered samples showed good agreement with predictions made by either the support vector machine or the random forest. Conclusion: The prediction methods using the proposed feature set can achieve larger AUC (the area under the ROC curve), smaller BER (the balanced error rate), and larger MCC (the Matthews' correlation coefficient) than those using the published feature sets, suggesting that our feature set is superior to the existing ones. The rules extracted by the simulated annealing bump hunting strategy have comparable coverage and accuracy but much better interpretability as those extracted by the patient rule induction method (PRIM), revealing that the strategy is more effective in inducing interpretable rules.","2006","19","1","2025-12-02","https://university.edu/papers/9e638887-41f8-467b-9cab-2eeef2514f16.pdf");
INSERT INTO Paper VALUES ("833","Scrambling on electrical power grids","Deregulated, the U.S. electrical power grid system has shown the emergence of behaviors that include scrambling by buyers to purchase electricity and unexpected increasing costs of electricity to consumers. To infer those behaviors, in this paper, we adapt a theoretical framework, developed by Newman in his work on spread of epidemic disease on networks, to the propagation of electricity buying and selling in a power grid system. Specifically, we represent the electrical power grid as a random bipartite graph of electricity sellers and buyers, which is then projected to a one-mode network of interacting buyers. The so-called transaction transferability among buyers is calculated as a function of the offered buying prices. The average number of buyers scrambling to buy electricity is obtained as a function of the transaction transferability. Together, the transaction transferability and the average number of scrambling buyers indicate that scrambles for electricity buying drive up costs to buyers.","2008","12","1","2025-12-02","https://university.edu/papers/88ebc64f-ce43-466f-9398-1117d101932b.pdf");
INSERT INTO Paper VALUES ("834","A Collaborative Code Review Platform for GitHub","The incorporation of peer code reviews as being part of a developer's work flow, and hence the software development lifecycle, has steadily grown in popularity over the past three decades. During the process of statically inspecting code, developers of a codebase are able to collaboratively detect possible code defects, as well as use code reviews as a means of transferring knowledge to improve the overall understanding of a system. The uptake of such practices is dependent on several factors, specifically the availability of tools that aid in providing an easy-to-use and intuitive platform to perform code reviews, and is readily accessible to members of a project. This paper briefly explores the act of code review, identifies the pitfalls of existing code review tools, and proposes the design and development of a web-based code review application, along with the evaluation of the prototype. The code review tool developed, Fistbump, targets the popular Git based repository hosting service, GitHub, and provides a versatile tool to coordinate and manage discussions between the owner of a pull request and the elected participants of a review.","2016","14","1","2025-12-02","https://university.edu/papers/b22d4275-8de5-4c50-acdd-e03e7b02d0b4.pdf");
INSERT INTO Paper VALUES ("835","Mining data streams: a review","The recent advances in hardware and software have enabled the capture of different measurements of data in a wide range of fields. These measurements are generated continuously and in a very high fluctuating data rates. Examples include sensor networks, web logs, and computer network traffic. The storage, querying and mining of such data sets are highly computationally challenging tasks. Mining data streams is concerned with extracting knowledge structures represented in models and patterns in non stopping streams of information. The research in data stream mining has gained a high attraction due to the importance of its applications and the increasing generation of streaming information. Applications of data stream analysis can vary from critical scientific and astronomical applications to important business and financial ones. Algorithms, systems and frameworks that address streaming challenges have been developed over the past three years. In this review paper, we present the state-of-the-art in this growing vital field.","2005","18","4","2025-12-02","https://university.edu/papers/514262fa-b3a3-4c5a-b4ab-186c41ce8c3e.pdf");
INSERT INTO Paper VALUES ("836","Secure Group Message Transfer Stegosystem","Grid environment is a virtual organization with varied resources from different administrative domains; it raises the requirement of a secure and reliable protocol for secure communication among various users and servers. The protocol should guarantee that an attacker or an unidentified resource will not breach or forward the information. For secure communication among members of a grid group, an authenticated message transferring system should be implemented. The key objective of this system is to provide a secure transferring path between a sender and its authenticated group members. In recent times, many researchers have proposed various steganographic techniques for secure message communications. This paper proposes a new secure message broadcasting system to hide the messages in such a way that an attacker cannot sense the existence of messages. In the proposed system, the authors use steganography and image encryption to hide group keys and secret messages using group keys in images for secure message broadcasting. The proposed system can withstand against conspiracy attack, message modification attack and various other security attacks. Thus, the proposed system is secure and reliable for message broadcasting.","2015","5","3","2025-12-02","https://university.edu/papers/61bafc80-76a9-424b-abbb-989c527a0fd5.pdf");
INSERT INTO Paper VALUES ("837","Conversion Algorithms and Implementations for Koblitz Curve Cryptography","In this paper, we discuss conversions between integers and tau-adic expansions and we provide efficient algorithms and hardware architectures for these conversions. The results have significance in elliptic curve cryptography using Koblitz curves, a family of elliptic curves offering faster computation than general elliptic curves. However, in order to enable these faster computations, scalars need to be reduced and represented using a special base-tau expansion. Hence, efficient conversion algorithms and implementations are necessary. Existing conversion algorithms require several complicated operations, such as multiprecision multiplications and computations with large rationals, resulting in slow and large implementations in hardware and microcontrollers with limited instruction sets. Our algorithms are designed to utilize only simple operations, such as additions and shifts, which are easily implementable on practically all platforms. We demonstrate the practicability of the new algorithms by implementing them on Altera Stratix II FPGAs. The implementations considerably improve both computation speed and required area compared to the existing solutions.","2010","2","1","2025-12-02","https://university.edu/papers/c8060308-f5bd-40ef-9bdf-474e875ace52.pdf");
INSERT INTO Paper VALUES ("838","Sustaining the Future of the Public Sector: Insights into a Swedish Municipality’s Dealing with Knowledge Management and Succession Planning","The ageing workforce soon leads to a number of retirements in government organisations that will put the knowledge basis at risk. Addressing this point the present study provides an analysis and evaluation of a Swedish municipality’s dealing with the aspects of knowledge management and succession planning against the background of demographic developments and the increased relevance of knowledge. It reports findings based on semi-structured interviews conducted with executive staff of the municipality. Results of data analysed show that the municipality is far from being ready to master the challenges ahead. To date the municipality follows a sporadic approach rather than a strategic and planned one when addressing the issue of succession planning. Indeed, the findings suggest that a muddling through approach prevails. Based on the findings some suggestions were derived that may help both municipalities facing similar circumstances as well as policy makers drafting suitable policies.","2016","2","4","2025-12-02","https://university.edu/papers/b81cb593-d6bd-48b2-9a17-15b0e7a54b41.pdf");
INSERT INTO Paper VALUES ("839","Kanbanize the release engineering process","Release management process must be adapted when IT organizations scale up to avoid discontinuity at the release flow and to preserve the software quality. This paper reports on means to improve the release process in a large-scale project. It discusses the rationale behind adopting Kanban principles for release management, how to implement these principles within a transitional approach, and what are the benefits. The paper discusses the post-transitional product to assess the status of the outcomes.","2013","17","2","2025-12-02","https://university.edu/papers/890a4d5f-6f8f-48a6-9177-8cf910e9a83f.pdf");
INSERT INTO Paper VALUES ("840","New techniques for efficiently assessing reliability of SOCs","In this paper we propose an approach to speed-up Fault Injection campaigns for the evaluation of dependability properties of complex digital systems. The approach exploits FPGA devices for system emulation, and new techniques are described, allowing emulating the effects of faults and to observe faulty behavior. Thanks to its flexibility and efficiency, the approach is suitable to be applied to SOC devices. The paper points out the flexibility of the approach, able to inject different faults of different types in custom logic, memory blocks, and processor cores. The proposed approach combines the speed of hardware-based techniques, and the flexibility of simulation-based techniques. Experimental results are provided showing that speed-up figures of up to 3 orders of magnitude with respect to state-of-the-art simulation-based techniques can be achieved.","2003","12","4","2025-12-02","https://university.edu/papers/e20da2d1-25d7-40bf-b5d3-222d2ac0011d.pdf");
INSERT INTO Paper VALUES ("841","BIT: Biologically Inspired Tracker.","Visual tracking is challenging due to image variations caused by various factors, such as object deformation, scale change, illumination change, and occlusion. Given the superior tracking performance of human visual system (HVS), an ideal design of biologically inspired model is expected to improve computer visual tracking. This is, however, a difficult task due to the incomplete understanding of neurons' working mechanism in the HVS. This paper aims to address this challenge based on the analysis of visual cognitive mechanism of the ventral stream in the visual cortex, which simulates shallow neurons (S1 units and C1 units) to extract low-level biologically inspired features for the target appearance and imitates an advanced learning mechanism (S2 units and C2 units) to combine generative and discriminative models for target location. In addition, fast Gabor approximation and fast Fourier transform are adopted for real-time learning and detection in this framework. Extensive experiments on large-scale benchmark data sets show that the proposed biologically inspired tracker performs favorably against the state-of-the-art methods in terms of efficiency, accuracy, and robustness. The acceleration technique in particular ensures that biologically inspired tracker maintains a speed of approximately 45 frames/s.","2016","16","3","2025-12-02","https://university.edu/papers/fd889fca-3c12-4166-baa8-4d25d0ad1ba5.pdf");
INSERT INTO Paper VALUES ("842","The General Gaussian Multiple-Access and Two-Way Wiretap Channels: Achievable Rates and Cooperative Jamming","The general Gaussian multiple-access wiretap channel (GGMAC-WT) and the Gaussian two-way wiretap channel (GTW-WT) are considered. In the GGMAC-WT, multiple users communicate with an intended receiver in the presence of an eavesdropper who receives their signals through another GMAC. In the GTW-WT, two users communicate with each other over a common Gaussian channel, with an eavesdropper listening through a GMAC. A secrecy measure that is suitable for this multiterminal environment is defined, and achievable secrecy rate regions are found for both channels. For both cases, the power allocations maximizing the achievable secrecy sum rate are determined. It is seen that the optimum policy may prevent some terminals from transmission in order to preserve the secrecy of the system. Inspired by this construct, a new scheme cooperative jamming is proposed, where users who are prevented from transmitting according to the secrecy sum rate maximizing power allocation policy ldquojamrdquo the eavesdropper, thereby helping the remaining users. This scheme is shown to increase the achievable secrecy sum rate. Overall, our results show that in multiple-access scenarios, users can help each other to collectively achieve positive secrecy rates. In other words, cooperation among users can be invaluable for achieving secrecy for the system.","2008","8","1","2025-12-02","https://university.edu/papers/7106bbf0-d0eb-4da8-bd69-35ef2c601a1c.pdf");
INSERT INTO Paper VALUES ("843","Recognizing and Drawing IC-Planar Graphs","IC-planar graphs are those graphs that admit a drawing where no two crossed edges share an end-vertex and each edge is crossedi¾?at most once. They are a proper subfamily of the 1-planar graphs. Given an embedded IC-planar graphi¾?G withi¾?n vertices, we present an On-time algorithm that computes a straight-line drawing ofi¾?G in quadratic area, and an $$On^3$$-time algorithm that computes a straight-line drawing ofi¾?G with right-angle crossings in exponential area. Both these area requirements are worst-case optimal. We also show that it is $$\mathrm {NP}$$-complete to test IC-planarity both in the general case and in the case in which a rotation system is fixed for the input graph. Furthermore, we describe a polynomial-time algorithm to test whether a set of matching edges can be added to a triangulated planar graph such that the resulting graph is IC-planar.","2015","2","1","2025-12-02","https://university.edu/papers/d10aa2e7-ea8e-4ed6-9381-4a89198c3f6e.pdf");
INSERT INTO Paper VALUES ("844","Visual Teach and Repeat using appearance-based lidar","Visual Teach and Repeat (VT&R) has proven to be an effective method to allow a vehicle to autonomously repeat any previously driven route without the need for a global positioning system. One of the major challenges for a method that relies on visual input to recognize previously visited places is lighting change, as this can make the appearance of a scene look drastically different. For this reason, passive sensors, such as cameras, are not ideal for outdoor environments with inconsistent/inadequate light. However, camera-based systems have been very successful for localization and mapping in outdoor, unstructured terrain, which can be largely attributed to the use of sparse, appearance-based computer vision techniques. Thus, in an effort to achieve lighting invariance and to continue to exploit the heritage of the appearance-based vision techniques traditionally used with cameras, this paper presents the first VT&R system that uses appearance-based techniques with laser scanners for motion estimation. The system has been field tested in a planetary analogue environment for an entire diurnal cycle, covering more than 11km with an autonomy rate of 99.7% of the distance traveled.","2012","7","4","2025-12-02","https://university.edu/papers/617456ed-9a2e-494b-85aa-eb46ead7827b.pdf");
INSERT INTO Paper VALUES ("845","Performance analysis of Wald-statistic based network detection methods for radiation sources","There have been increasingly large deployments of radiation detection networks that require computationally fast algorithms to produce prompt results over ad-hoc sub-networks of mobile devices, such as smart-phones. These algorithms are in sharp contrast to complex network algorithms that necessitate all measurements to be sent to powerful central servers. In this work, at individual sensors, we employ Wald-statistic based detection algorithms which are computationally very fast, and are implemented as one of three Z-tests and four chi-square tests. At fusion center, we apply the K-out-of-N fusion to combine the sensors' hard decisions. We characterize the performance of detection methods by deriving analytical expressions for the distributions of underlying test statistics, and by analyzing the fusion performances in terms of K, N, and the false-alarm rates of individual detectors. We experimentally validate our methods using measurements from indoor and outdoor characterization tests of the Intelligence Radiation Sensors Systems (IRSS) program. In particular, utilizing the outdoor measurements, we construct two important real-life scenarios, boundary surveillance and portal monitoring, and present the results of our algorithms.","2016","1","4","2025-12-02","https://university.edu/papers/85686dd9-8ab3-4029-acde-917af2a4d2ba.pdf");
INSERT INTO Paper VALUES ("846","Segment-of-Interest driven live game streaming: Saving bandwidth without degrading experience","Live game streaming is tremendously popular, and recent reports indicate that such platforms impose high traffic volume, leading to degraded user experience. In this paper, we propose a Segment-of-Interest (SoI) driven platform, so as to optimize live game streaming. Our platform uses various features collected from streamers and viewers to determine if the current segments of gameplays attract viewers. Upon determining the importance of individual segments, the limited bandwidth is allocated to the interested viewers in a Rate-Distortion (R-D) optimized manner, where the levels of segment importance are used as weights of game streaming quality. The underlaying intuition is: viewer experience is degraded only when the game streaming degradation is noticed by viewers. Simulation results show the benefits of our proposed solution: (i) it improves viewing quality by up to 5 dB, (ii) it saves bandwidth by up to 50 Gbps, and (iii) it efficiently performs resource allocation and scales to many viewers. Our presented testbed is opensource and can be leveraged by researchers and engineers to further improve live game streaming platforms.","2015","2","4","2025-12-02","https://university.edu/papers/cf67267f-a052-44dc-9afd-adb0bdae7c6f.pdf");
INSERT INTO Paper VALUES ("847","On star-forest ascending subgraph decomposition","The Ascending Subgraph Decomposition (ASD) Conjecture asserts that every graph $G$ with ${n+1\choose 2}$ edges admits an edge decomposition $G=H_1\oplus\cdots \oplus H_n$ such that $H_i$ has $i$ edges and it is isomorphic to a subgraph of $H_{i+1}$, $i=1,\ldots ,n-1$. We show that every bipartite graph $G$ with ${n+1\choose 2}$ edges such that the degree sequence $d_1,\ldots ,d_k$ of one of the stable sets satisfies $ d_{k-i}\ge n-i\; \text{for each}\; 0\le i\le k-1$, admits an ascending subgraph decomposition with star forests. We also give a necessary condition on the degree sequence which is not far from the above sufficient one.","2015","13","2","2025-12-02","https://university.edu/papers/26d35bf7-fef6-4a63-8ccc-e1e3b85c1ac5.pdf");
INSERT INTO Paper VALUES ("848","Reinforcement Learning Method for BioAgents","Machine Learning (ML) techniques are being employed in bioinformatics with increasing success. However, two problems are still prohibitive for symbolic ML methods: huge amount of data and lack of examples for training purposes. Thus, this paper introduces the use of reinforcement learning (RL), with the objective of dealing with these two drawbacks. Our work proposes and implement a RL method for the Bio Agents system, in order to improve the annotation of biological sequences in genome sequencing projects. Experiments were done with real data from two different genome sequencing projects: Paracoccidioides brasiliensis - Pb fungus and Paullinia cupana - Guarana plant. To assign reinforcement signals we have used reference genomes with curated annotations that are considered correct, these signals tackle specific databases and alignment algorithms. The results obtained with the inclusion of a RL layer in Bio Agents were better compared with the system without the proposed method. Also, to the best of our knowledge, this is the first attempt to apply RL techniques to annotation in bioinformatics projects.","2010","14","4","2025-12-02","https://university.edu/papers/6c788cc3-1235-40cc-857c-2bb58c3a0e72.pdf");
INSERT INTO Paper VALUES ("849","Controllability of switched bilinear systems","The controllability of switched bilinear systems (SBLSs) is considered. Three kinds of controllabilities, including weak controllability, approximate controllability, and global controllability, are investigated one by one. Sets of easily verifiable sufficient conditions are obtained for each case, which are applicable to a large class of switched bilinear systems.","2005","18","2","2025-12-02","https://university.edu/papers/547c7009-aa30-466c-ba4d-6f584daec946.pdf");
INSERT INTO Paper VALUES ("850","View and scale invariant action recognition using multiview shape-flow models","Actions in real world applications typically take place in cluttered environments with large variations in the orientation and scale of the actor. We present an approach to simultaneously track and recognize known actions that is robust to such variations, starting from a person detection in the standing pose. In our approach we first render synthetic poses from multiple viewpoints using Mocap data for known actions and represent them in a conditional random field (CRF) whose observation potentials are computed using shape similarity and the transition potentials are computed using optical flow. We enhance these basic potentials with terms to represent spatial and temporal constraints and call our enhanced model the shape, flow, duration-conditional random field (SFD-CRF). We find the best sequence of actions using Viterbi search in the SFD-CRF. We demonstrate our approach on videos from multiple viewpoints and in the presence of background clutter.","2008","4","4","2025-12-02","https://university.edu/papers/db594bda-f56f-415b-8c43-bb977040ca23.pdf");
INSERT INTO Paper VALUES ("851","Augmented consensus filter for simultaneous localization and tracking with limited sense range","In this paper, we investigate how to exploit distributed average consensus fusion for conducting simultaneous localization and tracking (SLAT) by using wireless sensor networks. To this end, we commence by establishing a limited sense range (LSR) nonlinear system that characterizes the coupling of target state and sensor localization with respect to each sensor. We then employ an augmented extended Kalman filter to estimate the sensor and target states of our system. Furthermore, we adopt a consensus filtering scheme which fuses the information from neighboring sensors. We thus obtain a two-stage distributed filtering framework that not only obtains updated sensor locations trough augment filtering but also provides an accurate target state estimate in consensus filtering. Additionally, our framework is computationally efficient because it only requires neighboring sensor communications. The simulation results reveal that the proposed filtering framework is much more robust than traditional information fusion methods in limited ranging conditions.","2016","4","3","2025-12-02","https://university.edu/papers/1d9d591f-ffb0-461a-97d5-63582f96fc6c.pdf");
INSERT INTO Paper VALUES ("852","Enterprise Architecture Framework with Early Business/ICT Alignment for Extended Enterprises","Incorporating information and communication technology (ICT) is strongly necessary in extended enterprises. To do this, enterprise engineering approach has important benefits; however, there is not a complete framework to model ICT components and ICT/business alignment. This paper presents an enterprise architecture framework for extended enterprises. The main aim enclosed in this paper is to provide a modeling framework from enterprise en- gineering approach which including ICT. A comparative analysis has been conducted in life cycle phases, modeling views and strategic alignment between different enterprise architectures. Next, the required building blocks have been proposed: ICT conceptualization, application portfolio, maturity model, align- ment heuristics and strategic dependencies. This proposal has been applied in the collaborative order management process of a ceramic tile company.","2010","12","2","2025-12-02","https://university.edu/papers/d78da2e0-df2f-43f8-8f88-289888be09a7.pdf");
INSERT INTO Paper VALUES ("853","Optimal surveillance coverage for teams of micro aerial vehicles in GPS-denied environments using onboard vision","This paper deals with the problem of deploying a team of flying robots to perform surveillance-coverage missions over a terrain of arbitrary morphology. In such missions, a key factor for the successful completion of the mission is the knowledge of the terrain's morphology. The focus of this paper is on the implementation of a two-step procedure that allows us to optimally align a team of flying vehicles for the aforementioned task. Initially, a single robot constructs a map of the area using a novel monocular-vision-based approach. A state-of-the-art visual-SLAM algorithm tracks the pose of the camera while, simultaneously, autonomously, building an incremental map of the environment. The map generated is processed and serves as an input to an optimization procedure using the cognitive, adaptive methodology initially introduced in Renzaglia et al. (Proceedings of the IEEE international conference on robotics and intelligent system (IROS), Taipei, Taiwan, pp. 3314---3320, 2010). The output of this procedure is the optimal arrangement of the robots team, which maximizes the monitored area. The efficiency of our approach is demonstrated using real data collected from aerial robots in different outdoor areas.","2012","11","4","2025-12-02","https://university.edu/papers/c0c9b058-49b9-4312-b77a-c8418149ef2f.pdf");
INSERT INTO Paper VALUES ("854","A Fast Wavelet-Based Image Progressive Transmission Method Based on Vector Quantization","In this paper, we propose a fast progressive image transmission method based on wavelet decomposition and vector quantization. The wavelet decomposition provides the useful classified characteristic. In addition, vector quantization (VQ) has the advantages of high compression ratio and coding easiness. Combining these techniques, we further design different VQ coding strategies for the wavelet coefficients in different sub bands so that a fast and efficient progressive transmission can be provided. Experimental results also confirm the high PSNR and low bit rate can be achieved in the first two and three phases. Moreover, our proposed method has higher PSNR values and lower bit rates than BMP in the first two transmission phases which means our method is capable of helping the receiver to make an early decision as to stop the transmission session or not.","2006","2","2","2025-12-02","https://university.edu/papers/d1e18ee7-f02b-484d-8b69-979005736cd6.pdf");
INSERT INTO Paper VALUES ("855","EEG signal preprocessing for biometric recognition","Electroencephalography (EEG) has been recently investigated as a biometric modality for automatic people recognition purposes. Several studies have shown that brain signals possess subject-specific traits that allow distinguishing people. Nonetheless, extracting discriminative characteristics from EEG recordings may be a challenging task, due to the significant presence of artifacts in the acquired data. In order to cope with such issue, in this paper we evaluate the effectiveness of some preprocessing techniques in automatically removing undesired EEG contributions, with the aim of improving the achievable recognition rates. Specifically, methods based on blind source separation and sample entropy estimation are here investigated. An extensive set of experimental tests, performed over a large database comprising recordings taken from 50 healthy subjects during three distinct sessions spanning a period of about one month, in both eyes-closed and eyes-open conditions, is carried out to analyze the performance of the proposed approaches.","2016","8","1","2025-12-02","https://university.edu/papers/c43a6be7-7386-4972-b85f-5aa72798d028.pdf");
INSERT INTO Paper VALUES ("856","Divergence minimization approach to joint phase estimation and decoding in satellite transmissions","In this paper, two joint phase estimation and decoding algorithms based on divergence minimization are presented for satellite coded transmissions in the presence of strong phase noise. The algorithms perform approximate Bayesian inference in a hybrid graphical model for time-varying phase and discrete symbols, where each pair of the random phase and data symbol are decoupled by minimizing the inclusive Kullback-Leibler (KL) divergence and minimizing the exclusive KL divergence, respectively. Simulations show that the algorithm using the inclusive KL divergence outperforms the expectation maximization (EM) algorithm, while the algorithm using the exclusive KL divergence achieves the same performance as that of the EM algorithm.","2015","19","1","2025-12-02","https://university.edu/papers/57f8fe73-3485-42ae-bb69-0da377ff4046.pdf");
INSERT INTO Paper VALUES ("857","Computational Metabolomics (Dagstuhl Seminar 15492)","he Dagstuhl Seminar 15492 on Computational Metabolomics brought together leading experimental (analytical chemistry and biology) and computational (computer science and bioinformatics) experts with the aim to foster the exchange of expertise needed to advance computational metabolomics. The focus was on a dynamic schedule with overview talks followed by breakout sessions, selected by the participants, covering the whole experimental-computational continuum in mass spectrometry, as well as the use of metabolomics data in applications. A general observation was that metabolomics is in the state that genomics was 20 years ago and that while the availability of data is holding back progress, several good initiatives are present. The importance of small molecules to life should be communicated properly to assist initiating a global metabolomics initiative, such as the Human Genome project. Several follow-ups were discussed, including workshops, hackathons, joint paper(s) and #R##N#a new Dagstuhl Seminar in two years to follow up on this one.","2016","8","4","2025-12-02","https://university.edu/papers/68901755-db54-4b90-8bcb-5434878c22e3.pdf");
INSERT INTO Paper VALUES ("858","Approximate inference for planning in stochastic relational worlds","Relational world models that can be learned from experience in stochastic domains have received significant attention recently. However, efficient planning using these models remains a major issue. We propose to convert learned noisy probabilistic relational rules into a structured dynamic Bayesian network representation. Predicting the effects of action sequences using approximate inference allows for planning in complex worlds. We evaluate the effectiveness of our approach for online planning in a 3D simulated blocksworld with an articulated manipulator and realistic physics. Empirical results show that our method can solve problems where existing methods fail.","2009","18","1","2025-12-02","https://university.edu/papers/feb98505-1bce-485a-b6d3-d4e4bc9110f6.pdf");
INSERT INTO Paper VALUES ("859","A new robust estimation method for ARMA models","This paper presents a new robust method to estimate the parameters of ARMA models. This method makes use of the autocorrelations estimates based on the ratio of medians together with a robust filter cleaner able to reject a large fraction of outliers, and a Gaussian maximum likelihood estimation which handles missing values. The main advantages of the procedure are its easiness, robustness and fast execution. Its effectiveness is demonstrated on an example of the forecasting of the French daily electricity consumptions.","2009","1","2","2025-12-02","https://university.edu/papers/91c4d0a7-4cb4-4430-9b8b-986f0cd7c6d2.pdf");
INSERT INTO Paper VALUES ("860","A two-step MF signal acquisition method for wireless underground sensor networks","Signal acquisition plays a critical role on the bit error rate (BER) of a#R##N#   direct sequence spread spectrum (DS/SS) communication system working with#R##N#   low frequency. In this paper, we propose a new signal acquisition method.#R##N#   The acquisition process includes coarse matched filter (MF) location in the#R##N#   first stage and an accurate MF acquisition as a verification mode for the#R##N#   second stage. The performance metrics, including mean acquisition time (MAT)#R##N#   and power consumption, are accuracy. The results indicate that when the#R##N#   signal-to-noise ratio (SNR) keeping consistent, the MAT of the proposed#R##N#   method is less than the original one. When the SNR is around -5dB, the#R##N#   system mismatch rate is about 5:6 x 10-4, which takes only one percent of#R##N#   those achieved in the original acquisition algorithms. The two-step MF#R##N#   acquisition method is stable except its power consumption being a little#R##N#   higher than the original method.","2016","2","1","2025-12-02","https://university.edu/papers/96f709f1-1e3d-4ec8-b681-1d70cc603e9d.pdf");
INSERT INTO Paper VALUES ("861","Reweighted l1 Dual Averaging Approach for Sparse Stochastic Learning.","Recent advances in stochastic optimization and regularized dual averaging approaches revealed a substantial interest for a simple and scalable stochastic method which is tailored to some more specific needs. Among the latest one can find sparse signal recovery and l0-based sparsity inducing approaches. These methods in particular can force many compo- nents of the solution shrink to zero thus clarifying the importance of the features and simplifying the evaluation. In this paper we concentrate on enhancing sparsity of the recently proposed l1 Regularized Dual Averaging (RDA) method with a simple reweighting iterative procedure which in a limit applies the l0-norm penalty. We present some theoretical justifica- tions of a bounded regret for a sequence of convex repeated games where every game stands for a separate reweighted l1-RDA problem. Numeri- cal results show an enhanced sparsity of the proposed approach and some improvements over the l1-RDA method in generalization error.","2014","2","2","2025-12-02","https://university.edu/papers/ce188f23-49d7-432f-a154-08da4ac75f4b.pdf");
INSERT INTO Paper VALUES ("862","Plant information systems, manufacturing capabilities, and plant performance","Firms have been investing over $5 billion a year in recent years on new information technology and software in their manufacturing plants. In this study, we develop a conceptual model based on the theory of dynamic capabilities to study how manufacturing plants realize improvements in plant performance by leveraging plant information systems to enable implementation of advanced manufacturing capabilities. We develop hypotheses about relationships between information systems, their impact on manufacturing practices, and the overall impact on plant performance. Analysis of survey data from 1,077 U.S. manufacturing plants provides empirical support for the dynamic capabilities model and suggests that manufacturing capabilities mediate the impact of information systems on plant performance. Our results underscore the importance of manufacturing and organizational capabilities in studying the impact of IT on manufacturing plant productivity, and provide a sharper theoretical lens to evaluate their impact.","2006","15","2","2025-12-02","https://university.edu/papers/5f845b61-91ed-4bc8-8c68-e339053f6525.pdf");
INSERT INTO Paper VALUES ("863","An investigation of finger versus stylus input in medical scenarios","An in-situ study on the routine work of clinicians at Graz University Hospital was carried out in order to evaluate the input method preferences. We conducted several experiments consisting of selection tasks on two different types of tablet PCs, with the end users in three experimental conditions: sitting, standing and walking. The results show that the medical staff performed better when using stylus operated device. In almost all tests, subjects performed the selection tasks significantly faster and more accurately (p < 0.001) with the stylus operated device, even though it had a smaller screen and therefore the targets were smaller. The only exception was the selection performance when seated, where no significant difference was found (p = 0.06). However, the error rate was significantly lower for stylus input for all experiment conditions. This result is also supported by the analysis of the questionnaires, where it was found that almost all subjects preferred stylus input.","2008","10","1","2025-12-02","https://university.edu/papers/c0e18051-edad-49ee-bd56-e687a6507b4f.pdf");
INSERT INTO Paper VALUES ("864","Optimal configuration of p-cycles in WDM networks","We investigate the deployment of p-cycles (preconfigured protection cycles) in WDM mesh networks with and without wavelength conversion. We develop optimization models for the configuration of the cycles and apply these on a case study for a pan-European network. The results in particular for wavelength converting networks show that p-cycles achieve high efficiency.","2002","11","3","2025-12-02","https://university.edu/papers/a4a20abb-a6cf-4053-bb4c-3d0faa7249d0.pdf");
INSERT INTO Paper VALUES ("865","Relaying with finite blocklength: Challenge vs. opportunity","In this paper, we study the performance of a system with multiple decode-and-forward (DF) relays under the finite blocklength (FBL) regime. We derive the FBL-Throughput under both perfect CSI and average CSI scenarios while the corresponding throughputs under an infinite blocklength assumption (IBL-throughput) are discussed as performance references. Through numerical analysis, we evaluate the system performance. We show a higher throughput under the FBL assumption than under the IBL assumption under the perfect CSI scenario.","2016","20","2","2025-12-02","https://university.edu/papers/91690364-e777-446e-b8d7-63bf7a3be58a.pdf");
INSERT INTO Paper VALUES ("866","Mining information from time series in the form of sentences of natural language","The goal of this paper is to provide a more detailed explanation of the principles how special formulas that characterize properties of trend of time series can be formed and how they are interpreted. Then we show how these formulas can be used in a tectogrammatical tree that construes special sentences of natural language, using which information on behavior of time series is provided. We also outline the principles of mining this information. The last part is devoted to application of the theory of intermediate quantifiers to mining summarized information on time series also in sentences of natural language. The formal theory of mining information from time series is continued.Special emphasis is payed to methods how the information can be provided in natural language.The presented theory formalizes semantics of part of natural language developed as a constituent of fuzzy natural logic.The formalization is provided in the language of higher-order mathematical fuzzy logic.","2016","10","2","2025-12-02","https://university.edu/papers/95e6f816-9648-4cb5-8a0f-34b54f00f552.pdf");
INSERT INTO Paper VALUES ("867","Information set generation in partially observable games","We address the problem of making single-point decisions in large partially observable games, where players interleave observation, deliberation, and action. We present information set generation as a key operation needed to reason about games in this way. We show how this operation can be used to implement an existing decision-making algorithm. We develop a constraint satisfaction algorithm for performing information set generation and show that it scales better than the existing depth-first search approach on multiple non-trivial games.","2012","20","4","2025-12-02","https://university.edu/papers/26444beb-6f00-4cc9-87c6-1e013f8982dc.pdf");
INSERT INTO Paper VALUES ("868","Indoor location retrieval using shape matching of KinectFusion scans to large-scale indoor point clouds","In this paper we show that indoor location retrieval can be posed as a part-in-whole matching problem of KinectFusion (KinFu) query scans in large-scale target indoor point clouds. We tackle the problem with a local shape feature-based 3D Object Retrieval (3DOR) system. We specifically show that the KinFu queries suffer from artifacts stemming from the non-linear depth distortion and noise characteristics of Kinect-like sensors that are accentuated by the relative largeness of the queries. We furthermore show that proper calibration of the Kinect sensor using the CLAMS technique (Calibrating, Localizing, and Mapping, Simultaneously) proposed by Teichman et al. effectively reduces the artifacts in the generated KinFu scan and leads to a substantial retrieval performance boost. Throughout the paper we use queries and target point clouds obtained at the world's largest technical museum. The target point clouds cover floor spaces of up to 3500m2. We achieve an average localization accuracy of 6cm although the KinFu query scans make up only a tiny fraction of the target point clouds.","2015","16","1","2025-12-02","https://university.edu/papers/8d7acfa0-90f6-4050-b848-4d52a8688992.pdf");
INSERT INTO Paper VALUES ("869","Performance Analysis of Contention Based Medium Access Control Protocols","This paper studies the performance of contention based medium access control (MAC) protocols. In particular, a simple and accurate technique for estimating the throughput of the IEEE 802.11 DCF protocol is developed. The technique is based on a rigorous analysis of the Markov chain that corresponds to the time evolution of the back-off processes at the contending nodes. An extension of the technique is presented to handle the case where service differentiation is provided with the use of heterogeneous protocol parameters, as, for example, in IEEE 802.11e EDCA protocol. Our results provide new insights into the operation of such protocols. The techniques developed in the paper are applicable to a wide variety of contention based MAC protocols.","2009","3","1","2025-12-02","https://university.edu/papers/d458eb21-cff4-4096-a02b-137d8307ae87.pdf");
INSERT INTO Paper VALUES ("870","On the Convergence Rate of Dual Ascent Methods for Linearly Constrained Convex Minimization","We analyze the rate of convergence of certain dual ascent methods for the problem of minimizing a strictly convex essentially smooth function subject to linear constraints. Included in our study are dual coordinate ascent methods and dual gradient methods. We show that, under mild assumptions on the problem, these methods attain a linear rate of convergence. Our proof is based on estimating the distance from a feasible dual solution to the optimal dual solution set by the norm of a certain residual.","1993","9","2","2025-12-02","https://university.edu/papers/c213d148-4028-45df-9934-cf2f6f9f3fab.pdf");
INSERT INTO Paper VALUES ("871","Weaving the Economic Linked Open Data","Efforts in integrating the basic economic functions under a common or compatible context could be accelerated by enabling semantic processing of the underlying data. We establish the basic flows among public budgeting, contracting and spending with business information and provide the necessary ontological elements that would integrate them in economic Linked Open Data corpus.","2012","16","3","2025-12-02","https://university.edu/papers/d01a1313-10d4-4b2c-ad5f-b40f797de21c.pdf");
INSERT INTO Paper VALUES ("872","Steps toward child-designed interactive stuffed toys","Within the past decade, computationally-enhanced toys have become a staple of children's environments. In large part, this is due to the small size, robust operation, and low cost of embedded computing that enables computers (and associated electronic devices) to be included within toys of all descriptions. More recently, a variety of powerful technologies have emerged so that children can design their own computational artifacts: that is, small (and inexpensive) processors, sensors, and actuators have been developed that are well-suited to combination with 'soft' materials such as textiles. This paper describes Plushbot, a system-in-development that allows children to create their own plush toys and stuffed animals, and to include computational enhancements within the toys that they create. Thus, Plushbot represents a step toward expanding children's creative design of their own interactive, computationally-enhanced characters. The paper describes the current state of the Plushbot software, shows a sample project created with the system, and describes plans for upcoming pilot tests with the system.","2011","8","4","2025-12-02","https://university.edu/papers/5b9542c4-6fc7-4757-aaae-7990558bae65.pdf");
INSERT INTO Paper VALUES ("873","Robot etiquette: how to approach a pair of people?","Research has been carried out on robots approaching one person [1, 3, 4]. However, further research is needed on robots approaching groups of people. In the study reported in this paper, we studied participants who were paired up for a task and assessed their perception and behaviors as they were approached by a robot from various angles. On an individual level, participants liked the frontal approaches, and they disliked being approached from the back. However, we found that the presence of a task-partner influenced participants' comfort with a robot approaching (i.e. when the robot approaches and one is standing behind the task-partner). Apart from the positioning of the individuals, the layout of the room, position of furniture and doors, also seemed to influence their experience. This pilot study was performed with a limited number of participants (N=30). However, the study offers preliminary insights into the factors that influence the choice for a robot approach direction when approaching a pair of people that are focused on a task.","2014","10","3","2025-12-02","https://university.edu/papers/987aaa4d-486c-423b-bc4b-6eea154ece6f.pdf");
INSERT INTO Paper VALUES ("874","An Automatic EEG Spike Detection Algorithm Using Morphological Filter","Epileptic electroencephalogram data contains transient components and background activities. One of the transients is spike, which occurs randomly with short-duration. Spike detection in EEG is significant for clinical diagnosis of epilepsy. Since it is time consuming to scan spikes manually, an automatic spike detection method is necessary. In this paper, we introduce an automatic spike detection method in epileptic EEG based on morphological filter. Firstly, an average weighted combination of open-closing and close-opening morphological operator, which eliminates statistical deflection of amplitude, is utilized to extract spike component from epileptic EEG. Then, according to the characteristic of spike component, the structure elements are constructed with two parabolas, and a new criterion is put forward to optimize center amplitude and width of the structure elements. The proposed method is evaluated by simulated epileptic EEG data. Results show that background activity is fully restrained and spike component is well extracted. Finally, the method is applied to normal and epileptic EEG data which are actually recorded from nine testees. The average detection rate of spikes is 91.62% and no false detection for normal EEG signals","2006","18","3","2025-12-02","https://university.edu/papers/58635e1f-2ea4-4a68-b467-a74646853373.pdf");
INSERT INTO Paper VALUES ("875","Lexicographically first reduced words","Abstract   In this paper we investigate properties of a certain equivalence relation on reduced words in  S   n   called  C  1 -equivalence. We combinatorially characterize the class of the lexicographically first reduced word of a permutation. We further show how this class is related to reduced words that are lattice words.","1995","8","3","2025-12-02","https://university.edu/papers/65c81e74-15bb-4c89-aac2-dfce29588e50.pdf");
INSERT INTO Paper VALUES ("876","Classification of Faces in Man and Machine","We attempt to shed light on the algorithms humans use to classify images of human faces according to their gender. For this, a novel methodology combining human psychophysics and machine learning is introduced. We proceed as follows. First, we apply principal component analysis (PCA) on the pixel information of the face stimuli. We then obtain a data set composed of these PCA eigenvectors combined with the subjects' gender estimates of the corresponding stimuli. Second, we model the gender classification process on this data set using a separating hyperplane (SH) between both classes. This SH is computed using algorithms from machine learning: the support vector machine (SVM), the relevance vector machine, the prototype classifier, and the K-means classifier. The classification behavior of humans and machines is then analyzed in three steps. First, the classification errors of humans and machines are compared for the various classifiers, and we also assess how well machines can recreate the subjects' internal decision boundary by studying the training errors of the machines. Second, we study the correlations between the rank-order of the subjects' responses to each stimulus—the gender estimate with its reaction time and confidence rating—and the rank-order of the distance of these stimuli to the SH. Finally, we attempt to compare the metric of the representations used by humans and machines for classification by relating the subjects' gender estimate of each stimulus and the distance of this stimulus to the SH. While we show that the classification error alone is not a sufficient selection criterion between the different algorithms humans might use to classify face stimuli, the distance of these stimuli to the SH is shown to capture essentials of the internal decision space of humans. Furthermore, algorithms such as the prototype classifier using stimuli in the center of the classes are shown to be less adapted to model human classification behavior than algorithms such as the SVM based on stimuli close to the boundary between the classes.","2006","11","1","2025-12-02","https://university.edu/papers/bd133cee-aa03-4458-9ee7-1cca004cbdbd.pdf");
INSERT INTO Paper VALUES ("877","Employing multiple-kernel support vector machines for counterfeit banknote recognition","Finding an efficient method to detect counterfeit banknotes is an imperative task in business transactions. In this paper, we propose a system based on multiple-kernel support vector machines for counterfeit banknote recognition. A support vector machine (SVM) to minimize false rates is developed. Each banknote is divided into partitions and the luminance histograms of the partitions are taken as the input of the system. Each partition is associated with its own kernels. Linearly weighted combination is adopted to combine multiple kernels into a combined matrix. Optimal weights with kernel matrices in the combination are obtained through semi-definite programming (SDP) learning. Two strategies are adopted to reduce the amount of time and space required by the SDP method. One strategy assumes the non-negativity of the kernel weights, and the other one is to set the sum of the weights to be unity. Experiments with Taiwanese banknotes show that the proposed approach outperforms single-kernel SVMs, standard SVMs with SDP, and multiple-SVM classifiers.","2011","2","3","2025-12-02","https://university.edu/papers/b70325c3-63c6-4436-adac-46765ac9a4dc.pdf");
INSERT INTO Paper VALUES ("878","Designing interactive systems in healthcare: a report on WISH 2011","This forum is dedicated to personal health in all its many facets: decision-making, goal setting, celebration, discovery, reflection, coordination---even entertainment. We'll look at innovations in interactive technologies and how they help address current critical healthcare challenges.   Elizabeth D. Mynatt, Editor","2012","14","4","2025-12-02","https://university.edu/papers/bf86161b-c8d2-461f-9dd9-5fdacf19299b.pdf");
INSERT INTO Paper VALUES ("879","Selectively Personalizing Query Auto-Completion","Query auto-completion (QAC) is being used by many of today's search engines. It helps searchers formulate queries by providing a list of query completions after entering an initial prefix of a query. To cater for a user's specific information needs, personalized QAC strategies use a searcher's search history and their profile. Is personalization consistently effective in different search contexts?   We study the QAC problem by selectively personalizing the query completion list. Based on a lenient personalized QAC strategy that encodes the ranking signal as a trade-off between query popularity and search context, we propose a model for selectively personalizing query auto-completion (SP-QAC) to study this trade-off. We predict effective trade-offs based on a regression model, where the typed query prefix, clicked documents and preceding queries in the same session are used to weigh personalization in QAC. Experiments on the AOL query log show the SP-QAC model can significantly outperform a state-of-the-art personalized QAC approach.","2016","9","1","2025-12-02","https://university.edu/papers/1bb87d98-2ebe-4e06-9af2-ec17b3801b44.pdf");
INSERT INTO Paper VALUES ("880","Task teaching to a force-controlled high-speed parallel robot","This paper purposes to implement fast and complicated tasks by a high-speed parallel robot, HEXA, for industrial applications and the others. Although this parallel robot does not use any force/torque sensors, it has sufficient capabilities to achieve various tasks by applying an integrated control of motion, force and compliance, which takes advantage of the back-driveability and friction compensation of the actuators. A key point is how simply and easily operators can bring out the performance. We develop an off-line task teaching system to realize the motion planning suitable for tasks. Some tasks are demonstrated by using this teaching and control system and we experimentally confirm the effectiveness of our system.","2003","7","2","2025-12-02","https://university.edu/papers/8ef9e00b-67df-414a-8852-c8a21ed36f96.pdf");
INSERT INTO Paper VALUES ("881","A low-latency and energy-efficient algorithm for convergecast in wireless sensor networks","In wireless sensor networks (WSN) the process of dissemination of data among various sensors (broadcast) and collection of data from all sensors (convergecast or data aggregation) are common communication operations. With increasing demands on efficient use of battery power, many efficient broadcast tree construction and channel allocation algorithms have been proposed. Generally convergecast is preceded by broadcast. Hence the tree used for broadcast is also used for convergecast. Our research shows that this approach is inefficient in terms of latency and energy consumption. In this paper we propose a heuristic solution for the problem of minimum energy convergecast which also works toward minimizing data latency. This algorithm constructs a tree using a greedy approach where new nodes are added to the tree such that weight on the branch to which it is added is less. The algorithm then allocates direct sequence spread spectrum or frequency hopping spread spectrum codes. Simulation results show that energy consumed and communication latency of our approach is lower than some of the existing approaches for convergecast. We have then used our algorithm to perform broadcast. Surprisingly our results show that this algorithms performance for broadcasting is better compared to other broadcast techniques.","2003","17","2","2025-12-02","https://university.edu/papers/53a09500-fbb9-44a7-81c6-535d6b605aa7.pdf");
INSERT INTO Paper VALUES ("882","A Comparison of Spatial Generalization Algorithms for LBS Privacy Preservation","Spatial generalization has been recently proposed as a technique for the anonymization of requests in location based services. This paper presents the results of an extensive experimental study, considering known generalization algorithms as well as new ones proposed by the authors.","2007","10","2","2025-12-02","https://university.edu/papers/f3446024-e717-4946-a1ff-a875d2b1f166.pdf");
INSERT INTO Paper VALUES ("883","A physics-based parametric representation of the wind direction signal in sea surface microwave brightness temperatures","Polarimetric passive measurements of sea surface brightness temperature have been proposed as a means of inferring wind speed and direction. A limited set of circle flight measurements of the wind direction dependence has demonstrated that there may be enough independent information in the polarimetric measurement to make this feasible. A predictive model by Yueh reproduces the observations closely enough that the dominant mechanisms are probably included. Optimizing the fit of this type of model with a growing dataset is made difficult by the close coupling of the Yueh approach with a particular wind-wave spectral model. This makes it unclear as to how to parameterize the model, a prerequisite of any systematic optimization technique. Here, we present an alternate formulation, using the Baum-Irisov model to isolate the particular properties of the wavy ocean surface that affect the radiance, in the form of six discrete parameters. Iterative local linearization techniques are used to optimize the values of these parameters with respect to any large dataset. The parameters are functions of only two variables (radiometer frequency and wind speed), while the effects of incidence angle, polarization, sea surface temperature, salinity, and wind direction are derived front the model. Since the data need only be binned by these two variables, a relatively small number of on-orbit/ground-truth datasets is required to evaluate the parameters.","2003","4","3","2025-12-02","https://university.edu/papers/c5b3f46c-f57d-4fe1-b838-0a74a49f9d9a.pdf");
INSERT INTO Paper VALUES ("884","Dynamic Description Logic Based Services Semantic Matching","A key issue in semantic Web services is semantic matching which is important to facilitate to reuse of Web services. Existing semantic matching technique such as ontology based, do not guarantee fulfilling the preconditions and desired effect, and hence do not guarantee the correctness of the matching results, in this paper we prose a novel semantic matching approach based on service dynamic description logic (SDDL). SDDL is used to present services specification for capturing both static information and dynamic state aspect of service function, and then semantic matching take into account all these aspects to achieve a precise matching. Furthermore not only exact matching, but also various kinds of matching degree are defined.","2008","5","1","2025-12-02","https://university.edu/papers/f6c24e9c-7492-4aa2-941c-b5f38a8c30db.pdf");
INSERT INTO Paper VALUES ("885","Intention-based diagnosis of programming errors","PROUST is a system which identifies the non-syntactic bugs in novices' programs and provides novices with help as to the misconceptions under which they were laboring that caused the bugs. In this paper we will discuss the methods which PROUST uses to identify and diagnose non-syntactic bugs. Key in this enterprise is PROUST's ability to cope with the significant variability exhibited by novices' programs: novice programs are designed and implemented in a variety of different ways, and usually have numerous bugs. We argue that diagnostic techniques that attempt to reason from faulty behavior to bugs are not effective in the face of such variability. Rather, PROUST's approach is to construct a causal model of the programmer's intentions and their realization (or non-realization) in the code. This model serves as a framework for bug recognition, and allows PROUST to reason about the consequences of the programmer's decisions in order to determine where errors were committed and why.","1984","8","4","2025-12-02","https://university.edu/papers/f73219db-26d2-489a-8028-0b42c0bea0ec.pdf");
INSERT INTO Paper VALUES ("886","Roundoff-error-free algorithms for solving linear systems via cholesky and LU factorizations","LU and Cholesky factorizations are computational tools for efficiently solving linear systems that play a central role in solving linear programs and several other classes of mathematical programs. In many documented cases, however, the roundoff errors accrued during the construction and implementation of these factorizations lead to the misclassification of feasible problems as infeasible and vice versa. Hence, reducing these roundoff errors or eliminating them altogether is imperative to guarantee the correctness of the solutions provided by optimization solvers. To achieve this goal without having to use rational arithmetic, we introduce two roundoff-error-free factorizations that require storing the same number of individual elements and performing a similar number of operations as the traditional LU and Cholesky factorizations. Additionally, we present supplementary roundoff-error-free forward and backward substitution algorithms, thereby providing a complete tool set for solving systems of linear eq...","2015","15","1","2025-12-02","https://university.edu/papers/84f322b5-81a3-49c4-956f-09c5a1dca723.pdf");
INSERT INTO Paper VALUES ("887","A simple manifold-based construction of surfaces of arbitrary smoothness","We present a smooth surface construction based on the manifold approach of Grimm and Hughes. We demonstrate how this approach can relatively easily produce a number of desirable properties which are hard to achieve simultaneously with polynomial patches, subdivision or variational surfaces. Our surfaces are  C  ∞ -continuous with explicit nonsingular  C  ∞  parameterizations, high-order flexible at control vertices, depend linearly on control points, have fixed-size local support for basis functions, and have good visual quality.","2004","1","4","2025-12-02","https://university.edu/papers/8a9e0e18-5978-4811-89e7-8200fcb99ba2.pdf");
INSERT INTO Paper VALUES ("888","Embedding various cycles with prescribed paths into k-ary n-cubes","The   k     k       -ary   n     n       -cube has been one of the most popular interconnection networks for large-scale multi-processor systems and data centers. In this study, we investigate the problem of embedding cycles of various lengths passing through prescribed paths in the   k     k       -ary   n     n       -cube. For   n≥2     n  ≥  2        and   k≥5     k  ≥  5        with   k     k        odd, we prove that every path with length   h     h        (  1≤h≤2n−1     1  ≤  h  ≤  2  n  −  1       ) in the   k     k       -ary   n     n       -cube lies on cycles of every length from   h+(k−1)(n−1)/2+k     h  +   (  k  −  1  )    (  n  −  1  )   /  2  +  k        to   k n        k    n          inclusive.","2017","2","3","2025-12-02","https://university.edu/papers/5ca8645c-acc0-4675-8ad2-c8e2b70920fa.pdf");
INSERT INTO Paper VALUES ("889","Pan-sharpening method via ARSIS concept under image super-resolution scheme","We present a novel fusion method to improve the spatial resolution of multispectral (MS) images, where the fused spectral images integrate the spectral information and spatial details from the original MS images and panchromatic (PAN) image, respectively. Band by band, a spectral image with high resolution is reconstructed from the original spectral image to take advantage of super-resolution technology. The pan-sharpening method via Amelioration de la Reso- lution Spatiale par Injection de Structures concept is further applied to obtain the fused images from the reconstructed spectral images and PAN image. Performance of the proposed method has been evalu- ated on the public optical satellite QuickBird images. Experimental results show that the fused spectral images both preserve the spatial details of high-resolution from the PAN image and have higher spec- tral resolution than the original spectral images. © 2012 SPIE and IS&T. (DOI: 10.1117/1.JEI.21.3.030501)","2012","9","4","2025-12-02","https://university.edu/papers/cc8b8565-b1c9-4388-8755-3e1ce06637cc.pdf");
INSERT INTO Paper VALUES ("890","Presentation by tree transformation","Structured documents are represented as trees. The layout or presentation of a document is also often modeled as a computation over a tree. But these trees are not generally the same. For instance, L/sup A/T/sub E/X converts a structured document to the T/sub E/X formatting hierarchy of boxes and glue. In other words, presentation is a mapping between trees. Casting it as a formal tree transformation offers both expressive, compact style specifications and efficient implementation. In our structured document system Ensemble, we have implemented a general framework for presentation by tree transformation. It consists of a core transformation engine; several distinct output tree languages or 'media'; and style files in a common language. To demonstrate its flexibility, we have built media for formatting programs, for presenting numerical data as graphs, and for displaying the tree structure of any document. We have also defined four efficiency requirements for interactive presentation, and tuned the implementation to meet each one.","1997","10","1","2025-12-02","https://university.edu/papers/1bb5f666-078b-443b-923d-a460e45712ff.pdf");
INSERT INTO Paper VALUES ("891","Synchronization Analysis and Design of Coupled Boolean Networks Based on Periodic Switching Sequences","A novel synchronization analysis method is developed to solve the complete synchronization problem of many Boolean networks (BNs) coupled in the leader–follower configuration. First, an error system is constructed in terms of the algebraic representation using the semitensor product of matrices. Then, the synchronization problem of coupled BNs is converted into a problem whether all the trajectories of the error system are convergent to the zero vector. Second, according to the structure analysis of this error system, which is in the form of a switched system with leader BN states as the switching signal, a necessary and sufficient synchronization condition is derived. An algorithm is developed, which helps to determine as soon as possible whether complete synchronization among coupled BNs is achieved. Finally, a constructive design approach to follower BNs is provided. All of these follower BNs designed by our approach can completely synchronize with a given leader BN from the    $(T_{t}+1)$   th step at most, where    $T_{t}$    is the transient period of the leader BN.","2016","2","3","2025-12-02","https://university.edu/papers/c9c504c9-80ba-4521-8e4a-bf2b22df57ef.pdf");
INSERT INTO Paper VALUES ("892","Pattern-based development of Domain-Specific Modelling Languages","Model-Driven Engineering (MDE) promotes the use of models to conduct all phases of software development in an automated way. Models are frequently defined using Domain- Specific Modelling Languages (DSMLs), which many times need to be developed for the domain at hand. However, while constructing DSMLs is a recurring activity in MDE, there is scarce support for gathering, reusing and enacting knowledge for their design and implementation. This forces the development of every new DSML to start from scratch. To alleviate this problem, we propose the construction of DSMLs and their modelling environments aided by patterns which gather knowledge of specific domains, design alternatives, concrete syntax, dynamic semantics and functionality for the modelling environment. They may have associated services, realized via components. Our approach is supported by a tool that enables the construction of DSMLs through the application of patterns, and synthesizes a graphical modelling environment according to them.","2015","20","4","2025-12-02","https://university.edu/papers/c6af6a59-22e8-4214-af91-06ac1b96608c.pdf");
INSERT INTO Paper VALUES ("893","A new version of conjugate gradient method parallel implementation","In the article the authors describe an idea of parallel implementation of a conjugate gradient method in a heterogeneous PC cluster and a supercomputer Hitachi SR-2201. The new version of algorithm implementation differs from the one applied earlier (Jordan and Bycul, 2002), because it uses a special method for storing sparse coefficient matrices: only non-zero elements are stored and taken into account during computations, so that the sparsity of the coefficient matrix is taken full advantage of. The article includes a comparison of the two versions. A speedup of the parallel algorithm has been examined for three different cases of coefficient matrices resulting in solving different physical problems. The authors have also investigated a preconditioning method, which uses the inversed diagonal of the coefficient matrix, as a preconditioning matrix.","2002","16","1","2025-12-02","https://university.edu/papers/93afcd72-6ee9-4ce3-b83b-df1d1fb29605.pdf");
INSERT INTO Paper VALUES ("894","Identification of driver state for lane-keeping tasks","Identification of driver state is a desirable element of many proposed vehicle active safety systems (e.g., collision detection and avoidance, automated highway, and road departure warning systems). In the paper, driver state assessment is considered in the context of a road departure warning and intervention system. A system identification approach, using vehicle lateral position as the input and steering wheel position as the output, is used to develop a model and to update its parameters during driving. Preliminary driving simulator results indicate that changes in the bandwidth and/or parameters of such a model may be useful indicators of driver fatigue. The approach is then applied to data from 12 2-h highway driving runs conducted in a full-vehicle driving simulator. The identified model parameters (/spl zeta/ /spl omega//sub n/, and DC gain) do not exhibit the trends expected as lane keeping performance deteriorates, despite having acceptably white residuals. As an alternative, model residuals are compared in a process monitoring approach using a model fit to an early portion of the 2-h driver run. Model residuals show the expected trends and have potential in serving as the basis for a driver state monitor.","1999","13","4","2025-12-02","https://university.edu/papers/c1ba1571-fccf-45db-9083-1eb4e4de7e3f.pdf");
INSERT INTO Paper VALUES ("895","Security Testing for Intrusion Provention System - The Security Evaluation Practice","In recent years,government,enterprise and bank network have become highly dependent on Internet.The drawback of this situation is that the consequences of disturbances of the underlying Internet may be serious as cascading effects can occur.This raised a high demand for security assurance.In order to impoving security,every year,they spend a lot of money to buy security products,with a high importance assigned to security evaluation.This paper will introduce the security evaluations process and will forcus on the tests done on hardware products,specifically Intrusion Provention System.","2009","15","1","2025-12-02","https://university.edu/papers/509c477e-c321-4a6c-8f13-8173d91c9f74.pdf");
INSERT INTO Paper VALUES ("896","Clustering SOAP Web Services on Internet Computing Using Fast Fractals","The interoperability of Web services has resulted in its adoption for recently-emerging cloud platforms. SOAP (Simple Object Access Protocol) is considered as the main platform independent communication tool for the Cloud Web service. Generally, Cloud Web services suffer performance bottlenecks and congestions that are mainly caused by the encoding of XML messages as they are bigger than the real payloads. In this paper, Fractal clustering model is proposed to compute the Fractal clustering similarity of SOAP messages in order to cluster them and enable the aggregation of SOAP messages to significantly reduce the size of the aggregated SOAP messages. Furthermore, as Fractal is a well-known as a time-consuming technique especially for large dataset, two fast Fractal clustering models have been proposed that are aiming to reduce the required clustering time. The proposed fast Fractal models have tremendously outperformed the classical Fractal model in terms of the processing time and have outperformed both K-means and PCA combined with K-means models in terms of both the processing time and SOAP messages size reduction.","2011","8","2","2025-12-02","https://university.edu/papers/a2374d75-36a7-411f-bcd6-cea6658dc6d3.pdf");
INSERT INTO Paper VALUES ("897","A fall detection study on the sensors placement location and a rule-based multi-thresholds algorithm using both accelerometer and gyroscopes","Falls are dangerous among the elderly population and are a major health concern. Many investigators have reported the use of accelerometers for fall detection. In addition, the use of miniature gyroscopes has also been reported to be able to detect falls, but the effects of sensor placement on the back of a person have not been studied thoroughly. In this paper we present a simple solution for effective fall detection using both an accelerometer and two gyroscopes placed, as a single unit, on three different positions along the thoracic vertebrae (i.e., T-4, T-7, and T-10). Results indicated that T-10 was not a good location for the gyroscope placement for fall detection. However, both T-4 and T-7 were suitable, with the results for T-4 being slightly better. Using a simple rule-based multi-thresholds algorithm that utilizes the recorded resultant gravitational acceleration, angular change, angular velocity, and angular acceleration, we were able to successfully detect all 60 falls and differentiate between falls and activities of daily living (ADL) with no false positives on young volunteers. More testing data is needed, especially for backward falls, to test the robustness of our simple algorithm and to improve the sensor portability for future trial studies on geriatric populations.","2011","13","2","2025-12-02","https://university.edu/papers/df1c6b64-49c4-449a-902c-e8ce5037a999.pdf");
INSERT INTO Paper VALUES ("898","Modeling Hesitation and Conflict: A Belief-Based Approach for Multi-class Problems","Support Vector Machine (SVM) is a powerful tool for binary classification. Numerous methods are known to fuse several binary SVMs into multi-class (MC) classifiers. These methods are efficient, but an accurate study of the misclassified items leads to notice two sources of mistakes: (1) the response of each classifier does not use the entire information from the SVM, and (2) the decision method does not use the entire information from the classifier responses. In this paper, we present a method which partially prevents these two losses of information by applying Belief Theories (BTs) to SVM fusion, while keeping the efficient aspect of the classical methods.","2006","14","1","2025-12-02","https://university.edu/papers/b90e2bd4-4acf-4f4c-a262-e9289dec0069.pdf");
INSERT INTO Paper VALUES ("899","A non-reference measure for objective edge map evaluation","Edge detection has been used extensively as a preprocessing step for many computer vision tasks. Due to its importance in image processing and the highly subjective nature of human evaluation and visual comparison of edge detectors, it is desirable to formulate objective edge map evaluation measures. One would like to use such a measure to make comparisons of results using the same edge detector with different parameters as well as to make comparisons of results using different edge detectors. Reconstruction-based measures have the clear advantage that they effectively incorporate original image data. In this paper, a general model for reconstruction-based measures is established in order to alleviate the shortcomings of the reconstruction-based measures, followed by the formulation of a new non-reference measure for objective edge map evaluation. Experimental results illustrate the effectiveness of the new measure both as a means of selecting optimal edge detector parameters and as a means of determining the relative performance of edge detectors for a given image.","2009","10","1","2025-12-02","https://university.edu/papers/fe07b0c2-15c2-4c79-b44f-073b023cbccf.pdf");
INSERT INTO Paper VALUES ("900","Exploring connectivity of the brain's white matter with dynamic queries","Diffusion tensor imaging (DTI) is a magnetic resonance imaging method that can be used to measure local information about the structure of white matter within the human brain. Combining DTI data with the computational methods of MR tractography, neuroscientists can estimate the locations and sizes of nerve bundles (white matter pathways) that course through the human brain. Neuroscientists have used visualization techniques to better understand tractography data, but they often struggle with the abundance and complexity of the pathways. In this paper, we describe a novel set of interaction techniques that make it easier to explore and interpret such pathways. Specifically, our application allows neuroscientists to place and interactively manipulate box or ellipsoid-shaped regions to selectively display pathways that pass through specific anatomical areas. These regions can be used in coordination with a simple and flexible query language which allows for arbitrary combinations of these queries using Boolean logic operators. A representation of the cortical surface is provided for specifying queries of pathways that may be relevant to gray matter structures and for displaying activation information obtained from functional magnetic resonance imaging. By precomputing the pathways and their statistical properties, we obtain the speed necessary for interactive question-and-answer sessions with brain researchers. We survey some questions that researchers have been asking about tractography data and show how our system can be used to answer these questions efficiently.","2005","18","3","2025-12-02","https://university.edu/papers/f0f1cd6f-ed71-4950-ac24-675177a0c801.pdf");
INSERT INTO Paper VALUES ("901","Quantification of cerebral cannabinoid receptors subtype 1 (CB1) in healthy subjects and schizophrenia by the novel PET radioligand [11C]OMAR.","Several studies have examined the link between the cannabinoid CB1 receptor and several neuropsychiatric illnesses, including schizophrenia. As such, there is a need for in vivo imaging tracers so that the relationship between CB1 and schizophrenia (SZ) can be further studied. In this paper, we present our first human studies in both healthy control patients and patients with schizophrenia using the novel PET tracer, [11C]OMAR (JHU75528), we have shown its utility as a tracer for imaging human CB1 receptors and to investigate normal aging and the differences in the cannabinoid system of healthy controls versus patients with schizophrenia. A total of ten healthy controls and nine patients with schizophrenia were included and studied with high specific activity [11C]OMAR. The CB1 binding (expressed as the distribution volume; VT) was highest in the globus pallidus and the cortex in both controls and patients with schizophrenia. Controls showed a correlation with the known distribution of CB1 and decline of [11C]OMAR binding with age, most significantly in the globus pallidus. Overall, we observed elevated mean binding in patients with schizophrenia across all regions studied, and this increase was statistically significant in the pons (p < 0.05), by the Students t-test. When we ran a regression of the control subjects VT values with age and then compared the patient data to 95% prediction limits of the linear regression, three patients fell completely outside for the globus pallidus, and in all other regions there were at least 1–3 patients outside of the prediction intervals. There was no statistically significant correlations between PET measures and the individual Brief Psychiatry Rating Score (BPRS) subscores (r = 0.49), but there was a significant correlation between VT and the ratio of the BPRS psychosis to withdrawal score in the frontal lobe (r = 0.60), and middle and posterior cingulate regions (r = 0.71 and r = 0.79 respectively). In conclusion, we found that [11C] OMAR can image human CB1 receptors in normal aging and schizophrenia. In addition, our initial data in subjects with schizophrenia seem to suggest an association of elevated binding specific brain regions and symptoms of the disease.","2010","1","3","2025-12-02","https://university.edu/papers/8f6f1e24-a55a-4192-acda-4a7f271fdaee.pdf");
INSERT INTO Paper VALUES ("902","New Coins From Old: Computing With Unknown Bias","Suppose that we are given a function f : (0, 1)→(0,1) and, for some unknown p∈(0, 1), a sequence of independent tosses of a p-coin (i.e., a coin with probability p of “heads”). For which functions f is it possible to simulate an f(p)-coin? This question was raised by S. Asmussen and J. Propp. A simple simulation scheme for the constant function f(p)≡1/2 was described by von Neumann (1951); this scheme can be easily implemented using a finite automaton. We prove that in general, an f(p)-coin can be simulated by a finite automaton for all p ∈ (0, 1), if and only if f is a rational function over ℚ. We also show that if an f(p)-coin can be simulated by a pushdown automaton, then f is an algebraic function over ℚ; however, pushdown automata can simulate f(p)-coins for certain nonrational functions such as $$f{\left( p \right)} = {\sqrt p }$$. These results complement the work of Keane and O’Brien (1994), who determined the functions f for which an f(p)-coin can be simulated when there are no computational restrictions on the simulation scheme.With an appendix by Christopher Hillar‡, University of California, Berkeley, 970 Evans Hall #3840, Berkeley, CA 94720-3840, USA, chillar@math.berkeley.edu","2005","9","2","2025-12-02","https://university.edu/papers/73e0631d-2a91-4dcd-9818-c8cc2ea67a26.pdf");
INSERT INTO Paper VALUES ("903","Theoretical modelling of fog computing: a green computing paradigm to support IoT applications","In this study, the authors focus on theoretical modelling of the fog computing architecture and compare its performance with the traditional cloud computing model. Existing research works on fog computing have primarily focused on the principles and concepts of fog computing and its significance in the context of internet of things (IoT). This work, one of the first attempts in its domain, proposes a mathematical formulation for this new computational paradigm by defining its individual components and presents a comparative study with cloud computing in terms of service latency and energy consumption. From the performance analysis, the work establishes fog computing, in collaboration with the traditional cloud computing platform, as an efficient green computing platform to support the demands of the next generation IoT applications. Results show that for a scenario where 25% of the IoT applications demand real-time, low-latency services, the mean energy expenditure in fog computing is 40.48% less than the conventional cloud computing model.","2016","1","3","2025-12-02","https://university.edu/papers/ac7d7ce0-eb7e-42fb-bc7e-b6fe6eba677f.pdf");
INSERT INTO Paper VALUES ("904","System Factory: integrating tools for system integration","Large-scale distributed systems such as global enterprise systems, e-commerce and e-service systems are critical for businesses and complex to build and run. Their design requires an advanced technology of system integration that guarantees satisfaction of various customer requirements. This paper advocates a holistic approach to system integration that supports an end-to-end systematic design: Business Process/spl rarr/Workload Pattern/spl rarr/Virtual System/spl rarr/Configuration/spl rarr/Data and Application Deployment. This approach is implemented as a System Factory, an integrated environment that incorporates and consolidates matching system analysis techniques. The functionality and structure of a System Factory prototype that is under development at HP Laboratories is described in the paper. The center of the factory is a repository that accumulates system solutions, patterns, and templates for specific business segments. Specialized shops with a common modeling and analysis base provide convenient means to find customized solutions.","2001","20","4","2025-12-02","https://university.edu/papers/6b51d466-4c1f-4cc6-a477-d45476c702ab.pdf");
INSERT INTO Paper VALUES ("905","Risk-based integrated production scheduling and electricity procurement for continuous power-intensive processes","For optimal operation of power-intensive plants, production scheduling and electricity procurement have to be considered simultaneously. In addition, uncertainty needs to be taken into account. For this purpose, an integrated stochastic mixed-integer linear programming model is developed that considers the two most critical sources of uncertainty: spot electricity price, and product demand. Conditional value-at-risk is incorporated into the model as a measure of risk. Furthermore, scenario reduction and multicut Benders decomposition are implemented to solve large-scale real-world problems. The proposed model is applied to an illustrative example as well as an industrial air separation case. The results show the benefit from stochastic optimization and the effect of taking a risk-averse rather than a risk-neutral approach. An interesting insight from the analysis is that in risk-neutral optimization, accounting for electricity price uncertainty does not yield significant added value; however, in risk-averse optimization, modeling price uncertainty is crucial for obtaining good solutions.","2016","14","1","2025-12-02","https://university.edu/papers/12678b69-46c0-4614-87d5-0c4fbe7f762d.pdf");
INSERT INTO Paper VALUES ("906","Anatomical origin and computational role of diversity in the response properties of cortical neurons","The maximization of diversity of neuronal response properties has been recently suggested as an organizing principle for the formation of such prominent features of the functional architecture of the brain as the cortical columns and the associated patchy projection patterns (Malach, 1994). We show that (1) maximal diversity is attained when the ratio of dendritic and axonal arbor sizes is equal to one, as found in many cortical areas and across species (Lund et al., 1993; Malach, 1994), and (2) that maximization of diversity leads to better performance in systems of receptive fields implementing steerable/shiftable filters, and in matching spatially distributed signals, a problem that arises in many high-level visual tasks.","1995","4","4","2025-12-02","https://university.edu/papers/7d4df9f7-f89a-4d50-a896-f539e68770f9.pdf");
INSERT INTO Paper VALUES ("907","Technical Note-Improved Dominance Conditions for the Three-Machine Flowshop Scheduling Problem","Existing combinatorial or elimination approaches for solving the three-machine flowshop scheduling problem are not applicable for the situation where the jobs have their least processing time on the second machine. We present improved dominance conditions that extend the applicability of combinatorial approaches to this situation. To derive these conditions we use Johnson's two-machine results as well as the nature of unscheduled jobs.","1978","10","4","2025-12-02","https://university.edu/papers/d6709705-8366-4a83-9cfa-5ae2c31c027c.pdf");
INSERT INTO Paper VALUES ("908","Conceptual programming","We introduce conceptual programming as a process model based on our programming experiences. Conceptual programming means having programmers work directly with their conceptual models, using their own terms or languages rather than those dictated by the computer. To be useful and effective, conceptual programming must be supported by a powerful programming environment. We have developed such an environment, GARDEN, and are beginning to get feedback on its use.","1989","14","3","2025-12-02","https://university.edu/papers/f3cd34af-d43c-477a-a9c8-444050cd078f.pdf");
INSERT INTO Paper VALUES ("909","Temporal Overdrive Recurrent Neural Network","In this work we present a novel recurrent neural network architecture designed to model systems characterized by multiple characteristic timescales in their dynamics. The proposed network is composed by several recurrent groups of neurons that are trained to separately adapt to each timescale, in order to improve the system identification process. We test our framework on time series prediction tasks and we show some promising, preliminary results achieved on synthetic data. To evaluate the capabilities of our network, we compare the performance with several state-of-the-art recurrent architectures.","2017","6","4","2025-12-02","https://university.edu/papers/e6b673e1-d384-4300-823c-d9bceb633e5e.pdf");
INSERT INTO Paper VALUES ("910","Hardware-in-the-loop simulation of two-shaft gas turbine engine’s electronic control unit","An electronic control unit for a fuel control system of two-shaft gas turbine engines plays an undisputable role in providing the required fuel flow to the engine as well as satisfying engine’s operational characteristics. One of the main challenges in designing such unit is the accuracy of its performance and the control strategy implementation on an electronic hardware via repeatable and comprehensive tests. In this article, a hardware-in-the-loop simulation is presented for testing of the electronic control unit for a two-shaft gas turbine engine. For this purpose, the engine is first presented and modeled by the use of Wiener block structure method. The fuel controller with Min–Max structure is then explained. Finally, the controller is implemented on a PC/104 hardware and tested in an hardware-in-the-loop simulation in order to verify its correct performance. The results show that the fuel controller satisfies all of the engine’s physical constraints, confirming the controller competence and successf...","2016","15","2","2025-12-02","https://university.edu/papers/48887863-160c-4ad2-b81e-663e777d3533.pdf");
INSERT INTO Paper VALUES ("911","Gait Recognition Using Flow Histogram Energy Image","Human gait is of essential importance for its wide use in biometric person-identification applications. In this work, we introduce a novel spatio-temporal gait representation, Flow Histogram Energy Image (FHEI), to characterize distinctive motion information of individual gait. We first extract the Histograms of Optical Flow (HOF) descriptors of each silhouette image of gait sequence, and construct an FHEI by averaging all the HOF features of a full gait cycle. We also propose a novel approach to generate two different synthetic gait templates. Real and synthetic gait templates are then fused to enhance the recognition accuracy of FHEI. We also adopt the Non-negative Matrix Factorization (NMF) to learn a part-based representation of FHEI templates. Extensive experiments conducted on the USF HumanID gait database indicate that the proposed FHEI approach achieves superior or comparable performance in comparison with a number of competitive gait recognition algorithms.","2014","5","1","2025-12-02","https://university.edu/papers/b10f68f1-9dc9-4c19-a54a-a3a6e62b6953.pdf");
INSERT INTO Paper VALUES ("912","A High-Accuracy Detection and Estimation Method of Intermodulated Sinusoids","As intermodulated sinusoids are generated when a nonlinear system is subject to multiple fundamental frequencies, an approach is proposed in this paper to detect and to estimate, or simply to retrieve the intermodulated sinusoids. It is shown that both detection and estimation performance are improved by using the intermodulation relationship as an additional constraint. Although the periodogram method is used here, the approach can be readily modified to accommodate other frequency retrieval techniques. The implementation and the performance of this approach are demonstrated by simulation examples.","2011","9","3","2025-12-02","https://university.edu/papers/f53a8e64-a1f7-4dc4-907e-d8cb25882ca5.pdf");
INSERT INTO Paper VALUES ("913","Monitoring communication channels on a shared memory multi-processor system on chip","To meet performance requirements, streaming applications have been mapped to Multi-Processor System on Chip (MPSoC). The Kahn Process Network (KPN) paradigm is sufficient when dealing with pipeline parallelism, but such point-to-point channels are impractical in the presence of massive task farm parallelism. Multi Writer Multi Reader (MWMR) channels generalize KPN in such a way that multiple writers and multiple readers access the same channel. They are implemented as software channels stored in on-chip memory to accommodate access by hardware and software tasks alike. The price to pay for this implementation is increased traffic to and from memory. Typical representatives are telecommunication applications which may treat hundreds or thousands of flows at a time, where the same chain of treatments is applied to every packet. The latency for this treatment depends on the packet's content, and can thus not be foreseen. Among multiple tasks which access a MWMR channel, the time to obtain a lock is variable. In consequence, fill states of MWMR channels vary heavily and it is crucial to monitor it in order to detect potential bottlenecks. We show how this can be done early in the design process by using SoCLib/DSX.","2011","3","2","2025-12-02","https://university.edu/papers/63d83215-868f-4d72-8af1-4a3498444ef2.pdf");
INSERT INTO Paper VALUES ("914","Intelligent Clustering in Vehicular ad hoc Networks","A network with high mobility nodes or vehicles is vehicular ad hoc Network (VANET). For improvement in communication efficiency of VANET, many techniques have been proposed; one of these techniques is vehicular node clustering. Cluster nodes (CNs) and Cluster Heads (CHs) are elected or selected in the process of clustering. The longer the lifetime of clusters and the lesser the number of CHs attributes to efficient networking in VANETs. In this paper, a novel Clustering algorithm is proposed based on Ant Colony Optimization (ACO) for VANET named ACONET. This algorithm forms optimized clusters to offer robust communication for VANETs. For optimized clustering, parameters of transmission range, direction, speed of the nodes and load balance factor (LBF) are considered. The ACONET is compared empirically with state of the art methods, including Multi-Objective Particle Swarm Optimization (MOPSO) and Comprehensive Learning Particle Swarm Optimization (CLPSO) based clustering techniques. An extensive set of experiments is performed by varying the grid size of the network, the transmission range of nodes, and total number of nodes in network to evaluate the effectiveness of the algorithms in comparison. The results indicate that the ACONET has significantly outperformed the competitors.","2016","18","3","2025-12-02","https://university.edu/papers/ead6243f-f003-4e10-8efa-89b203fa92b7.pdf");
INSERT INTO Paper VALUES ("915","Outstanding Paper Award: Analysis of Global EDF for Parallel Tasks","As multicore processors become ever more prevalent, it is important for real-time programs to take advantage of intra-task parallelism in order to support computation-intensive applications with tight deadlines. We prove that a Global Earliest Deadline First (GEDF) scheduling policy provides a capacity augmentation bound of 4-2/m and a resource augmentation bound of 2-1/m for parallel tasks in the general directed a cyclic graph model. For the proposed capacity augmentation bound of 4-2/m for implicit deadline tasks under GEDF, we prove that if a task set has a total utilization of at most m/(4-2/m) and each task's critical path length is no more than 1/(4-2/m) of its deadline, it can be scheduled on a machine with m processors under GEDF. Our capacity augmentation bound therefore can be used as a straightforward schedulability test. For the standard resource augmentation bound of 2-1/m for arbitrary deadline tasks under GEDF, we prove that if an ideal optimal scheduler can schedule a task set on m unit-speed processors, then GEDF can schedule the same task set on m processors of speed 2-1/m. However, this bound does not lead to a schedulabilty test since the ideal optimal scheduler is only hypothetical and is not known. Simulations confirm that the GEDF is not only safe under the capacity augmentation bound for various randomly generated task sets, but also performs surprisingly well and usually outperforms an existing scheduling technique that involves task decomposition.","2013","11","4","2025-12-02","https://university.edu/papers/f27cc903-9900-42d0-a67b-ad491cf23b4b.pdf");
INSERT INTO Paper VALUES ("916","Inapproximability of the Perimeter Defense Problem","We model the problem of detecting intruders using a set of infrared beams by the perimeter defense problem: given a polygon P, find a minimum set of edges S of the polygon such that any straight line segment crossing the polygon intersects at least one of the edges in S. We observe that this problem is equivalent to a new hiding problem, the Max-Hidden-Edge-Set problem. We prove the APX-hardness of the Max-Hidden-EdgeSet problem for polygons without holes and rectilinear polygons without holes, by providing gap-preserving reductions from the Max-5-Occurrence-2-Sat problem.","2009","2","3","2025-12-02","https://university.edu/papers/d5793ca5-c5ed-46c5-a717-540603ce922f.pdf");
INSERT INTO Paper VALUES ("917","Application of pseudo-distance to lossless coding of color-mapped images","Palette images are widely used in many applications, including WWW which occupies an important role in Cloud Computing. Recently, it has been shown that better compression can be obtained when a Huffman coder is used after a color-mapped image is transformed with a pseudo-distance metric. Unlike most of the color-mapped image compression techniques, which require two passes, the pseudo-distance compression technique requires one pass and runs in linear time. In this work, we show that further compression gains can be achieved for color-mapped images when a structured arithmetic coder is used along with the pseudo-distance metric.","2011","12","3","2025-12-02","https://university.edu/papers/cc0f7c7d-54ef-47d1-93e0-86dbaae52e1a.pdf");
INSERT INTO Paper VALUES ("918","Real-Time Tracking of Complex Structures for Visual Servoing","This paper presents a visualserv oing system which incorporates a novelthree-dimensionalmo del-based tracking system. This tracking system extends constrained active contour tracking techniques into three dimensions, placing them within a Lie algebraic framework. This is combined with modern graphicalrendering technology to create a system which can track complex three dimensional structures in real time at video frame rate (25 Hz) on a standard workstation without special hardware. The system is based on an internal CAD model of the object to be tracked which is rendered using binary space partition trees to perform hidden line removal. The visible features are identified on-line at each frame and are tracked in the video feed. Analytical and statistical edge saliency are then used as a means of increasing the robustness of the tracking system.","1999","9","1","2025-12-02","https://university.edu/papers/d7c9adb4-0400-4807-b8ed-6ae9802a98d7.pdf");
INSERT INTO Paper VALUES ("919","LTL Model Checking via Search Space Partition","The applicability of model checking is often limited by the size of the industrial system. This is known as state space explosion problem. Compositional verification has been particularly successful in this regard. This paper presents an approach based on a refinement of search space partition for reducing the complexity in verification of models with non-deterministic choices and open environment. The refinement depends on the representation of each portion of search space. Especially, search space can be refined stepwise to get better reduction. As reported in the case studies, search space partition improves the efficiency of verification with respect to the requirement of memory and obtains significant advantage over the use of the original one.","2006","4","3","2025-12-02","https://university.edu/papers/53768b8e-eda3-411d-a20a-40c217ef9163.pdf");
INSERT INTO Paper VALUES ("920","On Maximum-Likelihood Timing Synchronization","In this paper, we address the issue of symbol timing recovery for a coded burst transmission system. As direct maximum-likelihood (ML) estimation is intractable, we resort to the expectation-maximization (EM) algorithm in order to derive a receiver that iterates between data detection and synchronization. Conventional data-aided (DA) and decision-directed (DD) synchronizers can be interpreted as special cases of the proposed algorithm. The EM-based technique takes into account code properties and is especially well suited to scenarios where conventional schemes fail to provide the detector with a reliable timing estimate. The performance of the proposed algorithm is compared with conventional techniques through computer simulations, both in terms of mean-square estimation error (MSEE) and bit error rate (BER).","2007","19","3","2025-12-02","https://university.edu/papers/85d94619-c230-415e-a15a-94dee2779f7d.pdf");
INSERT INTO Paper VALUES ("921","GPFS: A Shared-Disk File System for Large Computing Clusters","GPFS is IBM's parallel, shared-disk file system for cluster computers, available on the RS/6000 SP parallel supercomputer and on Linux clusters. GPFS is used on many of the largest supercomputers in the world. GPFS was built on many of the ideas that were developed in the academic community over the last several years, particularly distributed locking and recovery technology. To date it has been a matter of conjecture how well these ideas scale. We have had the opportunity to test those limits in the context of a product that runs on the largest systems in existence. While in many cases existing ideas scaled well, new approaches were necessary in many key areas. This paper describes GPFS, and discusses how distributed locking and recovery techniques were extended to scale to large clusters.","2002","9","2","2025-12-02","https://university.edu/papers/7853ec59-161c-4a18-a36f-1fa4f3a97a86.pdf");
INSERT INTO Paper VALUES ("922","Interval homogeneous domination approach for global stabilization of nonlinear systems with time-varying powers","This paper considers the problem of global stabilization for a class of nonlinear systems with time-varying powers. A new design method based on the technique of adding a power integrator and the interval homogeneous domination approach, which can be thought as an evolution of the homogeneous domination approach, is developed to explicitly construct a smooth state feedback globally stabilizing controller. The novelty of this paper is the development of a systematic scheme, which provides us a new perspective to deal with the state feedback control problem for the nonlinear systems with time-varying powers.","2016","15","4","2025-12-02","https://university.edu/papers/a0c8f5fe-a54d-43a5-86cc-11d8e9ef532e.pdf");
INSERT INTO Paper VALUES ("923","The IWSLT 2011 Evaluation Campaign on Automatic Talk Translation","We report here on the eighth evaluation campaign organized in 2011 by the IWSLT workshop series. That IWSLT 2011 evaluation focused on the automatic translation of public talks and included tracks for speech recognition, speech translation, text translation, and system combination. Unlike in previous years, all data supplied for the evaluation has been publicly released on the workshop website, and is at the disposal of researchers interested in working on our benchmarks and in comparing their results with those published at the workshop. This paper provides an overview of the IWSLT 2011 evaluation campaign, and describes the data supplied, the evaluation infrastructure made available to participants , and the subjective evaluation carried out.","2012","1","4","2025-12-02","https://university.edu/papers/b302b11e-4d09-44b4-8a7f-d9fca1787fe2.pdf");
INSERT INTO Paper VALUES ("924","ConcernLines: A timeline view of co-occurring concerns","Understanding the evolution of a software system requires understanding how information about the release history, non-functional requirements and project milestones relates to functional requirements on the software components. This short paper describes a new tool, called CONCERNLINES, that supports this cognitive process by visualizing co-occurring concerns over time.","2009","1","4","2025-12-02","https://university.edu/papers/4c1cf422-8d53-4021-8ed6-021dffd8239e.pdf");
INSERT INTO Paper VALUES ("925","Segmentation of intravascular ultrasound images: a knowledge-based approach","Intravascular ultrasound imaging of coronary arteries provides important information about coronary lumen, wall, and plaque characteristics. Quantitative studies of coronary atherosclerosis using intravascular ultrasound and manual identification of wall and plaque borders are limited by the need for observers with substantial experience and the tedious nature of manual border detection. We have developed a method for segmentation of intravascular ultrasound images that identifies the internal and external elastic laminae and the plaque-lumen interface. The border detection algorithm was evaluated in a set of 38 intravascular ultrasound images acquired from fresh cadaveric hearts using a 30 MHz imaging catheter. To assess the performance of our border detection method we compared five quantitative measures of arterial anatomy derived from computer-detected borders with measures derived from borders manually defined by expert observers. Computer-detected and observer-defined lumen areas correlated very well (r=0.96, y=1.02x+0.52), as did plaque areas (r=0.95, y=1.07x-0.48), and percent area stenosis (r=0.93, y=0.99x-1.34.) Computer-derived segmental plaque thickness measurements were highly accurate. Our knowledge-based intravascular ultrasound segmentation method shows substantial promise for the quantitative analysis of in vivo intravascular ultrasound image data.","1995","2","3","2025-12-02","https://university.edu/papers/ade6ac3b-ace0-46c9-a977-35ce14fa7016.pdf");
INSERT INTO Paper VALUES ("926","Why high performance visual data analytics is both relevant and difficult","Data visualization, as well as data analysis and data analytics, are all an integral part of the scientific process. Collectively, these technologies provide the means to gain insight into data of ever-increasing size and complexity. Over the past two decades, a substantial amount of visualization, analysis, and analytics R&D has focused on the challenges posed by increasing data size and complexity, as well as on the increasing complexity of a rapidly changing computational platform landscape. While some of this research focuses on solely on technologies, such as indexing and searching or novel analysis or visualization algorithms, other R&D projects focus on applying technological advances to specific application problems. Some of the most interesting and productive results occur when these two activities-R&D and application-are conducted in a collaborative fashion, where application needs drive R&D, and R&D results are immediately applicable to real-world problems. © (2013) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.","2013","16","2","2025-12-02","https://university.edu/papers/6f46fc10-a71c-4c62-914b-94886caa832d.pdf");
INSERT INTO Paper VALUES ("927","Point-to-point scheduling over a wireless channel with costly channel state information","In this work, we are interested in understanding the trade-off between the cost of acquiring accurate information and the improvement in the system performance because of accuracy of information. Specifically, we consider the wireless scheduling scenario where a scheduler residing at the transmitter can acquire the channel state information (CSI) at various levels of accuracy, but at a cost which increases with accuracy. The scheduler is, therefore, required to make CSI acquisition as well as scheduling decisions to minimize the total cost over an infinite horizon. We pose this problem as a partially observable Markov decision problem. We analyze it by converting it into a perfect state Markov decision problem (MDP) with belief distribution as the state and provide structural properties of the optimal policy. Under a special case, where CSI is either known perfectly or is not known, we show that the problem can be simplified and posed as an MDP in which the policy determines a sampling interval for each channel state. We present a numerical technique to compute these sampling intervals and numerical results based on it.","2011","14","1","2025-12-02","https://university.edu/papers/cd5c45aa-fd41-45b3-ae88-0f72840434b3.pdf");
INSERT INTO Paper VALUES ("928","On the macroscopic optimization of multicell wireless systems with multiuser detection and multiple antennas - uplink analysis","In this paper, we consider a system with K single-antenna client users, n/sub B/ base stations (each base station has n/sub R/ antennas), as well as a centralized controller. A client user could be associated with a single base station at any time. All the base stations operate at the same frequency and have optimal multiuser detection per base station which cancels intracell interference only. We consider a general problem of uplink macroscopic resource management where the centralized controller dynamically determines an appropriate association mapping of the K users with respect to the n/sub B/ base stations over a macroscopic time scale. We propose a novel analytical framework for the above macroscopic scheduling problems. A simple rule is to associate a user with the strongest base station (camp-on-the-strongest-cell), and this has been widely employed in conventional cellular systems. However, based on the optimization framework, we found that this conventional approach is in fact not optimal when multiuser detection is employed at the base station. We show that the optimal macroscopic scheduling algorithm is of exponential complexity, and we propose a simple greedy algorithm as a feasible solution.","2005","19","1","2025-12-02","https://university.edu/papers/8e4115a5-71db-464e-8073-0962b364fadc.pdf");
INSERT INTO Paper VALUES ("929","A back propagation artificial neural network application in lithofacies identification","The traditional lithofacies identification by the geology method usually has the flaw of strong subjectivity, high randomness and high requirement of the geological interpreter. In order to accurately identify the lithofacies in each well and thus provide a better guidance for the plan of further exploration and exploitation, an integrated lithofacies identification method based on ANN (artificial neural network) is presented. Take the YJ Oilfield as an example, on the basis of well log data preprocessing, choose appropriate training samples and identify the lithofacies in single well taking advantage of the generalization and self-learning ability of the ANN algorithm, and compare the result to the lithofacies identification from core data. It shows that this method has relatively high accuracy when applied to lithofacies identification of clastic reservoirs which normally have complicated lithological sequences. Compared to the traditional identification method, the ANN method avoid the subjectivity in the well log interpretation and don't have to set up interpretation models for the district which usually calls for abundant experience; what's more, the interpreter could make a balance between accuracy and efficiency by shifting the neuron number of the hidden layer. In general, this method is of high practical value.","2015","9","3","2025-12-02","https://university.edu/papers/5604ecb1-775e-4adc-9b25-015470135357.pdf");
INSERT INTO Paper VALUES ("930","iVizTRANS: Interactive visual learning for home and work place detection from massive public transportation data","Using transport smart card transaction data to understand the homework dynamics of a city for urban planning is emerging as an alternative to traditional surveys which may be conducted every few years are no longer effective and efficient for the rapidly transforming modern cities. As commuters travel patterns are highly diverse, existing rule-based methods are not fully adequate. In this paper, we present iVizTRANS - a tool which combines an interactive visual analytics (VA) component to aid urban planners to analyse complex travel patterns and decipher activity locations for single public transport commuters. It is coupled with a machine learning component that iteratively learns from the planners classifications to train a classifier. The classifier is then applied to the city-wide smart card data to derive the dynamics for all public transport commuters. Our evaluation shows it outperforms the rule-based methods in previous work.","2015","3","4","2025-12-02","https://university.edu/papers/049b84f6-caeb-4f2d-94a7-24d7f4b9b9d8.pdf");
INSERT INTO Paper VALUES ("931","Individual Differences In Internet Usage Motives","The relationship between the psychobiological model of personality types (psychoticism, extraversion, and neuroticism) devised by Eysenck and Eysenck [Personality and individual differences: A natural science approach, Plenum Press, New York, 1985] and Internet use and usage motives was examined. A sample of 210 undergraduate students were asked to report on their motives for using the Internet and how often they engaged in a variety of Internet and web-based activities. The findings demonstrate distinctive patterns of Internet use and usage motives for those of different personality types. Specifically, those scoring high in neuroticism reported using the Internet to feel a sense of “belonging” and to be informed. Extraverts rejected the communal aspects of the Internet, and made more instrumental and goal-oriented use of Internet services. Finally, those scoring high in psychoticism demonstrated an interest in more deviant, defiant, and sophisticated Internet applications. Implications of the findings as well as suggestions for future research are included.","2004","6","3","2025-12-02","https://university.edu/papers/cbae7b54-633a-48fe-8ef3-8537f3ce2b02.pdf");
INSERT INTO Paper VALUES ("932","FCRA: Femtocell Cluster-Based Resource Allocation Scheme for OFDMA Networks","Recently, operators have resorted to femtocell networks in order to enhance indoor coverage and quality of service since macro-antennas fail to reach these objectives. Nevertheless, they are confronted to many challenges to make a success of femtocells deployment. In this paper, we address the issue of resources allocation in femtocell networks using OFDMA technology (e.g., WiMAX, LTE). Specifically, we propose a hybrid centralized/distributed resource allocation strategy namely \textit{Femtocell Cluster-based Resource Allocation} (\texttt{FCRA}). Firstly, \texttt{FCRA} builds interference-free femtocell clusters. Then, within a cluster the optimal resource allocation for each femtocell is performed by its cluster-head. Finally, the contingent collisions among different clusters are fixed. To achieve this, we formulate the problem mathematically as Min-Max optimization problem. Performance analysis shows that \texttt{FCRA} converges to the optimal solution in small-sized networks and outperforms two prominent related schemes (\texttt{C-DFP} and \texttt{DRA}) in large-sized ones. The results concern the throughput satisfaction rate, the spectrum spatial reuse, and the convergence time metrics.","2011","9","3","2025-12-02","https://university.edu/papers/bdf0c10d-b5fd-4e14-a3cb-ff6d31ad1e47.pdf");
INSERT INTO Paper VALUES ("933","The Genomedata format for storing large-scale functional genomics data","Summary: We present a format for efficient storage of multiple tracks of numeric data anchored to a genome. The format allows fast random access to hundreds of gigabytes of data, while retaining a small disk space footprint. We have also developed utilities to load data into this format. We show that retrieving data from this format is more than 2900 times faster than a naive approach using wiggle files.#R##N##R##N#Availability and Implementation: Reference implementation in Python and C components available at http://noble.gs.washington.edu/proj/genomedata/ under the GNU General Public License.#R##N##R##N#Contact: william-noble@uw.edu","2010","16","2","2025-12-02","https://university.edu/papers/db9fae25-37fd-46db-89ea-7887dc0708c2.pdf");
INSERT INTO Paper VALUES ("934","SUBSKY: Efficient Computation of Skylines in Subspaces","Given a set of multi-dimensional points, the skyline contains the best points according to any preference function that is monotone on all axes. In practice, applications that require skyline analysis usually provide numerous candidate attributes, and various users depending on their interests may issue queries regarding different (small) subsets of the dimensions. Formally, given a relation with a large number (e.g.,ge 10) of attributes, a query aims at finding the skyline in an arbitrary subspace with a low dimensionality (e.g., 2). The existing algorithms do not support subspace skyline retrieval efficiently because they (i) require scanning the entire database at least once, or (ii) are optimized for one particular subspace but incur significant overhead for other subspaces. In this paper, we propose a technique SUBSKY which settles the problem using a single B-tree, and can be implemented in any relational database. The core of SUBSKY is a transformation that converts multi-dimensional data to 1D values, and enables several effective pruning heuristics. Extensive experiments with real data confirm that SUBSKY outperforms alternative approaches significantly in both efficiency and scalability.","2006","8","2","2025-12-02","https://university.edu/papers/7685969a-2d82-4ea4-9fbd-07dac4f17d5f.pdf");
INSERT INTO Paper VALUES ("935","Zoom: A Serious Games Intervention Design Model - When Games Alone Are Not Enough!","This article posits reflections from the author's mature body of work that resulted in sizeable national (Denmark) and international (European) funded projects, a patent, commercial product, and a Serious Games company. Main focus is on sharing a two-stage in-action and on-action emergent model for evaluating the use of ICT (serious games and creative expression) in healthcare and learning intervention. The model, first published in 2005, being emergent, has evolved to suggest being applicable beyond existing contexts and situations e.g. informal, non-formal and formal. Thus, to advance the model, third party review, applied use and assessment toward discussions of pluses, minuses and possible improvements is welcomed. Additionally, within the model a secondary emphasis argues briefly, but importantly, how researching applied contemporary ICT requires an additional specific research ethic consideration. To position these foci, the author's research is first introduced.","2016","5","1","2025-12-02","https://university.edu/papers/a0794d17-9405-412d-9485-7cf6295f504b.pdf");
INSERT INTO Paper VALUES ("936","A classifier based on the maximal fuzzy similarity in the generalized Lukasiewicz-structure","The aim of this paper is to introduce improvements made to a classifier based on maximal fuzzy similarity. Improvements are based on the use of generalized Lukasiewicz-structure and weight optimization. The main benefits of the classifier are its computational efficiency and its strong mathematical background. It is based on many-valued logic and it provides semantic information about classification results. We show that if one chooses the power value in a right manner in the generalized Lukasiewicz-structure and the optimal weights for different feature, one can see significant enhancements in classification results.","2001","8","1","2025-12-02","https://university.edu/papers/aa3ea41a-8a92-465d-852a-53309446956c.pdf");
INSERT INTO Paper VALUES ("937","A Practical Approach to Hardware Performance Monitoring Based Dynamic Optimizations in a Production JVM","While the concept of online profile directed dynamic optimizations using hardware performance monitoring unit (PMU) data is not new, it has seen fairly limited or no use in commercial JVMs. The main reason behind this fact is the set of significant challenges involved in (1) obtaining low overhead and usable profiling support from the underlying platform (2) the complexity of filtering, interpreting and using precise PMU events online in a JVM environment (3) demonstrating the total runtime benefit of PMU data based optimizations above and beyond regular online profile based optimizations. In this paper we address all three challenges by presenting a practical framework for PMU data collection and use within a high performance product JVM on a highly scalable server platform. Our experiments with JavaTM workloads using the SunTM HotspotTM JDK 1.6 JVM on the Intel ® Itanium ® platform indicate that the hardware data collection overhead (less than 0.5%) is not as significant as the challenge of extracting the precise information for optimization purposes. We demonstrate the feasibility of mapping the instruction IP address based hardware event information to the runtime components as well as the JIT server compiler internal data structures for use in optimizations within a dynamic environment. We also evaluated the additional performance potential of optimizations such as object co-location during garbage collection and global instruction scheduling in the JIT compiler with the use of PMU generated load latency information. Experimental results show performance improvements of up to 14%  with an average of  2.2% across select Java server benchmarks such as SPECjbb2005[16], SPECjvm2008[17] and Dacapo[18]. These benefits were observed over and above those provided by profile guided server JVM optimizations in the absence of hardware PMU data.","2009","2","2","2025-12-02","https://university.edu/papers/85fd8a0b-8fa0-4410-bedb-edf0665e9541.pdf");
INSERT INTO Paper VALUES ("938","SVD-based feature extraction from time-series motion data and its application to gesture recognition","Singular value decomposition is used to extract features from time-series motion data. A matrix consisting of the time-series data is decomposed into left singular vectors which represent the patterns of the motion and singular values as a scalar, by which each corresponding left singular vector affects the matrix. Gesture recognition using the extracted features suggest the effectiveness of the method.","2014","17","4","2025-12-02","https://university.edu/papers/87a1abfc-551d-4d8d-a0e4-0dd00c9ac0fe.pdf");
INSERT INTO Paper VALUES ("939","Orthogonal ray graphs and nano-PLA design","The logic mapping problem and the problem of finding a largest square sub-crossbar with no defects in a nano-crossbar with nonprogrammable crosspoint defects and disconnected wire defects have been known to be NP-hard. This paper shows that for nano-crossbars with only disconnected wire defects, the former remains NP-hard, while the latter can be solved in polynomial time.","2009","19","3","2025-12-02","https://university.edu/papers/bf51c7ce-408a-478d-ae2c-44382885af07.pdf");
INSERT INTO Paper VALUES ("940","STDP-Compatible Approximation of Backpropagation in an Energy-Based Model.","We show that Langevin Markov chain Monte Carlo inference in an energy-based model with latent variables has the property that the early steps of inference, starting from a stationary point, correspond to propagating error gradients into internal layers, similar to backpropagation. The backpropagated error is with respect to output units that have received an outside driving force pushing them away from the stationary point. Backpropagated error gradients correspond to temporal derivatives with respect to the activation of hidden units. These lead to a weight update proportional to the product of the presynaptic firing rate and the temporal rate of change of the postsynaptic firing rate. Simulations and a theoretical argument suggest that this rate-based update rule is consistent with those associated with spike-timing-dependent plasticity. The ideas presented in this article could be an element of a theory for explaining how brains perform credit assignment in deep hierarchies as efficiently as backpropag...","2017","2","2","2025-12-02","https://university.edu/papers/79643c04-84b1-446a-becb-a900bb869bac.pdf");
INSERT INTO Paper VALUES ("941","A Framework for Evaluating Skyline Queries over Incomplete Data","Research interest in skyline queries has been significantly increased over the years, as skyline queries can be utilized in many contemporary applications, such as multi-criteria decision-making system, decision support system, recommendation system, data mining, and personalized systems. Skyline queries return data item that is not dominated by any other data items in all dimensions (attributes). Most of the existing skyline approaches assumed that database is complete and values are present during the skyline process. However, such assumption is not always to be true, particularly in a real world database where values of data item might not be available (missing) in one or more dimensions. Thus, the incompleteness of the data impacts negatively on skyline process due to losing the transitivity property which leads into the issue of cyclic dominance. Therefore, applying skyline technique directly on an incomplete database is prohibitive and might result into exhaustive pairwise comparison. This paper presents an approach that efficiently evaluates skyline queries in incomplete database. The approach aims at reducing the number of pairwise comparisons and shortens the searching space in identifying the skylines. Several experiments have been conducted to demonstrate that our approach outperforms the previous approach through producing a lower number of pairwise comparisons. Furthermore, the result also illustrates that our approach is scalable and efficient.","2016","2","3","2025-12-02","https://university.edu/papers/2a16e85f-519d-4833-903f-90ba0d12d6a9.pdf");
INSERT INTO Paper VALUES ("942","Extracting and Displaying Temporal and Geospatial Entities from Articles on Historical Events","This paper discusses a system that extracts and displays temporal and geospatial entities in text. The first task involves identification of all events in a document followed by identification of important events using a classifier. The second task involves identifying named entities associated with the document. In particular, we extract geospatial named entities. We disambiguate the set of geospatial named entities and geocode them to determine the correct coordinates for each place name, often called grounding. We resolve ambiguity based on sentence and article context. Finally, we present a user with the key events and their associated people, places and organizations within a document in terms of a timeline and a map. For purposes of testing, we use Wikipedia articles about historical events, such as those describing wars, battles and invasions. We focus on extracting major events from the articles, although our ideas and tools can be easily used with articles from other sources such as news articles. We use several existing tools such as Evita, Google Maps, publicly available implementationsofSupportVectorMachines,HiddenMarkovModelandConditionalRandomField, and the MIT SIMILE Timeline.","2014","9","1","2025-12-02","https://university.edu/papers/92e091d8-591b-41c8-bbc0-292b37055cb7.pdf");
INSERT INTO Paper VALUES ("943","Graph homomorphism revisited for graph matching","In a variety of emerging applications one needs to decide whether a graph G matches another Gp, i.e., whether G has a topological structure similar to that of Gp. The traditional notions of graph homomorphism and isomorphism often fall short of capturing the structural similarity in these applications. This paper studies revisions of these notions, providing a full treatment from complexity to algorithms. (1) We propose p-homomorphism (p-hom) and 1-1 p-hom, which extend graph homomorphism and subgraph isomorphism, respectively, by mapping edges from one graph to paths in another, and by measuring the similarity of nodes. (2) We introduce metrics to measure graph similarity, and several optimization problems for p-hom and 1-1 p-hom. (3) We show that the decision problems for p-hom and 1-1 p-hom are NP-complete even for DAGs, and that the optimization problems are approximation-hard. (4) Nevertheless, we provide approximation algorithms with provable guarantees on match quality. We experimentally verify the effectiveness of the revised notions and the efficiency of our algorithms in Web site matching, using real-life and synthetic data.","2010","12","1","2025-12-02","https://university.edu/papers/e631c260-3c2d-4afb-85ce-13850d78b6c5.pdf");
INSERT INTO Paper VALUES ("944","Some results about stabilization of periodic takagi-sugeno models","A class of non linear discrete time models with periodic parameters is considered in a Takagi-Sugeno (TS) form. The main objective of this paper is to show the potential improvement in the area of nonlinear periodic system control and observation using TS models. In order to achieve this goal, two problems are developed in this paper. The first part is dedicated to the design of a periodic TS fuzzy observer, where stability conditions are provided. In the second part, some results about the stabilization of periodic TS models with time varying delay are given. The adopted framework is based on Lyapunov's theory and uses linear matrix inequalities. In each case, a simulation example is provided to show the efficiency of the method.","2009","20","2","2025-12-02","https://university.edu/papers/d0e6ddd9-d2c5-405f-b80a-a942f29a8da0.pdf");
INSERT INTO Paper VALUES ("945","Network-Wide Traffic State Estimation Using Loop Detector and Floating Car Data","In real-time traffic management and intelligent transportation systems (ITS) applications, an accurate picture of the prevailing traffic state in terms of speeds and densities is critical, for which traffic state estimation methods are needed. The most popular and effective techniques used are so-called model-based traffic state estimators, which consist of a dynamic traffic flow model to predict the evolution of the state variables; a set of observation equations relating sensor observations to the system state; and data-assimilation techniques to combine the model predictions with the sensor observations. Commonly, both process and observation models are formulated in Eulerian (space–time) coordinates. However, recent studies show that (first-order) macroscopic traffic flow models can be formulated and solved more efficiently and accurately in Lagrangian (vehicle number–time) coordinates (which move with traffic stream) than in Eulerian coordinates (which are fixed in space). In this article such a Lagr...","2014","12","1","2025-12-02","https://university.edu/papers/79fa29f5-4bf4-46ed-b251-714ba57d14dd.pdf");
INSERT INTO Paper VALUES ("946","KNOMA: A New Approach for Knowledge Integration","In this paper we present a new meta-learning approach for Knowledge Integration. To generate accurate classifiers one can use combination techniques like Stacking, Bagging and Boosting. Such techniques are used for the generation of vote committees that produce decisions much more accurate than simple base classifiers. It is known that even using quite small partitions of the training database such techniques produce much more accurate decisions than a simple base classifier that uses all the training data. This is suitable for solving scalability problems. However, such techniques can not learn understandable knowledge, what is a drawback from the Knowledge Discover process point-of-view. To solve these problems, we introduce in this paper a Knowledge Integration technique capable of generate accurate and understandable rule sets taking as input base classifiers generated by a rule induction algorithm. Such rule sets are combined into a single rule set that, when evaluated over test instances, presents a better accuracy than any individual rule set and often outperforms Bagging and AdaBoosting.","2006","3","4","2025-12-02","https://university.edu/papers/641bfd02-4918-4836-9ee2-e3e0b4bca438.pdf");
INSERT INTO Paper VALUES ("947","Feedback for electromagnetic induction sensor arrays","A method using feedback is presented that reduces several measurement errors inherent in electromagnetic induction sensors. Errors associated with coupling between receive coils and errors associated with operating near magnetic soils will both be reduced. The method uses feedback that is directly injected into the receive coils and does not require secondary coils. A simple circuit is introduced to perform the feedback and is optimized to reduce the errors and make the circuit stable. Experimental results are presented to show the effectiveness of the feedback.","2016","4","1","2025-12-02","https://university.edu/papers/8c812c59-aade-4b99-97b8-853b955088a0.pdf");
INSERT INTO Paper VALUES ("948","Optimal Design of Lossless Passive Snubber for DC/DC Converters","This paper presents an optimal design of lossless passive snubber for DC/DC converters, which offers an efficient and best design method. The proposed method can not only reduce the spike voltage V dsp  of a power switch in the circuit, but also raise the conversion efficiency of the converter. In this paper, we have used Taguchi method to create the optimal design of LC lossless snubber. It can overcome the chaotic drawback of trial-and-error method, the bias of one-factor-at-a-time experiments, and the disadvantage of too many trials for full-factorial experiments. In Taguchi method, the voltage V  ds  of power switch and source side current I in  are the quality characteristics of the circuit, and the snubber inductor L  c , snubber capacitor C L , transformer leakage inductor L e , and switching frequency f are control factors which influence the circuit quality characteristics. According to the control factors and levels, this paper used an orthogonal array L 9  (3 4 ) to implement experiments, and made a factor response table and graph. Eventually, the optimal values of the control factors L c , C L , L e  and f were decided and then increased ratio of S/N to 16.8%. The simulation results demonstrated that the proposed method applying to optimal design of LC lossless snubber circuit was feasible and efficient","2006","8","2","2025-12-02","https://university.edu/papers/56668f85-83a6-417d-9e14-97425cbaf663.pdf");
INSERT INTO Paper VALUES ("949","Experimental and numerical determination of SAR distributions within culture flasks in a dielectric loaded radial transmission line","The effect of dielectric loading on the cell layer specific absorption rate (SAR) within a T-75 culture flask being irradiated within a transverse electromagnetic (TEM) cell was studied both experimentally and numerically. Direct thermal measurements of a T-75 containing 40 mL of culture medium and resting upon a 3-mm-thick slab of alumina ceramic (/spl epsiv//sub r/=9.6) revealed that, compared to the same flask resting upon a foam slab (/spl epsiv//sub r/1.0) of the same thickness, the average SAR at the cell layer was increased roughly fourfold. This fourfold increase is significant experimentally because it allows biologists to perform experiments over a larger range of SAR values needed to determine possible dose-response curves without the costs and difficulties of a fourfold increase in amplifier power. Finite-difference time-domain (FDTD) simulations of the SAR distribution were in good quantitative agreement with the experimental measurements. It is concluded that FDTD modeling can be a cost effective and scientifically acceptable means of obviating the thermal measurement of SAR.","2000","11","3","2025-12-02","https://university.edu/papers/56dbea8d-036c-4c8a-80be-6766ed9a8202.pdf");
INSERT INTO Paper VALUES ("950","Robust Signal Restoration in Chemical Reaction Networks","Molecular computing systems that are contained in well-mixed volumes are often modeled using chemical reaction networks. In these systems, concentrations of molecules are treated as signals and used for both communication and memory storage. A common design challenge for such a system is to avoid memory corruption caused by noise in the input signals. In this paper, we analyze two signal restoration algorithms for molecular systems modeled with chemical reaction networks. These algorithms are designed to prevent a memory signal from degrading over time, and we show that under modest conditions these algorithms will maintain the memory indefinitely. We also present an exact solution of the running time of the first algorithm which demonstrates that it converges in logarithmic time.","2016","14","1","2025-12-02","https://university.edu/papers/dc5cb9c8-6736-416c-adca-3a90fb2fd9b6.pdf");
INSERT INTO Paper VALUES ("951","A dynamic state estimation based sliding mode controller for wind energy generation system connected to multimachine grids","This paper proposes a sliding mode control scheme suitable for designing controllers in general nonlinear systems. To improve its performance, a chattering mitigation strategy is also proposed, which is proven to be capable of effectively alleviating the oscillations generated by the original sliding mode controller. For the validation of the functionality of the proposed control scheme in a nonlinear system, a sensorless doubly fed induction generator wind energy generation system connected to a multimachine system is used in the case study. Dynamic state estimation is required for sensorless doubly fed induction generator wind turbine as the internal state, rotor speed, which is used to construct the control scheme is not directly available. In order to do that, a unscented Kalman filter algorithm based dynamic state estimator is designed. The success of using proposed dynamic state estimation-based sliding mode control strategy to regulate the dynamical behavior of a wind energy system broadens the ken of the field of control methodology as well as the field of power systems.","2016","14","3","2025-12-02","https://university.edu/papers/770e6ade-f0b7-49d0-aff5-9c505230a37e.pdf");
INSERT INTO Paper VALUES ("952","Preliminary results of temporal normalization of MODIS land surface temperature","MODIS land surface temperature (LST) products have been widely used in numerous applications. Each pixel within the MODIS LST products is acquired at different local solar time even though they are in the same granule. A temporal consistency and spatial comprehensiveness data set will benefit us in the utilization of the LST products in related applications and researches. In this study, a diurnal temperature cycle (DTC) model was employed to normalize the MODIS LSTs to the same local solar time. The MODIS LSTs were derived from the Terra/MODIS and Aqua/MODIS LST products (MOD11_L2 and MYD11_L2, respectively). The results at daytime only are presented because the larger LSTs heterogeneity makes the comparison of LSTs before and after the temporal normalization much clearer. The preliminary results indicate that the spatial variations of the MODIS LSTs caused by different local solar time are removed after the temporal normalization. The temporal normalized LSTs may become more suitable for the analysis of land surface processes.","2011","5","1","2025-12-02","https://university.edu/papers/7c524499-3808-4464-806f-b267ebb39fb2.pdf");
INSERT INTO Paper VALUES ("953","GNSS Autonomous Localization: NLOS Satellite Detection Based on 3-D Maps","One of the main drawbacks of global navigation satellite systems (GNSSs) in urban environments is that signals may arrive at the receiver antenna only in nonline-of-sight (NLOS) conditions, leading to biased pseudorange estimates when they are taken for granted by the receiver and, eventually, wrong positioning. This article presents a study on the benefits of using three-dimensional (3-D) maps of cities to decide whether the GNSS signal coming from each tracked satellite is reliable. Based on this principle, two different 3-D maps and two methodologies are presented and compared. The results show the benefits of this approach.","2014","11","3","2025-12-02","https://university.edu/papers/f1d61387-d6c2-4a09-98bc-b1dcb55bc6dd.pdf");
INSERT INTO Paper VALUES ("954","Kernel reconstruction methods for Doppler broadening — Temperature interpolation by linear combination of reference cross sections at optimally chosen temperatures","This article establishes a new family of methods to perform temperature interpolation of nuclear interactions cross sections, reaction rates, or cross sections times the energy. One of these quantities at temperature T   is approximated as a linear combination of quantities at reference temperatures (Tj)(Tj). The problem is formalized in a cross section independent fashion by considering the kernels of the different operators that convert cross section related quantities from a temperature T0T0 to a higher temperature T — namely the Doppler broadening operation. Doppler broadening interpolation of nuclear cross sections is thus here performed by reconstructing the kernel of the operation at a given temperature T   by means of linear combination of kernels at reference temperatures (Tj)(Tj). The choice of the L2L2 metric yields optimal linear interpolation coefficients in the form of the solutions of a linear algebraic system inversion. The optimization of the choice of reference temperatures (Tj)(Tj) is then undertaken so as to best reconstruct, in the L∞L∞ sense, the kernels over a given temperature range [Tmin,Tmax][Tmin,Tmax]. The performance of these kernel reconstruction methods is then assessed in light of previous temperature interpolation methods by testing them upon isotope 238U. Temperature-optimized free Doppler kernel reconstruction significantly outperforms all previous interpolation-based methods, achieving 0.1%0.1% relative error on temperature interpolation of 238U total cross section over the temperature range [300 K,3000 K][300 K,3000 K] with only 9 reference temperatures.","2017","11","4","2025-12-02","https://university.edu/papers/226002c0-213d-4d5e-8584-381836ea1370.pdf");
INSERT INTO Paper VALUES ("955","The design of an active structural vibration reduction system using a modified particle swarm optimization","This paper presents the synthesis of an active control system using a modified particle swarm optimization method. The system's controller design is analyzed as a minimalization of the building stories' acceleration. The proposed fitness function is computationally efficient and incorporates the constraints on the system's stability and the maximum output of actuators. In order to handle the constraints the PSO was modified to take into account the particles' distance to the best and the worst solutions. The performance of the obtained controller was tested using historical earthquake records. The performed numerical simulations proved that the designed controller is capable of efficient vibrations reduction.","2010","12","4","2025-12-02","https://university.edu/papers/282f271d-3041-43cd-9c08-14487be6b72e.pdf");
INSERT INTO Paper VALUES ("956","Large-scale ligand-based predictive modelling using support vector machines","The increasing size of datasets in drug discovery makes it challenging to build robust and accurate predictive models within a reasonable amount of time. In order to investigate the effect of dataset sizes on predictive performance and modelling time, ligand-based regression models were trained on open datasets of varying sizes of up to 1.2 million chemical structures. For modelling, two implementations of support vector machines (SVM) were used. Chemical structures were described by the signatures molecular descriptor. Results showed that for the larger datasets, the LIBLINEAR SVM implementation performed on par with the well-established libsvm with a radial basis function kernel, but with dramatically less time for model building even on modest computer resources. Using a non-linear kernel proved to be infeasible for large data sizes, even with substantial computational resources on a computer cluster. To deploy the resulting models, we extended the Bioclipse decision support framework to support models from LIBLINEAR and made our models of logD and solubility available from within Bioclipse.","2016","10","1","2025-12-02","https://university.edu/papers/4f3ee30b-3dd7-4fa8-978d-b6a0d83471bd.pdf");
INSERT INTO Paper VALUES ("957","Secure group communication in wireless mesh networks","Wireless mesh networks (WMNs) have emerged as a promising technology that offers low-cost community wireless services. Security is critical for the deployment of these services. Previous work focused primarily on MAC and routing protocol security, while application-level security has received relatively little attention. In this paper we focus on providing data confidentiality for group communications in WMNs. We propose a new protocol framework, secure group overlay multicast (SeGrOM), that employs decentralized group membership, promotes localized communication, and exploits the wireless broadcast nature to achieve efficient and secure group communication. We analyze the performance and discuss the security properties of our protocols. We demonstrate through simulations that our protocols provide good performance and incur a significantly smaller overhead than a baseline centralized protocol optimized for WMNs.","2008","6","3","2025-12-02","https://university.edu/papers/6906a49d-1a4a-49dd-9a1d-2b7c3a2a415e.pdf");
INSERT INTO Paper VALUES ("958","Stochastic database cracking: towards robust adaptive indexing in main-memory column-stores","Modern business applications and scientific databases call for inherently dynamic data storage environments. Such environments are characterized by two challenging features: (a) they have little idle system time to devote on physical design; and (b) there is little, if any, a priori workload knowledge, while the query and data workload keeps changing dynamically. In such environments, traditional approaches to index building and maintenance cannot apply. Database cracking has been proposed as a solution that allows on-the-fly physical data reorganization, as a collateral effect of query processing. Cracking aims to continuously and automatically adapt indexes to the workload at hand, without human intervention. Indexes are built incrementally, adaptively, and on demand. Nevertheless, as we show, existing adaptive indexing methods fail to deliver workload-robustness; they perform much better with random workloads than with others. This frailty derives from the inelasticity with which these approaches interpret each query as a hint on how data should be stored. Current cracking schemes blindly reorganize the data within each query's range, even if that results into successive expensive operations with minimal indexing benefit.#R##N##R##N#In this paper, we introduce stochastic cracking, a significantly more resilient approach to adaptive indexing. Stochastic cracking also uses each query as a hint on how to reorganize data, but not blindly so; it gains resilience and avoids performance bottlenecks by deliberately applying certain arbitrary choices in its decision-making. Thereby, we bring adaptive indexing forward to a mature formulation that confers the workload-robustness previous approaches lacked. Our extensive experimental study verifies that stochastic cracking maintains the desired properties of original database cracking while at the same time it performs well with diverse realistic workloads.","2012","2","3","2025-12-02","https://university.edu/papers/c840cd35-e20f-4271-b58d-8a08266c376a.pdf");
INSERT INTO Paper VALUES ("959","Frequency Response Analysis of Latch Utilized in High-Speed Comparator","We investigated the dynamic nature of a highspeed CMOS comparator, and present a comparator frequency-response model based on small-signal linear analysis of a latch. The analytical frequency model offers good insight into the linearity of the quantizer utilized in CTDeltaSigma modulators. In addition, a novel design guideline for a high-speed CMOS comparator to ensure the quantizer linearity is presented.","2006","5","1","2025-12-02","https://university.edu/papers/e148c544-b585-44e2-b64e-124b7e2ad2c1.pdf");
INSERT INTO Paper VALUES ("960","Evaluating the Use of Reference Run Models in Fault Injection Analysis","Fault injection (FI) has been shown to be an effective approach to assessing the dependability of software systems. To determine the impact of faults injected during FI, a given oracle is needed. Oracles can take a variety of forms, including (i) specifications, (ii) error detection mechanisms and (iii) golden runs. Focusing on golden runs, in this paper we show that there are classes of software which a golden run based approach can not be used to analyse. Specifically, we demonstrate that a golden run based approach can not be used in the analysis of systems which employ a main control loop with an irregular period. Further, we show how a simple model, which has been refined using FI experiments, can be employed as an oracle in the analysis of such a system.","2009","4","2","2025-12-02","https://university.edu/papers/8419e530-75a2-4bff-847f-d69e9377155e.pdf");
INSERT INTO Paper VALUES ("961","Articulatory speech synthesis using diphone units","Two different parametric models of the vocal tract have been developed. These have been used to obtain area functions for use in an articulatory synthesiser based on the Kelly-Lochbaum (1962) model. Random sampling of the geometric space spanned by the model has been performed to obtain a codebook for use in spectral copy synthesis. A dynamic programming search of this codebook produces intelligible synthetic speech, but the overall quality is limited by the density of codebook entries in articulatory space. To increase the coverage without significantly increasing the codebook size, a method of generating several small codebooks, each of which covers a small amount of acoustic space has been developed. By using codebooks which map the regions of acoustic space defined by voiced diphones, it has been possible to significantly improve the quality of the synthetic speech.","1997","11","3","2025-12-02","https://university.edu/papers/89d11b79-91c9-4d60-b3af-fbe301b656f4.pdf");
INSERT INTO Paper VALUES ("962","Active mesh reconstruction of block-based motion information","This paper proposes an asymmetric scheme for motion estimation/compensation. While the estimation is performed with a classical block matching algorithm, the motion information is decoded by using an active mesh in order to implement the compensation stage. A mesh is positioned by taking into account the relevant spatial information of the image to be compensated and is used afterwards to reconstruct the motion information. Two main issues have to be addressed for conducting such a motion compensation technique: (i) how to optimally design an active mesh, (ii) how to reverse and interpolate a backward motion field estimated on an a priori grid of fixed-size blocks so as to determine a forward motion field on variable size triangular patches. While proposing a solution to these two problems, particular attention is paid to the computational burden. Such a scheme opens the possibility for added manipulation functionalities because of mesh capabilities.","1998","7","4","2025-12-02","https://university.edu/papers/aabcb2f7-ff2b-4c91-8f86-ebfc736ae4b7.pdf");
INSERT INTO Paper VALUES ("963","A characteristic of target cognition using marine radar","The radio detection and ranging (RADAR) is one of the useful instruments which a navigator uses for attempting safe navigation at poor weather conditions. In case of poor weather and there are lots of similar targets, they sometime make an error for its direction when they find the target in the landscape from RADAR information - target's direction, distance, echo size, echo shape, sweep and relationship among targets' echo. We have to prevent the errors for attempting safe navigation. The purpose of this paper is to find characteristics of the target cognition using marine RADAR with three steps: 1) to propose the navigator's model of the RADAR target cognition, 2) to evaluate the errors of the target cognition on the RADAR monitor and its judgment in the landscape, 3) to discuss the errors with the parallax.","2004","19","1","2025-12-02","https://university.edu/papers/6b51c3ba-fe39-417e-a79a-e25085cc5dc0.pdf");
INSERT INTO Paper VALUES ("964","Generalized Hadamard Product and the Derivatives of Spectral Functions","Real valued functions, $F(X)$, on a symmetric matrix argument are called spectral if $F(U^TXU) = F(X)$ for every orthogonal matrix $U$ and $X \in \mathrm{dom\,} F$. We are interested in a description of the higher order derivatives (when they exist) of $F$ with respect to $X$. Formulae for the gradient and the Hessian of $F$ are given in [A. S. Lewis, Math. Oper. Res., 21 (1996), pp. 576-588] and [A. S. Lewis and H. S. Sendov, SIAM Matrix Anal. Appl., 23 (2001), pp. 368-386]. In this work we present common features of these two formulae that are preserved in the higher order derivatives.","2006","5","4","2025-12-02","https://university.edu/papers/869f8729-6c20-42b6-9047-2c523c552994.pdf");
INSERT INTO Paper VALUES ("965","3.6-GHz 0.2-mW/ch/GHz 65-nm cross-correlator for synthetic aperture radiometry","A high-speed low-power cross-correlator ASIC has been implemented in a 65-nm CMOS process for the purpose of synthetic aperture radiometry from geostationary orbiting earth observation satellites. The chip performs cross-correlation on all individual signal pairs from 64 digital 1-bit inputs, which amounts to 2016 individual cross-correlation products. The experimental evaluation, using a specially developed PCB, demonstrates that the 3-mm 2  chip has a top performance of 3.6 GHz at a 1.2 V supply, at which it dissipates 790 mW.","2011","3","1","2025-12-02","https://university.edu/papers/b2c78063-c9dc-46e5-88d0-65ceccc8040b.pdf");
INSERT INTO Paper VALUES ("966","Pitfalls in a server-aided authenticated group key establishment","In this paper, we present a cryptanalysis of a recently proposed server-aided group key agreement scheme by Sun et al. This proposal is designed for mobile environments, in which a group of users aim at establishing a common secret key with the help of a semi-trusted server. At this, authentication is achieved using certificateless public key cryptography. We evidence that the scheme does not achieve forward secrecy, is vulnerable to a known session attack (that can, for instance, be mounted by a semi-honest server) and is not (as claimed by the authors) contributory. Further security hardships in more restricted models (i.e. in which stronger corruptions are allowed) are also discussed.","2016","8","4","2025-12-02","https://university.edu/papers/3427ef5a-2d1b-455a-93cf-7f73e2bab4a5.pdf");
INSERT INTO Paper VALUES ("967","ZUbers against ZLyfts apocalypse: an analysis framework for DoS attacks on mobility-as-a-service systems","The vulnerability of Mobility-as-a-Service (MaaS) systems to Denial-of-Service (DoS) attacks is studied. We use a queuing-theoretical framework to model the re-dispatch process used by operators to maintain a high service availability, as well as potential cyber-attacks on this process. It encompasses a customer arrival rate model at different sections of an urban area to pick up vehicles traveling within the network. Expanding this re-balance model, we analyze DoS cyber-attacks of MaaS systems by controlling a fraction of the cars maliciously through fake reservations (so called  Zombies ) placed in the system (similar to the computer science field where a  Zombie  is a computer that a remote attacker has accessed for malicious purpose). The attacker can then use the block-coordinate descent algorithm proposed in the present work to derive optimal strategies to minimize the efficiency of the MaaS system, thereby allowing us to quantify the economic loss of such systems under attack. The technique is shown to work well and enables us to arbitrarily deplete taxi availabilities based on the attacker's choice and the  radius  of attacks, which is demonstrated by drawing a 'Cal' logo in Manhattan. Finally, a cost-benefit analysis using data from 75 million taxi trips shows diminishing returns for the attacker and that countermeasures raising the attack cost to more than $15 could protect MaaS systems in NYC from  Zombies .","2016","18","1","2025-12-02","https://university.edu/papers/fb6ef5df-3df7-4e8a-9df1-cf89a6005174.pdf");
INSERT INTO Paper VALUES ("968","New e-Learning system architecture based on knowledge engineering technology","The paper focuses on the field of research on next generational e-Learning facility, in which knowledge-enhanced systems are the most important candidates. In the paper, a reference architecture based on the technologies of knowledge engineering is proposed, which has following three intrinsic characteristics, first, education ontologies are used to facilitate the integration of static learning resource and dynamic learning resource, second, based on semantic-enriched relationships between Learning Objects (LOs), it provides more advanced features for sharing, reusing and repurposing of LOs, third, with the concept of knowledge object, which is extended from LO, an implementing mechanism for knowledge extraction and knowledge evolution in e-Learning facilities is provided. With this reference architecture, a prototype system called FekLoma (Flexible Extensive Knowledge Learning Object Management Architecture) has been realized, and testing on it is carrying out.","2009","17","1","2025-12-02","https://university.edu/papers/65e02910-ada2-4575-bae5-b0ce196341db.pdf");
INSERT INTO Paper VALUES ("969","Active ageing with avatars: a virtual exercise class for older adults","In this paper we describe the development and testing of a virtual exercise class for older people delivered in real-time using active gaming technology (Microsoft's Kinect for Xbox 360). Four seniors (women, aged 64--74) participated. Each person received a gaming console and face-to-face instruction. At a set time each week for 6 weeks, participants logged on to take part in a 30-minute exercise class led by an instructor. On-screen, each person was represented by an avatar (Avatar Kinect software). Participants were able to see the avatars on their television screen and hear each other via headsets. Overall, we found the virtual exercise class format to be feasible and acceptable to older people. Despite some limitations with the hardware and software, participants enjoyed the experience of learning to use new technology. The use of avatars added novelty and made the program fun. The potential for a virtual exercise class, using gaming technology and avatars, to increase physical activity and enhance social connection amongst older Australians warrants further investigation.","2016","20","4","2025-12-02","https://university.edu/papers/11f04674-57d0-434b-b7eb-ba87f4ffd0fd.pdf");
INSERT INTO Paper VALUES ("970","Globally Convergent Dual MAP LP Relaxation Solvers using Fenchel-Young Margins","While finding the exact solution for the MAP inference problem is intractable for many real-world tasks, MAP LP relaxations have been shown to be very effective in practice. However, the most efficient methods that perform block coordinate descent can get stuck in sub-optimal points as they are not globally convergent. In this work we propose to augment these algorithms with an e-descent approach and present a method to efficiently optimize for a descent direction in the sub-differential using a margin-based formulation of the Fenchel-Young duality theorem. Furthermore, the presented approach provides a methodology to construct a primal optimal solution from its dual optimal counterpart. We demonstrate the efficiency of the presented approach on spin glass models and protein interaction problems and show that our approach outperforms state-of-the-art solvers.","2012","17","4","2025-12-02","https://university.edu/papers/bfa849b0-8d28-407f-8c44-e97c356ac81a.pdf");
INSERT INTO Paper VALUES ("971","Component-based modeling of complete buildings","We present a system to procedurally generate complex models with interdependent elements. Our system relies on the concept of components to spatially and semantically define various elements. Through a series of successive statements executed on a subset of components selected with queries, we grow a tree of components ultimately defining a model.#R##N##R##N#We apply our concept and representation of components to the generation of complete buildings, with coherent interior and exterior. It proves general and well adapted to support subdivision of volumes, insertion of openings, embedding of staircases, decoration of facades and walls, layout of furniture, and various other operations required when constructing a complete building.","2011","11","3","2025-12-02","https://university.edu/papers/5ee262b9-2c08-4b7f-8df6-845ea4be6cdf.pdf");
INSERT INTO Paper VALUES ("972","Method of Outer Approximations and Adaptive Approximations for a Class of Matrix Games","We present a novel technique for obtaining global solutions to discrete min-max problems that arise naturally in the receding horizon control of unmanned craft in which the controls can be adjusted only in notches, e.g., stop, half forward, full forward, left or right $$60^{\circ }$$60?, and in the finite precision global solution of certain classes of semi-infinite min-max problems. The technique consists of a method for transcribing min-max problems over discrete sets into a matrix game and matrix game-specific adaptations of the Method of Outer Approximations and the Method of Adaptive Approximations, which are normally used for solving optimal control and semi-infinite min-max problems. The efficiency of the Method of Outer Approximations depends on having a good initial approximation to a solution. To this end, we make use of adaptive approximation techniques to decompose a large matrix game into a sequence of lower dimensional games, the solution of each giving rise to a very good initial approximation to a solution for the next game. We show that a basic approach for solving a min-max matrix game, in which one maximizes over the elements of columns and minimizes over the elements of the rows of a matrix, requires a number of function evaluations which is equal to the product of the number of rows and the number of columns of the matrix, while with our new approach our experimental results require only a number of function evaluations which is the product of the number rows and a number ranging from 2 to 20, shortening computing times from years to fractions of a minute.","2016","7","3","2025-12-02","https://university.edu/papers/3bb7ef16-0c8b-4312-be45-4bafacb9d3bb.pdf");
INSERT INTO Paper VALUES ("973","A fast, on-line collision avoidance method for a kinematically redundant manipulator based on reflex control","A computationally efficient method to achieve reflexive collision avoidance is described. The system consists of four parallel, asynchronous control layers: a conventional servo tracking controller, a reactive trapezoidal velocity profiler, a joint-by-joint reflexive collision avoidance layer, and a guiding potential-function layer. The lowest two layers guarantee that the robot will not overshoot any joint-space position setpoint. The higher two layers compute successive set points based on a continuous, online inspection of configuration space. The guiding potential-function layer incorporates task-space-based attraction to a hand goal, while the reflexes permit use of kinematic redundancy for obstacle avoidance. In many cases, no explicit path planning is required to achieve competent, collision-free motion to a task-space goal while moving in a cluttered environment. Experimental results are described for the physical implementation of the system on the first four joints of a kinematically redundant robot. >","1992","8","3","2025-12-02","https://university.edu/papers/f0c77ecd-fdcf-4e70-991f-1690349a3f61.pdf");
INSERT INTO Paper VALUES ("974","Fast compaction in hypercubes","Compaction relocates active subcubes in a fragmented hypercube so as to produce a contiguous free region and eliminate the adverse impact of fragmentation on performance. The overhead of compaction is often contributed primarily by task migration, which makes use of disjoint paths for transmitting migrated data. Since task migration usually involves transmitting a large amount of data, the time required for migration with single paths is long, making compaction an undesirably lengthy process. This paper considers fast compaction through the use of all disjoint paths in existence for migration simultaneously from a source subcube to its target subcube, effectively reducing the size of data transmitted over a path and shortening the migration time. This approach leads to considerable savings in the compaction time for hypercubes which support circuit switching or wormhole routing, when compared with that using single migration paths.","1998","8","3","2025-12-02","https://university.edu/papers/8fd53e2f-73a4-40da-9f6d-ff3e1c360442.pdf");
INSERT INTO Paper VALUES ("975","Analysis of SINR Outage in Large-Scale Cellular Networks Using Campbell's Theorem and Cumulant Generating Functions","The signal-to-noise-plus-interference ratio (SINR) outage probability is one of the key performance parameters of a wireless cellular network, and its analytical as well as numerical evaluation has occupied many researchers. Recently, the introduction of stochastic geometric modeling of cellular networks has brought the outage problem to the forefront again. A popular and powerful approach is to exploit the available moment generating function (or Laplace transform) of received signal and interference, whenever it exists, by applying the Gil-Pelaez inversion formula. However, with the stochastic geometric modeling, the moment generating function may either be too complicated to exist in closed-form or at worst may not exist. Toward this end, in this paper, we study two alternate ways of evaluating the SINR outage. In the first case, we emphasize the significance of calculating cumulants over moments and exploit the fact that the cumulants of point processes are easily calculable using Campbell's theorem. The SINR outage is then analytically characterized by Charlier expansion based on Gaussian and Student's $t$-distributions and their associated Hermite and Krishnamoorthy polynomials. In the second case, we exploit the saddle point method, which gives a semi-analytical method of calculating the SINR outage, whenever the cumulant generating function of received signal and interference exists. For the purpose of demonstration, we apply these techniques on a downlink cellular network model where a typical user experiences a coordinated multi-point transmission, and the base stations are modeled by homogeneous Poisson point process. For the convenience of readers, we also provide a brief overview of moments, cumulants, their generating functions, and Campbell's theorem, without invoking measure theory. Numerical results illustrate the accuracy of the proposed mathematical approaches.","2016","8","4","2025-12-02","https://university.edu/papers/85c514ed-f549-4ffc-85e2-a3009cdf318b.pdf");
INSERT INTO Paper VALUES ("976","Validation of a new method for bone motion measurement by soft-tissue artifact compensation through spatial interpolation","Localizing a bone hidden behind soft tissue is crucial in biomechanics. A typical approach consists in placing markers on the skin, measuring their position/orientation, and from these measurements, estimating the position and orientation of the bone hidden behind the skin while compensating of soft tissue deformations. In this paper, we present a new method to address this problem. It requires to initially record scattered spacial transformations between the rigid body and the markers. Then, a natural neighbors interpolation algorithm, modified to apply to homogeneous transformations, is proposed. The presented method is validated on a robot manipulator on which soft tissue is placed.","2015","11","1","2025-12-02","https://university.edu/papers/81c9aeae-d930-4cc9-a186-0243231b9833.pdf");
INSERT INTO Paper VALUES ("977","Anytime properties of protograph-based repeat-accumulate codes","In this paper, a highly efficient protograph-based repeat-accumulate (P-RA) anytime code is proposed, which is derived from the combination of protograph-based low-density parity-check convolutional (P-LDPCC) and spatially coupled low-density parity-check convolutional (SC-LDPCC) codes. Density evolution technique is applied to demonstrate the anytime properties of the P-RA codes over the binary erasure channel (BEC). The simulation results show that P-RA codes perform better than SC-LDPCC and P-LDPCC codes. More importantly, the finite-length performance of P-RA codes is only dependent on the decoding delay rather than the decoding message position.","2015","8","4","2025-12-02","https://university.edu/papers/884bdf37-51d1-4c1a-ba45-51c579372baf.pdf");
INSERT INTO Paper VALUES ("978","On arithmetic operations of G-number","Heterogeneity in decision making evaluation is inevitable due to different background, preference and experience of decision makers. One aspect of the heterogeneity can be the type of numerical scale used in the evaluation such as crisp, interval, fuzzy and the most recent is the z-number. The calculation will be simpler if these different scales can be represented in a single form. A general form of uncertain number known as granular number or simply denoted as G-number have been introduced to cater the problem. At present, two basic operations, which are the addition and multiplication have been given and implemented in AHP method and Djikstra's algorithm. Nevertheless, in order to be further useful in some other decision making models, it is essential to introduce the other two arithmetic operations, which are the subtraction and division. In this paper, the negation and the reciprocal of G-number is determined in order to obtain the subtraction and division operations. Some numerical examples and the general formula are given at the end of the paper.","2015","14","3","2025-12-02","https://university.edu/papers/609c4c9b-4d61-46e8-8829-07ad8b42702c.pdf");
INSERT INTO Paper VALUES ("979","Drops and Kinks: Modeling the Retention of Flow for Hour of Code Style Tutorials","It can be difficult to evaluate Hour of Code activities for outcome measures such as motivation. Participation levels, for example, might be more indicative of marketing effectiveness and give little insight into longitudinal user engagement. By imagining these activities as a series of steps, we can develop a survival function model based on simple Markov chains. The student-retention this model predicts can be compared to empirical retention data gathered from traditional step-by-step and puzzle based programming tutorials. Retention of Flow is an affective evaluation [1] instrument that compares empirical student retention data to this model to better understand student motivation throughout the activity and beyond. This paper discusses two specific aspects of this Retention of Flow analysis. Drops, or sharp declines in retention, indicate a loss of motivation resulting from cognitive, practical and technical challenges. Kinks in retention indicate more gradual shifts in activity motivation. This paper uses data from a puzzle and a tutorial-based Hour of Code activity to show how understanding the Retention of Flow as a mathematical model can help with the evaluation and the design of programming tutorials.","2016","3","3","2025-12-02","https://university.edu/papers/e106d8a0-0c84-43d5-b085-db5921659715.pdf");
INSERT INTO Paper VALUES ("980","'You're Mr. Lebowski, I'm the Dude': Inducing Address Term Formality in Signed Social Networks","We present an unsupervised model for inducing signed social networks from the content exchanged across network edges. Inference in this model solves three problems simultaneously: (1) identifying the sign of each edge; (2) characterizing the distribution over content for each edge type; (3) estimating weights for triadic features that map to theoretical models such as structural balance. We apply this model to the problem of inducing the social function of address terms, such as Madame, comrade, and dude. On a dataset of movie scripts, our system obtains a coherent clustering of address terms, while at the same time making intuitively plausible judgments of the formality of social relations in each film. As an additional contribution, we provide a bootstrapping technique for identifying and tagging address terms in dialogue. 1","2015","18","1","2025-12-02","https://university.edu/papers/2fed8617-1266-4a2b-ab58-e6c28c8e41f1.pdf");
INSERT INTO Paper VALUES ("981","Spatio-Temporal data mining on MCS over Tibetan Plateau using satellite meteorological datasets","This paper presents an automatic meteorological data mining approach based on analyzing and mining heterogeneous remote sensed image datasets. The cloud structures are firstly identified and tracked in satellite remote sensed images, after which heterogeneous cloud features and properties are extracted and integrated to form a unified dataset. The C4.5 decision tree algorithm and dependency network analysis are then employed to discover useful knowledge for weather forecasting, by which a group of derivation rules and a conceptual model for metrological environment factors are generated. Experimental results have shown that the system reduces the heavy workload of manual weather forecasting and provides meaningful interpretations to the forecasted results.","2009","12","4","2025-12-02","https://university.edu/papers/6b88f43a-4470-46ad-b0a0-3c1a0b0f4ecf.pdf");
INSERT INTO Paper VALUES ("982","A Set of Practices for Distributed Pair Programming","Geographically distributed teams have adopted agile practices as a work strategy. One of these practices is Distributed Pair Programming (DPP) that consists in two developers working remotely on the same design, algorithm, or code. In this paper, we describe a set of practices for DPP. In our research we seek to understand how distributed teams can use and adopt DPP in a more effective way. Based on a systematic literature review and a field study, we suggest twelve practices that can help both professionals and software organizations in the practice of DPP.","2014","20","2","2025-12-02","https://university.edu/papers/cc36bfec-b131-4efe-bbcf-3648137fbf6d.pdf");
INSERT INTO Paper VALUES ("983","Biomimetic binaural sound source localisation with ego-noise cancellation","This paper presents a spiking neural network (SNN) for binaural sound source localisation (SSL). The cues used for SSL were the interaural time (ITD) and level (ILD) differences. ITDs and ILDs were extracted with models of the medial superior olive (MSO) and the lateral superior olive (LSO). The MSO and LSO outputs were integrated in a model of the inferior colliculus (IC). The connection weights between the MSO and LSO neurons to the IC neurons were estimated using Bayesian inference. This inference process allowed the algorithm to perform robustly on a robot with ~40,dB of ego-noise. The results showed that the algorithm is capable of differentiating sounds with an accuracy of 15°.","2012","15","4","2025-12-02","https://university.edu/papers/77831d95-3b2e-413f-8d54-faa9c4139cbf.pdf");
INSERT INTO Paper VALUES ("984","Classification of EEG signals recorded during right/left hand movement imagery using Fast Walsh Hadamard Transform based features","Brain computer interface (BCI) allows people to communicate with machines without the use of muscle systems. Although there are various kind of techniques to understand intend of the BCI user, electroencephalography (EEG) is the most popular, practical and widely implemented one. The performance of the EEG based BCI highly depends on extracting effective features. However, there is no a general feature extraction method which provides satisfied performance for all various kind of BCI applications. Therefore, it is very valuable to develop a new feature extraction method. In this paper, we proposed a novel Fast Walsh Hadamard Transform based feature extraction method for classification of EEG signals recorded during right/left hand movement imagery. It does not only provide well-discriminative attributes but also the computational time of extracting the features from a single EEG trial is fast. The proposed method was successfully applied to Data Set III of BCI competition 2003, and achieved a classification accuracy of 88.87% on the test data. The obtained satisfactory results proved that this method can be a successful alternative to the existing feature extraction methods.","2016","8","2","2025-12-02","https://university.edu/papers/96407960-3e55-4728-8dc9-25b5bf8a6c39.pdf");
INSERT INTO Paper VALUES ("985","Optimal k-Leader Selection for Coherence and Convergence Rate in One-Dimensional Networks","We study the problem of optimal leader selection in consensus networks under two performance measures (1) formation coherence when subject to additive perturbations, as quantified by the steady-state variance of the deviation from the desired trajectory, and (2) convergence rate to a consensus value. The objective is to identify the set of $k$ leaders that optimizes the chosen performance measure. In both cases, an optimal leader set can be found by an exhaustive search over all possible leader sets; however, this approach is not scalable to large networks. In recent years, several works have proposed approximation algorithms to the $k$-leader selection problem, yet the question of whether there exists an efficient, non-combinatorial method to identify the optimal leader set remains open. This work takes a first step towards answering this question. We show that, in one-dimensional weighted graphs, namely path graphs and ring graphs, the $k$-leader selection problem can be solved in polynomial time (in both $k$ and the network size $n$). We give an $O(n^3)$ solution for optimal $k$-leader selection in path graphs and an $O(kn^3)$ solution for optimal $k$-leader selection in ring graphs.","2016","18","2","2025-12-02","https://university.edu/papers/54bd7839-64ca-4801-83d7-e2a088a064e4.pdf");
INSERT INTO Paper VALUES ("986","Competing institutional logics in ICT4D education projects: A South American study","We take an institutional logics perspective to explain why design-reality gaps persist in ICT4D projects. From case study interviews at development agencies at work on two national education projects, one in Argentina and one in Uruguay, we show how two main institutional logics strongly shaped thought and action among development staff. The presence of an education sector professionalism logic aimed at creating real changes in education was not surprising because both projects were directed towards the education domain. Yet, this logic in many ways was secondary to a technology sector professionalism logic that focused on superior performance in product development, solving problems with technology, and evaluating technology uptake. We show how these two logics competed over time and within projects. We conclude by noting that an institutional logics perspective helps explain the persistence of design-reality gaps by making clear, for example, why solutions such as participatory design may fall short because they fail to come to terms with competing logics.","2016","14","2","2025-12-02","https://university.edu/papers/ab6b1d1f-1365-4c0c-9dd7-c34ac251c416.pdf");
INSERT INTO Paper VALUES ("987","Information extraction for Thai documents","An increasing amount of electronically available information is stored in Asian language documents, which makes Information Retrieval (IR) and Information Extraction (IE) for these languages important for a large number of users. Analysis and extraction of information in these languages presents several interesting problems not seen in Western European languages; these are interesting in their own right and for the insights they can give into more general IR and IE techniques. We describe these problems and our system for Thai language IE One of the main concerns when working with Thai natural language is that the structure of the language itself is highly ambiguous. The analyser therefore requires more sophisticated techniques and large amounts of domain knowledge to cope with these ambiguities. We describe our approach to a natural language analysis system that performs preprocessing for the Thai language and the extraction module to retrieve specific information according to the predefined concept definitions.","2000","20","3","2025-12-02","https://university.edu/papers/bec693e5-f5e4-4607-a0bd-597ddc29f8f9.pdf");
INSERT INTO Paper VALUES ("988","Stability analysis of a generalised 2D digital Roesser type systems via lagrange method","In this paper we investigate the asymptotic stability of a generalised 2-dimensional (2D) digital Roesser type filter, which is expressed by delayed partial difference equations. The work is carried out on the grounds of a doubly congruence transformation and the Lagrange method approach, which is applied on the transformed system to provide the stability conditions. It is worth pointing out that the reports on application of the Lagrange method on even non-delayed discrete systems is not vast as the z-transform and energy method. Finally, we note here that this paper is concerned with the stability analysis of delayed systems, which is still an emerging research field.","2008","10","3","2025-12-02","https://university.edu/papers/ed782d33-f2f7-4908-bcc0-dbd92d37a809.pdf");
INSERT INTO Paper VALUES ("989","The simulation of temperature field in the laser forming of steel plates","Laser forming of metal plates is a flexible forming process that forms sheet by means of thermal stresses induced by external heat source instead of using external forces. The stresses are generated by temperature gradient induced by laser. In this paper, a finite element analysis model including convective and radiation boundary conditions to predict the three-dimensional temperature field is established for a metal plate under the influence of a moving Gaussian heat source. The effects of various laser forming parameters on temperature distributions are investigated using the established model. By using variable scanning velocities a constant temperature gradient in the plate plane is achieved, which can be used to accurately form differently desired shapes of the plate.","2007","11","1","2025-12-02","https://university.edu/papers/96f80590-9145-4ed4-895a-021b04c7ccb6.pdf");
INSERT INTO Paper VALUES ("990","Optimal Bounds for the Similarity Density of the Thue-Morse Word with Overlap-Free and 73-Power-Free Infinite Binary Words","We consider a measure of similarity for infinite words that generalizes the usual number-theoretic notion of asymptotic or natural density for subsets of natural numbers. We show that every 73-power-free infinite binary word, other than the Thue-Morse word t and its complement t¯, has this measure of similarity with t between 13 and 23, and that this bound is optimal in a strong sense just for the class of overlap-free words. This is a generalization of a classical 1927 result of Kurt Mahler.","2015","3","4","2025-12-02","https://university.edu/papers/503e9f47-aa42-46c8-a147-9b973d420d13.pdf");
INSERT INTO Paper VALUES ("991","A spectral representation for appearance-based classification and recognition","We present a spectral representation for appearance based image classification and object recognition. Based on a generative process, the representation is derived by partitioning the frequency domain into small disjoint regions. This gives rise to a set of filters and a representation consisting of marginal distributions of those filter responses. We use a neural network, to learn a classifier through training examples. We propose a filter selection algorithm by maximizing the performance over training data. A distinct advantage of our representation is that it can be effectively used for different classification and recognition tasks, which is demonstrated by experiments and comparisons in texture classification, face recognition, and appearance-based 3D object recognition.","2002","14","2","2025-12-02","https://university.edu/papers/fc3e91c0-b99c-4ab7-8c0d-0ff6e7559b3a.pdf");
INSERT INTO Paper VALUES ("992","A Human Judgement Corpus and a Metric for Arabic MT Evaluation","We present a human judgments dataset and an adapted metric for evaluation of Arabic machine translation. Our mediumscale dataset is the first of its kind for Arabic with high annotation quality. We use the dataset to adapt the BLEU score for Arabic. Our score (AL-BLEU) provides partial credits for stem and morphological matchings of hypothesis and reference words. We evaluate BLEU, METEOR and AL-BLEU on our human judgments corpus and show that AL-BLEU has the highest correlation with human judgments. We are releasing the dataset and software to the research community.","2014","19","4","2025-12-02","https://university.edu/papers/a0fa39fc-66d5-42a1-8ba0-7f4f70270781.pdf");
INSERT INTO Paper VALUES ("993","Lifted message passing as reparametrization of graphical models","Lifted inference approaches can considerably speed up probabilistic inference in Markov random fields (MRFs) with symmetries. Given evidence, they essentially form a lifted, i.e., reduced factor graph by grouping together indistinguishable variables and factors. Typically, however, lifted factor graphs are not amenable to off-the-shelf message passing (MP) approaches, and hence requires one to use either generic optimization tools, which would be slow for these problems, or design modified MP algorithms. Here, we demonstrate that the reliance on modified MP can be eliminated for the class of MP algorithms arising from MAP-LP relaxations of pairwise MRFs. Specifically, we show that a given MRF induces a whole family of MRFs of different sizes sharing essentially the same MAP-LP solution. In turn, we give an efficient algorithm to compute from them the smallest one that can be solved using off-the-shelf MP. This incurs no major overhead: the selected MRF is at most twice as large as the fully lifted factor graph. This has several implications for lifted inference. For instance, running MPLP results in the first convergent lifted MP approach for MAP-LP relaxations. Doing so can be faster than solving the MAP-LP using lifted linear programming. Most importantly, it suggests a novel view on lifted inference: it can be viewed as standard inference in a reparametrized model.","2014","7","2","2025-12-02","https://university.edu/papers/1baaae0e-f9b1-470e-a661-6d282fe1dacc.pdf");
INSERT INTO Paper VALUES ("994","Finexus: Tracking Precise Motions of Multiple Fingertips Using Magnetic Sensing","With the resurgence of head-mounted displays for virtual reality, users need new input devices that can accurately track their hands and fingers in motion. We introduce Finexus, a multipoint tracking system using magnetic field sensing. By instrumenting the fingertips with electromagnets, the system can track fine fingertip movements in real time using only four magnetic sensors. To keep the system robust to noise, we operate each electromagnet at a different frequency and leverage bandpass filters to distinguish signals attributed to individual sensing points. We develop a novel algorithm to efficiently calculate the 3D positions of multiple electromagnets from corresponding field strengths. In our evaluation, we report an average accuracy of 1.33 mm, as compared to results from an optical tracker. Our real-time implementation shows Finexus is applicable to a wide variety of human input tasks, such as writing in the air.","2016","15","1","2025-12-02","https://university.edu/papers/cb8a4746-9cfd-4344-a0fd-fca897e5e5e6.pdf");
INSERT INTO Paper VALUES ("995","A physical layer simulator for WiMAX in Rayleigh fading channel","WiMAX is a wireless technology which offers high data rate transmission in broadband. In this paper, the architecture of the WiMAX physical layer simulator is presented. The main blocks are implemented with the aid of the Matlab programming language and the bit error rate (BER) curves are presented in Rayleigh fading channel.","2011","6","1","2025-12-02","https://university.edu/papers/513d139c-bfc9-45ee-ad77-294c122d912f.pdf");
INSERT INTO Paper VALUES ("996","Fuzzy Entropy-assisted Fuzzy-Rough Feature Selection","Feature selection (FS) is a dimensionality reduction technique that aims to select a subset of the original features of a dataset which offer the most useful information. The benefits of feature selection include improved data visualisation, transparency, reduction in training and utilisation times and improved prediction performance. Methods based on fuzzy-rough set theory (FRFS) have employed the dependency function to guide the process with much success. This paper presents a novel fuzzy-rough FS technique which is guided by fuzzy entropy. The use of this measure in fuzzy-rough feature selection can result in smaller subset sizes than those obtained through FRFS alone, with little loss or even an increase in overall classification accuracy.","2006","14","3","2025-12-02","https://university.edu/papers/69e99d8b-6e21-4b94-8b7a-2668b83bc883.pdf");
INSERT INTO Paper VALUES ("997","A comparative study of restoration schemes and spare capacity assignments in mesh networks","This paper presents the results of a comparative study of spare capacity assignment for original quasipath restoration (OQPR), improved quasipath restoration (IQPR), link restoration (LR), path restoration (PR) and link-disjoint path restoration (LDPR) schemes. Numerical results indicate that the restoration schemes studied can be sorted from most expensive to least expensive (spare capacity assignment cost) in the following order: LR, OQPR, IQPR, LDPR and PR. Since IQPR is computationally very efficient, simpler than PR, scalable, and economical in spare capacity assignment, it provides a good alternative to PR when quick restoration is desired. However, due to the potential difficulty in rapid failure isolation coupled with the increasing importance of restoration speed and simplicity, LDPR is an attractive scheme. A number of networks with different topologies and projected traffic demand patterns are used in the experiments to study the effect of various network parameters on spare capacity assignment cost. The experimental analysis shows that network topology, demand patterns and the average number of hops per primary route have a significant impact on the spare capacity assignment cost savings offered by one scheme over the other.","2003","18","4","2025-12-02","https://university.edu/papers/6a18948b-17a8-4fa1-a54f-fb96128151bf.pdf");
INSERT INTO Paper VALUES ("998","A batch algorithm for maintaining a topological order","The dynamic topological order problem is that of efficiently updating a topological order after some edge(s) are inserted into a graph. Much prior work exists on the unit-change version of this problem, where the order is updated after every single insertion. No previous (non-trivial) algorithms are known for the batch version of the problem, where the order is updated after every batch of insertions. We present the first such algorithm. This requires O(min{k · (v + e), ve}) time to process any sequence of k insertion batches. This is achieved by only recomputing those region(s) of the order affected by the inserted edges. In many cases, our algorithm will only traverse small portions of the graph when processing a batch. We empirically evaluate our algorithm against previous algorithms for this problem, and find that it performs well when the batch size is sufficiently large.","2010","4","2","2025-12-02","https://university.edu/papers/5245a2e9-948d-4c98-9528-b9c609faa3c7.pdf");
INSERT INTO Paper VALUES ("999","Affective Primacy in Intraorganizational Task Networks","To better understand the role of affect in organizational task-related networks, we developed a theory of affective primacy that identifies cognitive and motivational mechanisms through which the affective value of a social relationship a feeling of positive affect from interactions with a colleague operates as an antecedent of perceived instrumental value a subjective evaluation of a relationship's contribution to accomplishing assigned tasks. We tested this theory with full-network data collected over three years from employees in a small functional-form organization, which we analyzed with a methodology drawing from the social relations model of interpersonal perception and Bayesian models for social network analysis. We found that, over time, the affective value of social relationships influences both perceptions of instrumental value and the formation of task-related ties through multiple paths not accounted for by either perceived instrumental value or formal-structural requirements. We also show that the emergence of task-related networks rests primarily on high-activation positive emotions, such as excitement a subjective state of feeling energized rather than positive emotions with lower levels of activation, such as pleasantness a subjective state of feeling gratified. We discuss implications of these findings for organizational theory and managerial practice.","2015","2","4","2025-12-02","https://university.edu/papers/acfb9cb5-3409-41e6-943e-e989fdd68031.pdf");
INSERT INTO Paper VALUES ("1000","Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches","Simple classical spin models well-known to physicists as the ANNNI and Heisenberg XY Models, in which long-range interactions occur in a pattern given by the Mexican Hat operator, can generate many of the structural properties characteristic of the ocular dominance columns and iso-orientation patches seen in cat and primate visual cortex.","1991","1","2","2025-12-02","https://university.edu/papers/ff5ddba7-fbd4-4af3-8c9d-bf6f3eccc0c8.pdf");
INSERT INTO Paper VALUES ("1001","Resilient and efficient MANET aerial communications for search and rescue applications","The ability of first-responders to react to the aftermath of natural disasters depends heavily on receiving accurate, real-time data about the structures that may have been affected. Because transportation infrastructure may be unusable, aerial assessments are the gold standard by which such assessments are performed. The advent of mobile ad-hoc networks (MANETs) and autonomous aircraft represents a unique opportunity to allow for rapid response, while minimizing the cost of deployment and increasing reliability and operator safety. This paper describes the key challenges to implement fault-tolerant and efficient deployments of collaborative autonomous aircraft to increase operational reliability and performance when performing aerial sensing and assessment. Some challenges are introduced by mobility, such as wireless communication, group navigation, and data collection. Security also represents a challenge during the operation of the MANET. We consider the effects of limited resources (e.g., real-time processing power, battery packs) available on the aircraft. By understanding both the application context and the resource availability, networked aircraft can reorganize to ensure resiliency for the mission if a resource failure occurs within the network.","2013","3","2","2025-12-02","https://university.edu/papers/6040b623-cfff-4141-ae5a-e67b5b96c240.pdf");
INSERT INTO Paper VALUES ("1002","Semi-blind channel estimation for the uplink of multi-carrier code-division multiple access systems with timing offset","Timing offsets (TO) introduce misaligned interferences and phase errors, which degrade the performance of channel estimation. The authors propose a new semi-blind channel estimator that can cancel the TO effects on channel estimation and work well in the uplink of multi-carrier code-division multiple access systems in the presence of TO. The proposed channel estimator exploits the spreading sequence information instead of pilots to accomplish semi-blind estimation. Since the estimated channel coefficients are affected by the users' transmitted data, the effect of the users' data needs to be reduced. For this purpose, the authors also propose two smoothing algorithms, division smoothing and optimisation smoothing. In addition, to extend the new estimator to the system where the number of active users is too large, channel estimation over multiple symbols is discussed. The simulation results show that the proposed semi-blind estimator works better than a conventional estimator in the presence of TO, and its performance is very close to the conventional estimator in the absence of TO. Besides, the proposed estimator is compared with a sub-space estimator in simulation, and the results indicate that the new proposed estimator can achieve the same mean square error performance over the duration of a single symbol as the sub-space estimator over the duration of several symbols.","2009","17","4","2025-12-02","https://university.edu/papers/a4898285-6c0c-4390-8f98-cd3c19e09123.pdf");
INSERT INTO Paper VALUES ("1003","Conversational virtual character for the Web","Talking virtual characters are graphical simulations of real or imaginary persons capable of human-like behaviour, most importantly talking and gesturing. Coupled with artificial intelligence (AI) techniques, the virtual characters are expected to represent the ultimate abstraction of a human-computer interface, the one where the computer looks, talks and acts like a human. Such an interface would include audio/video analysis and synthesis techniques combined with AI, dialogue management and a vast knowledge base in order to be able to respond quasi-intelligently to the users by: speech, gesture and even mood. While this goal lies further on in the future, we present an architecture that reaches towards it, at the same time aiming for a possibility of practical applications in the nearer future. Our architecture is aimed specifically at the Web. It involves a talking virtual character capable of involving in a fairly meaningful conversation with the user who types in the input.","2002","14","3","2025-12-02","https://university.edu/papers/a91640a2-d2e2-4cb4-b4ed-631ee48b280e.pdf");
INSERT INTO Paper VALUES ("1004","Understanding information sharing in software development through Wiki log analysis","The use of wikis in software development seems to be growing rapidly. Recently, software development teams have begun to employ wikis to do such things as: collaborate across locations; brainstorm and track projects; organize knowledge; and facilitate information sharing. This poster reports preliminary findings from the analysis of the logs of two wikis, which supported two different software development projects. This work shows that, with the wiki log analysis, it is possible to identify patterns of information sharing.","2009","5","4","2025-12-02","https://university.edu/papers/d060a3a0-7fc4-4825-889e-0c7861a1f332.pdf");
INSERT INTO Paper VALUES ("1005","Predicting appropriate semantic web terms from words","The Semantic Web language RDF was designed to unambiguously define and use ontologies to encode data and knowledge on the Web. Many people find it difficult, however, to write complex RDF statements and queries because doing so requires familiarity with the appropriate ontologies and the terms they define. We describe a system that suggests appropriate RDF terms given semantically related English words and general domain and context information. We use the Swoogle Semantic Web search engine to provide RDF term and namespace statistics, the WorldNet lexical ontology to find semantically related words, and a naive Bayes classifier to suggest terms. A customized graph data structure of related namespaces is constructed from Swoogle's database to speed up the classifier model learning and prediction time.","2008","18","2","2025-12-02","https://university.edu/papers/ec692f70-ac1c-4789-974b-fb1007dc6b81.pdf");
INSERT INTO Paper VALUES ("1006","Autonomous real-time surveillance system with distributed IP cameras","An autonomous Internet Protocol (IP) camera based object tracking and behaviour identification system, capable of running in real-time on an embedded system with limited memory and processing power is presented in this paper. The main contribution of this work is the integration of processor intensive image processing algorithms on an embedded platform capable of running at real-time for monitoring the behaviour of pedestrians. The Algorithm Based Object Recognition and Tracking (ABORAT) system architecture presented here was developed on an Intel PXA270-based development board clocked at 520 MHz. The platform was connected to a commercial stationary IP-based camera in a remote monitoring station for intelligent image processing. The system is capable of detecting moving objects and their shadows in a complex environment with varying lighting intensity and moving foliage. Objects moving close to each other are also detected to extract their trajectories which are then fed into an unsupervised neural network for autonomous classification. The novel intelligent video system presented is also capable of performing simple analytic functions such as tracking and generating alerts when objects enter/leave regions or cross tripwires superimposed on live video by the operator.","2009","10","1","2025-12-02","https://university.edu/papers/754ac6a4-8c55-478b-ace3-06b1c0243e28.pdf");
INSERT INTO Paper VALUES ("1007","Integrating uncertainty into ontology mapping","This paper gives an outline of my PhD thesis which describes the integration of managing uncertainty into ontology mapping. Ontology mapping is one of the most important tasks for ontology interoperability and its main aim is to find semantic relationships between entities (i.e. concept, attribute, and relation) of two ontologies, However, in the process of mapping, uncertainty and incompleteness of semantics in the syntactic representation and description of relations between entities in ontologies will lead to imprecise results. If we want to obtain better results, it becomes more significant for the ontology mapping to be able to deal with uncertainty.","2007","11","3","2025-12-02","https://university.edu/papers/d0ade545-883b-47ab-ac72-5dd598b66eb7.pdf");
INSERT INTO Paper VALUES ("1008","Research Note---Should Captive Sardines Be Compensated? Serving Customers in a Confined Zone","Many services are delivered to a (large) number of customers simultaneously within a confined zone (e.g., restaurants, resorts, trains, and airplanes). Under unexpected high demand, customers experience discomfort from two major sources: (a) the sardine effect that arises when too many customers (i.e., sardines) compete for space and service resources, and (b) the captivity effect that results from an exit cost incurred by customers who self-select to “escape” the unpleasant service. This paper investigates the optimal compensation and pricing policies under these two effects. We find that offering compensation to sardines can improve profit and social welfare. However, consumers do not benefit when compensated for the discomfort from crowding. This paper also provides insights by exploring the impact of changes in the two effects on price and profit.","2009","19","1","2025-12-02","https://university.edu/papers/fe92d557-f3d5-4fe7-9ad3-427b414eb8e7.pdf");
INSERT INTO Paper VALUES ("1009","Resolution conversion integrated with quantization in coded domain for DV to MPEG-4 transcoder","We propose a new algorithm for the fast conversion of MPEG-4 from DV. DV, which is a video compression coding format, is adopted by commercial and non-commercial digital video cameras and achieves high video quality using a fixed high bitrate of 25 Mbps. However, compared with MPEG-4, which is used extensively in IP or mobile phone applications, DV has a higher storage and transmission cost. This is due to the extremely low coding efficiency of DV required to maintain high quality for frame-accurate editing. In this paper, we analyze the difference between DV and MPEG-4, and propose a new algorithm for the fast conversion of MPEG-4 from DV. Our algorithm accelerates the conversion process in the coded domain using the property of conversion matrices, where resolution conversion, quantization, and inverse quantization are integrated. The experimental results indicate that, while the integration and approximation of a conversion matrix do not affect the video quality, this could greatly reduce the number of operands.","2005","2","1","2025-12-02","https://university.edu/papers/d2ec061b-7fad-4962-a6dd-eb91db1457f8.pdf");
INSERT INTO Paper VALUES ("1010","Visualization properties for data quality visual assessment: An exploratory case study","Data quality assessment outcomes are essential to ensure useful analytical processes results. Relevant computational approaches provide assessment support, especially to data defects that present more precise rules. However, data defects that are more dependent of data context knowledge challenge the data quality assessment since the process involves human supervision. Visualization systems belong to a class of supervised tools that can make visible data defect structures. Despite their considerable design knowledge encodings, there is little support design to visual quality assessment of data defects. Therefore, this work reports a case study that has explored which and how visualization properties facilitate visual detection of data defect. Its outcomes offer a first set of implications to design visualization system to permit data quality visual assessment.","2017","12","4","2025-12-02","https://university.edu/papers/6b95e5e5-3aa5-408a-bd51-0e22e5a55941.pdf");
INSERT INTO Paper VALUES ("1011","A data-hiding technique using scene-change detection for video steganography ☆","This paper presents a data-hiding technique using scene-change detection for video steganography. Reducing the distortions in videos and securing the embedded data remain as competing goals in any video steganographic system. In this study, a data-hiding technique using discrete cosine transform (DCT) and discrete wavelet transform (DWT) coefficients is proposed to enhance the security of hidden data and minimize distortions to maintain better video quality. In this work, scene changes are detected using the DCT coefficients of video sequences for hiding data. Then, the cover-video and the payload are fused and normalized using the DWT coefficients to enhance video quality. The MATLAB simulation results indicate that the proposed method outperforms existing state-of-the-art methods. The comparison results reveal that the proposed data-hiding method offers better security and minimizes distortions for better video quality.","2016","14","4","2025-12-02","https://university.edu/papers/de2e9c13-0944-4277-bee4-1c993155019a.pdf");
INSERT INTO Paper VALUES ("1012","FPAC: fast, fixed-cost authentication for access to reserved resources","Enhanced network services often involve allocating resources (bandwidth/buffer space) preferentially to packets belonging to certain flows or traffic classes. Such services are vulnerable to denial-of-service attacks if packet classification is based on information that can be forged, such as source and destination addresses and port numbers. Traditional message authentication codes (MACs), often considered the only solution to this problem, are really not designed to solve it. In particular, their per-packet costs are so high that they enable another form of denial-of-service attack based on overwhelming the verification mechanism. We describe the problem of denial of access to reserved resources and the inadequacies of conventional solutions. We then observe that it is reasonable to trade some of the strong security guarantees provided by conventional MACs for a lower per-packet cost. We propose a new packet authentication algorithm, designed to solve the problem of protecting reserved resources, with a very low, fixed per-packet cost. While it cannot replace conventional MACs for end-to-end authentication, we argue that it is a better solution for the problem considered here. We present measurements from a prototype implementation that can verify a packet of arbitrary size in as few as 1000 machine cycles on an Intel architecture machine.","2002","14","3","2025-12-02","https://university.edu/papers/fd5173d3-1f09-4910-abe5-07dbfd6a0dea.pdf");
INSERT INTO Paper VALUES ("1013","A methodology for estimating execution times of IO traces in SSDs: student research abstract","Solid-state drives (SSDs) have been spotlighted as a new storage device that replaces hard-disk drives (HDDs). Because SSD is operated only by electronic chips while HDD is operated by magnetic moving parts, they have two strong points as follows [1]: Compared to HDD, SSD provides higher bandwidth, lower latency, and longer life time.","2016","16","2","2025-12-02","https://university.edu/papers/9f8ad5f6-941c-40fd-a7ed-276f8097b38e.pdf");
INSERT INTO Paper VALUES ("1014","Bats, birds, and boggans: the simulated armies of epic","In  Epic  (2013), crowds are integral to the narrative and form a character as a whole. This required a new type of crowd at Blue Sky Studios, one that permits dynamic interaction between crowd characters and the environments around them in addition to supporting the high-resolution geometry with fur, deformation rigs, and material complexities needed for shots where the crowd is close to camera. Our crowd framework centers around the choice to separate the simulation process from the technique used to render the crowd. This meant we could use different simulators for different shots. At times, the crowd exceeded 100,000 characters, far more than in any of our previous films. To manage all this data we store only per character joint animation instead of deformed geometry. This compact format allows us to both display art direct-able representations of the crowd in real-time and to defer evaluation of the expensive parts of the rig until render time. To render the crowd with our in-house ray-tracing renderer,  CGIStudio™ , we build a custom, optimized deformation system that supports rendering of both deformed geometry and deformed voxels.","2013","6","1","2025-12-02","https://university.edu/papers/e12891c5-0b38-4fa6-a6a6-275117c7582f.pdf");
INSERT INTO Paper VALUES ("1015","Performance analysis of keyword advertising campaign using gender-brand effect of search queries","In this research, we analyze the relationship among (1) the performance metrics of a sponsored search campaign, (2) the gender orientation of queries, and (3) the occurrence of branded terms in queries. The aim of this research is to investigate the effectiveness of increased personalization of search engine advertising in order to improve the consumer’s online experience. We segregate keyphrases from a dataset covering thirty-three consecutive months from a major US retailer consisting of 7 million daily records of a real time keyword advertising campaign into three gender categories (male, female and neutral) each with two groups (branded and unbranded) term usage. Using ANOVA, we analyze the effect of gender and brand keyphrases on critical sponsored search performance metrics of impressions, clicks, cost-per-clicks, sales revenue, orders, items purchased and return on advertising. Research findings show that the combination of brand focus with the gender-orientation of keyphrases is a significant factor in predicting sponsored search performance and behavior. There are statistically significant variations in consumer behavior as measured by sponsored search metrics among the gender categories. Specifically, females are more attracted to the use of branded terms than males, perhaps due to the trust and customer loyalty generated by brand image. Our results establishes that positive brand reputation creates dramatic influence on consumer’s loyalty over the brand and hence strongly affects their interests, activities and purchasing behavior in e-commerce environment.","2014","5","1","2025-12-02","https://university.edu/papers/d04ad3c4-210b-4011-bff8-f32808b0372e.pdf");
INSERT INTO Paper VALUES ("1016","A mobile ray tracing engine with hybrid number representations","This paper presents optimization techniques devised to a hardware ray tracing engine which has been developed for mobile platforms. Whereas conventional designs deal with either fixed-point or floating-point numbers, the proposed techniques are based on hybrid number representations with fixed-point and floating-point ones. Carefully mixing the two heterogeneous number representations in computation and value encoding could improve efficiency of the ray tracing engine in terms of both energy and silicon area. Compared to a floating-point-based design, 35% and 16% area reduction was achieved in ray-box and ray-triangle intersection units, respectively. In addition, such hybrid representation could encode a bounding box in 40% smaller space at a reasonably low cost.","2015","19","3","2025-12-02","https://university.edu/papers/7b92dd2b-0f88-4a0f-b7b1-d19577116e16.pdf");
INSERT INTO Paper VALUES ("1017","Fuzzy logic based system for classification of atrial fibrillation cardiac arrhythmias","Intelligent diagnosis systems represent nowadays important technical means in the medical field and particularly in cardiology. In such a field where uncertainty is always present, classical techniques of classification show a lack of efficiency thus leading to erroneous results. Fuzzy logic proved to be a suitable method for classification problems, particularly in cardiology. This paper aims to present a fuzzy-logic-based system for the classification of three types of atrial fibrillation arrhythmias. The obtained results have shown good performance of the designed classifier.","2006","15","4","2025-12-02","https://university.edu/papers/c4a24f8f-de6b-427f-9c94-c6b9a8770d86.pdf");
INSERT INTO Paper VALUES ("1018","Segmentation of heterogeneous blob objects through voting and level set formulation","Blob-like structures occur often in nature, where they aid in cueing and the pre-attentive process. These structures often overlap, form perceptual boundaries, and are heterogeneous in shape, size, and intensity. In this paper, voting, Voronoi tessellation, and level set methods are combined to delineate blob-like structures. Voting and subsequent Voronoi tessellation provide the initial condition and the boundary constraints for each blob, while curve evolution through level set formulation provides refined segmentation of each blob within the Voronoi region. The paper concludes with the application of the proposed method to a dataset produced from cell based fluorescence assays and stellar data.","2007","11","4","2025-12-02","https://university.edu/papers/e63823c6-1799-43ae-8132-e76359fd270d.pdf");
INSERT INTO Paper VALUES ("1019","Some randomized code constructions from group actions","We study in this paper randomized constructions of binary linear codes that are invariant under the action of some group on the bits of the codewords. We study a non-Abelian randomized construction corresponding to the action of the dihedral group on a single copy of itself as well as a randomized Abelian construction based on the action of an Abelian group on a number of disjoint copies of itself. Cyclic codes have been extensively studied over the last 40 years. However, it is still an open question as to whether there exist asymptotically good binary cyclic codes. We argue that by using a slightly more complex group than a cyclic group, namely, the dihedral group, the existence of asymptotically good codes that are invariant under the action of the group on itself can be guaranteed. In particular, we show that, for infinitely many block lengths, a random ideal in the binary group algebra of the dihedral group is an asymptotically good rate-half code with a high probability. We argue also that a random code that is invariant under the action of an Abelian group G of odd order on k disjoint copies of itself satisfies the binary Gilbert-Varshamov (GV) bound with a high probability for rate 1/k under a condition on the family of groups. The underlying condition is in terms of the growth of the smallest dimension of a nontrivial F/sub 2/-representation of the group and is satisfied by roughly most Abelian groups of odd order, and specifically by almost all cyclic groups of prime order.","2006","6","3","2025-12-02","https://university.edu/papers/fd41ff03-5d71-41d7-bba0-db68b01465b0.pdf");
INSERT INTO Paper VALUES ("1020","Estimating dissolved organic carbon concentration in turbid coastal waters using optical remote sensing observations","Dissolved Organic Carbon (DOC) is an important component in the global carbon cycle. It also plays an important role in influencing the coastal ocean biogeochemical (BGC) cycles and light environment. Studies focussing on DOC dynamics in coastal waters are data constrained due to the high costs associated with in situ water sampling campaigns. Satellite optical remote sensing has the potential to provide continuous, cost-effective DOC estimates. In this study we used a bio-optics dataset collected in turbid coastal waters of Moreton Bay (MB), Australia, during 2011 to develop a remote sensing algorithm to estimate DOC. This dataset includes data from flood and non-flood conditions. In MB, DOC concentration varied over a wide range (20–520 μM C) and had a good correlation (R2 = 0.78) with absorption due to coloured dissolved organic matter (CDOM) and remote sensing reflectance. Using this data set we developed an empirical algorithm to derive DOC concentrations from the ratio of Rrs(412)/Rrs(488) and tested it with independent datasets. In this study, we demonstrate the ability to estimate DOC using remotely sensed optical observations in turbid coastal waters.","2016","4","2","2025-12-02","https://university.edu/papers/3a70de2d-512e-42d1-be37-9c30a74ec958.pdf");
INSERT INTO Paper VALUES ("1021","Generating Realistic Facial Expressions with Wrinkles for Model-Based Coding","Due to the limitations of current computer graphics technology mimicing realistic facial textures, such as wrinkles, is very difficult. Facial texture updating and compression are crucial to achieving realistic facial animation for low bit rate model-based coding. In this paper, we present a partial texture updating method for realistic facial expression synthesis with facial wrinkles. First, fiducial points on a face are estimated using a color-based deformable template matching method. Second, an extended dynamic mesh matching algorithm is developed for face tracking. Next, textures of interest (TOI) in the potential expressive wrinkles and mouth?eye texture areas are captured by the detected fiducial points. Among the TOI, the so-called active textures or expressive textures are extracted by exploring temporal correlation information. Finally, the entire facial texture is synthesized using the active texture. Compared to the entire texture updating scheme, partially updating and compressing facial textures significantly reduce the computational complexity and bit rates while still producing an acceptable visual quality. Experiments on the video sequences demonstrate the advantage of the proposed algorithm.","2001","10","4","2025-12-02","https://university.edu/papers/93d39cb3-c5b5-44a5-8587-11789ecdac90.pdf");
INSERT INTO Paper VALUES ("1022","A novel method for scattered radiation compensation in X-ray imaging systems, using partially transparent shields (PTS)","A new method for scattered radiation compensation in 2D projection radiographic imaging is presented. By comparing the detected signal under a small partially transparent shield (e.g. aluminum disk or strip), positioned between the X-ray source and the object being imaged, with the detected signal near the border of the shadow of the shield, the radiation scatter signal in the location of the shield is calculated. For polychromatic X-radiation, calibration with two known basis materials allows accurate calculation of the radiation scatter. Shields are positioned at several locations between object and source. By an interpolation technique, the radiation scatter in every region of interest can be calculated. The radiation scatter image is then subtracted from the original image of the object. The method needs only one exposure of the object. The primary radiation signals at the locations of the shields have undergone an extra drop, but the information about the object under the shields is not lost. One could restore the image by compensating for the effect of the shields on the primary signal. The theory of PTS is presented and results of experiments are given. >","1994","11","1","2025-12-02","https://university.edu/papers/6921d13a-ef78-400a-a632-649be54532f0.pdf");
INSERT INTO Paper VALUES ("1023","The case of the bold button: Social shaping of technology and the digital scholarly edition","The role and usage of a certain technology is not imparted wholesale on the intended user community—technology is not deterministic. Rather, a negotiation between users and the designers of the technology will result in its particular form and function. This article considers a side effect of these negotiations. When a certain known technology is used to convey a new technological concept or model, there is a risk that the paradigm associated by the users with the known technology will eclipse the new model and its affordances in part or in whole. The article presents a case study of this ‘paradigmatic regression’ centering on a transcription tool of the Huygens Institute in the Netherlands. It is argued that similar effects also come into play at a larger scale within the field of textual scholarship, inhibiting the exploration of the affordances of new models that do not adhere to the pervasive digital metaphor of the codex. An example of such an innovative model, the knowledge graph model, is briefly introduced to illustrate the point.","2016","19","4","2025-12-02","https://university.edu/papers/0818b654-d2fd-4774-ba00-b259453b7906.pdf");
INSERT INTO Paper VALUES ("1024","Scratchpad memories vs locked caches in hard real-time systems: a quantitative comparison","We propose in this paper an algorithm for off-line selection of the contents of on-chip memories. The algorithm supports two types of on-chip memories, namely locked caches and scratchpad memories. The contents of on-chip memory, although selected off-line, is changed at run-time, for the sake of scalability with respect to task size. Experimental results show that the algorithm yields to good ratios of on-chip memory accesses on the worst-case execution path, with a tolerable reload overhead, for both types of on-chip memories. Furthermore, we highlight the circumstances under which one type of on-chip memory is more appropriate than the other depending of architectural parameters (cache block size) and application characteristics (basic block size).","2007","10","3","2025-12-02","https://university.edu/papers/b6eb8e2b-044c-4ea1-8644-7a45fcd721e6.pdf");
INSERT INTO Paper VALUES ("1025","Experiential cognitive therapy in the treatment of panic disorders with agoraphobia: a controlled study.","The use of a multicomponent cognitive-behavioral treatment strategy for panic disorder with agoraphobia is actually one of the preferred therapeutic approaches for this disturbance. This method involves a mixture of cognitive and behavioral techniques that are intended to help patients identify and modify their dysfunctional anxiety-related thoughts, beliefs and behavior. The paper presents a new treatment protocol for Panic Disorder and Agoraphobia, named Experiential-Cognitive Therapy (ECT) that integrates the use of virtual reality (VR) in a multicomponent cognitive-behavioral treatment strategy. The VR software used for the trial is freely downloadable: www.cyberpsychology.info/try.htm. Moreover, the paper presents the result of a controlled study involving 12 consecutive patients aged 35–53. The selected subjects were randomly divided in three groups: ECT group, that experienced the Cognitive Behavioral Therapy–Virtual Reality assisted treatment (eight sessions), a CBT group that experienced the trad...","2003","13","3","2025-12-02","https://university.edu/papers/8c019935-4a95-4685-9c08-694986fa558c.pdf");
INSERT INTO Paper VALUES ("1026","Design and experiment of a universal space-saving end-effector for multi-task operations","Purpose – The purpose of this paper is to present the design and experiment of a universal space-saving end-effector for multi-task operations. Design/methodology/approach – The universal end-effector is equipped with capture and actuation transmission capabilities with two corresponding subsystems, which are highly integrated systems of mechanics, electronics and sensors. A trefoil-shaped capture system is developed for closed envelop. The worm gear pair is adopted for self-locking and space-saving, and it is used in a unique manner for three grapple chains’ synchronous motion. The combination of optimal straight path linkage and pantograph mechanism is proposed in the transmission system. The electrical structure and the multi-sensory system provide the foundation for control strategy. Findings – Simulations and experiments demonstrated characteristics of the universal end-effector. The compliance of the manipulator guaranteed the achievement of “soft capture” by the end-effector. Due to the self-lockin...","2016","6","2","2025-12-02","https://university.edu/papers/9485fcc3-cf8f-4d6a-993d-7a1a5406cfaa.pdf");
INSERT INTO Paper VALUES ("1027","Cyclic resultants","We characterize polynomials having the same set of nonzero cyclic resultants. Generically, for a polynomial f of degree d, there are exactly 2^d^-^1 distinct degree d polynomials with the same set of cyclic resultants as f. However, in the generic monic case, degree d polynomials are uniquely determined by their cyclic resultants. Moreover, two reciprocal (''palindromic'') polynomials giving rise to the same set of nonzero cyclic resultants are equal. In the process, we also prove a unique factorization result in semigroup algebras involving products of binomials. Finally, we discuss how our results yield algorithms for explicit reconstruction of polynomials from their cyclic resultants.","2005","2","2","2025-12-02","https://university.edu/papers/4ac69df3-8ca3-455f-b0d3-9bd9ab6b30c1.pdf");
INSERT INTO Paper VALUES ("1028","Visualizing Project Evolution through Abstract Syntax Tree Analysis","What is a developer's contribution to a repository? By only counting commits and number of lines changed, existing tools that visualize source code repositories (such as GitHub's graphs) fall short on showing the effective contributions made by each developer. When many commits are viewed as a group, the details are lost. Commit information can be misleading since lines of code give no indication of what was actually being worked on without careful examination of the changed code. Providing a semantic view of this information could provide deeper insights into how software projects evolve since changes to design and features are not clearly visible from line changes alone. We present TypeV: a method for visualizing Java source code repositories. Instead of counting line changes in a commit we extract detailed type information over time by using the differences between abstract syntax trees (ASTs). We are then able to track the additions and deletions of declarations and invocations for each type. Furthermore, we can track each author's type usage over time. Using TypeV, we examine specific cases in well-known repositories where our tool reveals interesting and useful information. We then compare type coverage information from the AST compared to file coverage to determine if unique information is provided by type information.","2016","14","3","2025-12-02","https://university.edu/papers/d55f54e8-91ab-4999-b075-64ea0f766df3.pdf");
INSERT INTO Paper VALUES ("1029","Distributed file system support for virtual machines in grid computing","This paper presents a data management solution which allows fast virtual machine (VM) instantiation and efficient run-time execution to support VMs as execution environments in grid computing. It is based on novel distributed file system virtualization techniques and is unique in that: 1) it provides on-demand access to VM state for unmodified VM monitors; 2) it supports user-level and write-back disk caches, per-application caching policies and middleware-driven consistency models; and 3) it supports the use of meta-data associated with files to expedite data transfers. The paper reports on its performance in a WAN setup using VMware-based VMs. Results show that the solution delivers performance over 30% better than native NFS and can bring application-perceived overheads below 10% relatively to a local disk setup. The solution also allows a VM with 1.6GB virtual disk and 320MB virtual memory to be cloned within 160 seconds when it is first instantiated (and within 25 seconds for subsequent clones).","2004","19","3","2025-12-02","https://university.edu/papers/6c4a197b-42bc-42f8-bb47-7fff6a905dab.pdf");
INSERT INTO Paper VALUES ("1030","A method for testability analysis and BIST insertion at the RTL","The goal of this research is to provide a means for BIST and circular BIST analysis and evaluation at the register transfer level (RTL). RTL circuits consist of interconnections of registers, functional units (ALUs), multiplexers and buses. The analysis is done via two metrics that measure the effectiveness with which an individual register in the circuit generates test patterns, the entropy-based randomness and expected state coverage. The testability metrics are computed by means of a Markov chain model that takes as input the RTL circuit description, and provides analytical values for the probability distribution of the state of each register in the circuit. The Markov model works by partitioning the circuit into small pieces, each containing the information necessary to analyze a single register. It then models each register separately as the register moves from state to state. A wide variety of BIST methodologies, including conventional, MISR-based, and circular BIST, can be modeled with this technique. >","1995","4","3","2025-12-02","https://university.edu/papers/6c3f9da0-e506-40d2-b759-94aed06b72a8.pdf");
INSERT INTO Paper VALUES ("1031","Fast and memory efficient polygonal simplification","Conventional wisdom says that in order to produce high-quality simplified polygonal models, one must retain and use information about the original model during the simplification process. We demonstrate that excellent simplified models can be produced without the need to compare against information from the original geometry while performing local changes to the model. We use edge collapses to perform simplification, as do a number of other methods. We select the position of the new vertex so that the original volume of the model is maintained and we minimize the per-triangle change in volume of the tetrahedra swept out by those triangles that are moved. We also maintain surface area near boundaries and minimize the per-triangle area changes. Calculating the edge collapse priorities and the positions of the new vertices requires only the face connectivity and the the vertex locations in the intermediate model. This approach is memory efficient, allowing the simplification of very large polygonal models, and it is also fast. Moreover, simplified models created using this technique compare favorably to a number of other published simplification methods in terms of mean geometric error.","1998","10","2","2025-12-02","https://university.edu/papers/a1d82a8b-9827-4e56-8afe-8fb891ae813c.pdf");
INSERT INTO Paper VALUES ("1032","A Combination of Evolutionary Algorithm and Game Theory for Optimal Location and Operation of DG from DG Owner Standpoints","The use of distributed generation (DG) resources is seen as a key important factor in improving technical and economic aspects of distribution systems. However, little research exists concerning the optimal location and operation of DGs. This paper proposes a novel method to find simultaneously the optimal location and operation of DGs. The method is developed in two phases, namely Phase 1 and 2. Phase 1 deals with the optimal location of DGs using a multiobjective optimization problem in which active power loss reduction, voltage profile improvement, and voltage regulation are the objectives. A Pareto frontier differential evolution (PDE) algorithm is developed to solve the multiobjective problem. Phase 2 copes with the optimal income of the DGs’ owners along with the optimal total payment of the distribution company by adopting a bi-level optimization method with two agents. Game theory is employed to assist in finding optimal contract prices. The performance of the proposed method is evaluated by using two IEEE, 33-bus, and 69-bus, standard distribution networks. This paper concludes that the proposed method can serve as an accurate tool for practitioners in finding the optimal location and operation strategy of DGs.","2016","4","3","2025-12-02","https://university.edu/papers/05bfac85-c491-4d1e-a946-74a9afe77d42.pdf");
INSERT INTO Paper VALUES ("1033","Creating meaningful multimedia with the multimedia design and planning pyramid","Most multimedia creation models and tools are disjoint entities. It remains the multimedia author's responsibility to integrate the functionality of these models and tools. MUDPY facilitates the creation of meaningful multimedia (stand-alone or online) by exposing the semantic connections between the various design components. The paper describes the multimedia design and planning pyramid (MUDPY), a meta-design framework for multimedia project planning and design.","2004","9","4","2025-12-02","https://university.edu/papers/afc6bc1f-6cd0-4822-8757-38ca85680e59.pdf");
INSERT INTO Paper VALUES ("1034","Local Optima Avoidable Particle Swarm Optimization","This paper proposes a Local Optima Avoidable Particle Swarm Optimization (LOAPSO) which remarkably outperforms the standard PSO in the sense that it can avoid entrapment in local optimum. Three benchmark functions are used to validate the proposed algorithm and compare its performance with that of the other algorithms known as hybrid PSOs and six functions reported in SIS2005 are used to better verification of the proposed algorithm. Numerical results indicate that LOAPSO is considerably competitive due to its ability to avoid being trapped in local optima and to find the functions' global optimum as well as better convergence performance.","2009","15","2","2025-12-02","https://university.edu/papers/e5b32514-96f6-471c-9c96-6e83705d5885.pdf");
INSERT INTO Paper VALUES ("1035","High Dynamic Range versus Standard Dynamic Range compression efficiency","High Dynamic Range (HDR) image and video technology aims at conveying the full range of perceptible shadow and highlight details with sufficient precision. HDR is regarded by many experts as the next evolution in digital media. However, industrial broadcasters have concerns regarding the bandwidth overhead that this new technology entails. While many consider that broadcasting HDR content would increase bandwidth requirements by around 20%, this number is based on studies where, in addition to the SDR main stream, HDR-related side information is conveyed. A recent subjective evaluation reported that encoding HDR video content in a single layer might require less bandwidth than its associated SDR version. Similar results were discussed in the MPEG ad-hoc group on High Dynamic Range and Wide Color Gamut. In this article, we explain how having more information can result in lower bandwidth requirements. To this end, we describe several limitations of the human vision system that, when exploited, optimize the HDR distribution pipeline for a human observer. Our theoretical assumption about the higher efficiency of HDR is backed up by a statistical analysis of pixel distribution in real images. The Spatial Index objective metric also reconfirms our assumption.","2016","6","3","2025-12-02","https://university.edu/papers/97303ac9-7772-4261-b89d-375adebc0d03.pdf");
INSERT INTO Paper VALUES ("1036","Centralized multi-scale singular value decomposition for feature construction in LIDAR image classification problems","Creation and selection of relevant features for machine learning applications (including image classification) is typically a process requiring significant involvement of domain knowledge. It is thus desirable to cover at least part of that process with semi-automated techniques capable of discovering and visualizing those geometric characteristics of images that are potentially relevant to the classification objective. In this work, we propose to utilize multi-scale singular value decomposition (MSVD) along with approximate nearest neighbors algorithm: both have been recently realized using the randomized approach, and can be efficiently run on large, high-dimensional datasets (sparse or dense). We apply this technique to create a multi-scale view of every point in a publicly available set of LIDAR data of riparian images, with classification objective being separating ground from vegetation. We perform “centralized MSVD” for every point and its neighborhood generated by an approximate nearest neighbor algorithm. After completion of this procedure, the original set of 3-dimensional data is augmented by 36 dimensions generated by MSVD (in three different scales), which is then processed using a novel discretization pre-processing method and the SVM classification algorithm with RBF kernel. The result is two times better that the one previously obtained (in terms of its classification error level). The generic nature of the MSVD mechanism and standard mechanisms used for classification (SVM) suggest a wider utility of the proposed approach for other problems as well.","2012","9","1","2025-12-02","https://university.edu/papers/f7829bd5-403f-481d-8483-98d4e090810f.pdf");
INSERT INTO Paper VALUES ("1037","On the Satisfiability of Metric Temporal Logics over the Reals","We show that there is a satisfiability-preserving translation of QTL formulae interpreted over finitely variable behaviors into formulae of the CLTL-overclocks logic. The satisfiability of CLTL-over-clocks can be determined through a suitable encoding into the input logics of SMT solvers, so it constitutes an effective decision procedure for QTL. Although decision procedures for determining satisfiability of QTL (and for the expressively equivalent logics MITL and QMLO) already exist, the automata-based techniques they employ appear to be very difficult to realize in practice, and, to the best of our knowledge, no implementation currently exists for them. A prototype tool for QTL based on the encoding presented here has, instead, been implemented and is publicly available.","2013","8","3","2025-12-02","https://university.edu/papers/aaca8314-7026-4f8f-a061-f306f6fe18a2.pdf");
INSERT INTO Paper VALUES ("1038","A Rendering Equation for Specular Transfers and Its Integration into Global Illumination","In this paper, we present a rigorous theoretical formulation of the fundamental problem—indirect illumination from area sources via curved ideal specular surfaces. Intensity and area factors are introduced to clarify this problem and to rectify the radiance from these specular surfaces. They take surface geometry, such as Gaussian curvature, into account. Based on this formulation, an algorithm for integrating ideal specular transfers into global illumination is also presented. This algorithm can deal with curved specular reflectors and transmitters. An implementation is described based on wavefront tracing and progressive radiosity. Sample images generated by this method are presented.","1997","5","1","2025-12-02","https://university.edu/papers/d5b4af85-56f6-438c-8e09-931e10dc714a.pdf");
INSERT INTO Paper VALUES ("1039","Pipelined Multiprocessor System-on-Chip for Multimedia","This book describes analytical models and estimation methods to enhance performance estimation of pipelined multiprocessor systems-on-chip (MPSoCs). A framework is introduced for both design-time and run-time optimizations. For design space exploration, several algorithms are presented to minimize the area footprint of a pipelined MPSoC under a latency or a throughput constraint. A novel adaptive pipelined MPSoC architecture is described, where idle processors are transitioned into low-power states at run-time to reduce energy consumption. Multi-mode pipelined MPSoCs are introduced, where multiple pipelined MPSoCs optimized separately are merged into a single pipelined MPSoC, enabling further reduction of the area footprint by sharing the processors and communication buffers. Readers will benefit from the authors combined use of analytical models, estimation methods and exploration algorithms and will be enabled to explore billions of design points in a few minutes.","2013","7","2","2025-12-02","https://university.edu/papers/29352938-3d08-480b-8686-3feb72c5197d.pdf");
INSERT INTO Paper VALUES ("1040","Model-based Bayesian reinforcement learning in partially observable domains","Bayesian reinforcement learning in partially observable domains is notoriously difficult, in part due to the unknown form of the beliefs and the optimal value function. We show that beliefs represented by mixtures of products of Dirichlet distributions are closed under belief updates for factored domains. Belief monitoring algorithms that use this mixture representation are proposed. We also show that the optimal value function is a linear combination of products of Dirichlets for factored domains. Finally, we extend BEETLE, which is a point-based value iteration algorithm for Bayesian RL in fully observable domains, to partially observable domains.","2008","1","1","2025-12-02","https://university.edu/papers/d267d409-df65-48d2-8faf-747da256f1fd.pdf");
INSERT INTO Paper VALUES ("1041","State Estimation for a Class of Piecewise Affine State-Space Models","We propose a filter for piecewise affine state-space models. In each filtering recursion, the true filtering posterior distribution is a mixture of truncated normal distributions. The proposed filter approximates the mixture with a single normal distribution via moment matching. The proposed algorithm is compared with the extended Kalman filter (EKF) in a numerical simulation, where the proposed method obtains, on average, better root mean square error than the EKF.","2017","18","2","2025-12-02","https://university.edu/papers/4b0969ef-e327-45ea-b4b9-dcd957451a30.pdf");
INSERT INTO Paper VALUES ("1042","Correlated multi-dimensional qos metrics for trust evaluation within web services","Trust and reputation techniques have offered favorable solutions to the web service selection problem. In distributed systems, service consumers identify pools of service providers that offer similar functionalities. Therefore, the selection task is mostly influenced by the non-functional requirements of the consumers captured by a varied number of QoS metrics. In this paper, we present a QoS-aware trust model that leverages the correlation information among various QoS metrics. We compute the trustworthiness of web services based on probability theory by exploiting two statistical distributions, namely, Dirichlet and generalized Dirichlet, which represent the distributions of the outcomes of multi-dimensional correlated QoS metrics. We employ the Dirichlet and generalized Dirichlet when the QoS metrics are positively or negatively correlated, respectively. Experimental results endorse the advantageous capability of our model in capturing the correlation among QoS metrics and estimating the trustworthiness and reputation of service providers.","2014","1","4","2025-12-02","https://university.edu/papers/1a466e7f-cf4a-4b85-bc5d-b0493c27dbb8.pdf");
INSERT INTO Paper VALUES ("1043","A compact low power mixed-signal equalizer for gigabit Ethernet applications","In this paper we propose a novel structure of a discrete-time mixed-signal linear equalizer designed for analog front end of Gigabit Ethernet receivers. The circuit is an FIR filter which involves 6 taps based on a coefficient-rotating structure. Here, a simple structure is used for merging digital to analog conversion of the filter's coefficients and multipliers needed for 6 taps. This structure results in high speed and low power dissipation as well as less A/D converter complexity. Simulated in a 0.18 /spl mu/m CMOS technology, this equalizer operates at 125 MHz while dissipating 10 mw from a 1.8 V power supply.","2006","1","3","2025-12-02","https://university.edu/papers/c22ad2cf-3bd6-44d1-8000-0b23d1d61647.pdf");
INSERT INTO Paper VALUES ("1044","U-Mart system, software for open experiments of artificial market","Agent-based simulation is one of the promising approaches to understand and design complex socio-economic systems. The U-Mart project is a research program of providing economists and computer scientists with an artificial market, as a test bed for interdisciplinary study. The U-Mart system is a set of artificial market software developed by the U-Mart project. It contains network-based and stand-alone artificial market servers, GUI-based human interfaces for mutual trading in the market and monitoring of the market, API and a wrapper program for development of software agents, and a log viewer for analysis of experimental results. This paper gives an overview of the U-Mart project/system. Concept of a revised version of the U-Mart system under development is also discussed.","2003","7","3","2025-12-02","https://university.edu/papers/f9c05f88-8476-41dd-918e-f626a6a3d793.pdf");
INSERT INTO Paper VALUES ("1045","A hierarchical framework for face tracking using state vector fusion for compressed video","Faces usually are the most interesting objects in certain categories of video, like home videos and news clips. A novel sensor fusion based face tracking system is presented that tracks faces in compressed video, and aids automatic video indexing. Tracking is done by fusing the measurements from three independent sensors - motion and colour based trackers (Achanta, R. et al., IEEE Int. Conf. on Multimedia and Expo, 2002) and a face detector (Wang, J. et al., Proc. Int. Workshop on Advanced Image Technology, 2002) using a novel hierarchical framework based on Kalman filter state vector fusion. The tracking results show that the fused results are better than those of any individual sensors or their mean.","2003","19","4","2025-12-02","https://university.edu/papers/d7af982a-7e83-42f7-9a40-9bfadc6957ab.pdf");
INSERT INTO Paper VALUES ("1046","The Imperion Threading System","This paper describes the use of the command, facade and decorator design patterns to alter the interface and add new responsibilities to threads. Termed Project Imperion, the threads are developed with the same design patterns as previously reported for Imperion GUI components [Lyon 2004b]. The benefits of Imperion threading include: simplifying code, easing maintenance, separation of thread management logic from the business logic and improved reliability. Our experience shows that threads are often run more than once. They are frequently stopped and then restarted. However, the present mechanisms for doing this are both low-level and exception-prone. Imperion threads have built-in support for iteration. They support killing and restarting threads by introducing a new class called the RunJob. The RunJob tracks the number of times it has been run, and can be set to run only so many times before it dies. It can be set to start automatically, or be set to wait until explicitly started (or restarted). The Imperion threading system is a more reliable threading system than the normal java.lang.Thread. Imperion removes dangerous methods and guards’ inputs in order to avoid exceptions. For example, the daemon property can only be set during construction, priorities are guarded for correctness and restarting is safe. This avoids a fruitful source of complex run-time errors that have been bugging both novice and seasoned programmers since the release of JDK 1.0. Project Imperion was named for the Latin root, imperium, which means the power to command. Like the Intel use of the word CELERON, the on suffix was added to give the word a high-tech look (like electron, proton or muon). It was first conceived at the skunk works of DocJava, Inc., in the late 1990’s.","2004","15","2","2025-12-02","https://university.edu/papers/581b9337-ea10-40a0-ba2e-00d617463b4a.pdf");
INSERT INTO Paper VALUES ("1047","The use of GPS for vehicle stability control systems","This paper presents a method for using global positioning system (GPS) velocity measurements to improve vehicle lateral stability control systems. GPS can be used to calculate the sideslip angle of a vehicle without knowing the vehicle model. This measurement is combined with other traditional measurements to control the lateral motion of the vehicle. Noise estimates are provided for all measurement systems to allow the sensors to be accurately represented. Additionally, a method to calculate the lateral forces at the tires is presented. It is shown that the tire estimation algorithm performs well outside the linear region of the tire. Results for the controller and force calculations are shown using a nonlinear model to simulate the vehicle and the force calculations are validated with experimental measurements on a test vehicle.","2004","15","3","2025-12-02","https://university.edu/papers/b0e530e7-81ad-4d03-a9b3-8a01c3f1e7f6.pdf");
INSERT INTO Paper VALUES ("1048","NYU-MILA Neural Machine Translation Systems for WMT'16","We describe the neural machine translation system of New York University (NYU) and University of Montreal (MILA) for the translation tasks of WMT’16. The main goal of NYU-MILA submission to WMT’16 is to evaluate a new character-level decoding approach in neural machine translation on various language pairs. The proposed neural machine translation system is an attention-based encoder‐decoder with a subword-level encoder and a character-level decoder. The decoder of the neural machine translation system does not require explicit segmentation, when characters are used as tokens. The character-level decoding approach provides benefits especially when translating a source language into other morphologically rich languages.","2016","4","1","2025-12-02","https://university.edu/papers/87f88f8b-150a-48c9-a699-3c312a4c8113.pdf");
INSERT INTO Paper VALUES ("1049","Detection of microcalcifications in mammograms using error of prediction and statistical measures","A two-stage method for detecting microcalcifications in mammograms is presented. In the first stage, the determination of the candidates for microcalcifications is performed. For this purpose, a 2-D linear prediction error filter is applied, and for those pixels where the prediction error is larger than a threshold, a statistical measure is calculated to determine whether they are candidates for microcalcifications or not. In the second stage, a feature vector is derived for each candidate, and after a classification step using a support vector machine, the final detection is performed. The algo- rithm is tested with 40 mammographic images, from Screen Test: The Alberta Program for the Early Detection of Breast Cancer with 50-m resolution, and the results are evaluated using a free- response receiver operating characteristics curve. Two different analyses are performed: an individual microcalcification detection analysis and a cluster analysis. In the analysis of individual micro- calcifications, detection sensitivity values of 0.75 and 0.81 are ob- tained at 2.6 and 6.2 false positives per image, on the average, respectively. The best performance is characterized by a sensitivity of 0.89, a specificity of 0.99, and a positive predictive value of 0.79. In cluster analysis, a sensitivity value of 0.97 is obtained at 1.77 false positives per image, and a value of 0.90 is achieved at 0.94 false positive per image. © 2009 SPIE and IS&T.","2009","15","4","2025-12-02","https://university.edu/papers/f7d26645-c483-4eaf-abcd-09f47d1ff13e.pdf");
INSERT INTO Paper VALUES ("1050","Axiomatizing operational equivalence in the presence of side effects","The authors present a formal system for deriving assertions about programs with side effects. The assertions considered are the following: (i) the expression e diverges (i.e. fails to reduce to a value); and (ii) e/sub 0/ and e/sub 1/ are strongly isomorphic (i.e. reduce to the same value and have the same effect on memory up to production of garbage). The e, e/sub j/ are expressions of a first-order scheme- or Lisp-like language with the data operations atom, eq, car, cdr, cons, setcar, setcdr, the control primitives let and if, and recursive definition of function symbols. >","1989","16","3","2025-12-02","https://university.edu/papers/96169c9f-147e-49f3-a078-5eefa0d56493.pdf");
INSERT INTO Paper VALUES ("1051","A high order HDG method for curved-interface problems via approximations from straight triangulations","We propose a novel technique to solve elliptic problems involving a non-polygonal interface/boundary. It is based on a high order hybridizable discontinuous Galerkin method where the mesh does not exactly fit the domain. We first study the case of a curved-boundary value problem with mixed boundary conditions since it is crucial to understand the applicability of the technique to curved interfaces. The Dirichlet data is approximated by using the transferring technique developed in a previous paper. The treatment of the Neumann data is new. We then extend these ideas to curved interfaces. We provide numerical results showing that, in order to obtain optimal high order convergence, it is desirable to construct the computational domain by interpolating the boundary/interface using piecewise linear segments. In this case the distance of the computational domain to the exact boundary is only \(O(h^2)\).","2016","3","2","2025-12-02","https://university.edu/papers/f7a8a9f8-4abe-46aa-9ca2-5d4457618f1d.pdf");
INSERT INTO Paper VALUES ("1052","The Learning Process of Scientific Imagineering through AR in Order to Enhance STEM Literacy","The aim of this research was to study the Learning Process of Scientific Imagineering by Augmented Reality to Enhance STEM Literacy. The research methodology was a Document Analysis that was related to the Imagineering and scientific process and Augmented Reality (AR) in Education to enhance the Learning Process of Scientific Imagineering by Augmented Reality to Enhance STEM Literacy. The results showed that the Learning Process of Scientific Imagineering by Augmented Reality to Enhance STEM Literacy consisted of the learning process of Scientific Imagineering and the AR Learning Environment. The learning process of Scientific Imagineering consisted of 6 steps as follows: 1) imagine;             2) study and research; 3) design; 4) develop; 5) present; and 6) evaluate. The AR Learning Environment consists of six factors namely 1) flexibility; 2) user’s reaction;                               3) educational efficiency enhancement; 4) learning convenience; 5) motivation building and 6) collaborative learning encouragement. The learning process of Scientific Imagineering and AR Learning environment can develop #R##N#the student’s STEM Literacy.","2016","9","1","2025-12-02","https://university.edu/papers/a9c7c05c-d8d2-4f18-b088-bf1e04b1c312.pdf");
INSERT INTO Paper VALUES ("1053","The testability-preserving concurrent decomposition and factorization of Boolean expressions","The authors present a concurrent method for the decomposition and factorization of Boolean expressions. The method uses only two-literal single-cube divisors and double-cube divisors considered concurrently with their complements. The authors demonstrate that these objects, despite their simplicity, provide a very good framework on which to reason about common algebraic divisors and the duality relations between expressions. The simplicity of these objects makes it possible to compute the cost function associated with them accurately and dynamically. Hence, the method is entirely greedy, and in each iteration it extracts the best expression along with its complement. The decomposition is based on testability-preserving transformations, and the synthesized multilevel network is fully tested by a complete test derived for the original circuit. The algorithm has been implemented and excellent results on several benchmark circuits illustrate its efficiency and effectiveness. >","1992","12","1","2025-12-02","https://university.edu/papers/bcd66ca4-2dfa-44e9-bcc7-48e860d2e228.pdf");
INSERT INTO Paper VALUES ("1054","An unsupervised methodology for the detection of epileptic seizures in long-term EEG signals","An unsupervised methodology for the detection of Epileptic seizures in EEG recordings is proposed. The time-frequency content of the EEG signals is extracted using the Short Time Fourier Transform. The analysis focuses on the EEG energy distribution among the well-established delta, theta and alpha rhythms (2–13 Hz), as energy variations in these frequency bands are widely associated with seizure activity. Relying on seizure rhythmicity, the classification is performed by isolating the segments where each rhythm is more clearly and dominantly expressed over the others. For the first time, an unsupervised methodology is evaluated using more than 978 hours of EEG recordings from a public database. The results show that the proposed methodology achieves high seizure detection sensitivity with significantly reduced human intervention.","2015","8","1","2025-12-02","https://university.edu/papers/17357454-b189-4017-9922-7233544fc894.pdf");
INSERT INTO Paper VALUES ("1055","Using high performance systems to build collections for a digital library","Nothing is more distributed than the Web, with its content spread across thousands of servers. High performance hardware and software is essential for an effective download, analysis, and organization of this content. We describe our experience with a highly parallel Web crawling system (Mercator) to construct - automatically - collections of scientific resources for the National Science Digital Library.","2002","11","2","2025-12-02","https://university.edu/papers/830dcea7-70e6-4d1d-8129-99ee8e2cec4c.pdf");
INSERT INTO Paper VALUES ("1056","Extraction of reference lines from documents with grey-level background using sub-images of wavelets","Based on wavelets, a new theoretical method has been developed to process form documents. In this method, two-dimensional multiresolution analysis (MSA), wavelet decomposition algorithm, and compactly supported orthonormal wavelets are used to transform a document image into sub-images. According to these sub-images, the reference lines of forms can be extracted, and knowledge about the geometric structure of the document can be acquired. Experiments prove that this new method can be applied to process documents with promising results.","1995","17","3","2025-12-02","https://university.edu/papers/641a7af4-6d20-459a-b7da-e5f74ba8b464.pdf");
INSERT INTO Paper VALUES ("1057","On the discrete-time modeling and control of synchronous generators by means of variational integrators and sliding modes","This work deals with the discrete-time modeling and control design for synchronous generators by means of a variational integrator and sliding modes. First, a continuous non-conservative Lagrangian is formulated for the plant, then, the respective discrete Lagrangian is determined. Based on this, discrete-time rules are derived for synchronous generators. Second, a sliding-mode controller is proposed for the velocity stabilization of the system, and a nonlinear observer is designed for the non-measurable states. Simulations show the good performance of the synchronous generator when closed-loop with the novel discrete-time controller.","2016","9","4","2025-12-02","https://university.edu/papers/ed529142-e1ad-4656-9b35-dae32f898ebe.pdf");
INSERT INTO Paper VALUES ("1058","Wireless sensors on rotating structures: performance evaluation and radio link characterization","Wireless sensors capable of sensing, processing, and wireless communication can be useful for many monitoring purposes. Wireless sensor network testbeds to date have not considered sensors placed on fast moving structures. Fast rotating structures are commonly found in mechanical and vehicular systems, and the challenges of using wireless sensors on such structures have not been adequately addressed. The paper presents a testbed built of wireless sensors affixed to the spindle of a computer controlled lathe. By examining sensor communication errors with respect to rotation speeds and sensor locations, the study revealed an eminent dependency of packet error rates on rotation speeds, burstiness of bit errors, periodic received signal strengths, and dominance of multipath effects in the testbed. The study found the effects of non-uniform antenna gains, machine noise, hardware stability, and automatic gain control to be insignificant. While analytic derivation of Doppler effects with simplified assumptions has shown it to be insignificant, their coupled effects in a multipath environment remain to be studied further.","2007","17","1","2025-12-02","https://university.edu/papers/a1c12b19-a1c4-4056-81fb-6e2de027b462.pdf");
INSERT INTO Paper VALUES ("1059","Picture diary","Picture Diary  is about a boy's first love. It was my attempt to make an animation that can touch people like a poem. This animated short is mainly 3D with toonshaders, and made using Alias|Wavefront Maya 3.0, Painter 6.0, Photoshop, and After Effects.","2002","11","1","2025-12-02","https://university.edu/papers/7095a061-0467-44c1-9286-5e8afd286d9a.pdf");
INSERT INTO Paper VALUES ("1060","An Identification Genetic Algorithm for a Family of Duffing's System","Resumen en: This paper shows a simple way to recover the whole unknown parameters set of the Duffing`s oscillator by using a genetic algorithm. The fact that the sy...","2003","14","1","2025-12-02","https://university.edu/papers/aed3691a-b532-4f83-9c7e-4ef115b8a75d.pdf");
INSERT INTO Paper VALUES ("1061","The POWDER protocol as infrastructure to serving and compressing semantic data","The POWDER protocol is a Semantic Web technology that takes advantage of natural groupings of URIs to annotate all the resources in a regular expression-delineated sub-space of the URI space. POWDER is a mechanism for accreditation, trustmarking and resource discovery, emphasising the publishing of attributed metadata by third parties and trusted authorities. Demonstrating its versatility, it has also been deployed in unforeseen use cases, such as repository compression. In this paper, we present the POWDER protocol, explain its position in the Semantic Web architecture, expose and discuss current implementations and use cases and future directions.","2012","17","3","2025-12-02","https://university.edu/papers/9e90fdbf-98a4-497e-a618-a5450f4094e2.pdf");
INSERT INTO Paper VALUES ("1062","Improved error bounds for the erasure/list scheme: the binary and spherical cases","We derive improved bounds on the error and erasure rate for spherical codes and for binary linear codes under Forney's erasure/list decoding scheme and prove some related results.","2004","7","1","2025-12-02","https://university.edu/papers/b68eda30-4727-4e22-aa12-7e93a2f858f7.pdf");
INSERT INTO Paper VALUES ("1063","Generalized GEMM Kernels on GPGPUs: experiments and applications","General purpose computing on graphics processing units (GPGPU) is fast becoming a common feature of high performance computing centers. In this paper we discuss#R##N#some implementation issues related to dense linear algebra computations on GPUs, such as the GEneral Matrix-Matrix product, as well as other kernels sharing the same computational pattern, such as the matrix form of the All-Pairs Shortest-Path problem. Our CUDA implementation has shown a significant improvement on the NVIDIA processing units over  the vendor's software. We review the optimization techniques that can be employed to implement such operations, as well as outline further development work in connected application domains.","2009","1","2","2025-12-02","https://university.edu/papers/8f12f293-c1da-4e7a-a921-7334c781fb7a.pdf");
INSERT INTO Paper VALUES ("1064","Analytical Solution of the Energy Management for Fuel Cell Hybrid Propulsion Systems","The objective of an energy management strategy for fuel cell hybrid propulsion systems is to minimize the fuel needed to provide the required power demand. This minimization is defined as an optimization problem. Methods such as dynamic programming numerically solve this optimization problem. Strategies such as the equivalent consumption minimization strategy derive an analytical solution based on low-order models that approximate fuel cell stack and battery behavior. This paper presents an analytical solution based on models of the fuel cell system and battery close to physics. Apart from an analytical solution, this solution provides a fundamental understanding of the energy management problem. Because the solution is analytic and does not need a priori knowledge, the computation time is limited, and real-time implementation is possible. The solution presented is validated against existing optimizing energy management strategies in both simulations and experiments. For simulations, a midsize distribution truck is chosen. Experiments are carried out on a 10-kW scale test facility that comprises a fuel cell system, a battery, a motor with load, and an electronic load. In both simulations and measurements, the solution presented in this paper performs best compared to the equivalent consumption minimization strategy and a range-extender strategy, although the differences are within 3%. In the simulations, the solution presented approaches a minimum in fuel consumption, derived offline using dynamic programming, within 1%.","2012","5","4","2025-12-02","https://university.edu/papers/7af3f31b-c66a-4c96-bed6-d04f1fa49a8f.pdf");
INSERT INTO Paper VALUES ("1065","Effect of segmentation method on video retrieval performance","This paper presents experiments that evaluate the effect of different video segmentation methods on text-based video retrieval. Segmentations relying on modalities like speech, video and text or their combination are compared with a baseline sliding window segmentation. The results suggest that even with the sliding window segmentation, acceptable performance can be obtained on a broadcast news retrieval task. Moreover, in the case where manually segmented data are available for training, the approach combining the different modalities can lead to IR results close to those obtained with a manual segmentation.","2005","8","2","2025-12-02","https://university.edu/papers/e76b520d-d0ed-4dce-ba99-9fb3117b16f5.pdf");
INSERT INTO Paper VALUES ("1066","Temporal resolution scalable video coding","Scalable video coding is important in a number of applications where video needs to be decoded and displayed at a variety of spatial and temporal resolution scales or when resilience to errors is necessary. In this paper, we investigate a temporal-domain approach for resolution scalable video coding. This approach was originally proposed to and since then has been included in the Moving Picture Experts Group (MPEG-2) standard. Temporal scalability, although not limited to, is particularly useful for applications such as, HDTV as well as for high quality telecommunication applications that may require high frame rate (e.g., 60 Hz) progressive video. Furthermore, it allows flexibility in use of progressive or interlaced video formats for coding even though the source video may be progressive with high frame rate. Our technique builds on the motion-compensated DCT framework of nonscalable (single layer) MPEG-2 video coding and adds motion compensated inter-layer coding. In our simulations we focus on the 2- layer temporally scalable coding and compare the performance of using progressive video format for both layers to that when interlaced video format is used for both layers; all interim video formats used are derived from original high temporal resolution progressive video. In each case we compare the performance of two inter-layer prediction configurations and evaluate their prediction efficiency. >","1994","9","4","2025-12-02","https://university.edu/papers/c324f1d7-fb30-48ee-9211-66513ef6d027.pdf");
INSERT INTO Paper VALUES ("1067","Analysis of YouTube user experience from passive measurements","In this paper, we analyze the YouTube service and the traffic generated from its usage. The purpose of this study is to identify by strictly using passive measurements the information that can be used as metrics or indicators of the progress of individual video sessions and to estimate the impact of these metrics in the user experience. We find a novel method to track the progress of the video playback that, in contrast to previous works, does not require instrumentation of the video player neither browser-based plug-ins. Instead, we extract important statistical information about the status of the playback by reverse engineering the metrics in related HTTP requests that are generated during playback. For the purpose of collecting these metrics, a tool was developed to perform YouTube traffic measurements by means of passive network monitoring in a large university campus network. The analysis of the obtained data revealed the most important sources of initial delay in the sessions as well as buffer outage events and download rate statistics. Further analysis revealed the impact of video advertisements and re-buffering events on the user experience in terms of video abandonment rate.","2013","5","4","2025-12-02","https://university.edu/papers/be278b24-f687-4c9b-94b9-6b3eab7cfe45.pdf");
INSERT INTO Paper VALUES ("1068","Structured Log Linear Models for Noise Robust Speech Recognition","The use of discriminative models for structured classification tasks, such as speech recognition is becoming increasingly popular. This letter examines the use of structured log-linear models for noise robust speech recognition. An important aspect of log-linear models is the form of the features. By using generative models to derive the features, state-of-the-art model-based compensation schemes can be used to make the system robust to noise. Previous work in this area is extended in two important directions. First, a large margin training of sentence-level log linear models is proposed for automatic speech recognition (ASR). This form of model is shown to be similar to the recently proposed structured Support Vector Machines (SVM). Second, based on the designed joint features, efficient lattice-based training and decoding are performed. This novel model combines generative kernels, discriminative models, efficient lattice-based large margin training and model-based noise compensation. It is evaluated on a noise corrupted continuous digit task: AURORA 2.0.","2010","6","4","2025-12-02","https://university.edu/papers/d23086c5-699c-4adc-8cb4-b14eb9a28280.pdf");
INSERT INTO Paper VALUES ("1069","Hardware validated unified model of multibit temporally and spatially oversampled image sensors with conditional reset","We describe a photon statistics-based theoretical model of the response to incident light of an image sensor and show that conditional reset and multibit temporal oversampling increase the dynamic range signifi- cantly. This photon-based modeling approach describes the full image sensor design space of temporal and spatial oversampling either with a binary comparison or with a multibit read of each sample. We find excellent quantitative agreement between measurements on custom hardware and our theoretical predictions. We then use this model to show what improvements in dynamic range and low-light response can be achieved by over- sampling and what the limits of improvement caused by pixel size and lens parameters are. © The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI. (DOI: 10.1117/1.JEI.23.1.013021)","2014","10","2","2025-12-02","https://university.edu/papers/89ffef2c-04b7-4895-9c4c-0c425cc43b3d.pdf");
INSERT INTO Paper VALUES ("1070","Matching images based on consistency graph and region adjacency graphs","The image matching methods based on regions have many advantages over the point matching techniques, and the most charming one is that once region being matched, all pixels are matched in theory. It would benefit many applications, such as object retrieval, stereo corresponding, semantic understanding a scene, object tracking. This paper proposes a new region matching algorithm based on consistency graph and region adjacency graphs. Firstly, the segmented images are transformed into region adjacency graphs, and the potential region pairs and the potential edge segment pairs are packaged in a consistency graph. Since the rightly matched pair always is accompanied by harmonious neighbourhoods, the right correspondences tend to cluster together, and the error corresponding relationship should have few chances to connect to any compatible neighbourhood. Thus, the solution space is greatly reduced and the corresponding relationship can be found in a polynomial computational complexity just by a simple method, such as seed-growth method. To the best of our knowledge, the method is the first one to match two images by region adjacency graphs and find the corresponding relationship in a polynomial computational complexity. Experiments on the existing benchmark show that the proposed method could quickly find the right corresponding relationship between images with illumination, rotation and affine transformation.","2017","7","1","2025-12-02","https://university.edu/papers/af52e99e-10d0-46aa-b6c5-51f578de390f.pdf");
INSERT INTO Paper VALUES ("1071","Hands and knowledge: gesture as an epistemic engine in reminiscence therapy","Conversation analyses have revealed that information imbalances between speakers and hearers are represented in their speech and drive the epistemic engine to equalize the imbalances. Considering multi-modal communication, however, information can also be conveyed by body movements and reveal the unspoken imbalances in detail. Group reminiscence therapy is used to treat elderly people who are developing dementia, but it is a conversation process in which the epistemic engine involves cultural differences among the participants. In the present study, detailed analyses of conversation during therapy showed that speakers can use gestures to show their epistemic status and the information imbalance between the participants; hearers can imitate the speaker's gestures to show their understanding in the conversational sequence; unspoken epistemic differences can be revealed by the difference between the gestures of the speaker and hearer; and other participants can observe the difference visually and update a gesture to point out the unspoken difference. I discuss the multi-modal structure of an epistemic engine in reminiscence therapy and its implications for the care given to dementia patients.","2012","17","2","2025-12-02","https://university.edu/papers/b6ef2da7-2f57-4bb3-9b4d-8b2f761415b8.pdf");
INSERT INTO Paper VALUES ("1072","The Trend of the Security Research for the Insider Cyber Threat","In this paper, we discuss an insider security which has been one of the biggest issues in the network security. By surveying and analyzing an issue of previous studies, we suggest an effective approach for future research. Approximately 90% of the information leakage incidents are recently being performed by internal workers. It is coming as a more serious problem than outsider attacks. The information leakage incident makes an organization or a company not only loses information but also gives a hard blow to the image. To prevent economic loss and damage to the image in advance, we need various research and development for effective solution.","2009","1","4","2025-12-02","https://university.edu/papers/c841bf77-6288-4e3b-8501-c8417823452c.pdf");
INSERT INTO Paper VALUES ("1073","I'll Buy That! Cybersecurity in the Internet Marketplace","Interviews with chief security officers in the Internet supply chain (those companies that provide Internet services or encourage people to use the Internet) reveal dramatically different attitudes about corporate cybersecurity. The authors' preliminary investigation suggests that a company's market discipline explains these differences.","2007","3","4","2025-12-02","https://university.edu/papers/c7572bff-def2-4bab-bcc4-f88ce9004a4c.pdf");
INSERT INTO Paper VALUES ("1074","Why is Posterior Sampling Better than Optimism for Reinforcement Learning","Computational results demonstrate that posterior sampling for reinforcement learning (PSRL) dramatically outperforms algorithms driven by optimism, such as UCRL2. We provide insight into the extent of this performance boost and the phenomenon that drives it. We leverage this insight to establish an $\tilde{O}(H\sqrt{SAT})$ Bayesian expected regret bound for PSRL in finite-horizon episodic Markov decision processes, where $H$ is the horizon, $S$ is the number of states, $A$ is the number of actions and $T$ is the time elapsed. This improves upon the best previous bound of $\tilde{O}(H S \sqrt{AT})$ for any reinforcement learning algorithm.","2016","18","2","2025-12-02","https://university.edu/papers/b1e162d7-2396-4c2c-9bf2-439b8de569a9.pdf");
INSERT INTO Paper VALUES ("1075","On a direct construction of inverse scattering problems for integrable nonlinear evolution equations in the two-spatial dimension","We present a method to construct inverse scattering problems for integrable nonlinear evolution equations in the two-spatial dimension. The temporal component is the adjoint of the linearized equation and the spatial component is a partial differential equation with respect to the spatial variables. Although this idea has been known for the one-spatial dimension for some time, it is the first time that this method is presented for the case of the higherspatial dimension. We present this method in detail for the Veselov-Novikov equation and the Kadomtsev-Petviashvili equation.","2004","6","1","2025-12-02","https://university.edu/papers/8aadff8b-c956-42c5-995d-1757d6a23d0b.pdf");
INSERT INTO Paper VALUES ("1076","Flexible group communication protocol for distributed systems","The group protocol has to support applications with enough quality (QoS) and types of service in change of QoS supported by the underlying network and QoS requirements of applications. A flexible group service is supported for applications by cooperation of multiple autonomous agents. A group protocol to coordinate the cooperation of the agents is composed of a collection of functions like retransmission and receipt confirmation. Each agent dynamically and autonomously takes a class of module for each protocol function in change of QoS supported by networks and required by application.","2003","14","3","2025-12-02","https://university.edu/papers/d0e33ddc-37ce-4d05-9083-a2db4349404d.pdf");
INSERT INTO Paper VALUES ("1077","Cooperative Spectrum Sensing for Cognitive Radios Using Kriged Kalman Filtering","A cooperative cognitive radio (CR) sensing problem is considered, where a number of CRs collaboratively detect the presence of primary users (PUs) by exploiting the novel notion of channel gain (CG) maps. The CG maps capture the propagation medium per frequency from any point in space and time to each CR user. They are updated in real-time using Kriged Kalman filtering (KKF), a tool with well-appreciated merits in geostatistics. In addition, the CG maps enable tracking the transmit-power and location of an unknown number of PUs, via a sparse regression technique. The latter exploits the sparsity inherent to the PU activities in a geographical area, using an  l  1 -norm regularized, sparsity-promoting weighted least-squares formulation. The resulting sparsity-cognizant tracker is developed in both centralized and distributed formats, to reduce computational complexity and memory requirements of a batch alternative. Numerical tests demonstrate considerable performance gains achieved by the proposed algorithms .","2011","20","4","2025-12-02","https://university.edu/papers/a19a612c-8027-4f0d-a8e4-059a460d5cdc.pdf");
INSERT INTO Paper VALUES ("1078","Convergence of a numerical method for the compressible Navier–Stokes system on general domains","We propose a mixed numerical method for solving the compressible Navier–Stokes system and study its convergence and stability with respect to the physical domain. The numerical solutions are shown to converge, up to a subsequence, to a weak solution of the problem posed on the limit domain.","2016","19","2","2025-12-02","https://university.edu/papers/9553ee9c-f599-4305-92e9-ee7ef0c1db06.pdf");
INSERT INTO Paper VALUES ("1079","Markov chain Monte Carlo on asymmetric GARCH model using the adaptive construction scheme","We perform Markov chain Monte Carlo simulations for a Bayesian inference of the GJR-GARCH model which is one of asymmetric GARCH models. The adaptive construction scheme is used for the construction of the proposal density in the Metropolis-Hastings algorithm and the parameters of the proposal density are determined adaptively by using the data sampled by the Markov chain Monte Carlo simulation. We study the performance of the scheme with the artificial GJR-GARCH data. We find that the adaptive construction scheme samples GJR-GARCH parameters effectively and conclude that the Metropolis-Hastings algorithm with the adaptive construction scheme is an efficient method to the Bayesian inference of the GJR-GARCH model.","2009","12","4","2025-12-02","https://university.edu/papers/a6c03776-cf41-4068-9921-b999e2972255.pdf");
INSERT INTO Paper VALUES ("1080","VLSI architectures for block matching algorithms using systolic arrays","We investigate hardware implementation of block matching algorithms (BMAs) for motion estimation of moving sequences. Using systolic arrays, we propose VLSI architectures for the two-stage BMA and full search (FS) BMA. The two-stage BMA using integral projections reduces greatly the computational complexity with its performance comparable to that of the FS BMA. The proposed hardware architectures for the two-stage BMA and FS BMA are faster than the conventional hardware architectures with lower hardware complexity. Also, the proposed architecture of the first stage of the two-stage BMA is modeled in VHDL and simulated. Simulation results show the functional validity of the proposed architecture.","1996","17","2","2025-12-02","https://university.edu/papers/7260a141-1561-489f-9be4-76e0a65903d6.pdf");
INSERT INTO Paper VALUES ("1081","An adaptive two-stage algorithm for ML and sub-ML decoding of binary linear block codes","Two distinct codeword-searching procedures based on iterative bounded-distance decoding (BDD) are combined to form an adaptive two-stage maximum-likelihood (ML) decoder for binary linear block codes. During the first stage of the algorithm, a tight upper bound on an error likelihood metric ('discrepancy') is established iteratively for the ML codeword. First-stage processing requires sorting and storage. Adaptive switching to the second stage removes the sorting and storage requirements and allows to rule out redundant BDDs efficiently. Second-stage processing accounts for all codewords with discrepancy lower bound below the upper bound of the ML codeword and guarantees ML performance. In addition, the proposed two-stage algorithm is inherently tunable for controlled suboptimum operation. Under sub-ML operation, the overall scheme can be interpreted as a generalization of the Chase (1972) algorithm. Simulation studies for the (24,12,8) extended Golay and the (64,30,14) and (128,64,22) extended Bose-Chaudhuri-Hocquenghem (BCH) codes illustrate and support these theoretical developments.","2003","10","2","2025-12-02","https://university.edu/papers/f61cb5a6-a248-4f6f-99f7-a832fbab6f09.pdf");
INSERT INTO Paper VALUES ("1082","RingSTM: scalable transactions with a single atomic instruction","Existing Software Transactional Memory (STM) designs attach metadata to ranges of shared memory; subsequent runtime instructions read and update this metadata in order to ensure that an in-flight transaction's reads and writes remain correct. The overhead of metadata manipulation and inspection is linear in the number of reads and writes performed by a transaction, and involves expensive read-modify-write instructions, resulting in substantial overheads.   We consider a novel approach to STM, in which transactions represent their read and write sets as Bloom filters, and transactions commit by enqueuing a Bloom filter onto a global list. Using this approach, our RingSTM system requires at most one read-modify-write operation for any transaction, and incurs validation overhead linear not in transaction size, but in the number of concurrent writers who commit. Furthermore, RingSTM is the first STM that is inherently livelock-free and privatization-safe while at the same time permitting parallel writeback by concurrent disjoint transactions.We evaluate three variants of the RingSTM algorithm, and find that it offers superior performance and/or stronger semantics than the state-of-the-art TL2 algorithm under a number of workloads.","2008","10","4","2025-12-02","https://university.edu/papers/f0bd9bcf-05ed-4c35-9a97-87997626fd22.pdf");
INSERT INTO Paper VALUES ("1083","Behavior arbitration for autonomous mobile robots using emotion mechanisms","Conventional AI (artificial intelligence) technology has been criticized on many drawbacks such as brittleness under dynamically changing environments. To overcome this problem, other approaches called behavior-based AI, new AI, emergent computation, animat approach and so on were proposed and confirmed their usefulness. Since computational ability of mobile robots is limited in general, it is required that robots extract feasible information from their environment for appropriate behavior control by themselves. On the other hand, in living organisms, there are mainly two systems to cope with dynamically changing environment: 1) immune system, and 2) emotional system. Based on this fact, in this paper, we present a new method of behavior arbitration mechanisms for autonomous mobile robots by paying close attention to emotional system in living organisms. We confirm the feasibility of our proposed method by applying to an obstacle avoidance problem of a mobile robot as a practical example.","1995","16","4","2025-12-02","https://university.edu/papers/7ce956fe-9455-439c-88e7-139c58f51306.pdf");
INSERT INTO Paper VALUES ("1084","Two-level MMSE relay strategy for an AF wireless relay network","This paper presents optimal amplify-and-forward (AF) relay amplifying matrices based on the minimum mean square error (MMSE) criterion for a cooperative AF wireless relay network consisting of a one-source-one-destination node pair and two-level N relay nodes. During data transmission, power is constrained at the source node, at the relay nodes in the first and the second levels, and at the destination node. In addition, this paper considers the case that power is intentionally not constrained. Hence, for the no-power constraint example, a positive scaling factor is employed to meet the target signal-to-noise ratio (SNR TGT ) at the destination node. With the derived optimal relay amplifying matrices, bit error rate (BER) of the wireless relay network under both power and no-power constraint is simulated.","2012","20","3","2025-12-02","https://university.edu/papers/81a64a10-d975-401a-93f9-0276dad61b64.pdf");
INSERT INTO Paper VALUES ("1085","Designing Interdisciplinary Approaches To Problem Solving Into Computer Languages","Many interdisciplinary design efforts require the involvement of computer scientists because of the complexity of the problem solving tools available for the projects. This paper demonstrates how appropriate language design can place high level languages in the hands of scientists and engineers, thus providing a more automated approach to problem solving that may reduce the amount of computer scientist involvement. The language SequenceL serves as an example of this approach.","2002","18","4","2025-12-02","https://university.edu/papers/7fe39e5d-fe8e-4283-8997-ef3d731d78fa.pdf");
INSERT INTO Paper VALUES ("1086","Energy-efficient color approximation for digital LCD interfaces","The limited resolution capabilities of color displays, coupled with the limited perceptual resolution of the human eye have been exploited to reduce the actual number of colors that are simultaneously displayed. In this work, we propose a color approximation approach, orthogonal to traditional color simplification schemes done either in the frame buffer or in the LCD controller; that targets the reduction of the energy required for the transmission of color data on digital LCD interfaces. Our approach leverages the serial nature of the transmission so as to approximate RGB pixel values with suitable codes that minimize the number of transitions on the LCD bus, for a given tolerated image quality level. Application of this scheme on a set of images shows energy savings from 60% to 75%, depending on the image quality.","2005","10","1","2025-12-02","https://university.edu/papers/e5a35caf-407c-4d6e-ad96-f4a82a954065.pdf");
INSERT INTO Paper VALUES ("1087","Contact task with an unknown inclined plane","In recent years, intelligent robots that work automatically have become required. Conventional robots have been used in specific environments, but these new robots are going to be used in universal environments that are not constant. For that reason, in this study, we attach two visual sensors, which are CCD cameras, and one force sensor to a robot to provide information on the outside environment. The robot execute contact task, for example, wiping windows, the robot manipulator perpendicularly and flexibly contacts the environment. For perpendicular contact, it is necessary to detect the angle of the plane and for flexible contact, it is essential to utilize a universal force controller. In this paper, we propose two newly developed methods. One is the angle detection of the inclined plane by perspective, and the second is the universal force controller that contains of variable stiffness impedance controller and sliding mode controller. Angle detection and contact task were carried out using the proposed control system and the practicability of this method was verified.","2007","8","1","2025-12-02","https://university.edu/papers/aceacd7a-2d72-4118-9f87-a7bd3aa17286.pdf");
INSERT INTO Paper VALUES ("1088","PCMM-based feature compensation schemes using model interpolation and mixture sharing","In this paper, we propose an effective feature compensation scheme based on the speech model in order to achieve robust speech recognition. The proposed feature compensation method is based on parallel combined mixture model (PCMM). The previous PCMM works require a highly sophisticated procedure for estimation of the combined mixture model in order to reflect the time-varying noisy conditions at every utterance. The proposed schemes can cope with the time-varying background noise by employing the interpolation method of the multiple mixture models. We apply the 'data-driven' method to PCMM for more reliable model combination and introduce a frame-synched version for estimation of environments a posteriori. In order to reduce the computational complexity due to multiple models, we propose a technique for mixture sharing. The statistically similar Gaussian components are selected and the smoothed versions are generated for sharing. The performance was examined over Aurora 2.0 and speech corpus recorded while car-driving. The experimental results indicate that the proposed schemes are effective in realizing robust speech recognition and reducing the computational complexities under both simulated environments and real-life conditions.","2004","10","4","2025-12-02","https://university.edu/papers/fa900577-7da4-4ecd-b2d4-1afddf62e91c.pdf");
INSERT INTO Paper VALUES ("1089","Parallel Discrete-Event Simulation on Data Processing Engines","Development of a decent parallel simulator is challenging work. It should achieve enough performance, scalability and fault tolerance. Our proposal is utilizing general-purpose data processing engines such as MapReduce implementations for parallel simulation. Widely used and mature engines take away a large part of the development effort and support scalability and fault tolerance. We demonstrate that a parallel discrete-event simulator can be implemented on such engines, Apache Hadoop and Apache Spark, by modeling message passing of distributed systems on MapReduce key-value processing model. Implemented simulators could handle 108 nodes with 10 computers. Preliminary evaluation showed that our Spark-based simulator is about 20 times as fast as an existing simulator thanks to Time Warp.","2016","15","3","2025-12-02","https://university.edu/papers/c96f1727-68ce-44f3-86d3-c535dc03e51e.pdf");
INSERT INTO Paper VALUES ("1090","On-line soft error correction in matrix-matrix multiplication","a b s t r a c t Soft errors are one-time events that corrupt the state of a computing system but not its overall func- tionality. Soft errors normally do not interrupt the execution of the affected program, but the affected computation results cannot be trusted any more. A well known technique to correct soft errors in matrix-matrix multiplication is algorithm-based fault tolerance (ABFT). While ABFT achieves much bet- ter efficiency than triple modular redundancy (TMR) - a traditional general technique to correct soft errors, both ABFT and TMR detect errors off-line after the computation is finished. This paper extends the traditional ABFT technique from off-line to on-line so that soft errors in matrix-matrix multiplication can be detected in the middle of the computation during the program execution and higher efficiency can be achieved by correcting the corrupted computations in a timely manner. Experimental results demon- strate that the proposed technique can correct one error every ten seconds with negligible (i.e. less than 1%) performance penalty over the ATLAS dgemm().","2013","8","4","2025-12-02","https://university.edu/papers/7318164e-bb4a-4569-a3b6-170475c57d58.pdf");
INSERT INTO Paper VALUES ("1091","Scalable, high-quality, SAT-based multi-layer escape routing","Escape routing for Printed Circuit Boards (PCBs) is an important problem arising from modern packaging with large numbers of densely spaced pins, such as BGAs. Single-layer escape routing has been well-studied, but large, dense BGAs often require multiple PCB layers to be fully escaped. Unfortunately, multi-layer escape routing is much more challenging than single-layer escape routing, and currently lacks scalable, high-quality, automatic solutions. As a result, multi-layer escape routing for high-end BGAs typically requires extensive human intervention in practice.   This paper introduces a novel approach to multi-layer escape routing. Our approach builds on recent advances in SAT (Boolean satisfiability) solving, in particular, the solver M ono SAT, which efficiently supports network-flow constraints within a general constraint-solving framework. We formulate multi-layer escape routing in this framework and demonstrate scalability to the largest BGAs presently in common use, with more than 2000 pins. Our approach supports 45- and 90-degree routing, simultaneously places traces and vias, and supports all commonly used via technologies, including through-hole, blind, buried, and any-layer micro-vias. In addition, because our approach is based on constraint-solving, it can flexibly interoperate with partial solutions from other routing techniques.   We demonstrate the utility of our technique by finding escape routings for a diverse set of large, commercial BGAs. Compared to a typical layer-by-layer approach, our approach produces better routings, often saving one or more PCB layers for larger BGAs, and in some cases, proving that no solution is possible with fewer layers. Finally, we describe how our technique can be extended to handle common additional constraints, such as differential-pair constraints.","2016","4","2","2025-12-02","https://university.edu/papers/40e9e833-9545-490f-8556-b69e4f572d0c.pdf");
INSERT INTO Paper VALUES ("1092","Lazy Pipelines: Enhancing quality in approximate computing","Approximate computing techniques based on Voltage Over-Scaling (VOS) can provide quadratic improvements in power efficiency. However, voltage scaling is limited by the inherent fault-tolerance of an application, thus preventing VOS schemes from realizing their full potential. To gain further power efficiency a reduction of the error rate experienced in a given voltage level is required. We propose Lazy Pipelines, a micro-architectural technique that utilizes vacant cycles in a VOS functional unit to extend execution and reduce the error rate.","2016","15","3","2025-12-02","https://university.edu/papers/e30e95cf-006e-4025-ade0-5ef233b50cc4.pdf");
INSERT INTO Paper VALUES ("1093","Convergence of the Modified Craig-Sneyd scheme for two-dimensional convection-diffusion equations with mixed derivative term","We consider the Modified Craig-Sneyd (MCS) scheme which forms a prominent time stepping method of the Alternating Direction Implicit type for multidimensional time-dependent convection-diffusion equations with mixed spatial derivative terms. Such equations arise often, notably, in the field of financial mathematics. In this paper a first convergence theorem for the MCS scheme is proved where the obtained bound on the global temporal discretization errors has the essential property that it is independent of the (arbitrarily small) spatial mesh width from the semidiscretization. The obtained theorem is directly pertinent to two-dimensional convection-diffusion equations with mixed derivative term. Numerical experiments are provided that illustrate our result.","2016","4","3","2025-12-02","https://university.edu/papers/d88316c5-f4a7-4692-9c6c-9609bdeb9f67.pdf");
INSERT INTO Paper VALUES ("1094","BETTY: prediction of beta-strand type from sequence.","Most secondary structure prediction programs do not distinguish between parallel and antiparallel β-sheets. However, such knowledge would constrain the available topologies of a protein significantly, and therefore aid existing fold recognition algorithms. For this reason, we propose a technique which, in combination with existing secondary structure programs such as PSIPRED, allows one to distinguish between parallel and antiparallel β-sheets. We propose the use of a support vector machine (SVM) procedure, BETTY, to predict parallel and antiparallel sheets from sequence. We found that there is a strong signal difference in the sequence profiles which SVMs can efficiently extract. With strand type assignment accuracies of 90.7% and 83.3% for antiparallel and parallel strands, respectively, our method adds considerably to existing information on current 3-class secondary structure predictions. BETTY has been implemented as an online service which academic researchers can access from our website http://www.fz- juelich.de/nic/cbb/service/service.php.","2007","13","2","2025-12-02","https://university.edu/papers/d0e664e9-1d0c-47c0-bbed-07bb98895020.pdf");
INSERT INTO Paper VALUES ("1095","On model checking for real-time properties with durations","The verification problem for real-time properties involving duration constraints (predicates) is addressed. The duration of a state property, along an interval of a computation sequence of a real-time system, is the time the property is true. In particular, the global time spent in such an interval is the duration of the formula 'true'. The real-time logic TCTL is extended to a duration logic called SDTL in which duration constraints can be expressed. The problem of the verification of SDTL formulas with respect to a class of timed models of reactive systems is investigated. New model checking procedures are proposed for the most significant properties expressible in SDTL, including eventuality and invariance properties. Such results are provided for the two cases of discrete and dense time. >","1993","16","4","2025-12-02","https://university.edu/papers/6f9fdeac-748f-4c67-bf88-99c406d7dc9c.pdf");
INSERT INTO Paper VALUES ("1096","Summary for AVEC 2016: Depression, Mood, and Emotion Recognition Workshop and Challenge","The sixth Audio-Visual Emotion Challenge and workshop AVEC 2016 was held in conjunction ACM Multimedia'16. This year the AVEC series addresses two distinct sub-challenges, multi-modal emotion recognition and audio-visual depression detection. Both sub-challenges are in a way a return to AVEC's past editions: the emotion sub-challenge is based on the same dataset as the one used in AVEC 2015, and depression analysis was previously addressed in AVEC 2013/2014. In this summary, we mainly describe participation and its conditions.","2016","20","4","2025-12-02","https://university.edu/papers/e2da1369-733f-4f37-81fd-a4db9430891f.pdf");
INSERT INTO Paper VALUES ("1097","Toward Formal Semantics for Data and Schema Evolution in Data Stream Management Systems","Data Stream Management Systems (DSMSs) do not statically respond to issued queries -- rather, they continuously produce result streams to standing queries, and often operate in a context where any interruption can lead to data loss. Support for schema evolution in continuous query processing is currently unaddressed. In this work we address evolution in DSMSs by proposing semantics for three evolution primitives: Add Attribute and Drop Attribute (schema evolution), and Alter Data (data evolution). We characterize how a subset of commonly used query operators in a DSMS act on and propagate these primitives.","2009","8","1","2025-12-02","https://university.edu/papers/de509be2-6efd-4596-a20f-3443c95587b4.pdf");
INSERT INTO Paper VALUES ("1098","Towards Probabilistic Operator-Multiple Robot Decision Models","Coupled operator-multiple vehicle systems are modelled in a unified framework using probabilistic graphs to yield a methodology for analyzing semi-autonomous systems. The framework uses conditional probabilistic dependencies between all elements, leading to a Bayesian network (BN) with probabilistic evaluation capability. Vehicle attitude/navigation states and target/classification states can be evaluated using nonlinear estimators such as the EKF, multiple model filter, information filter, or other approaches. Discrete operator decisions are being modeled as Bayesian network blocks, with conditional dependencies on the vehicle and tracking estimators. Initial decision models use combinations of softmax and discrete probability distributions.","2007","10","3","2025-12-02","https://university.edu/papers/b2c1da55-f99e-45db-b0cd-910d87c561f1.pdf");
INSERT INTO Paper VALUES ("1099","Twitter as a Learning Community in Higher Education","Introduction Didactic methods incorporating the new technologies are evolving slowly, which is why teachers should also update their skills to include the use of Information and Communication Technologies (ICT). Still, these resources are starting to contribute to the promotion of new forms of learning, forming part of a new emerging paradigm involving the construction and production of knowledge in cyberspace. Access to such knowledge makes vast quantities of information available to people, instantaneously or with a certain time delay, as well as facilitating contact with and knowledge of countless resources and communication platforms in any place at any time (Johnson, Smith, Willis, Levine, & Haywood, 2011; Kop, 2012). The Internet is a valuable resource in higher education, especially as a means of bridging long distances, thereby promoting the feedback process, a key component of learning. Moreover, it promotes the motivation and regulation of students in the training process. Certain authors go even further (Fried, 2008; Hembrooke & Gay, 2003), indicating that ICTs have a negative impact on learning, as they disperse attention and promote the diversification of the type of tasks carried out on an autonomous basis. Although others researchers as Hsu and Ching (2012) indicated that the proliferation of Web 2.0 applications--especially the social media--among people and the ever greater use of mobile devices also contributes to broaden the possibilities of ubiquitous, collaborative learning. Still, the Internet as a source of learning continues to expand and gain ground, as it generates and facilitates communication and the acquisition of a great number and diversity of resources, and provides different ways to apply fundamental principles of learning in higher education (Gernsbacher, 2015). It is also worth noting that it gives rise to knowledge, though most of its content is not directly associated with regulated learning and the physical space of classrooms. On the Internet we can all be consumers, creators and disseminators at the same time. This is one of the premises of the EMIREC model (Cloutier, 1975): any emitter is a receiver and any receiver is also an emitter. Kaplan and Haenlein (2010) define social media as the applications that are supported on the Internet and are based on the ideological and technological foundations of Web 2.0 and allow creating and interacting with contents generated by users by open and free means. In this sense, Khan (2013) outlined that they provide opportunities to users to develop relationships, communication, and collaboration (sharing contents). These social media integrate a large variety of emergent tools and technologies as wikis, blogs, and microblogging, content communities (YouTube, Pinterest, Slideshare), social nets (Twitter, Facebook, etc.), social tagging and folksonomies (Delicious, Addthis, Diigo), online games, collaborative plataforms, and other web 2.0 platforms where users create, exchange, comment, and value their own contents. Today no one questions the great educational potential of Web 2.0 tools, but their integration into learning contexts still has to take off, and one cannot as yet speak of widespread use. Diaz-Gandasegui (2011) holds that social media are one of the main sources of leisure among the younger generations. This helps them to acquire the technical skills required for the use of the new technologies, although it does not ensure a widespread familiarisation or acquisition of skills within this group. It is also worth noting that, owing to the way in which they invade people's lives, social media can be seen either as a potential threat, or alternatively as a great opportunity that can be extended to different facets (Stoughton, Thompson, & Meade, 2015). However, the use of social media as a didactic tool is still at an incipient stage, despite the accessibility made possible by their application, as they are easy to use and available as an open resource on the Internet. …","2016","17","2","2025-12-02","https://university.edu/papers/cf6cf4ad-20a2-46ed-ab02-848338930195.pdf");
INSERT INTO Paper VALUES ("1100","Performance Evaluation of Differentiated Services Mechanisms Over Wireless Sensor Networks","Data reliability and real-time delivery of critical information are very crucial in many wireless sensor network applications such as intruder detection and surveillance. In this paper, we explore different mechanisms to provide differentiated services for time-critical information flows. We compare their performances in terms of the packet delivery ratio and end-to-end latency for a high-priority information flow. Our simulation and delay analysis results show that an approach where the wireless medium is reserved along the path from the source to the sink for a high-priority information flow, can provide guaranteed and low latency delivery for a high-priority flow, with acceptable delay impact to the low-priority flows.","2006","14","1","2025-12-02","https://university.edu/papers/575e9392-9ccf-4f93-b2fe-421d6363f140.pdf");
INSERT INTO Paper VALUES ("1101","Active Learning with Distributional Estimates","Active Learning (AL) is increasingly important in a broad range of applications. Two main AL principles to obtain accurate classification with few labeled data are refinement of the current decision boundary and exploration of poorly sampled regions. In this paper we derive a novel AL scheme that balances these two principles in a natural way. In contrast to many AL strategies, which are based on an estimated class conditional probability ^p(y|x), a key component of our approach is to view this quantity as a random variable, hence explicitly considering the uncertainty in its estimated value. Our main contribution is a novel mathematical framework for uncertainty-based AL, and a corresponding AL scheme, where the uncertainty in ^p(y|x) is modeled by a second-order distribution. On the practical side, we show how to approximate such second-order distributions for kernel density classification. Finally, we find that over a large number of UCI, USPS and Caltech4 datasets, our AL scheme achieves significantly better learning curves than popular AL methods such as uncertainty sampling and error reduction sampling, when all use the same kernel density classifier.","2012","18","3","2025-12-02","https://university.edu/papers/ef53968c-67d1-49b3-bd30-1eb668272933.pdf");
INSERT INTO Paper VALUES ("1102","A Deterministic Algorithm for Maximizing Submodular Functions","The problem of maximizing a non-negative submodular function was introduced by Feige, Mirrokni, and Vondrak [FOCS'07] who provided a deterministic local-search based algorithm that guarantees an approximation ratio of $\frac 1 3$, as well as a randomized $\frac 2 5$-approximation algorithm. An extensive line of research followed and various algorithms with improving approximation ratios were developed, all of them are randomized. Finally, Buchbinder et al. [FOCS'12] presented a randomized $\frac 1 2$-approximation algorithm, which is the best possible. #R##N#This paper gives the first deterministic algorithm for maximizing a non-negative submodular function that achieves an approximation ratio better than $\frac 1 3$. The approximation ratio of our algorithm is $\frac 2 5$. Our algorithm is based on recursive composition of solutions obtained by the local search algorithm of Feige et al. We show that the $\frac 2 5$ approximation ratio can be guaranteed when the recursion depth is $2$, and leave open the question of whether the approximation ratio improves as the recursion depth increases.","2015","9","3","2025-12-02","https://university.edu/papers/63d5fbf4-a86a-4bd5-8624-56206805dc67.pdf");
INSERT INTO Paper VALUES ("1103","Context-Aware services for physical hypermedia applications","In this paper we present an approach for designing and deploying context-aware services in the context of physical hypermedia applications, those applications in which mobile users explore real and digital objects using the hypermedia paradigm We show how to adapt the objects' response to the user's navigation context by changing the role these objects play in the user's travel We first motivate our research with a simple example and survey some related work; next we introduce the concept of travel object and show that physical objects might assume the role of different type of travel objects We then present an architectural approach for context-aware services and describe its evolution into a software substrate for physical hypermedia services We conclude by indicating some further work we are pursuing.","2006","14","4","2025-12-02","https://university.edu/papers/b923cc0e-b2cc-4d3a-b6da-70ba12424f32.pdf");
INSERT INTO Paper VALUES ("1104","A framework to support alternative paths to provide the better end-to-end performance on the Internet","A common requirement to improve the end-to-end performance on the Internet is critical because the Internet becomes an infrastructure of our daily life. There have been many research studies to understand characteristics of the inside of the Internet and to try to improve the end-to-end performance with caching technologies in application programs. This paper proposes a new framework to improve the end-to-end performance on the Internet. The approach taken in this paper is to establish an alternative path between end-to-end hosts by the installation of rely hosts at the intermediate. The major advantage for previous caching studies can be easily applicable to all applications on a network path. The paper also describes the results of the experiment which measured a path quality of the intermediate link to select the better alternative path than the original path. This framework can be easily extended to construct a virtual network for the better performance on the Internet. The network provides the better performance for all Internet users.","2000","15","4","2025-12-02","https://university.edu/papers/8910579c-2785-4a52-b718-bb2df6715a81.pdf");
INSERT INTO Paper VALUES ("1105","On the Merits of Migrating to a Fully Packet-Based Mobile Backhaul RAN Infrastructure","This paper addresses the important issue of how to optimize the performance of the current mobile backhaul Radio Access Network (RAN) infrastructure to cope with the growing and dynamic nature of the emerging data-centric mobile multimedia traffic and services. Specifically, this work proposes and devises a simple and cost-effective EPON-based dynamic multiservice RAN architecture that efficiently transports and supports a wide range of existing and emerging data-centric mobile multimedia traffic and services along with the diverse quality of service (QoS) and rate requirements set by these services.","2009","13","3","2025-12-02","https://university.edu/papers/8030f6b6-af7c-45e9-80be-dd6d59983aeb.pdf");
INSERT INTO Paper VALUES ("1106","A high throughput deblocking filter design supporting multiple video coding standards","This paper presents a high throughput, VLSI architecture for multi-standard in-loop deblocking filter (ILF) supporting H.264 BP/MP/HP, AVS, and VC-1 video decoding. It comprises 38.4Kgates and 672bytes of local memory using TSMC 0.13µm CMOS technology when operating at 225 MHz which meets the real-time processing requirement for high-resolution video decoding. We develop a PDB scheme and an integrated 1-D filter to realize various coding tools of the deblocking filter supporting multiple video coding standards.","2009","2","3","2025-12-02","https://university.edu/papers/904780bb-fd39-4eb9-b78d-dfd94f475b6d.pdf");
INSERT INTO Paper VALUES ("1107","An improved adaptive rood pattern search for fast block-matching motion estimation in JVT/H.26L","Adaptive rood pattern search (ARPS) algorithm for fast block-matching motion estimation was recently proposed by Nie and Ma. Compared with the well-known diamond search, two to three times of speed-up improvement based on the MPEG-4 VM encoding platform has been accomplished. In this paper, an improved version of ARPS, denoted as ARPS-2, is proposed. Both APRS and ARPS-2 are incorporated into JVT/H.26L JM-4.2 encoding platform for conducting performance evaluation. Experimental results clearly show that both algorithms have achieved superb performance on computational gain. Furthermore, the ARPS-2 is slightly superior to ARPS.","2003","16","2","2025-12-02","https://university.edu/papers/ad9d5d0c-c861-42a8-b14b-429fd0c8ebda.pdf");
INSERT INTO Paper VALUES ("1108","Characteristics of Pupil Diameter Variation during Paying Attention to a Specific Image","The severely disabled people have difficulties in communication with other people because they can hardly move their body. To understand the intention of disabled people, communication devices using eye movement have been developed. In these systems, the user can click by keeping the stationary gaze during the predetermined time. However, the gaze stationarily induced by discursive looking may cause the unintended clicking. To solve this problem, we focused on the pupil diameter variation caused by attention. The pupil diameter variation has possibility of judging whether the user pays attention or not. In this paper, we investigate the characteristics of the pupil diameter variation during paying attention by using the visual stimuli. In the experiment, four images were randomly presented to subjects. The subjects counted the frequency of a specific image which subjects previously selected among four images. As a result, the pupil diameter during the presentation of the specific image is significantly larger than that of other 3 images from 1 to 2 s after visual stimulus presentation.","2015","11","1","2025-12-02","https://university.edu/papers/6d220b0a-0ff6-4cbd-b728-a2da43c539e0.pdf");
INSERT INTO Paper VALUES ("1109","Simulating the viability of water institutions under volatile rainfall conditions - The case of the Lake Naivasha Basin","This study views the Lake Naivasha Basin in Kenya's Rift Valley as a hydro-economic system with slowly emerging basin-wide water management institutions. Possible institutions face two interlinked challenges. Firstly, large scale horticultural activities as a core economic activity in the basin require substantial and regular amounts of irrigation water, abstracted from the lake and its aquifer. The lake level and thus irrigation water availability reveal a falling trend over the last two decades, which calls for institutions aimed at restricting further expansion in water use. Secondly, the region is characterized by volatile weather conditions where periods of average and above average rainfall have alternated with prolonged droughts for centuries. That leads to highly volatile water inflows into the lake. The two challenges combined thus call for water management institutions that support sustainable water use in both the short and the long run. This study therefore investigates the effect of water institutions already existing or proposed by local stakeholder organizations on preserving target lake levels against a background of highly volatile water availability which negatively affects the economic viability of institutions. To take the absence of functioning basin-wide coordination mechanisms for water allocation into account, we employ the solution format of Multiple Optimization Problems with Equilibrium Constraints (MOPEC) in our integrated hydro-economic model. Stochastic scenario simulations with the model reveal that compliance to water regulations and thus the viability of water institutions in the Naivasha Basin would require very high penalties which are not likely to be accepted by users. We develop a hydro-economic model for the Lake Naivasha Basin in Kenya.We simulate the local hydro-economic system under different water institutions.Formally, we solve a Multiple Optimization Problem with Equilibrium Constraints.We focus on the interaction between weather stochastics and water institutions.Results show that economic scarcity might undermine water institutions.","2016","10","4","2025-12-02","https://university.edu/papers/61a91dc8-8e89-43fc-be13-e2d1d85f4851.pdf");
INSERT INTO Paper VALUES ("1110","Human activity classification in people centric sensing exploiting sparseness measurement","Existing human activity recognition models in people centric sensing have explored different features of the mobile phone data to achieve considerable accuracy. However, the heterogeneity of such data caused by different phone carrying modes during data collection process remains a challenge. It has been observed by us that although the waveform of tri-axial accelerometer data varies in different modes, its sparseness within segmented frames tends to preserve in general. In this paper, we propose to adopt an augmented feature set by taking into account the sparseness measurement to improve the robustness of human activity classification. It has been shown in the experiment results that the sparseness features have a high importance ranking among the list. In addition, the experiment results show that the AUC measurement results of the Random Forest model can be improved both in single and mixed phone carrying modes, which justify the effectiveness of the sparseness measure in addressing the heterogeneity of tri-axial accelerometer data on mobile phones.","2015","14","2","2025-12-02","https://university.edu/papers/d1c92b4b-b634-4074-99a4-149127ed8b98.pdf");
INSERT INTO Paper VALUES ("1111","An online writer identification system using regression-based feature normalization and codebook descriptors","This paper describes a strategy to identify the authorship of online handwritten documents. We regard our research framework to that of a retrieval problem and adapt the so called codebook based Vector of Local Aggregate descriptor (VLAD) that has been promising for the object retrieval application in image processing. The codebook comprises a set of code vectors with associated Voronoi cells computed from a clustering algorithm on a set of feature vectors along the online trace. However, we show that the VLAD formulation at times, cannot effectively discriminate between writers, when their respective feature vectors are not linearly separable in the Voronoi cell of the code vectors. To overcome this problem, we propose a novel descriptor that improves upon the VLAD formulation. Secondly, we explore a normalization for the feature vectors prior to the generation of the VLAD. Our method is different to the min–max and z-score in that it takes care in ensuring that the codevectors are not influenced by the presence of outliers in the data. The performance of our proposed descriptor with the new feature normalization are evaluated on two publicly available Online Handwriting Databases – the IAM and IBM-UB1. The results show a marked improvement over the VLAD.","2017","19","2","2025-12-02","https://university.edu/papers/038a5698-3529-4c1d-8d45-2677e209b927.pdf");
INSERT INTO Paper VALUES ("1112","On the construction of the multimedia network TCSL dictionary","The multimedia network TCSL dictionary is a new media form, which is supported by the modern technologies, such as computer graphics, human-computer interaction technology, network transmission technology, speech input and output technology, 3D technology, panoramic simulation technology and so on. It is constituted of five main modules: search engine, vocabulary interface, thesaurus module, multimedia library and exercise bank. This dictionary has the following characteristics: fusion of multimedia elements, theme classification of vocabulary, openness of thesaurus system and powerful interactive function. Its successful experience in dictionary design and application of advanced technologies will profit the development of other types of teaching resources and ultimately promote the innovation and development of international Chinese teaching resources.","2011","18","2","2025-12-02","https://university.edu/papers/e35fb2fe-c0de-47c4-af0f-92803b20afb0.pdf");
INSERT INTO Paper VALUES ("1113","Image segmentation using situational DCT descriptors","It is of utmost importance in multimedia processing to achieve still image segmentation, i.e., to partition images into regions of coherent color and texture. We present a new image segmentation method using a special visual descriptor. For each pixel p, the discrete cosine transform (DCT) of the block centered on p together with its location in the image is employed as its content descriptor thus resulting int a long vector /spl nu//spl I.oarr//sub p/, referred to as situational DCT descriptors (SDDs). A scalar quantization step is then carried out on the DCT component of SDDs to reflect the fact that the human vision system is not of uniform discrimination to details of different frequencies. Next the principal component analysis is conducted to drastically reduce the dimensionality of SDDs. The adaptive K-mean algorithm is then performed to arrive at the region assignment for each pixel. The final partitioning results are obtained after performing the post-processing step. Experimental results using this method demonstrate encouraging performances.","2001","4","3","2025-12-02","https://university.edu/papers/fa4af4de-3167-452e-be5f-988a9e7df2a8.pdf");
INSERT INTO Paper VALUES ("1114","Innovative Decision Support in a Petrochemical Production Environment","Sasol, an integrated energy and chemicals company based in South Africa, leads the world in producing liquid fuels from natural gas and coal. Sasol faces many challenges, such as stricter fuel specifications, fluctuating oil and gas prices, and unique developing-world issues. Historically, the petrochemical industry based business decisions on average production limits. Sasol critically needed a better method to understand and include the effect of variability and dynamics in its decisions. The company's modeling operations using stochastic simulation (MOSS) methodology is an application of operations research that has helped to radically improve decision making. Sasol used this methodology to build three discrete-event simulation models spanning its unique coal-to-liquids value chain. The models have repeatedly proven their value by enhancing insights, enabling collaboration, ensuring efficient and effective production, and improving Sasol's bottom line. This work has applications in the wider chemical and fuels industries and represents a major step forward for operations research and chemical engineering.","2011","5","1","2025-12-02","https://university.edu/papers/8f255750-c53f-4e4b-a2d3-4330048ef868.pdf");
INSERT INTO Paper VALUES ("1115","Recursive filters for optical flow","Working toward efficient (real-time) implementations of optical flow methods, the authors have applied simple recursive filters to achieve temporal smoothing and differentiation of image intensity, and to compute 2d flow from component velocity constraints using spatiotemporal least-squares minimization. Accuracy in simulation is similar to that obtained in the study by Barren et al. (1994), while requiring much less storage, less computation, and shorter delays. >","1995","1","4","2025-12-02","https://university.edu/papers/915c2bec-7fcd-407b-b194-f149d61599be.pdf");
INSERT INTO Paper VALUES ("1116","Deriving Players & Themes in the Regesta Imperii using SVMs and Neural Networks","The Regesta Imperii (RI) are an important source for research in European-medieval history. Sources spread over many centuries of medieval history ‐ mainly charters of German-Roman Emperors ‐ are summarized as “Regests” and pooled in the RI. Interesting medieval demographic groups and players are i.a. cities, citizens or spiritual institutions (e.g. bishops or monasteries). Themes of historical interest are i.a. peace and war or the endowment of new privileges. We investigate the RI for important players and themes, applying state-of-the-art text classification methods from computational linguistics. We examine the performance of different classification methods in view of the linguistically very heterogeneous RI, including a Neural Network approach that is designed to capture complex interactions between players and themes.","2016","3","3","2025-12-02","https://university.edu/papers/6e72f1cf-ef2f-4300-bde3-e3c828082778.pdf");
INSERT INTO Paper VALUES ("1117","Distinct hippocampal and basal ganglia contributions to probabilistic learning and reversal","The hippocampus and the basal ganglia are thought to play fundamental and distinct roles in learning and memory, supporting two dissociable memory systems. Interestingly, however, the hippocampus and the basal ganglia have each, separately, been implicated as necessary for reversal learning-the ability to adaptively change a response when previously learned stimulus-outcome contingencies are reversed. Here, we compared the contribution of the hippocampus and the basal ganglia to distinct aspects of learning and reversal. Amnesic subjects with selective hippocampal damage, Parkinson subjects with disrupted basal ganglia function, and healthy controls were tested on a novel probabilistic learning and reversal paradigm. In this task, reversal can be achieved in two ways: Subjects can reverse a previously learned response, or they can select a new cue during the reversal phase, effectively 'opting out' of the reversal. We found that both patient groups were intact at initial learning, but differed in their ability to reverse. Amnesic subjects failed to reverse, and continued to use the same cue and response learned before the reversal. Parkinson subjects, by contrast, opted out of the reversal by learning a new cue-outcome association. These results suggest that both the hippocampus and the basal ganglia support reversal learning, but in different ways. The basal ganglia are necessary for learning a new response when a previously learned response is no longer rewarding. The failure of the amnesic subjects to reverse their response or to learn a new cue is consistent with a more general role for the hippocampus in configural learning, and suggests it may also support the ability to respond to changes in cue-outcome contingencies.","2009","12","1","2025-12-02","https://university.edu/papers/de22a094-b622-4611-b5c3-7fdc27fe42aa.pdf");
INSERT INTO Paper VALUES ("1118","Computing distances between NURBS-defined convex objects","Computing the distance between modelled objects is proving to be a fundamental operation for solving many problems in robotics and elsewhere. Most of the previous work in this area has focused on computing the distance between polyhedra, as the problem is easier to solve than the general case and the answer is sufficient for many problems. Here we focus on computing the distance between convex objects defined by NURBS curves or patches, for which the critical step is the evaluation of the support mapping. Experimental results are given for the two-dimensional case.","1998","2","2","2025-12-02","https://university.edu/papers/dbfeeb60-68c5-4fd9-ba89-f5b439442f2a.pdf");
INSERT INTO Paper VALUES ("1119","Fast Frequent Free Tree Mining in Graph Databases","Free tree, as a special graph which is connected, undirected and acyclic, is extensively used in domains such as computational biology, pattern recognition, computer networks, XML databases, etc. In this paper, we present a computationally efficient algorithm F3TM (Fast Frequent Free Tree Mining) to discover all frequent free trees in a graph database. We focus ourselves on how to reduce the cost of candidate generation and minimize the number of candidates being generated. We prove a theorem that the completeness of frequent free trees can be guaranteed by growing vertices from a limited range of vertices in a free tree. Two pruning techniques, automorphism-based pruning and pruning based on canonical mapping are proposed which significantly reduce the cost of candidate generation. We conducted experimental studies on a real application dataset and we show that our F3TM outperforms the upto- date algorithms by an order of magnitude.","2006","12","2","2025-12-02","https://university.edu/papers/7adbc351-8116-461c-93fd-b699b8fe810d.pdf");
INSERT INTO Paper VALUES ("1120","Aesthetics of color combinations","The previous literature on the aesthetics of color combinations has produced confusing and conflicting claims. For example, some researchers suggest that color harmony increases with increasing hue similarity whereas others say it increases with hue contrast. We argue that this confusion is best resolved by considering three distinct judgments about color pairs: (a) preference for the pair as a whole, (b) perceived harmony of the two colors, and (c) preference for the figural color when viewed against the background color. Empirical support for this distinction shows that pair preference and harmony ratings both increase as hue similarity increases, but preference correlates more strongly with component color preferences and lightness contrast than does harmony. Although ratings of both pair preference and harmony decrease as hue contrast increases, ratings of figural color preference increase as hue contrast with the background increases. Our results refine and clarify well-known and often contradictory claims of artistic color theory.","2010","6","4","2025-12-02","https://university.edu/papers/a8008aa9-29a3-4a8f-9723-3aa97023cbdc.pdf");
INSERT INTO Paper VALUES ("1121","Finding overlapping communities in multiplex networks","We define an approach to identify overlapping communities in multiplex networks, extending the popular clique percolation method for simple graphs. The extension requires to rethink the basic concepts on which the clique percolation algorithm is based, including cliques and clique adjacency, to allow the presence of multiple types of edges.","2016","8","3","2025-12-02","https://university.edu/papers/186ea6bd-bf24-408e-92ad-5f6a7c5788b0.pdf");
INSERT INTO Paper VALUES ("1122","A modified cyclostationary spectrum sensing based on softmax regression model","In this paper, a modified Cyclostationary Feature Detection (CFD) algorithm based on softmax regression model is proposed, which targets for improving the sensing performance under low signal-to-noise ratio (SNR). The softmax regression model provides excellent classification performance; moreover, it is simple and runs fast compared with other classification algorithms in machine learning. Therefore we choose this model to be used for spectrum sensing, which happens to be a binary hypothesis-testing problem. In this method, cyclostationary characteristic parameters were extracted as the training set and test set Then the softmax classifier which had been trained was used to detect the primary user (PU) exists or not. Numerical results show that the proposed spectrum sensing method has better sensing performance than the traditional CFD method.","2016","6","3","2025-12-02","https://university.edu/papers/4f64976a-391e-4b54-b93e-e1b019bedcca.pdf");
INSERT INTO Paper VALUES ("1123","Grammatik mit Widersprüchen","Dieser Aufsatz skizziert wichtige Aspekte der Optimalitatstheorie, die in der theoretischen Linguistik erhebliche Bedeutung erlangt hat. Sie stellt ein System von Prinzipien dar, die potenziell zueinander in Konflikt stehen. Die Konflikte werden in einer strikten Hierarchie der Prinzipien aufgelost. Wir zeigen, dass die Optimalit atstheorie in vielen Dimension ein sehr viel restriktiveres Modell der Sprachkompetenz darstellt als ihre Konkurrenten. Auch sind im wesentlichen die Vorhersagen erfullt, die sich aus der spezifischen Art der Konfliktlosung ergeben. Modifikationen scheinen im Bereich der Gradierung von Grammatikalit at beim Problem der Ineffability geboten.","2015","11","4","2025-12-02","https://university.edu/papers/d3c3496a-170c-430a-87cc-7b08de1fb329.pdf");
INSERT INTO Paper VALUES ("1124","An Information Integration Framework Based on XML to Support Mechatronics Multi-disciplinary Design","To implement the information integration of multi-disciplinary applications, an information integration framework of mechatronics system multi-disciplinary design is developed. This developed integration framework adopts a XML Web service based architecture which facilitates the seamless information integration in Internet environments. MSCIM (mechatronics system common information model) is defined as well as the standard data access interfaces are specified. MSCIM includes all the major objects and the relationships of objects in the process of mechatronics systems design. As a neutral and Web-friendly industry standard, the XML schema is used as the formal definition language of the MSCIM. DAF (data access facility) is adopted as the standard data access interface and the accurate definition is given via WSDL. Standard data access interfaces are implemented through SOAP (simple object access protocol) over HTTP which provides the multi-disciplinary design application with a generic way to exchange information and access public data. Furthermore, this information integration framework provides the multi-disciplinary engineers with an integrated logical view of mechatronics systems and realizes cooperation of multi-disciplinary teams which shortens the development cycle and saves the cost at the same time in mechatronics multi-disciplinary design.","2008","7","2","2025-12-02","https://university.edu/papers/afe41d6c-ce44-4c28-9235-2f8aeabf7694.pdf");
INSERT INTO Paper VALUES ("1125","The perceptions of CEIT postgraduate students regarding reality concepts: Augmented, virtual, mixed and mirror reality","The purpose of this study is to determine perception of postgraduate Computer Education and Instructional Technologies (CEIT) students regarding the concepts of Augmented Reality (AR), Virtual Reality (VR), Mixed Reality (MR), Augmented Virtuality (AV) and Mirror Reality; and to offer a table that includes differences and similarities between these concepts. This study also aims to determine the likelihood of CEIT postgraduate students for using the said concepts in education. In this context, the frequently used reality concepts in the CEIT field have been examined from the perspective of the participants and in terms of the following traits: frequency of potential use, perceived usefulness, and perceived effectiveness. The phenomenological method was used in this qualitative study. 10 CEIT graduate students have been the participants of this research; with 4 of these pursuing a PhD and 6 pursuing a Master’s Degree. 14 open-ended questions related to AR, VR, MR, AV and Mirror Reality concepts were used throughout semi-structured and face-to-face interviews in order to collect data. Findings show that AR and VR are the most familiar concepts. Participants have several misconceptions about the reality concepts but the least amount of misconception was associated with AR and VR. Most of the participants had no idea about MR and none of them had any idea about Mirror Reality. Findings refer that VR is the most frequently used kind of reality owing to the fact that it can be developed and implemented more easily and there are several AR studies because of its current popularity.","2017","1","1","2025-12-02","https://university.edu/papers/703f93ce-8013-4623-84d7-a5e5e419b9fa.pdf");
INSERT INTO Paper VALUES ("1126","Fast similarity search and clustering of video sequences on the world-wide-web","We define similar video content as video sequences with almost identical content but possibly compressed at different qualities, reformatted to different sizes and frame-rates, undergone minor editing in either spatial or temporal domain, or summarized into keyframe sequences. Building a search engine to identify such similar content in the World-Wide Web requires: 1) robust video similarity measurements; 2) fast similarity search techniques on large databases; and 3) intuitive organization of search results. In a previous paper, we proposed a randomized technique called the video signature (ViSig) method for video similarity measurement. In this paper, we focus on the remaining two issues by proposing a feature extraction scheme for fast similarity search, and a clustering algorithm for identification of similar clusters. Similar to many other content-based methods, the ViSig method uses high-dimensional feature vectors to represent video. To warrant a fast response time for similarity searches on high dimensional vectors, we propose a novel nonlinear feature extraction scheme on arbitrary metric spaces that combines the triangle inequality with the classical Principal Component Analysis (PCA). We show experimentally that the proposed technique outperforms PCA, Fastmap, Triangle-Inequality Pruning, and Haar wavelet on signature data. To further improve retrieval performance, and provide better organization of similarity search results, we introduce a new graph-theoretical clustering algorithm on large databases of signatures. This algorithm treats all signatures as an abstract threshold graph, where the distance threshold is determined based on local data statistics. Similar clusters are then identified as highly connected regions in the graph. By measuring the retrieval performance against a ground-truth set, we show that our proposed algorithm outperforms simple thresholding, single-link and complete-link hierarchical clustering techniques.","2005","1","1","2025-12-02","https://university.edu/papers/5129753a-7fb2-46fc-b6f7-80d4c7ea0240.pdf");
INSERT INTO Paper VALUES ("1127","Fault estimation and active fault tolerant control for servo systems","In this paper, the problems of fault estimation and fault tolerant control for motor servo systems are investigated. The motor servo systems are modeled as continuous-time linear systems with unknown inputs and actuator faults. Based on the faulty system model, a robust fault estimation and active fault tolerant control scheme is proposed. In this scheme, an observer-based robust fault estimator is designed to obtain the magnitude and characteristics of the faults; then, on the basis of the estimated fault information, an output feedback active fault tolerant controller is constructed to keep the post-fault dynamic system robust asymptotically stable. Simulation results illustrate the applicability and effectiveness of the proposed approach.","2016","17","4","2025-12-02","https://university.edu/papers/0a2df899-701c-4790-9f9b-19106ea602d6.pdf");
INSERT INTO Paper VALUES ("1128","A Table-Based Approach to Study the Impact of Process Variations on FinFET Circuit Performance","This paper presents a novel table-based approach for efficient statistical analysis of Finfield effect transistor circuits. The proposed approach uses a new scheme for interpolation of look-up tables (LUTs) with respect to process parameters. The effect of various process parameters, viz., channel length, fin width, and effective oxide thickness is studied for three circuits: buffer chain, static random access memory cell, and high-gain low-voltage op-amp. Compared to mixed-mode (device-circuit) simulation, the proposed LUT-based approach is shown to be much faster, thus making it practically a feasible and attractive option for variability analysis especially for emerging technologies where compact models are not available for circuit simulation.","2010","16","1","2025-12-02","https://university.edu/papers/f1d3bcae-ece3-4775-9936-3739b847d996.pdf");
INSERT INTO Paper VALUES ("1129","Self-excited dynamic active antenna","Proposes the self-excited dynamic active antenna (SDAA) that can detect a contact location between an insensitive flexible beam and an object through observation of the fundamental natural frequency of the beam in contact with the object. The main, part of SDAA is composed of a flexible beam, one permanent magnet and two electromagnets not only for producing the exciting motion but also for changing the boundary condition of the beam. We show that the contact position is uniquely determined by utilizing the fundamental natural frequencies before and after changing the boundary condition. We present the basic working principle of SDAA and show some experimental results to verify the idea.","1997","6","3","2025-12-02","https://university.edu/papers/5b45d799-286f-454d-a70d-a4abe406c6d1.pdf");
INSERT INTO Paper VALUES ("1130","Software implementation of a recursive fault tolerance algorithm on a network of computers","RAFT is a recursive algorithm for fault tolerance that uses a combination of dynamic space and time redundancy techniques for detecting faulty processors and recovering from errors.  U  *  is a multicomputer testbed consisting of a network of AT&T 3B2 computers running a network operating system based on the UNIX system. This paper describes a software implementation of RAFT on  U  * , and demonstrates the effectiveness of a RAFT-like scheme for designing fault-tolerant multicomputer systems. Results of Monte Carlo experiments, conducted on this system that validated the theoretical basis of RAFT, are presented. Experimentally observed performance penalty, incurred due to fault tolerance, is also presented.","1986","10","1","2025-12-02","https://university.edu/papers/f7e4a9e0-63bd-4b1b-8066-932697890bf0.pdf");
INSERT INTO Paper VALUES ("1131","An agent-oriented model of a dynamic engineering design process","One way to make engineering design effective and efficient is to make its processes flexible i.e. self-adjusting, self-configuring, and self-optimizing at run time. This paper presents the descriptive part of the Dynamic Engineering Design Process (DEDP) modelling framework developed in the PSI project. The project aims to build a software tool to assist managers to analyse and enhance the productivity of the DEDPs through process simulations. The framework incorporates the models of teams and actors, tasks and activities as well as design artefacts as the major interrelated parts. DEDPs are modelled as weakly defined flows of tasks and atomic activities that may only “become apparent” at run time because of several presented dynamic factors. The processes are self-formed through the mechanisms of collaboration in the dynamic team of actors. These mechanisms are based on contracting negotiations. DEDP productivity is assessed by the Units of Welfare collected by the multi-agent system that models the design team. The models of the framework are formalized in the family of PSI ontologies.","2005","8","2","2025-12-02","https://university.edu/papers/ce374861-3db7-417f-a616-d78afc39f364.pdf");
INSERT INTO Paper VALUES ("1132","A Classification of Challenges in the Semantic Web Based on the General Architecture","The Semantic Web has the purpose of making information available and understandable for computers and humans. However, some issues and challenges are present during this process. This paper presents a proposal of challenges in the Semantic Web. In this sense, we have considered an organization of three categories based on the general architecture proposed by Berners-Lee: Representation, Reasoning/Querying, and Quality. We also mention some methods for partially solving these challenges, and drawbacks of using machine learning approaches.","2015","2","3","2025-12-02","https://university.edu/papers/322a4ceb-0b64-4583-8ada-e1c836ab6782.pdf");
INSERT INTO Paper VALUES ("1133","Prediction of molecular volume and surface of alkanes by molecular topology","Molecular volume and molecular surface are expressed as a function of topological degree in alkane graphs. This allows not only a straightforward approach to calculate such physicochemical magnitudes but also an interpretation of the role of the local vertex invariant (LOVI) or valence degree, 6, as well as the connectivity indices in the prediction of physicochemical properties. The interpretation is based on the concept of molecular accessibility (as introduced by Estrada, J. Phys. Chem. A 2002, 106, 9085) for which precise mathematical definitions are provided.","2003","4","4","2025-12-02","https://university.edu/papers/49a22ab4-f376-4e6b-afae-2b2c679ee570.pdf");
INSERT INTO Paper VALUES ("1134","Two-dimensional time-division multiplexing for 3D-SoCs","Through-silicon vias (TSVs) are used as high-speed interconnects between dies in a 3D System-on-Chip (SoC). However, their speed cannot be utilized during test application due to inherent limitations of the scan chains of the cores, which prevent the use of high shift frequencies. Moreover, due to their high area cost, only a limited number of TSVs can be used for test application. As a result, the time needed for transferring test data to the cores in multiple dies can be considerable. We propose an efficient test-access mechanism (TAM) architecture, which exploits the high speed of TSVs to minimize the time for testing 3D SoCs. By the means of time-division multiplexing and an effective test scheduling method, the proposed TAM architecture offers significant savings in test time, TSV count and TAM cost.","2016","13","2","2025-12-02","https://university.edu/papers/7d6d6216-3ff9-4553-ba9f-f3f4a7a3b7bf.pdf");
INSERT INTO Paper VALUES ("1135","Any Beamsplitter Generates Universal Quantum Linear Optics","In 1994, Reck et al. showed how to realize any linear-optical unitary transformation using a product of beamsplitters and phaseshifters. Here we show that any single beamsplitter that nontrivially mixes two modes, also densely generates the set of m × m unitary transformations (or orthogonal transformations, in the real case) on m ≥ 3 modes. (We prove the same result for any 2-mode real optical gate, and for any 2-mode optical gate combined with a generic phaseshifter.) Experimentally, this means that one does not need tunable beamsplitters or phaseshifters for universality: any nontrivial beamsplitter is universal. Theoretically, it means that one cannot produce “intermediate” models of quantum-optical computation (analogous to the Clifford group for qubits) by restricting the allowed beamsplitters and phaseshifters: there is a dichotomy; one either gets a trivi al set or else a universal set. No similar classification theorem for gates acting on qubits is currently know n. We leave open the problem of classifying optical gates that act on 3 or more modes.","2013","9","1","2025-12-02","https://university.edu/papers/7245aa30-d19f-485c-a1d3-34d861e0a871.pdf");
INSERT INTO Paper VALUES ("1136","A smooth fictitious domain/multiresolution method for elliptic equations on general domains","We propose a smooth fictitious domain/multiresolution method for enhancing the accuracy order in solving second order elliptic partial differential equations on general bivariate domains. We prove the existence and uniqueness of the solution of a corresponding discrete problem and a so-called interior error estimate which justifies the improved accuracy order. Numerical experiments are conducted on a Cassini oval.","2016","3","1","2025-12-02","https://university.edu/papers/000b054b-8c73-432e-b6e5-b531a2072a28.pdf");
INSERT INTO Paper VALUES ("1137","Language Model Adaptation for Lecture Transcription by Document Retrieval","With the spread of MOOCs and video lecture repositories it is more important than ever to have accurate methods for automatically transcribing video lectures. In this work, we propose a simple yet effective language model adaptation technique based on document retrieval from the web. This technique is combined with slide adaptation, and compared against a strong baseline language model and a stronger slide-adapted baseline. These adaptation techniques are compared within two different acoustic models: a standard HMM model and the CD-DNN-HMM model. The proposed method obtains improvements on WER of up to 14% relative with respect to a competitive baseline as well as outperforming slide adaptation.","2014","17","4","2025-12-02","https://university.edu/papers/3e398ca5-b598-4356-be62-d5dec1dbce0f.pdf");
INSERT INTO Paper VALUES ("1138","Experiments of HMM adaptation for hands-free connected digit recognition","A scenario concerning hands-free connected digit recognition in a noisy office environment is investigated. An array of six omnidirectional microphones and a corresponding time delay compensation module are used to provide a beamformed signal as input to a hidden Markov model (HMM) based recognizer. Two different techniques of phone HMM adaptation have been considered, to reduce the mismatch between training and test conditions. Adaptation material and test material were collected in two different sessions. Results show that a digit accuracy close to 98% can be achieved when the talker is at 1.5 m distance from the array. This result has to be compared with 99.5% accuracy obtained by using a close-talk microphone.","1998","1","1","2025-12-02","https://university.edu/papers/891f8f4c-f5d7-4ce7-8335-8f60620aaedb.pdf");
INSERT INTO Paper VALUES ("1139","PARFAIT: towards a framework-based agile reengineering process","We present a sketch of a framework-based agile reengineering process, named PARFAIT, whose objective is to provide the users with evolved versions of legacy systems, as soon as possible. The overall static structure of the rational unified process (RUP), originally developed for forward systems engineering, has been here adapted for reengineering and is used for PARFAIT documentation. Frameworks are used in the process aiming at an agile approach to support the reengineering. Frameworks allow applications to be rapidly created, more than if they are built from scratch. Agile characteristics, such as incremental approach, cooperative approach with users and customers, straightforwardness, etc. give PARFAIT the ability to support the rapid evolution of the legacy system to a new version, according to the users and customers needs. A summary of a case study and the results obtained in the reengineering are presented. This study refers to a concrete reengineering case of a real system for controlling entry and exit of electronic appliances in a repair shop.","2003","18","2","2025-12-02","https://university.edu/papers/af9c4fdc-085f-464a-98cc-0d5d516c4125.pdf");
INSERT INTO Paper VALUES ("1140","Bluetooth RSSI based collision avoidance in multirobot environment","Multi-robot system is gaining its importance in robotic research. One critical issue in multi-robot system is collision among the mobile robots while sharing same workspace. This paper deals with the collision-free path planning for multiple mobile robots using Bluetooth RSSI value. In the proposed collision avoidance algorithm a decentralized approach with fixed priority level for robots is considered. A variable speed technique based on the RSSI value of robots is used and the obstacle avoidance is implemented based on State based Obstacle Avoidance Algorithm. Proposed algorithm is implemented and tested using Webots 3D simulator.","2016","4","4","2025-12-02","https://university.edu/papers/f5569b67-46ef-4d71-8aa4-c6b43770947a.pdf");
INSERT INTO Paper VALUES ("1141","An English and/or Japanese writing support tool based on a web search engine","This paper proposes a writing support tool for learners of English and/or Japanese as a second language based on a web search engine. The proposed tool can support language learners writing a sentence in English and/or Japanese. The proposed tool consists of a composition and a learning support module. The composition support module searches example sentences and word usage on the web, and verifies given sentences and expressions by the hit count and the statistical analysis on snippets provided by the search engine. It produces a table and a graph based on the hit count of those queries, and it provides example sentences based on learner's vocabulary level. We consider that search logs include important information for learning support. The learning support module analyses each/all learner's search log and provides effective learning supports. By using the proposed tool, learners can search example sentences which they need, verify entered sentences and expressions, and learn languages effectively.","2010","7","3","2025-12-02","https://university.edu/papers/a6b07fae-b22e-4372-ac3d-026e5e79c603.pdf");
INSERT INTO Paper VALUES ("1142","A Novel Predictive Handover Protocol for Mobile IP in Vehicular Networks","Vehicular networking is an emerging technology that offers the potential of providing a variety of new services. However, extending vehicular networks to include internet protocol (IP) connections is still problematic, due in part to the incompatibility of mobile IP handovers with the increased mobility of vehicles. The handover process, consisting of discovery, registration, and packet forwarding, has a large overhead and disrupts connectivity. With increased handover frequency and smaller access-point (AP) dwell times in vehicular networks, the handover causes a large degradation in performance. This paper proposes a predictive handover protocol, using a combination of a Kalman filter (KF) and an online hidden Markov model (HMM), to minimize the effects of prediction errors and to capitalize on advanced handover registration. Extensive simulated experiments were carried out in the network simulator ns-2 to study the performance of the proposed protocol within a variety of traffic and network topology scenarios. Results show a significant improvement to both prediction accuracy and network performance when compared with recent proposed approaches.","2016","11","4","2025-12-02","https://university.edu/papers/4ad170e5-b78b-4513-a8d8-758f301b39a9.pdf");
INSERT INTO Paper VALUES ("1143","Joint Beamforming and Antenna Subarray Formation for MIMO Cognitive Radios","The antenna subarray formation (ASF) is a promising technique for multiple-input multiple-output (MIMO) receiver. For MIMO cognitive radio systems, we propose a joint beamforming and ASF scheme in this letter which maximizes the cognitive achievable capacity subject to the peak transmit power constraint at the secondary transmitter, peak interference power constraint at the primary receiver, and the limited number of nonzero elements in the ASF matrix. To solve the joint optimization problem, we propose a relax-and-recover scheme. Simulation results have shown that the proposed scheme outperforms the conventional antenna selection scheme.","2013","17","1","2025-12-02","https://university.edu/papers/8652b3c7-2fe7-450e-a5c7-6f19813a1473.pdf");
INSERT INTO Paper VALUES ("1144","Provable Bayesian Inference via Particle Mirror Descent","Bayesian methods are appealing in their flexibility in modeling complex data and ability in capturing uncertainty in parameters. However, when Bayes' rule does not result in tractable closed-form, most approximate inference algorithms lack either scalability or rigorous guarantees. To tackle this challenge, we propose a simple yet provable algorithm, \emph{Particle Mirror Descent} (PMD), to iteratively approximate the posterior density. PMD is inspired by stochastic functional mirror descent where one descends in the density space using a small batch of data points at each iteration, and by particle filtering where one uses samples to approximate a function. We prove result of the first kind that, with $m$ particles, PMD provides a posterior density estimator that converges in terms of $KL$-divergence to the true posterior in rate $O(1/\sqrt{m})$. We demonstrate competitive empirical performances of PMD compared to several approximate inference algorithms in mixture models, logistic regression, sparse Gaussian processes and latent Dirichlet allocation on large scale datasets.","2015","10","3","2025-12-02","https://university.edu/papers/cf3f48bb-b30a-44c8-9e32-e38a98e89193.pdf");
INSERT INTO Paper VALUES ("1145","Collaborative business transactions management: issues and challenges","Summary form only given. This tutorial seeks to discuss the key concepts in collaborative business transaction management. Its intent is to explain the concept in business transaction and how it is different from traditional database transaction and workflow transaction management, to evaluate existing approaches, and to present existing techniques from other areas that can be adopted for business transactions and their limitations, and lastly to discuss a framework that addresses the challenges that are unique to business transaction management in the service oriented environment.","2005","15","2","2025-12-02","https://university.edu/papers/bb3e1373-bf63-473e-98c3-8e714562f315.pdf");
INSERT INTO Paper VALUES ("1146","The disentangling number for phylogenetic mixtures","We provide a logarithmic upper bound for the disentangling number on unordered lists of leaf labeled trees. This result is useful for analyzing phylogenetic mixture models. The proof depends on interpreting multisets of trees as high-dimensional contingency tables.","2012","4","3","2025-12-02","https://university.edu/papers/f984cb9d-b23e-4f77-a519-d316fc2d0e43.pdf");
INSERT INTO Paper VALUES ("1147","Rollout Algorithms for Stochastic Scheduling Problems","Stochastic scheduling problems are difficult stochastic control problems with combinatorial decision spaces. In this paper we focus on a class of stochastic scheduling problems, the quiz problem and its variations. We discuss the use of heuristics for their solution, and we propose rollout algorithms based on these heuristics which approximate the stochastic dynamic programming algorithm. We show how the rollout algorithms can be implemented efficiently, with considerable savings in computation over optimal algorithms. We delineate circumstances under which the rollout algorithms are guaranteed to perform better than the heuristics on which they are based. We also show computational results which suggest that the performance of the rollout policies is near-optimal, and is substantially better than the performance of their underlying heuristics.","1999","19","4","2025-12-02","https://university.edu/papers/66116e80-eca9-4969-8ef1-f7b3bc5f1b73.pdf");
INSERT INTO Paper VALUES ("1148","Subadaptive piecewise linear quantization for speech signal (64 kbit/s) compression","We propose a simple speech compression algorithm using subband division and subadaptive piecewise linear quantization for a voice-mail system. Voice mail is an audio equivalent of sending letters. The main differences are that computer networks deliver the mail and that electronic recording is used instead of letters. Although speech data are stored in a semiconductor memory device, its capacity and the available network capacity are limited. Therefore, it is necessary to compress the data as much as possible. However, there are two conditions to be satisfied. The first is that the reconstructed datum must be understood correctly. Second, we need to identify the sender. Signals with a rate of 64 kbit/s are compressed at a ratio of about 1/9 using the proposed subband division and subadaptive piecewise linear quantization.","1996","13","3","2025-12-02","https://university.edu/papers/7811c51d-6d50-46c2-8d42-94ba95549fed.pdf");
INSERT INTO Paper VALUES ("1149","Extending Limabeam with discrimination and coarse gradients.","Limabeam is an approach to multi-microphone array processing for ASR which makes minimal assumptions about system geometry, instead searching for filters to maximise output likelihoods under a speech model. The first results of Limabeam on the AMI meeting corpus are given, then two extensions of the algorithm for this corpus. First, it is shown that the original local gradient following sticks in local minima, and a coarser gradient is used. Second, a new discriminative objective function is provided to handle mismatched silence models. The extensions are based on examination of 2D receptive fields and 2D likelihood maps which are novel near-field analogs of radial beamformer response patterns, but do not show radial symmetry and have many local minima. The extended Limabeam improves WER on TDOA baselines on the AMI corpus, by 1% rel. when both are adapted with decodes and by 19% rel. when both adapted with ground truth.","2014","14","1","2025-12-02","https://university.edu/papers/e8e2f27c-c55f-42ca-8277-46b7a943a2e0.pdf");
INSERT INTO Paper VALUES ("1150","An Entrainment-Based Model of Temporal Organizational Fit, Misfit, and Performance","Entrainment refers to the synchronization of the tempo and/or phase of two or more activities within a system. This article utilizes entrainment theory to develop a conceptual model and related propositions describing and explaining the relationship between temporal fit, misfit, and performance at the organizational level of analysis. Essential to the development of our model is the concept of organization-environment (O-E) temporal fit, which is a state of synchronization or alignment of organization and environment activity cycles. O-E temporal fit is positioned as an important contingency element because temporal misfit implies inefficiencies, substandard performance, and the potential death of the organization over time. Overall, this article offers a theoretical perspective that fills a gap in the extant organizational research literature regarding the elusive and understudied perspective of time and posits its relationship to organizational performance.","2008","8","4","2025-12-02","https://university.edu/papers/7c233140-b5b9-461d-b5ca-5ddc354f46cc.pdf");
INSERT INTO Paper VALUES ("1151","HITS' Cross-lingual Entity Linking System at TAC 2011: One Model for All Languages","This paper presents HITS’ system for crosslingual entity linking at TAC 2011. We approach the task in three stages: (1) context disambiguation to obtain a language-independent representation, (2) entity disambiguation, (3) clustering of the queries that have not been linked in the second step. For each of these steps one single model is trained and applied to both languages, i.e. English and Chinese. A multilingual knowledge base derived from Wikipedia is at the core of the system. The results achieved in the TAC cross-lingual entity task support our one-model-for-all-languages approach: the F1 scores of all three runs we submitted exceed the median value by 4.8 to 5.5 percent points.","2011","18","3","2025-12-02","https://university.edu/papers/f3bf8381-3fa1-4576-b347-364a3033e581.pdf");
INSERT INTO Paper VALUES ("1152","An Automated Detection Process to Detect Ovarian Tissues Using Type P63 Digitized Color Images","Dramatic improvements have been made in the field of digital image processing especially for biomedical image analysis over the past decade. With the availability of modern digital scanners, histopathology slides can be easily stored in digitized color image format. Therefore, histopathology digitized images have become a popular data source for both computer vision and machine learning techniques. There are several computer aided algorithms currently available to assist pathology experts to carry out their routine examination for detecting various tissues such as ovarian cancer cells and ovarian reproductive tissues. Automated detection of ovarian reproductive tissues is one of the important diagnosis interests for pathologists these days. One of the popular diagnosis preferences to identify ovarian tissues is ultrasound scanner. However, due to different shape, size and color, identification of ovarian tissues is a challenging task for ultrasound scanners as it process gray scale images. At present, pathological microscopic manual analysis is considered the best laboratory analysis practice for ovarian tissue cells although it is time-consuming, laborious and prone to errors. An alternate option would be to analyze these ovarian tissues automatically using color digitized images acquired from microscopic slides. In this paper a fully automated detection approach for color digitized image acquired from microscopic slides is presented and analyzed. The proposed method was found to be faster in comparison to other approaches. The approach also is beneficial as experts will not need to tune processing parameters for new batches of images. Experimental results from an analysis of the proposed approach using batch processing of a large number of images indicated high degree of accuracy and performance compared to the manual microscopic analysis.","2015","16","3","2025-12-02","https://university.edu/papers/f8d95016-2b9c-431a-afda-54e0cdf238fd.pdf");
INSERT INTO Paper VALUES ("1153","Number of connected spanning subgraphs on the Sierpinski gasket","We study the number of connected spanning subgraphs f(d,b) (n) on the generalized Sierpinski gasket SG(d,b) (n) at stage n with dimension d equal to two, three and four for b = 2, and layer b equal to three and four for d = 2. The upper and lower bounds for the asymptotic growth constant, defined as zSG(d,b) = lim(v ->infinity) ln f(d,b)(n)/v where v is the number of vertices, on SG(2,b) (n) with b = 2, 3, 4 are derived in terms of the results at a certain stage. The numerical values of zSG(d,b) are obtained.","2009","18","2","2025-12-02","https://university.edu/papers/e206d1ee-5fe9-4db8-be31-4251abdb9bfb.pdf");
INSERT INTO Paper VALUES ("1154","Bipartite spectral graph partitioning for clustering dialect varieties and detecting their linguistic features","In this study we use bipartite spectral graph partitioning to simultaneously cluster varieties and identify their most distinctive linguistic features in Dutch dialect data. While clustering geographical varieties with respect to their features, e.g. pronunciation, is not new, the simultaneous identification of the features which give rise to the geographical clustering presents novel opportunities in dialectometry. Earlier methods aggregated sound differences and clustered on the basis of aggregate differences. The determination of the significant features which co-vary with cluster membership was carried out on a post hoc basis. Bipartite spectral graph clustering simultaneously seeks groups of individual features which are strongly associated, even while seeking groups of sites which share subsets of these same features. We show that the application of this method results in clear and sensible geographical groupings and discuss and analyze the importance of the concomitant features.","2011","13","1","2025-12-02","https://university.edu/papers/a2751dd4-4e2c-4686-bad5-6262e48dbd1d.pdf");
INSERT INTO Paper VALUES ("1155","The Flood-Gate Principle - a Hybrid Approach to a High Security Solution *","The classical role of a firewall consists in protec ting a computer network against attacks from the outside world, espe cially the Internet. Firewalls are often expensive, hard to configure and they are comprehended only by experts. Sometimes the level of security is t oo high to use a firewall, and information flow has not to be 'online'. Here we prop ose to use 'flood- gates' as described in the following. They provide a modern , simple and easy- to-understand method to secure a network on a very high se curity level. E- mails, plain files and all sorts of electronic data can be exchanged over such flood-gates without possibly compromising the 'own' network by the most dangerous classes of attacks. Information passes through the flood-gates even though there is not a single moment of a physically conne ction between the own network and the outside world. The disadvantage of service restrictions can be overcome by a multilevel security approach. As a pr actical example a concrete 'real-life' implementation of the flood-gate principle in the financial sector is described in detail in this paper.","1998","16","4","2025-12-02","https://university.edu/papers/a95ef075-2d20-47a8-bb38-8d3bfdc8baa4.pdf");
INSERT INTO Paper VALUES ("1156","The Jakes fading model for antenna arrays incorporating azimuth spread","A new method for simulating the multiplicative fading of the narrow-band, flat wireless channel for antenna array receivers is presented. The new approach produces a set of fading waveforms, one waveform associated with each receiver element, in which the waveforms are appropriately correlated to take into account the spread, or dispersion, in the azimuth (arrival angle) of the received signal. The new method is an extension of the Jakes (1974) method of simulating fading in which the appropriate correlation of the set of waveforms is accomplished by directly considering the azimuth of scatterers in a particular distribution about the mobile transmitter. The models used for this cluster of scatterers are a ring and a disk of scatterers. Further modifications of the disk model permit the generation of fading waveforms which are correlated in a manner which reflect actual field measurements of azimuth dispersion. Analytical correlation of these models is reviewed for purposes of verification with the waveforms generated by the method.","2002","12","1","2025-12-02","https://university.edu/papers/fba290c0-9f83-46e2-994e-3dc5bd0b1ccd.pdf");
INSERT INTO Paper VALUES ("1157","An Algorithm for Modifying Neurotransmitter Release Probability Based on Pre- and Postsynaptic Spike Timing","The precise times of occurrence of individual pre- and postsynaptic action potentials are known to play a key role in the modification of synaptic efficacy. Based on stimulation protocols of two synaptically connected neurons, we infer an algorithm that reproduces the experimental data by modifying the probability of vesicle discharge as a function of the relative timing of spikes in the pre- and postsynaptic neurons. The primary feature of this algorithm is an asymmetry with respect to the direction of synaptic modification depending on whether the presynaptic spikes precede or follow the postsynaptic spike. Specifically, if the presynaptic spike occurs up to 50 ms before the postsynaptic spike, the probability of vesicle discharge is upregulated, while the probability of vesicle discharge is downregulated if the presynaptic spike occurs up to 50 ms after the postsynaptic spike. When neurons fire irregularly with Poisson spike trains at constant mean firing rates, the probability of vesicle discharge converges toward a characteristic value determined by the pre- and postsynaptic firing rates. On the other hand, if the mean rates of the Poisson spike trains slowly change with time, our algorithm predicts modifications in the probability of release that generalize Hebbian and Bienenstock-Cooper-Munro rules. We conclude that the proposed spike-based synaptic learning algorithm provides a general framework for regulating neurotransmitter release probability.","2001","15","2","2025-12-02","https://university.edu/papers/de5bae50-aca9-472d-ae23-9c21f8a4e97c.pdf");
INSERT INTO Paper VALUES ("1158","A CMOS Thermal Sensor and Its Applications in Temperature Adaptive Design","With transistor feature size scaling and higher integration density, power density has become a major problem. High power density results in elevated on chip temperature, which has significant impacts on power consumption and circuit reliability. In this work, we have presented a temperature adaptive design technique using a novel low overhead CMOS temperature sensor. We have shown that, by online monitoring of temperature, circuit power consumption can be adjusted adaptively so as to stabilize the chip temperature and achieve a robust design.","2006","19","1","2025-12-02","https://university.edu/papers/a4453651-1c13-4e3a-a6a2-093f4566d21d.pdf");
INSERT INTO Paper VALUES ("1159","A novel perspective on stereophonic acoustic echo cancellation","The stereophonic acoustic echo is due to the coupling between two loudspeakers and two microphones. In the classical approach, this configuration is modelled by a two-input/two-output system with real random variables. In this paper, we propose to redesign this scheme as a single-input/single-output system with complex random variables. In this framework, we illustrate the behavior of some basic adaptive algorithms and present a distortion method which is more suitable for this model.","2012","13","2","2025-12-02","https://university.edu/papers/7c74818a-4002-42c0-bf93-0ddecccb7dd9.pdf");
INSERT INTO Paper VALUES ("1160","Use of extrinsic information transfer chart to predict behavior of turbo codes","In this paper, we consider turbo codes that are now introduced in various international standards, including the UMTS standard for third generation personal communications and the ETSI DVB-T standard for Terrestrial Digital Video Broadcasting, and review the method of extrinsic information transfer. The convergence properties of the iterative decoding process associated with a given turbo-coding scheme are assessed using the so-called extrinsic information transfer (EXIT) chart analysis technique. This approach provides an opportunity to foresee the bit error rate (BER) of a turbo code system using only the EXIT chart. It is shown that EXIT charts are powerful tools to analyze and optimize the convergence behavior of iterative systems utilizing the turbo principle, i.e., systems exchanging and refining extrinsic information. The idea is to consider the associated SISO stages as information processors that map input a priori LLR's onto output extrinsic LLR's, the information content being obviously assumed to increase from input to output, and introduce them to the design of turbo systems without the reliance on extensive simulation. Compared with existing methods for generating EXIT functions, a suggested approach provides insight into the iterative behavior of linear turbo systems with substantial reduction in numerical complexity.","2009","15","3","2025-12-02","https://university.edu/papers/c15dcd50-a8ed-46d9-86af-5249eabfb284.pdf");
INSERT INTO Paper VALUES ("1161","What's in a Step? Toward General, Abstract Representations of Tutoring System Log Data","The Pittsburgh Science of Learning Center (PSLC) is developing a data storage and analysis facility, called DataShop. It currently handles log data from 6 full-year tutoring systems and dozens of smaller, experimental tutoring systems. DataShop requires a representation of log data that supports a variety of tutoring systems, atheoretical analyses and theoretical analyses. The theory-based analyses are strongly related to student modeling, so the lessons learned in developing the DataShop's representation may apply to student modeling in general. This report discusses the representation originally used by the DataShop, the problems encountered, and how the key concept of 'step' evolved to meet these challenges.","2007","16","1","2025-12-02","https://university.edu/papers/f24afbcc-99b8-450f-af1c-224442e07752.pdf");
INSERT INTO Paper VALUES ("1162","Technical risk information: decision tool or rhetorical ammunition? Undisputed facts in the Yucca mountain debate","This paper examines how both opponents and proponents of the proposed high-level nuclear waste repository at Yucca mountain Nevada claim that uncontroversial information supports their conflicting positions. Four pieces of information in particular are claimed by both sides: the distance of the proposed site from Las Vegas, the volume of waste that has been produced, the threat of terrorism since 9/11/01, and the occurrence of an earthquake in early 2002. Possible explanations for the difference include naive positivism, social constructionism, persistent beliefs and implicit warrants. The latter two models better explain observed knowledge/preference states. If so, more or better information alone will not improve the dialog about Yucca mountain. Rather, dialog should include a discussion of the ways in which they interpret information and draw conclusions based on their beliefs and warrants. This conclusion may be generalized to a range of information-intensive risk decisions.","2005","10","3","2025-12-02","https://university.edu/papers/7dd7134c-3be0-4824-b609-f9d80ff354eb.pdf");
INSERT INTO Paper VALUES ("1163","Measuring the Perceived Functional Affordances of Collaborative Innovation Networks in Social Product Development","The social model of open innovation allows all members of a community to participate in new product development. Social-media co-innovation platforms are the main enablers of this model of open innovation. One aspect of this business transformation model, co-innovation platform affordances, has captured the attention of researchers and practitioners. Although the importance of co-innovation platform affordances has been established, the development of a valid and reliable instrument to measure this construct in research studies has not been reported in the literature. This paper conceptualizes co-innovation platform affordances and develops a valid and reliable measurement instrument capturing critical facets of co-innovation, namely ideation, collaboration, and communication.","2016","5","1","2025-12-02","https://university.edu/papers/8a9f97b7-0225-4795-b792-8cb6cd4ff8d8.pdf");
INSERT INTO Paper VALUES ("1164","A Distributed Prioritized Multiple Access Scheme for Ad Hoc Networks Using Time-Frequency Hopping Communications","In the time-frequency hopping (TFH) communications, a terminal transmits data at pseudo-random time slots and carrier frequencies, leading to high security against eavesdropping and anti-interference capability. However, in an ad hoc network using the TFH communications, it is challenging to coordinate stations in a distributed manner to share the time/frequency resources, avoid collision, and provide service differentiation. In this paper, we propose a distributed, prioritized multiple access control (MAC) protocol for TFH-based ad hoc networks, named TFH-MAC. In this scheme, the channel occupancy ratio (COR) is introduced to indicate the transmission of stations in a matrix of time-frequency resource blocks. By assigning different predetermined COR thresholds and contention window sizes to traffic classes, the priorities in channel access can be provided. Furthermore, the low-complexity random linear coding (RLC) is employed to repair frames from time-frequency spread segments with partial collision. In particular, the segments correctly received in previous transmissions can be combined with newly successfully received segments for decoding. Thus, the transmission efficiency is increased. An analytical model using mean value analysis is proposed to study the performance of saturated TFH-MAC theoretically, and the transmission probability, collision probability, throughout, and frame service time are derived. Extensive simulation results have verified the analytical model and demonstrated the optimal traffic load and resource matrix dimension to maximize the network throughput.","2016","4","2","2025-12-02","https://university.edu/papers/146bc306-2c69-4358-8c12-b4803ab84444.pdf");
INSERT INTO Paper VALUES ("1165","A speech coder for PC multimedia net‐to‐net communication","Abstract#R##N##R##N#The paper presents a speech coding algorithm for operation at 11025 samples/s. The coder provides improved speech quality and compatibility with the MS-Windows multimedia environment. The coding algorithm has been developed by adapting the ITU G729 and enhancing it with some recent developments in the medium band coding. The coder operates over a band of frequencies ranging from 20 to 5400 Hz at a bit rate of 8.9 kbit/s. Application of this coder includes intranet VoIP, voice chatting, multimedia communications, and voice archiving. Copyright © 2001 John Wiley & Sons, Ltd.","2001","7","4","2025-12-02","https://university.edu/papers/7e608600-06bb-40f5-a507-4fcf9095ad73.pdf");
INSERT INTO Paper VALUES ("1166","High order pLSA for indexing tagged images","This work presents a method for the efficient indexing of tagged images. Tagged images are a common resource of social networks and occupy a large portion of the social media stream. Their basic characteristic is the co-existence of two heterogeneous information modalities, i.e. visual and tag, which refer to the same abstract meaning. This multi-modal nature of tagged images makes their efficient indexing a challenging task that apart from dealing with the heterogeneity of modalities, it needs to also exploit their complementary information capacity. Towards this objective, we propose the extension of probabilistic latent semantic analysis to higher order, so as to become applicable for more than two observable variables. Then, by treating images, visual features and tags as the three observable variables of an aspect model, we learn a space of latent topics that incorporates the semantics of both visual and tag information. Our novelty is on using the cross-modal dependencies learned from a corpus of images to approximate the joint distribution of the observable variables. By penalizing the co-existence of visual content and tags that are known from experience to exhibit low dependency, we manage to filter out the effect of noisy content in the resulting latent space.","2013","19","2","2025-12-02","https://university.edu/papers/e4b94821-dbf9-4ca3-9b61-1a87498c79ee.pdf");
INSERT INTO Paper VALUES ("1167","Graphs with maximum Laplacian and signless Laplacian Estrada index","The Laplacian Estrada index ( L E E ) and the signless Laplacian Estrada index ( S L E E ) of a graph G are, respectively, the sum of the exponentials of the eigenvalues of the Laplacian and signless Laplacian matrix of G . The vertex frustration index ź b of a graph G is the minimum number of vertices whose deletion from G results in a bipartite graph. Graphs having maximum L E E and S L E E values are determined among graphs with n vertices and 1 ź ź b ź n - 3 .","2016","3","2","2025-12-02","https://university.edu/papers/4cc24001-139e-4b34-a416-9b92b74bb7ec.pdf");
INSERT INTO Paper VALUES ("1168","The Concept and Model of 4 Dimensional Traffic Engineering","This paper proposes to apply the prediction of coming traffic for routing named 4 dimensional traffic engineering (4D-TE). Current TE can optimize the usage of network resource by dynamic control depending on an instant status of the network, not for long period. The 4D-TE reflects not only current actual traffic but also coming traffic transition, that is, time as fourth dimension is added for an optimum route search. It predicts traffic transition by referring past statistical data and allocates the minimum cost route for coming large traffic. This paper clarifies how much effectiveness we can get by the 4D-TE. Then, this paper describes the required functions such as traffic pattern management, the prediction of traffic transition and optimum route calculation, and shows how to define link cost for route calculation. Finally, concerning the architecture of control plane for the 4D-TE, the performance of hierarchical architecture is modeled and evaluated.","2006","13","4","2025-12-02","https://university.edu/papers/ac7ad71a-129b-4376-9cae-f30f4a53f24b.pdf");
INSERT INTO Paper VALUES ("1169","Automatic domain terminology extraction using graph mutual reinforcement","Information Extraction (IE) aims at mining knowledge from unstructured data. Terminology extraction is one of crucial subtasks in IE. In this paper, we propose a novel approach of domain terminology extraction based on ranking, according to linkage of authors, papers and conferences in domain proceedings. Candidate terms are extracted by statistical methods and then ranked by the values of importance derived from mutual reinforcement result in the author-paper-conference graph. Furthermore, we integrate our approach with several classical termhood-based methods including C-value and inverse document frequency. The presented approach does not require any training data, and can be extended to other domains. Experimental results show that our approach outperforms several competitive methods.","2010","17","2","2025-12-02","https://university.edu/papers/cc160f75-0707-4d14-a4f0-ae13e254656e.pdf");
INSERT INTO Paper VALUES ("1170","Joint admission control and content caching policy for energy harvesting access points","Wireless caching has been used to improve network performance and reduce bandwidth and energy consumption. In this paper, we study the issue of joint admission control and content caching for wireless access points with energy harvesting capability. Given limited energy supply, the access points, in a competitive environment, aim to maximize their payoff defined in terms of revenue by optimizing their admission control and content caching policy. Moreover, the throughput of the content transmission by the access point has to be maintained above a certain threshold. Thus, we propose a constrained stochastic game to model this competitive caching scenario. The equilibrium policy, which is a mapping from the energy, cache, and demand states to the action, is obtained from the model. From the performance evaluation, the joint admission control and content caching policy can achieve significantly better performance than that of the baseline schemes, especially when the energy harvesting rate becomes constricted.","2016","2","4","2025-12-02","https://university.edu/papers/d3f2b07f-95dd-48e3-b40f-5a83fc7e86e8.pdf");
INSERT INTO Paper VALUES ("1171","Online policy iteration based algorithms to solve the continuous-time infinite horizon optimal control problem","In this paper we discuss two online algorithms based on policy iterations for learning the continuous-time (CT) optimal control solution when nonlinear systems with infinite horizon quadratic cost are considered.","2009","9","4","2025-12-02","https://university.edu/papers/a817852a-a320-4c39-8377-8205fdbf9147.pdf");
INSERT INTO Paper VALUES ("1172","An improved multi-objective evolutionary optimization of data-mining-based fuzzy decision support systems","The paper presents an approach to designing from data fuzzy decision systems (fuzzy rule-based classifiers (FRBCs)) by means of four multi-objective evolutionary optimization algorithms (MOEOAs) including the well-known NSGA-II, ϵ-NSGA-II, SPEA2, and our generalization of SPEA2 (referred to as SPEA3). The advantages of SPEA3 (a better-balanced distribution and a higher spread of solutions than for SPEA2) are shown using selected benchmark tests. The main building blocks of our FRBC and the main components of its MOEOA-based optimization are briefly presented. The proposed FRBCs with genetically optimized accuracy-interpretability trade-off are effective and modern tools for intelligent decision support in various areas of applications. In this paper, the application to designing credit-granting decision support system based on Statlog (German Credit Approval) financial benchmark data set is presented. A comparison of our approach employing various MOEOAs is also carried out.","2016","10","3","2025-12-02","https://university.edu/papers/ab4f47bb-6789-450c-9305-2bb60643db07.pdf");
INSERT INTO Paper VALUES ("1173","Lyrics-to-Audio Alignment by Unsupervised Discovery of Repetitive Patterns in Vowel Acoustics","Most of the previous approaches to lyrics-to-audio alignment used a pre-developed automatic speech recognition (ASR) system that innately suffered from several difficulties to adapt the speech model to individual singers. A significant aspect missing in previous works is the self-learnability of repetitive vowel patterns in the singing voice, where the vowel part used is more consistent than the consonant part. Based on this, our system first learns a discriminative subspace of vowel sequences, based on weighted symmetric non-negative matrix factorization (WS-NMF), by taking the self-similarity of a standard acoustic feature as an input. Then, we make use of canonical time warping (CTW), derived from a recent computer vision technique, to find an optimal spatiotemporal transformation between the text and the acoustic sequences. Experiments with Korean and English data sets showed that deploying this method after a pre-developed, unsupervised, singing source separation achieved more promising results than other state-of-the-art unsupervised approaches and an existing ASR-based system.","2017","5","1","2025-12-02","https://university.edu/papers/e265a9c7-69b8-4b4c-9294-4c3943324a84.pdf");
INSERT INTO Paper VALUES ("1174","Scalable Certification Framework for Behavioral Synthesis Front-End","Behavioral synthesis entails application of a sequence of transformations to compile a high-level description of a hardware design (e.g., in C/C++/SystemC) into a register-transfer level (RTL) implementation. In this paper, we present a scalable equivalence checking framework to validate the correctness of compiler transformations employed by behavioral synthesis front-end. Our approach makes use of dual-rail symbolic simulation of the input and output of a transformation, together with identification and inductive verification of their loop structures. We have evaluated our framework on transformations applied by an open source behavioral synthesis tool to designs from the CHStone benchmark. Our tool can automatically validate more than 75 percent of the total of 1008 compiler transformations applied, taking an average time of 1.5 seconds per transformation.","2014","11","4","2025-12-02","https://university.edu/papers/7d8d8223-3adf-42d8-bbc3-f548d77981a5.pdf");
INSERT INTO Paper VALUES ("1175","Local Kernel Density Ratio-Based Feature Selection for Outlier Detection","Selecting features is an important step of any machine learning task, though most of the focus has been to choose features relevant for classication and regression. In this work, we present a novel non-parametric evaluation criterion for lter-based feature selection which enhances outlier detection. Our proposed method seeks the subset of features that represents the inherent characteristics of the normal dataset while forcing outliers to stand out, making them more easily distinguished by outlier detection algorithms. Experimental results on real datasets show the advantage of this feature selection algorithm compared to popular and state-of-the-art methods. We also show that the proposed algorithm is able to overcome the small sample space problem and perform well on highly imbalanced datasets.","2012","1","3","2025-12-02","https://university.edu/papers/e54c68b1-4e70-4cc0-88db-a1a86d220ee8.pdf");
INSERT INTO Paper VALUES ("1176","Humanoid Vertical Jumping based on Force Feedback and Inertial Forces Optimization","This paper proposes adapting human jumping dynamics to humanoid robotic structures. Data obtained from human jumping phases and decomposition together with ground reaction forces (GRF) are used as model references. Moreover, bodies inertial forces are used as task constraints while optimizing energy to determine the humanoid robot posture and improve its jumping performances.","2005","7","4","2025-12-02","https://university.edu/papers/ce678146-db73-472b-a9db-d663cd575144.pdf");
INSERT INTO Paper VALUES ("1177","Image2Weather: A Large-Scale Image Dataset for Weather Property Estimation","To facilitate weather property estimation from images, a large-scale image dataset associated with rich weather information is developed. Based on the taken time and geographical information of an image, we associate it with weather properties obtained from a weather forecast website. Through data filtering like indoor/outdoor classification and sky region detection, a clean and large-scale image-weather dataset (named Image2Weather dataset) consisting of more than 180,000 photos is built to promote related researches. In addition to reporting statistical characteristics of this dataset, we investigate the relationship between several visual features and weather properties, which then serve as the foundation of interesting applications like weather type classification and temperature estimation. We show effectiveness of weather property estimation based on the Image2Weather dataset, and discuss how it can be leveraged to facilitate related studies in the future.","2016","18","4","2025-12-02","https://university.edu/papers/90b77dbe-1f56-48eb-9fff-170a081a425c.pdf");
INSERT INTO Paper VALUES ("1178","Sentiment classification of online reviews to travel destinations by supervised machine learning approaches","The rapid growth in Internet applications in tourism has lead to an enormous amount of personal reviews for travel-related information on the Web. These reviews can appear in different forms like BBS, blogs, Wiki or forum websites. More importantly, the information in these reviews is valuable to both travelers and practitioners for various understanding and planning processes. An intrinsic problem of the overwhelming information on the Internet, however, is information overloading as users are simply unable to read all the available information. Query functions in search engines like Yahoo and Google can help users find some of the reviews that they needed about specific destinations. The returned pages from these search engines are still beyond the visual capacity of humans. In this research, sentiment classification techniques were incorporated into the domain of mining reviews from travel blogs. Specifically, we compared three supervised machine learning algorithms of Naive Bayes, SVM and the character based N-gram model for sentiment classification of the reviews on travel blogs for seven popular travel destinations in the US and Europe. Empirical findings indicated that the SVM and N-gram approaches outperformed the Naive Bayes approach, and that when training datasets had a large number of reviews, all three approaches reached accuracies of at least 80%.","2009","11","2","2025-12-02","https://university.edu/papers/f3540443-14bb-4873-b03e-14755492de69.pdf");
INSERT INTO Paper VALUES ("1179","Planning a minimum-time trajectories for robot arms","The minimum-time path for a robot arm has been a long-standing and unsolved problem of considerable interest. We present a general solution to this problem that involves joint-space tesselation, a dynamic time-scaling algorithm, and graph search. The solution incorporates full dynamics of movement and actuator constraints, and can be easily extended for joint limits and workspace obstacles, but is subject to the particular tesselation scheme used. The results presented show that, in general, the optimal paths are not straight lines, but rather curves in joint-space that utilize the dynamics of the arm and gravity to help in moving the arm faster to its destination. Implementation difficulties due to the tesselation and to combinatorial proliferation of paths are discussed.","1985","11","4","2025-12-02","https://university.edu/papers/7978071b-0343-439b-af69-29650350615b.pdf");
INSERT INTO Paper VALUES ("1180","Syntactic Stylometry for Deception Detection","Most previous studies in computerized deception detection have relied only on shallow lexico-syntactic patterns. This paper investigates syntactic stylometry for deception detection, adding a somewhat unconventional angle to prior literature. Over four different datasets spanning from the product review to the essay domain, we demonstrate that features driven from Context Free Grammar (CFG) parse trees consistently improve the detection performance over several baselines that are based only on shallow lexico-syntactic features. Our results improve the best published result on the hotel review data (Ott et al., 2011) reaching 91.2% accuracy with 14% error reduction.","2012","16","1","2025-12-02","https://university.edu/papers/60ef18be-78de-4fb5-bb83-53f15f693e44.pdf");
INSERT INTO Paper VALUES ("1181","Adaptive over-relaxed mean shift","Mean shift is a popular nonparametric density estimation method. One of its drawbacks is that it converges slowly in many cases. Inspired by the successful accelerated variants of bound optimisation algorithms such as Expectation Maximisation, we propose an accelerated version of the mean shift algorithm. The appealing property is that, compared with the standard mean shift algorithm, the number of iterations to convergence is signicantly decreased. Additionally for the Gaussian kernel, no extra computation is introduced at each iteration. We empirically show on various data sets that the extended algorithm can provide a considerable speedup.","2005","4","4","2025-12-02","https://university.edu/papers/88df62b0-dbf7-4521-b4d9-0e23bf9efae3.pdf");
INSERT INTO Paper VALUES ("1182","Fractal analysis of semantically distributed data","The purpose of this paper is to present a simple, but efficient methodology for analysing semantically distributed data. The analysis reveals important information about the statistical distribution of the geographically distributed data sets. This information can be helpful in deriving accurate data mining models that correctly reflect the semantics of the distributed data sites and help in avoiding inappropriate summarisation of the data. Although, our methodology operates on distributed homogeneous data sets, it can also work with certain heterogeneous data sets that can be transformed into homogeneous data sets without a reduction in their intrinsic dimensionality. Experiments showed that this type of transformation is in fact feasible for some data sets. We propose a measure for comparison of data sets based on the correlation fractal dimension and the cross-value. We tested our methodology on real world data sets and showed that the proposed approach discovers differences in the semantics of both di...","2009","3","4","2025-12-02","https://university.edu/papers/78c9e9fe-8165-459d-b4f3-db4db82c278b.pdf");
INSERT INTO Paper VALUES ("1183","SR ARQ delay statistics on N-state Markov channels with non-instantaneous feedback","In this paper the packet delay statistics of a fully reliable selective repeat ARQ (SR ARQ) scheme is investigated. An N-state discrete time Markov channel model is used to describe the packet error process and the channel round trip delay is considered to be non zero, i.e., ACK/NACK messages are received at the transmitter m channel slots after the packet transmission started. The ARQ packet delay statistics is evaluated by means of an exact analysis by jointly tracking packet errors and channel state evolution. Furthermore, procedures to derive a Markov channel description of a Rayleigh fading process are discussed and the delay statistics obtained from the Markov analysis is compared with that estimated by simulation of the SR ARQ protocol over the actual fading process. The accuracy of the delay statistics obtained from the Markov Channel representation of the actual fading process is investigated by explicitly addressing the effect of the number of states considered in the Markov channel model and the impact of the Doppler frequency. Finally, besides giving a new analysis to obtain link layer statistics over N-state Markov channels, the paper provides important considerations on the adequacy of the widely used Markov modeling approach for the characterization of higher layer performance","2006","5","1","2025-12-02","https://university.edu/papers/d7d748a1-8462-43a5-99c9-cc9e6e66a0c8.pdf");
INSERT INTO Paper VALUES ("1184","Convexity theory for the term structure equation","We study convexity and monotonicity properties for prices of bonds and bond options when the short rate is modeled by a diffusion process. We provide conditions under which convexity of the price in the short rate is guaranteed. Under these conditions the price is decreasing in the drift and increasing in the volatility of the short rate. We also study convexity properties of the logarithm of the price.","2007","6","1","2025-12-02","https://university.edu/papers/f06f285f-8ded-4399-8bef-7142ea737f3c.pdf");
INSERT INTO Paper VALUES ("1185","Two properties of pseudo-random sequences (Corresp.)","The so-called 'pseudo-random' (p-r) sequences defined below have two properties which may make them useful in certain communication systems. Stated roughly, the first property is that the minimum distance between different signals of a special class is maximized and the second is that the probability that one member of this class be mistaken for some other member is minimized. The so-called 'pseudo-random' (p-r) sequences defined below have two properties which may make them useful in certain communication systems. Stated roughly, the first property is that the minimum distance between different signals of a special class is maximized and the second is that the probability that one member of this class be mistaken for some other member is minimized.","1959","6","2","2025-12-02","https://university.edu/papers/a1ffa912-c394-488a-ba0e-a8ff0e1dec80.pdf");
INSERT INTO Paper VALUES ("1186","On deriving the second-stage training set for trainable combiners","Unlike fixed combining rules, the trainable combiner is applicable to ensembles of diverse base classifier architectures with incomparable outputs. The trainable combiner, however, requires the additional step of deriving a second-stage training dataset from the base classifier outputs. Although several strategies have been devised, it is thus far unclear which is superior for a given situation. In this paper we investigate three principal training techniques, namely the re-use of the training dataset for both stages, an independent validation set, and the stacked generalization. On experiments with several datasets we have observed that the stacked generalization outperforms the other techniques in most situations, with the exception of very small sample sizes, in which the re-using strategy behaves better. We illustrate that the stacked generalization introduces additional noise to the second-stage training dataset, and should therefore be bundled with simple combiners that are insensitive to the noise. We propose an extension of the stacked generalization approach which significantly improves the combiner robustness.","2005","15","1","2025-12-02","https://university.edu/papers/4aeacf98-15fd-459b-971b-7b1e631fa4dd.pdf");
INSERT INTO Paper VALUES ("1187","Puzzle-based auction mechanism for spectrum sharing in cognitive radio networks","In this work we investigate an auction mechanism for sharing available wireless bandwidth among competing cognitive radios. The bandwidth under consideration may be either in an unlicensed spectrum or in an unused licensed band. Spectrum sharing is achieved via a mechanism in which a cognitive radio acting as the auctioneer advertises spectrum availability to bidding cognitive radios and defines a puzzle to solve as a method to access it. The cognitive radios act as bidders by computing the solution to the problem (i.e., the “puzzle”). The winner is the bidder who submits the first correct bid and thus gains access to the spectrum for the next time interval. We consider two different variances of our scheme based on parallelizable and non-parallelizable problems and demonstrate that the latter provides a fair auction in contrast to the former. We propose a verification database to counter malicious “greedy” players. Our algorithm provides a centralized, easy-to-implement, and computationally fast multiple-access scheme that is verifiable by all participating cognitive radios.","2016","2","4","2025-12-02","https://university.edu/papers/bb5e22b4-dbc7-4b40-83f7-585e61d9ceda.pdf");
INSERT INTO Paper VALUES ("1188","An Investigation on Testing of Parallelized Code with OpenMP","Testing is a crucial element of software development. As OpenMP becomes more widely used, a relevant question for developers is: How will programs, that have been parallelized with OpenMP, be tested for correctness? OpenMP programs are concurrent programs and as such all the risks of concurrent programming are present as well. This paper presents some observations about testing parallelized loops using OpenMP.","2007","16","2","2025-12-02","https://university.edu/papers/6aadfa8c-8a38-4039-aa52-e316ad8176eb.pdf");
INSERT INTO Paper VALUES ("1189","CEPE: Cooperative Editor for Processes Elicitation","Companies normally hire external consultants to carry out their business process re-engineering. While this can be straightforward in the short term, it does not produce the desired results in the mid and long term. A low level of worker involvement and a continuous dependency on external consultancy are the main drawbacks. We propose an alternative approach to BPR, specifically to workflow design, where company workers play an active role in re-designing the organization's processes in a cooperative style. The paper describes the essence of a BPR method based on participatory design and stepwise refinement which we believe will generate better results than the traditional approach. We describe in detail the CEPE tool: Cooperative Editor for Processes Elicitation, which is a cooperative graphic editor that supports the building of the knowledge about the current process and its associated problems. That is the second phase of the proposed method.","2000","17","4","2025-12-02","https://university.edu/papers/d204a1da-e943-4d61-8770-b6e4d6db751e.pdf");
INSERT INTO Paper VALUES ("1190","Automatic scoring of online discussion posts","Online discussions forums, known as forums for short, are conversational social cyberspaces constituting rich repositories of content and an important source of collaborative knowledge. However, most of this knowledge is buried inside the forum infrastructure and its extraction is both complex and difficult. The ability to automatically rate postings in online discussion forums, based on the value of their contribution, enhances the ability of users to find knowledge within this content. Several key online discussion forums have utilized collaborative intelligence to rate the value of postings made by users. However, a large percentage of posts go unattended and hence lack appropriate rating.   In this paper, we focus on automatic rating of postings in online discussion forums. A set of features derived from the posting content and the threaded discussion structure are generated for each posting. These features are grouped into five categories, namely (i) relevance, (ii) originality, (iii) forum-specific features, (iv) surface features, and (v) posting-component features. Using a non-linear SVM classifier, the value of each posting is categorized into one of three levels High, Medium, or Low. This rating represents a seed value for each posting that is leveraged in filtering forum content. Experimental results have shown promising performance on forum data.","2008","5","4","2025-12-02","https://university.edu/papers/505cce8f-1af8-4c03-bc03-6adc714e2c94.pdf");
INSERT INTO Paper VALUES ("1191","Dynamic view-dependent simplification for polygonal models","Presents an algorithm for performing view-dependent simplifications of a triangulated polygonal model in real-time. The simplifications are dependent on viewing direction, lighting and visibility, and are performed by taking advantage of image-space, object-space and frame-to-frame coherences. A continuous level-of-detail representation for an object is first constructed off-line. This representation is then used at run-time to guide the selection of appropriate triangles for display. The list of displayed triangles is updated incrementally from one frame to the next. Our approach is more effective than the current level-of-detail-based rendering approaches for most scientific visualization applications where there are a limited number of highly complex objects that stay relatively close to the viewer.","1996","13","1","2025-12-02","https://university.edu/papers/b86d2099-9a0f-413b-ab31-1e24f2b087c1.pdf");
INSERT INTO Paper VALUES ("1192","An information fusion framework with multi-channel feature concatenation and multi-perspective system combination for the deep-learning-based robust recognition of microphone array speech","We present an information fusion approach to the robust recognition of multi-microphone speech. It is based on a deep learning framework with a large deep neural network (DNN) consisting of subnets designed from different perspectives. Multiple knowledge sources are then reasonably integrated via an early fusion of normalized noisy features with multiple beamforming techniques, enhanced speech features, speaker-related features, and other auxiliary features concatenated as the input to each subnet to compensate for imperfect front-end processing. Furthermore, a late fusion strategy is utilized to leverage the complementary natures of the different subnets by combining the outputs of all subnets to produce a single output set. Testing on the CHiME-3 task of recognizing microphone array speech, we demonstrate in our empirical study that the different information sources complement each other and that both early and late fusions provide significant performance gains, with an overall word error rate of 10.55% when combining 12 systems. Furthermore, by utilizing an improved technique for beamforming and a powerful recurrent neural network (RNN)-based language model for rescoring, a WER of 9.08% can be achieved for the best single DNN system with one-pass decoding among all of the systems submitted to the CHiME-3 challenge.","2016","10","1","2025-12-02","https://university.edu/papers/3db8c157-807e-483d-b51a-7b8b2991b607.pdf");
INSERT INTO Paper VALUES ("1193","Reliability modeling of multi-state degraded systems with multi-competing failures and random shocks","In this paper, we develop a generalized multi-state degraded system reliability model subject to multiple competing failure processes, including two degradation processes, and random shocks. The operating condition of the multi-state systems is characterized by a finite number of states. We also present a methodology to generate the system states when there are multi-failure processes. The model can be used not only to determine the reliability of the degraded systems in the context of multi-state functions, but also to obtain the states of the systems by calculating the system state probabilities. Several numerical examples are given to illustrate the concepts.","2005","14","3","2025-12-02","https://university.edu/papers/79acc860-2bf1-49e8-b269-9bedd5e43f44.pdf");
INSERT INTO Paper VALUES ("1194","A New Method for Earth Observation Data Analytics Based on Symbolic Machine Learning","This work introduces a new classification method in the remote sensing domain, suitably adapted to dealing with the challenges posed by the big data processing and analytics framework. The method is based on symbolic learning techniques, and it is designed to work in complex and information-abundant environments, where relationships among different data layers are assessed in model-free and computationally-effective modalities. The two main stages of the method are the data reduction-sequencing and the association analysis. The former refers to data representation; the latter searches for systematic relationships between data instances derived from images and spatial information encoded in supervisory signals. Subsequently, a new measure named the evidence-based normalized differential index, inspired by the probability-based family of objective interestingness measures, evaluates these associations. Additional information about the computational complexity of the classification algorithm and some critical remarks are briefly introduced. An application of land cover mapping where the input image features are morphological and radiometric descriptors demonstrates the capacity of the method; in this instructive application, a subset of eight classes from the Corine Land Cover is used as the reference source to guide the training phase.","2016","9","3","2025-12-02","https://university.edu/papers/9ca4e6b7-bc38-4a5e-a3ff-2e01376d85a2.pdf");
INSERT INTO Paper VALUES ("1195","Human symbiotic robot design based on division and unification of functional requirements","The study described aims to develop human symbiotic robots, which have the abilities of carrying out physical, informational, and psychological interaction, and support daily work in a human's living space. We mainly discuss two essential design requirements for realizing human-robot symbiosis, such as safety and dexterity. First, through the development of human symbiotic robot WENDY (Waseda ENgineering Designed sYmbiont), a mechanical design method is proposed. Next, the effectiveness of the method is evaluated by several basic experiments, such as object grasping by using visual information, impact safety motion, and pressure control on the fingertip. Finally, performances of WENDY are also exhibited from several experiments that require high level integration of whole body mechanisms.","2000","20","3","2025-12-02","https://university.edu/papers/ca569793-3d52-415a-a02a-a02c00d8f6a0.pdf");
INSERT INTO Paper VALUES ("1196","Modeling within-motif dependence for transcription factor binding site predictions","Motivation: The position-specific weight matrix (PWM) model, which assumes that each position in the DNA site contributes independently to the overall protein--DNA interaction, has been the primary means to describe transcription factor binding site motifs. Recent biological experiments, however, suggest that there exists interdependence among positions in the binding sites. In order to exploit this interdependence to aid motif discovery, we extend the PWM model to include pairs of correlated positions and design a Markov chain Monte Carlo algorithm to sample in the model space. We then combine the model sampling step with the Gibbs sampling framework for de novo motif discoveries.#R##N##R##N#Results: Testing on experimentally validated binding sites, we find that about 25% of the transcription factor binding motifs show significant within-site position correlations, and 80% of these motif models can be improved by considering the correlated positions. Using both simulated data and real promoter sequences, we show that the new de novo motif-finding algorithm can infer the true correlated position pairs accurately and is more precise in finding putative transcription factor binding sites than the standard Gibbs sampling algorithms.#R##N##R##N#Availability: The program is available at http://www.people.fas.harvard.edu/~junliu/","2004","19","2","2025-12-02","https://university.edu/papers/ec67ab32-76ce-496f-b409-ca1280fc8f58.pdf");
INSERT INTO Paper VALUES ("1197","A simple Bayesian multistage interference canceller for multiuser detection in TDD-CDMA receivers","A simple multiuser detector (MUD) is proposed for channels affected by severe multipath and is then suitable for time-division duplexing code-division multiple-access (TDD-CDMA) receivers. For each user, after coherent combining and despreading, a suitable 'Bayesian' memoryless nonlinearity gives symbol-by-symbol the expected values of the transmitted data. These are employed for soft removal of intersymbol and multiple-access interference (MAI) from the received sequences. The procedure is iterated in a multistage structure until final decisions are taken. From the comparison with other solutions, the proposed receiver exhibits better performance (close to the ideal canceller) and equal or minor complexity.","2001","5","3","2025-12-02","https://university.edu/papers/a048e811-ab16-4016-8bf4-1cd652478e7a.pdf");
INSERT INTO Paper VALUES ("1198","Extending Lambek Grammars: a Logical Account of Minimalist Grammars","We provide a logical definition of Minimalist grammars, that are Stabler's formalization of Chomsky's minimalist program. Our logical definition leads to a neat relation to categorial grammar, (yielding a treatment of Montague semantics), a parsing-as-deduction in a resource sensitive logic, and a learning algorithm from structured data (based on a typing-algorithm and type-unification). Here we emphasize the connection to Montague semantics which can be viewed as a formal computation of the logical form.","2001","17","2","2025-12-02","https://university.edu/papers/b146fdef-c8eb-43dc-9992-d01ff423163f.pdf");
INSERT INTO Paper VALUES ("1199","The Development and Implementation of Scaffolding-Based Self-Regulated Learning System for e/m-Learning","This paper proposes a self-regulated learning (SRL) system with scaffolding support in order to develop independent learning skills among students. The SRL system uses self-regulated learning and scaffolding theories to appeal to both instructors and learners. On the part of the instructors, a Content Accessibility Subsystem is provided to easily organize learning materials and to dynamically provide different levels of support for their learners. As for the learners, many subsystems are proposed that provide a conducive mobile learning environment for them. With the application of the scaffolding theory, the system can easily adjust to provide help to the learners, facilitating SRL processes anytime and anywhere, and establishing the learners’ SRL patterns gradually. The learners in the experiment deemed that that the proposed system could provide them selfregulatory attributes. The experiment results show that the average SRL score of learners increases, though the improvement is not significant. However, the result also showed that the SR skills of students in the group of Low SR significantly improved.","2010","20","3","2025-12-02","https://university.edu/papers/c037e3bc-d301-4ef5-9ef4-09b46cbe6abe.pdf");
INSERT INTO Paper VALUES ("1200","The End of the Net as We Know it? Deep Packet Inspection and Internet Governance","Advances in network equipment now allow internet service providers to monitor the content of data packets in real-time and make decisions about how to handle them. If deployed widely this technology, known as deep packet inspection (DPI), has the potential to alter basic assumptions that have underpinned Internet governance to date. The paper explores the way Internet governance is responding to deep packet inspection and the political struggles around it. Avoiding the extremes of technological determinism and social constructivism, it integrates theoretical approaches from the sociology of technology and actor-centered institutionalism into a new framework for technology-aware policy analysis.","2011","17","3","2025-12-02","https://university.edu/papers/bc2dd766-c551-4571-b2f0-4ff9fad82be1.pdf");
INSERT INTO Paper VALUES ("1201","The effectiveness of brain-compatible blended learning material in the teaching of programming logic","Blended learning is an educational approach which integrates seemingly distinct educational approaches, such as face-to-face and online experiences. In a blended learning environment the classroom lectures can, for example, be augmented with learning material offered in a variety of technologically delivered formats. There exist extensive evidence that a blended learning approach which mixes face-to-face and online learning materials is substantially more effective than using only face-to-face educational methods. However, in order to be effective, blended learning course material should still be designed and presented according to sound pedagogical principles. This article presents the results of an experiment to augment the teaching of fundamental programming logic based on the pedagogical principles underpinning brain-compatible learning materials via e-learning delivery mechanisms. The research uses both qualitative and quantitative methods. Results show promise for this use of brain-compatible material in a blended learning context.","2016","16","4","2025-12-02","https://university.edu/papers/f7eb1184-05cd-41a9-ba83-aadcdc1dbafd.pdf");
INSERT INTO Paper VALUES ("1202","Robust Synchronization for Multistable Systems","In this note, we study a robust synchronization problem for multistable systems evolving on manifolds within an Input-to-State Stability (ISS) framework. Based on a recent generalization of the classical ISS theory to multistable systems, a robust synchronization protocol is designed with respect to a compact invariant set of the unperturbed system. The invariant set is assumed to admit a decomposition without cycles, that is, with neither homoclinic nor heteroclinic orbits. Numerical simulation examples illustrate our theoretical results.","2016","7","3","2025-12-02","https://university.edu/papers/bc61f9c3-8b5c-49d2-bd7e-fd265456f9ef.pdf");
INSERT INTO Paper VALUES ("1203","Visual Simulation of Heat Shimmering and Mirage","We provide a physically-based framework for simulating the natural phenomena related to heat interaction between objects and the surrounding air. We introduce a heat transfer model between the heat source objects and the ambient flow environment, which includes conduction, convection, and radiation. The heat distribution of the objects is represented by a novel temperature texture. We simulate the thermal flow dynamics that models the air flow interacting with the heat by a hybrid thermal lattice Boltzmann model (HTLBM). The computational approach couples a multiple-relaxation-time LBM (MRTLBM) with a finite difference discretization of a standard advection-diffusion equation for temperature. In heat shimmering and mirage, the changes in the index of refraction of the surrounding air are attributed to temperature variation. A nonlinear ray tracing method is used for rendering. Interactive performance is achieved by accelerating the computation of both the MRTLBM and the heat transfer, as well as the rendering on contemporary graphics hardware (GPU)","2007","5","2","2025-12-02","https://university.edu/papers/754ce170-32b1-43bb-80a7-a617e81e6b4b.pdf");
INSERT INTO Paper VALUES ("1204","A Validity Criterion for Fuzzy Clustering","This paper describes a validity index for fuzzy clustering: Pattern Distances Ratio PDR and a cluster number selection procedure using that index.#R##N##R##N#As other validity indices, solution presented in this paper may be used when a need for assessing of clustering or fuzzy clustering result adequacy arises. Most common example of such situation is when clustering algorithm that requires certain parameter, for example number of clusters, is selected but we lack a priori knowledge of this parameter and we would use educated guesses in concert with trial and error procedures. Validity index may allow to automate such process whenever it is necessary or convenient. In particular, it might ease incorporation of fuzzy clustering into more complex, intelligent systems.#R##N##R##N#The validity index presented in this paper might be seen as measuring the goodness of clustering of individual examples. When it is averaged over the clustered set, it bears some resemblance to the validity indices based on notions of compactness and separation. During experiments it was used as a cluster number selection criterion for fuzzy c-means. Those experiments showed that PDR can perform well in this role but a special selection procedure should be followed, instead of usual minimum search. The procedure is also described.","2013","17","4","2025-12-02","https://university.edu/papers/619c1c04-03a9-4d3b-84a3-c253fab5d79f.pdf");
INSERT INTO Paper VALUES ("1205","Design, simulation and evaluation of uniform magnetic field systems for head-free eye movement recordings with scleral search coils","The precise measurement of eye movements is important for investigating vision, oculomotor control and vestibular function. The magnetic scleral search coil technique is one of the most precise measurement techniques for recording eye movements with very high spatial (≈ 1 arcmin) and temporal (>kHz) resolution. The technique is based on measuring voltage induced in a search coil through a large magnetic field. This search coil is embedded in a contact lens worn by a human subject. The measured voltage is in direct relationship to the orientation of the eye in space. This requires a magnetic field with a high homogeneity in the center, since otherwise the field inhomogeneity would give the false impression of a rotation of the eye due to a translational movement of the head. To circumvent this problem, a bite bar typically restricts head movement to a minimum. However, the need often emerges to precisely record eye movements under natural viewing conditions. To this end, one needs a uniform magnetic field that is uniform over a large area. In this paper, we present the numerical and finite element simulations of the magnetic flux density of different coil geometries that could be used for search coil recordings. Based on the results, we built a 2.2 × 2.2 × 2.2 meter coil frame with a set of 3 × 4 coils to generate a 3D magnetic field and compared the measured flux density with our simulation results. In agreement with simulation results, the system yields a highly uniform field enabling high-resolution recordings of eye movements.","2016","1","3","2025-12-02","https://university.edu/papers/0aac3fdb-6175-44a2-93bc-2322763d8c6b.pdf");
INSERT INTO Paper VALUES ("1206","A Scene Image is Nonmutually Exclusive—A Fuzzy Qualitative Scene Understanding","Ambiguity or uncertainty is a pervasive element of many real-world decision-making processes. Variation in decisions is a norm in this situation when the same problem is posed to different subjects. Psychological and metaphysical research has proven that decision making by humans is subjective. It is influenced by many factors such as experience, age, background, etc. Scene understanding is one of the computer vision problems that fall into this category. Conventional methods relax this problem by assuming that scene images are mutually exclusive; therefore, they focus on developing different approaches to perform the binary classification tasks. In this paper, we show that scene images are nonmutually exclusive and propose the fuzzy qualitative rank classifier (FQRC) to tackle the aforementioned problems. The proposed FQRC provides a ranking interpretation instead of binary decision. Evaluations in terms of qualitative and quantitative measurements using large numbers and challenging public scene datasets have shown the effectiveness of our proposed method in modeling the nonmutually exclusive scene images.","2014","14","2","2025-12-02","https://university.edu/papers/5537d348-0863-42b2-8a7a-eb0935cbc69a.pdf");
INSERT INTO Paper VALUES ("1207","Noncoherent detection of coherent lightwave signals corrupted by phase noise","Waves are treated that modulate by either on-off keying (OOK) or binary frequency-shift keying (FSK) and are further impaired by additive Gaussian noise. Heterodyne detection of such a waveform produces an electronic bandpass signal, which, to ease demodulation in the presence of phase noise, is noncoherently demodulated to extract the baseband pulse stream. The treatment goes beyond previous bit error rate (BER) analyses of optical heterodyne receivers for OOK and FSK. First, there is full adherence to the standard (Brownian motion) model of phase noise. Also, the receiver structure is formulated in such a way that the probability density function of the receiver output samples can be accurately determined. This permits calculations of the additive noise and phase noise tolerable when achieving bit error rates as small as 10/sup -9/. Finally, the study is comprehensive regarding the range of parameters explored. Filtering at an intermediate frequency (IF) alone, as well as IF filtering plus postdetection low-pass filtering, is considered. When the receiver parameters decision threshold (for OOK) and IF filter bandwidth are optimized, large amounts of phase noise can be accommodated with only minor increases in required signal-to-noise ratio. This is especially important when the bit rate is moderate compared to the laser linewidth. >","1988","5","4","2025-12-02","https://university.edu/papers/758bfc0f-0437-4ecc-873c-eb69dc68f569.pdf");
INSERT INTO Paper VALUES ("1208","An empirical research on exploring information sharing behaviour based on virtual teams","Based on theory of reasoned action (TRA) and literature study regarding virtual teams, we conducted an empirical research on influential factors associated with information sharing behaviour of a virtual team and constructed a model for studying virtual team's information sharing behaviour. Taking advantage of an international course of BOHKNET as the sample of a virtual team, we tested various assumptions related to the model, verified the validity of the model, which confirmed these influential factors further grounded on analysing the data of collected questionnaires. Subsequently, we introduced some strategies for prompting information sharing of virtual teams.","2011","3","1","2025-12-02","https://university.edu/papers/8f6eb86b-d6cc-44bd-8ab6-0b2f7129bc90.pdf");
INSERT INTO Paper VALUES ("1209","Automatic generation of HMM topology for sign language recognition","Sign language is used for communicating to people with hearing difficulties. Recognition of a sign language image sequence is challenging because of the variety of hand shapes and hand motions. We propose a method to automatically construct a transitional structure(topology) of a Hidden Markov Model(HMM) for recognizing sign language words. Unlike conventional HMM, the constructed topology has branches and junctions in order to represent a flexible structure. The proposed method consists of segmentation of a motion, and construction of the topology from segments. The topology is constructed from an initial topology by modifying it. With experiments, we show the effectiveness of the proposed method.","2008","10","2","2025-12-02","https://university.edu/papers/ea62daad-58f2-44a2-999f-4d137687ab4e.pdf");
INSERT INTO Paper VALUES ("1210","A Complete Variational Tracker","We introduce a novel probabilistic tracking algorithm that incorporates combinatorial data association constraints and model-based track management using variational Bayes. We use a Bethe entropy approximation to incorporate data association constraints that are often ignored in previous probabilistic tracking algorithms. Noteworthy aspects of our method include a model-based mechanism to replace heuristic logic typically used to initiate and destroy tracks, and an assignment posterior with linear computation cost in window length as opposed to the exponential scaling of previous MAP-based approaches. We demonstrate the applicability of our method on radar tracking and computer vision problems.","2014","7","1","2025-12-02","https://university.edu/papers/8a18f8a9-e888-4267-9dce-47b7bfaa98cd.pdf");
INSERT INTO Paper VALUES ("1211","A Root of Trust for the Personal Cloud.","The Personal Cloud paradigm has recently emerged as a way to allow individuals to manage under their control the collection, usage and sharing of data in different contexts and for different types and sensitivities of data. While much research work is tackling the organisation and semantic exploitation of the user's workspace, far less attention has been paid to security issues. We promote a new approach, called Secure Personal Cloud, where the root of security is made of secure hardware and the access control policies are easily extracted from the personal cloud itself, with minimal user interaction. Our solution is based on the tight integration of a Personal Cloud platform (Cozy) with a trusted component (PlugDB).","2016","18","4","2025-12-02","https://university.edu/papers/dbcbece3-caaa-4d6f-b189-979478806378.pdf");
INSERT INTO Paper VALUES ("1212","A technique for electromagnetic interference measurements on instruments","The aim of this paper is to highlight the problems that arise when the immunity of measurement instruments to power line voltage disturbances has to be evaluated. The lack of an international product standard puts at the user's disposal only some basic standards which, in giving only general criteria for test result classification, make it difficult to choose suitable acceptance criteria and, consequently, to plan a proper set of tests, especially for very complex instruments. After an introduction on the state of art of electromagnetic compatibility (EMC) international standards, a measurement technique adopted by the authors to evaluate the immunity of complex instruments to conducted disturbances is presented. Finally, experimental tests carried out on VXI instruments are given and discussed exhaustively.","1998","11","1","2025-12-02","https://university.edu/papers/a356e6f2-8909-4eab-b646-aeffc3fe089f.pdf");
INSERT INTO Paper VALUES ("1213","XL4C4D - Adding the Graph Transformation Language XL to CINEMA 4D","A plug-in for the 3D modeling application CINEMA 4D is presented which allows to use the graph transformation language XL to transform the 3D scene graph of CINEMA 4D. XL extends Java by graph query and rewrite facilities via a data model interface, the default rewrite mechanism is that of relational growth grammars which are based on parallel single-pushout derivations. We illustrate the plug-in at several examples, some of which make use of advanced 3D features.","2013","2","4","2025-12-02","https://university.edu/papers/d5fa38b5-a128-4b8f-b640-d1b9a3a0c847.pdf");
INSERT INTO Paper VALUES ("1214","Analysis, decomposition and superposition of quadratic potential force fields for distributed manipulation","Distributed manipulation systems induce motions on objects through the application of many external forces. An actuator array performs distributed manipulation using a planar array of many stationary elements, which cooperate to manipulate larger objects through the generation of a programmable force field. This paper defines and studies a class of manipulation force fields called quadratic potential fields. Methodology is developed to decompose these fields into simpler components and superimpose them both vectorially and geometrically, simplifying the design of manipulation strategies. Application to trajectory following is also presented.","2003","20","2","2025-12-02","https://university.edu/papers/7888b36d-6cd1-45bf-9beb-b3967a39601e.pdf");
INSERT INTO Paper VALUES ("1215","Insight into model mechanisms through automatic parameter fitting: a new methodological framework for model development","Background#R##N#Striking a balance between the degree of model complexity and parameter identifiability, while still producing biologically feasible simulations using modelling is a major challenge in computational biology. While these two elements of model development are closely coupled, parameter fitting from measured data and analysis of model mechanisms have traditionally been performed separately and sequentially. This process produces potential mismatches between model and data complexities that can compromise the ability of computational frameworks to reveal mechanistic insights or predict new behaviour. In this study we address this issue by presenting a generic framework for combined model parameterisation, comparison of model alternatives and analysis of model mechanisms.","2014","3","3","2025-12-02","https://university.edu/papers/dfc52b2f-e1c8-4142-b814-484f309b6af1.pdf");
INSERT INTO Paper VALUES ("1216","Join Optimization in the MapReduce Environment for Column-wise Data Store","The chain join processing which combines records from two or more tables sequentially has been well studied in the centralized databases. However, it has seldom been discussed in the cloud computing era, and remains imperative to be solved, especially where structured (or relational) data are stored in a column (attribute) wise fashion in distributed file systems (e.g., Google File System) over hundreds of or even thousands of commodities PCs. In this paper, we propose a novel method for chain join processing, which is one of the common primitives in the cloud era for column-wise stored data analysis. By effectively selecting the dedicated records (tuples) for the chain join based on the information exploited within bipartite join graph, communication cost for record transmission could be reduced dramatically. A bushy tree structure is deployed to regulate the chain join sequence, which further reduces the number of intermediate results generated and transmitted, and explores higher parallelism in join processing, while results in more efficient join processing. Our extensive performance study confirms the effectiveness and efficiency of our methods.","2010","18","2","2025-12-02","https://university.edu/papers/c41b1e3a-2d73-41cd-8f04-af24704e6591.pdf");
INSERT INTO Paper VALUES ("1217","An analysis of symbolic linguistic computing models in decision making","It is common that experts involved in complex real-world decision problems use natural language for expressing their knowledge in uncertain frameworks. The language is inherent vague, hence probabilistic decision models are not very suitable in such cases. Therefore, other tools such as fuzzy logic and fuzzy linguistic approaches have been successfully used to model and manage such vagueness. The use of linguistic information implies to operate with such a type of information, i.e. processes of computing with words (CWW). Different schemes have been proposed to deal with those processes, and diverse symbolic linguistic computing models have been introduced to accomplish the linguistic computations. In this paper, we overview the relationship between decision making and CWW, and focus on symbolic linguistic computing models that have been widely used in linguistic decision making to analyse if all of them can be considered inside of the CWW paradigm.","2013","12","1","2025-12-02","https://university.edu/papers/7e73b6ee-7f20-44bd-9c9f-de99bfaa4f67.pdf");
INSERT INTO Paper VALUES ("1218","Graph Rewriting and Strategies for Modeling Biochemical Networks","In this paper, we present a rewriting framework for modeling molecular complexes, biochemical reaction rules, and generation of biochemical networks based on the representation of molecular complexes as a particular type of multi- graphs with ports called molecular graphs. The advantage of this approach is to obtain for free a rewriting calculus which allows defining at the same level transformation rules and strategies for modeling rule selection and application, in order to prototype network generation.","2007","7","3","2025-12-02","https://university.edu/papers/c9059ebc-acc4-47cf-a582-54f621b93ea9.pdf");
INSERT INTO Paper VALUES ("1219","Appearance-based object recognition using multiple views","Object recognition from a single view fails when the available features are not sufficient to determine the identity of a single object, either because of similarity with another object or because of feature corruption due to clutter and occlusion. Active object recognition systems have addressed this problem successfully, but they require complicated systems with adjustable viewpoints that are not always available. In this paper we investigate the performance gain available by combining the results of a single view object recognition system applied to imagery obtained from multiple fixed cameras. In particular, we address performance in cluttered scenes with varying degrees of information about relative camera pose. We argue that a property common to many computer vision recognition systems, which we term a weak target error, is responsible for two interesting limitations of multi-view performance enhancement: the lack of significant improvement in systems whose single-view performance is weak, and the plateauing of performance improvement as additional multi-view constraints are added.","2001","10","4","2025-12-02","https://university.edu/papers/ac938f78-f927-4d0b-ad55-466879fa129f.pdf");
INSERT INTO Paper VALUES ("1220","Generating function analysis of some joint distributions for Poisson loss systems","We present a new approach to derive joint distributions for stationary Poisson loss systems. In particular, for M/M/m/0 and M/M/1/n we find the Laplace transforms (with respect to time t) of the probability that at time t there are i customers in the system and during [0,t], j customers are refused admissions for M/M/m/0 we further determine the LT of the probability that the system was full for less than s time units during [0,t] and serves i customers at time t. Explicit formulas for the corresponding moments are also given.","1999","19","3","2025-12-02","https://university.edu/papers/ccdc42b6-2c75-4006-b1fb-9ab54d04b540.pdf");
INSERT INTO Paper VALUES ("1221","Automatic Extraction and Post-coordination of Spatial Relations in Consumer Language.","To incorporate ontological concepts in natural language processing (NLP) it is often necessary to combine simple concepts into complex concepts (post-coordination). This is especially true in consumer language, where a more limited vocabulary forces consumers to utilize highly productive language that is almost impossible to pre-coordinate in an ontology. Our work focuses on recognizing an important case for post-coordination in natural language: spatial relations between disorders and anatomical structures. Consumers typically utilize such spatial relations when describing symptoms. We describe an annotated corpus of 2,000 sentences with 1,300 spatial relations, and a second corpus of 500 of these relations manually normalized to UMLS concepts. We use machine learning techniques to recognize these relations, obtaining good performance. Further, we experiment with methods to normalize the relations to an existing ontology. This two-step process is analogous to the combination of concept recognition and normalization, and achieves comparable results.","2015","12","4","2025-12-02","https://university.edu/papers/e2e36e88-427d-45a2-adcf-917c85cc9448.pdf");
INSERT INTO Paper VALUES ("1222","Multilevel selection in models of prebiotic evolution II: a direct comparison of compartmentalization and spatial self-organization.","Multilevel selection has been indicated as an essential factor for the evolution of complexity in interacting RNA-like replicator systems. There are two types of multilevel selection mechanisms: implicit and explicit. For implicit multilevel selection, spatial self-organization of replicator populations has been suggested, which leads to higher level selection among emergent mesoscopic spatial patterns (traveling waves). For explicit multilevel selection, compartmentalization of replicators by vesicles has been suggested, which leads to higher level evolutionary dynamics among explicitly imposed mesoscopic entities (protocells). Historically, these mechanisms have been given separate consideration for the interests on its own. Here, we make a direct comparison between spatial self-organization and compartmentalization in simulated RNA-like replicator systems. Firstly, we show that both mechanisms achieve the macroscopic stability of a replicator system through the evolutionary dynamics on mesoscopic entities that counteract that of microscopic entities. Secondly, we show that a striking difference exists between the two mechanisms regarding their possible influence on the long-term evolutionary dynamics, which happens under an emergent trade-off situation arising from the multilevel selection. The difference is explained in terms of the difference in the stability between self-organized mesoscopic entities and externally imposed mesoscopic entities. Thirdly, we show that a sharp transition happens in the long-term evolutionary dynamics of the compartmentalized system as a function of replicator mutation rate. Fourthly, the results imply that spatial self-organization can allow the evolution of stable folding in parasitic replicators without any specific functionality in the folding itself. Finally, the results are discussed in relation to the experimental synthesis of chemical Darwinian systems and to the multilevel selection theory of evolutionary biology in general. To conclude, novel evolutionary directions can emerge through interactions between the evolutionary dynamics on multiple levels of organization. Different multilevel selection mechanisms can produce a difference in the long-term evolutionary trend of identical microscopic entities.","2009","9","2","2025-12-02","https://university.edu/papers/c0ba5f56-ba3e-416a-80f3-534f527ad09f.pdf");
INSERT INTO Paper VALUES ("1223","A unified stochastic model for detecting and tracking faces","We propose merging face detection and face tracking into a single probabilistic framework. The motivation stems from a broader project in algorithmic modeling, centered on the design and analysis of the online computational process in visual recognition. Detection is represented as a tree-structured graphical network in which likelihoods are assigned to each history or 'trace' of processing, thereby introducing a new probabilistic component into coarse-to-fine search strategies. When embedded within a temporal Markov framework, the resulting tracking system yields encouraging results.","2005","3","2","2025-12-02","https://university.edu/papers/4ceac340-f221-4c48-9961-4bee4a98a2b9.pdf");
INSERT INTO Paper VALUES ("1224","GenomeLaser: Fast and accurate haplotyping from pedigree genotypes","We present a software tool called GenomeLaser that determines the haplotypes of each person from unphased high-throughput genotypes in family pedigrees. This method features high accuracy, chromosome-range phasing distance, linear computing, flexible pedigree types and flexible genetic marker types.http://www.4dgenome.com/software/genomelaser.html.","2015","4","2","2025-12-02","https://university.edu/papers/c8823479-de3d-47a0-944d-b1c43ae43ae4.pdf");
INSERT INTO Paper VALUES ("1225","Adolescent Problematic Social Networking and School Experiences: The Mediating Effects of Sleep Disruptions and Sleep Quality","Abstract An important developmental task for adolescents is to become increasingly responsible for their own health behaviors. Establishing healthy sleep routines and controlling media use before bedtime are important for adequate, quality sleep so adolescents are alert during the day and perform well at school. Despite the prevalence of adolescent social media use and the large percentage of computers and cell phones in adolescents' bedrooms, no studies to date have investigated the link between problematic adolescent investment in social networking, their sleep practices, and associated experiences at school. A sample of 1,886 students in Australia aged between 12 and 18 years of age completed self-report data on problematic social networking use, sleep disturbances, sleep quality, and school satisfaction. Structural equation modeling (SEM) substantiated the serial mediation hypothesis: for adolescents, problematic social networking use significantly increased sleep disturbances, which adversely affecte...","2015","9","2","2025-12-02","https://university.edu/papers/07a87b3d-ebb7-4599-9485-200874c9af57.pdf");
INSERT INTO Paper VALUES ("1226","On the Sample Complexity of End-to-end Training vs. Semantic Abstraction Training","We compare the end-to-end training approach to a modular approach in which a system is decomposed into semantically meaningful components. We focus on the sample complexity aspect, in the regime where an extremely high accuracy is necessary, as is the case in autonomous driving applications. We demonstrate cases in which the number of training examples required by the end-to-end approach is exponentially larger than the number of examples required by the semantic abstraction approach.","2016","9","1","2025-12-02","https://university.edu/papers/9069efb4-0053-426c-9b57-9e59b5c4e7c4.pdf");
INSERT INTO Paper VALUES ("1227","Designing Full-Connectivity WDM Optical Interconnects with Reduced Switching and Conversion Complexity","Most existing wavelength division multiplexing (WDM) optical interconnects make use of a large number of switching elements and require wide-range tunable wavelength converters to support full-connectivity among inputs and outputs. This results in complex and expensive designs. In this paper, we propose new full-connectivity single-stage and multi-stage WDM optical interconnects with and reduced hardware complexity. The proposed designs require a smaller number of switching elements and use only fixed-range wavelength conversion. Analysis of hardware complexity shows that, the proposed designs have a smaller number of switching and conversion costs compared to most existing interconnects","2006","5","4","2025-12-02","https://university.edu/papers/d6bdb0e7-10f8-454c-bc11-b8b764ac8ff2.pdf");
INSERT INTO Paper VALUES ("1228","Privacy-Respecting Auctions as Incentive Mechanisms in Mobile Crowd Sensing","In many mobile crowdsensing scenarios it is desirable to give micro-payments to contributors as an incentive for their participation. However, to further encourage participants to use the system, one important requirement is protection of user privacy. In this work we present a reverse auction mechanism as an efficient way to offer incentives to users by allowing them to determine their own price for the data they provide, but also as a way to motivate them to submit better quality data. At the same time our auction protocol guarantees bidders' anonymity and suggests a new rewarding mechanism that enables winners to claim their reward without being linked to the data they contributed. Our protocol is scalable, can be applied to a large class of auctions and remains both computation- and communication-efficient so that it can be run to the mobile devices of users.","2015","11","3","2025-12-02","https://university.edu/papers/cac10f46-7766-46a8-8522-109313ad9c8f.pdf");
INSERT INTO Paper VALUES ("1229","Socially relevant computing","In this paper, we introduce socially relevant computing as a new way to reinvigorate interest in computer science. Socially relevant computing centers on the use of computation to solve problems that students are most passionate about. It draws on both the solipsistic and altruistic side of the current generation of students. It presents computer science as a cutting-edge technological discipline that empowers them to solve problems of personal interest (socially relevant with a little s), as well as problems that are important to society at large (socially relevant with a capital s). We believe that socially relevant computing offers a vision of computer science that has the potential to improve the quantity, quality and diversity of students in our discipline. We describe preliminary results from two on-going curricular experiments at SUNY Buffalo and at Rice University that implement our vision of socially relevant computing.","2008","20","4","2025-12-02","https://university.edu/papers/734136a5-7e43-4457-9c18-0d9648c31a53.pdf");
INSERT INTO Paper VALUES ("1230","Management practice in Malaysian Smart School: tasks and support analysis of the ICT implementation","This study elucidates the type of management practice carried out and the support received by the Malaysian Smart Schools in the implementation of ICT in their school management. The results revealed that the management tasks related to the students' assessments, time table scheduling, administrative records and financial accounting contributed to most of the ICT usage. The results also showed that the Smart Schools Initiative received considerable support from the relevant governmental agencies, parents and private companies and such continuous support was important to maintain the effective and efficient management practice of the Malaysian Smart Schools.","2004","7","2","2025-12-02","https://university.edu/papers/f613c9a0-6d7b-4725-b340-39cb65c7ce7c.pdf");
INSERT INTO Paper VALUES ("1231","Streaming Algorithms for k-Center Clustering with Outliers and with Anonymity","Clustering is a common problem in the analysis of large data sets.  Streaming algorithms, which make a single pass over the data set using small working memory and produce a clustering comparable in cost to the optimal offline solution, are especially useful. We develop the first streaming algorithms achieving a constant-factor approximation to the cluster radius for two variations of the  k -center clustering problem. We give a streaming (4 +  i¾? )-approximation algorithm using  O ( i¾? i¾? 1 kz ) memory for the problem with  outliers , in which the clustering is allowed to drop up to  z of the input points; previous work used a random sampling approach which yields only a bicriteria approximation. We also give a streaming (6 +  i¾? )-approximation algorithm using  O ( i¾? i¾? 1ln ( i¾? i¾? 1)  k +  k 2) memory for a variation motivated by anonymity considerations in which each cluster must contain at least a certain number of input points.","2008","1","2","2025-12-02","https://university.edu/papers/6a624082-6226-4f07-beff-ce06e4bc195d.pdf");
INSERT INTO Paper VALUES ("1232","Equivocable and extractable commitment schemes","We investigate commitment schemes with special security properties, such as equivocability and extractability, motivated by their applicability to highly secure commitment schemes, such as non-malleable or universally-composable commitment schemes. In the public random string model, we present constructions of non-interactive commitment schemes (namely, both the commitment phase and the decommitment phase consist of a single message sent from committer to receiver) that are both equivocable and extractable. One of our constructions uses necessary and sufficient assumptions (thus improving over previous constructions). We combine these constructions with the non-malleability construction paradigm of [8] and obtain, in the public random string model, a non-interactive commitment scheme that is non-malleable with respect to commitment. The assumptions used for this scheme are more general than those used in previous constructions.","2003","7","1","2025-12-02","https://university.edu/papers/cb296a16-974d-4754-a9a5-9c8cf1bb004a.pdf");
INSERT INTO Paper VALUES ("1233","Simulation of the impact of traffic lights placement on vehicle's energy consumption and CO 2 emissions","This paper proposes a method to estimate the impact of traffic light placement policies in term of vehicles' fuel consumption and CO 2  emissions. The method comprises two steps. First, speed profiles are generated representing vehicle's behavior. Then, the mechanical energy spent by the vehicle is computed. The estimation is then used to compare different policies of traffic light placement. Simulations have been carried out to analyze the impact of semaphores distributed into a real road. The relation between the number of traffic lamps and the energy spent is quantified. Finally, a sensitivity analysis is provided considering different classes of vehicles travelling on urban roads.","2012","20","2","2025-12-02","https://university.edu/papers/d933f4ec-f487-4c13-ba65-ffa0675c1847.pdf");
INSERT INTO Paper VALUES ("1234","Synthesis of custom processors based on extensible platforms","Efficiency and flexibility are critical, but often conflicting, design goals in embedded system design. The recent emergence of extensible processors promises a favorable tradeoff between efficiency and flexibility, while keeping design turnaround times short. Current extensible processor design flows automate several tedious tasks, but typically require designers to manually select the parts of the program that are to be implemented as custom instructions.In this work, we describe an automatic methodology to select custom instructions to augment an extensible processor, in order to maximize its efficiency for a given application program. We demonstrate that the number of custom instruction candidates grows rapidly with program size, leading to a large design space, and that the quality (speedup) of custom instructions varies significantly across this space, motivating the need for the proposed flow. Our methodology features cost functions to guide the custom instruction selection process, as well as static and dynamic pruning techniques to eliminate inferior parts of the design space from consideration. Further, we employ a two-stage process, wherein a limited number of promising instruction candidates are first selected, and then evaluated in more detail through cycle-accurate instruction set simulation and synthesis of the corresponding hardware, to identify the custom instruction combinations that result in the highest program speedup or maximize speedup under a given area constraint.We have evaluated the proposed techniques using a state-of-the-art extensible processor platform, in the context of a commercial design flow. Experiments with several benchmark programs indicate that custom processors synthesized using automatic custom instruction selection can result in large improvements in performance (upto 5.4X, average of 3.4X), energy (upto 4.5X, average of 3.2X), and energy-delay product (upto 24.2X, average of 12.6X), while speeding up the design process significantly.","2002","5","2","2025-12-02","https://university.edu/papers/8e09f794-9fbc-4787-817e-eb8aecd6bda0.pdf");
INSERT INTO Paper VALUES ("1235","Annotating database schemas to help enterprise search","In large enterprises, data discovery is a common problem faced by users who need to find relevant information in relational databases. In this scenario, schema annotation is a useful tool to enrich a database schema with descriptive keywords. In this paper, we demonstrate Barcelos, a system that automatically annotates corporate databases. Unlike existing annotation approaches that use Web oriented knowledge bases, Barcelos mines enterprise spreadsheets to find candidate annotations. Our experimental evaluation shows that Barcelos produces high quality annotations; the top-5 have an average precision of 87%.","2015","16","1","2025-12-02","https://university.edu/papers/56c2b034-5767-45ba-a2e7-4adab4f647b3.pdf");
INSERT INTO Paper VALUES ("1236","Energy-Efficient Spectrum Leasing in Cognitive Relay Networks","In this paper, we propose an energy-efficient resource allocation algorithm to minimize the total average transmission power of secondary users (SUs) in cognitive relay networks. Each SU in cognitive relay networks can choose direct transmission or cooperative transmission with the help of relay nodes (RNs). The primary users (PUs) may lease the licensed spectrum for a fraction of time to SUs for some remuneration. So the SUs adopt time-division multiple-access (TDMA) to access the licensed spectrum. For energy efficiency, we jointly consider the time slot scheduling and transmission strategy selection (i.e. direct transmission or cooperative transmission) problem. Numerical results indicate that the transmission power consumption indeed decreases due to the cooperative diversity.","2011","11","1","2025-12-02","https://university.edu/papers/5d72b2ef-de63-4abb-ba63-369cf4c1e299.pdf");
INSERT INTO Paper VALUES ("1237","Emerging collective behavior in a simple artificial financial market","We consider a simple model for a society of economic agents, where each can invest a discrete quantity. Interactions among agents happen in a neighborhood and depend on the motivation level (insider information, economy prospects, etc.). The profit of the group fluctuates stochastically and is used to update individual motivations. We analyze the behavior, as a function of time, of the global persistence, given the initial quantity of money invested. Our simulations show that this quantity -- a measure of the probability that the amount of money of the entire group remains at least equal to the initial amount -- has a power law updating behavior. We have also performed simulations with heterogeneous agents, including deceiver and conservative agents. We show that, although there is no regular pattern regarding the average wealth, robust power laws for persistence exist, indicating that this can be used to model the emerging collective behavior. Besides, the updating of motivation and the presence of conservatives and deceivers is remarkable and has an influence on the persistence.","2005","2","2","2025-12-02","https://university.edu/papers/e9f937b6-7991-4362-87f3-5641d2f5ac85.pdf");
INSERT INTO Paper VALUES ("1238","A System for Parking Lot Marking Detection","In this paper, we proposed a robust parking lot marking detection technique that is one important component for intelligent transportation systems and assisted/autonomous driving. Our system learns features of parking lot markings from training data and matches these templates to detected features in the test video during runtime. In the proposed system, maximally stable extremal regions MSER are used to detect a set of parking lot marking candidates. Features are then extracted from the detected candidates and Support Vector Machine SVM is applied to classify the parking lot marking in an efficient manner. With the detected parking lot markings, a parking lot is estimated by fitting two adjacent parking lot markings. The proposed technique is tested on real world street-view videos captured with an in-car camera. The experimental results show that the proposed technique is robust and capable of detecting parking lots under different lighting, marking sizes, and marking poses.","2014","17","4","2025-12-02","https://university.edu/papers/f3d9e4ab-c813-4491-9a47-e3d054f97060.pdf");
INSERT INTO Paper VALUES ("1239","PDFMEF: A Multi-Entity Knowledge Extraction Framework for Scholarly Documents and Semantic Search","We introduce PDFMEF, a multi-entity knowledge extraction framework for scholarly documents in the PDF format. It is implemented with a framework that encapsulates open-source extraction tools. Currently, it leverages PDFBox and TET for full text extraction, the scholarly document filter described in [5] for document classification, GROBID for header extraction, ParsCit for citation extraction, PDFFigures for figure and table extraction, and algorithm extraction [27]. While it can be run as a whole, the extraction tool in each module is highly customizable. Users can substitute default extractors with other extraction tools they prefer by writing a thin wrapper to implement the abstracts. The framework is designed to be scalable and is capable of running in parallel using a multi-processing technique in Python. Experiments indicate that the system with default setups is CPU bounded, and leaves a small footprint in the memory, which makes it best to run on a multi-core machine. The best performance using a dedicated server of 16 cores takes 1.3 seconds on average to process one PDF document. It is used to index extracted information and help users to quickly locate relevant results in published scholarly documents and to efficiently construct a large knowledge base in order to build a semantic scholarly search engine. Part of it is running on CiteSeerX digital library search engine.","2015","14","4","2025-12-02","https://university.edu/papers/f1dcae35-6e81-4ed8-9dc8-4e7c148d6b68.pdf");
INSERT INTO Paper VALUES ("1240","Pattern-based AI scripting using ScriptEase","Creating realistic artificially-intelligent characters is seen as one of the major challenges of the commercial games industry. Historically, character behavior has been specified using simple finite state machines and, more recently, by AI scripting languages. These languages are relatively 'simple', in part because the language has to serve three user communities: game designers, game programmers, and consumers - each with different levels of programming experience. The scripting often becomes unwieldy, given that potentially hundreds (thousands) of characters need to be defined, the characters need non-trivial behaviors, and the characters have to interface with the plot constraints. In this paper, the ScriptEase model for AI scripting is presented. The model is pattern-template based, allowing designers to quickly build complex behaviors without doing explicit programming. This paper describes ScriptEase's behavior patterns and user interface. This is demonstrated by generating code for BioWare's Neverwinter Nights game. In addition to behaviors, the model is being extended to include encounter, dialog, and plot patterns.","2003","11","3","2025-12-02","https://university.edu/papers/ecba47ea-3af7-4b59-a02c-874eb98dd133.pdf");
INSERT INTO Paper VALUES ("1241","Phase Transitions in Neural Networks","Various simulations of cortical subnetworks have evidenced something like phase transitions with respect to key parameters. We demonstrate that such transitions must indeed exist in analogous infinite array models. For related finite array models classical phase transitions (which describe steady-state behavior) may not exist, but there can be distinct qualitative changes in ('metastable') transient behavior as key system parameters pass through critical values.","1988","17","1","2025-12-02","https://university.edu/papers/edb31d1d-495f-40aa-b9f4-42d4f4ae3064.pdf");
INSERT INTO Paper VALUES ("1242","A dynamic scheduler for balancing HPC applications","Load imbalance cause significant performance degradation in High Performance Computing applications. In our previous work we showed that load imbalance can be alleviated by modern MT processors that provide mechanisms for controlling the allocation of processors internal resources. In that work, we applied static, hand-tuned resource allocations to balance HPC applications, providing improvements for benchmarks and real applications.   In this paper we propose a dynamic process scheduler for the Linux kernel that automatically and transparently balances HPC applications according to their behavior. We tested our new scheduler on an IBM POWER5 machine, which provides a software-controlled prioritization mechanism that allows us to bias the processor resource allocation. Our experiments show that the scheduler reduces the imbalance of HPC applications, achieving results similar to the ones obtained by hand-tuning the applications (up to 16%). Moreover, our solution reduces the application's execution time combining effect of load balance and high responsive scheduling.","2008","8","4","2025-12-02","https://university.edu/papers/e0ac8b20-3add-4d6a-9d03-d6ddf4f1ae96.pdf");
INSERT INTO Paper VALUES ("1243","Compressive CSIT estimation for multi-user massive MIMO with autonomous adaptation of pilot and feedback","Acquisition of accurate channel state information (CSI) at the base station (CSIT) is a major challenge of deploying frequency-division duplexing (FDD) massive MIMO systems. Although compressive sensing (CS) based CSIT estimation approaches have been proposed to reduce the pilot training overhead for massive MIMO systems, the existing schemes cannot properly dimension the minimum required pilot symbols to estimate the CSIT of all users at the required CSIT quality, because of the loose bounds on the required number of measurements for successful CS recovery and the unknown sparsity levels of user channels. In this paper, we propose a robust closed-loop compressive CSIT feedback and estimation framework which not only exploits the joint sparsity structure of the multi-user (MU) massive MIMO channels to improve the CSIT estimation performance, but also has the learning capability to adapt to the minimum pilot and feedback resources needed under unknown and time-varying channel sparsity levels. We establish the convergence of the proposed closed-loop adaptation algorithm. Simulations show that the proposed framework has substantial performance gain over conventional open-loop algorithms and is robust to dynamic sparsity and model mismatch.","2016","13","4","2025-12-02","https://university.edu/papers/c8ba1135-766d-4a70-aeae-c32c6f122a50.pdf");
INSERT INTO Paper VALUES ("1244","Monocular depth perception by evaluation of the blur in defocused images","We present a range sensing method based on monocular computer vision. The method exploits the physical effect that the imaging properties of an optical system depend on the acquisition parameters and the object distance. Basic principle is to compare the blur in a couple of defocused images of the same scene, taken with different apertures (depth-from-defocus). Our approach is working along the edges, but not restricted to ideal step edges. >","1994","16","3","2025-12-02","https://university.edu/papers/4dfeac9a-7ce9-4f3b-b35b-177aa4a8a5d9.pdf");
INSERT INTO Paper VALUES ("1245","Inferring Popularity of Domain Names with DNS Traffic: Exploiting Cache Timeout Heuristics","Popularity ranking of Internet services is an important metric for network operators, because it enables mid- to-long term planning of their network facilities and root cause analysis for unexpected traffic. The service-oriented traffic monitoring is much helpful to infer the popularity, hence it has been gathering much attention from both researchers and practitioners. Lately, service identification of a given flow has become very difficult due to the rapid growth of CDNs and/or encrypted traffic, while some research works employed preceding DNS traffic as a hint. However, because of its cache mechanism, the DNS message count deviates from the actual number of flows, which can greatly degrade the ranking reliability. We propose a theoretical model for inferring the user's number of accesses per domain name by exploiting the characteristics of the DNS message count. To the best of our knowledge, this paper is the first attempt to formulate the effect of user's stub resolvers; previous studies were focused on analyzing the effect of cache servers. We evaluated the precision of our model with a real dataset of traffic of thousands of users. By analyzing the top-50 domain names by the number of users, we can infer the number of flows within a 24% error rate on average in 42 out of 50 FQDNs.","2014","10","3","2025-12-02","https://university.edu/papers/79ba08cb-cfd4-4877-aa13-312f3ff743de.pdf");
INSERT INTO Paper VALUES ("1246","Large dynamic range time-frequency signal analysis with application to helicopter Doppler radar data","Despite the enhanced time-frequency analysis (TFA) detailing capability of quadratic TFAs like the Wigner and Cohen representations, their performance with signals of large dynamic range (DNR in excess of 40 dB) is not acceptable due to the inability to totally suppress the cross-term artifacts which typically are much stronger than the weakest signal components that they obscure. AMTI and GMTI radar targets exhibit such high dynamic range when microDoppler is present, with the aspects of interest being the weakest components. This paper presents one of two modifications of linear TFA to provide the enhanced detailing behavior of quadratic TFAs without introducing cross terms, making it possible to see the time-frequency detail of extremely weak signal components. The technique described here is based on subspace-enhanced linear predictive extrapolation of the data within each analysis window to create a longer data sequence for conventional STFT TFA. The other technique, based on formation of a special two-dimensional transformed data matrix analyzed by high-definition two-dimensional spectral analysis methods such as 2-D AR or 2-D minimum variance, is compared to the new technique using actual AMTI and GMTI radar data.","2003","17","1","2025-12-02","https://university.edu/papers/d2f0be3d-f30b-495b-a0a3-33eee1283684.pdf");
INSERT INTO Paper VALUES ("1247","A network flow model for biclustering via optimal re-ordering of data matrices","The analysis of large-scale data sets using clustering techniques arises in many different disciplines and has important applications. Most traditional clustering techniques require heuristic methods for finding good solutions and produce suboptimal clusters as a result. In this article, we present a rigorous biclustering approach, OREO, which is based on the Optimal RE-Ordering of the rows and columns of a data matrix. The physical permutations of the rows and columns are accomplished via a network flow model according to a given objective function. This optimal re-ordering model is used in an iterative framework where cluster boundaries in one dimension are used to partition and re-order the other dimensions of the corresponding submatrices. The performance of OREO is demonstrated on metabolite concentration data to validate the ability of the proposed method and compare it to existing clustering methods.","2010","20","2","2025-12-02","https://university.edu/papers/aa52d6ed-c7c7-43ba-9f33-dc0849fa2c31.pdf");
INSERT INTO Paper VALUES ("1248","Sequential sampling techniques for algorithmic learning theory","A sequential sampling algorithm or adaptive sampling algorithm is a sampling algorithm that obtains instances sequentially one by one and determines from these instances whether it has already seen enough number of instances for achieving a given task. In this paper, we present two typical sequential sampling algorithms. By using simple estimation problems for our example, we explain when and how to use such sampling algorithms for designing adaptive learning algorithms.","2005","6","3","2025-12-02","https://university.edu/papers/afe39323-0a0c-4d8e-8317-4b7bfe98f9ad.pdf");
INSERT INTO Paper VALUES ("1249","The Use of Bayesian Learning of Neural Networks for Mobile User Position Prediction","Mobility management plays a central role in providing ubiquitous communications services in future wireless mobile networks. In mobility management, there are two key operations, location update and paging, commonly used in tracking mobile users on the move. Location update is to inform the network about a mobile user's current location, while paging is used for the network to locate a mobile user. Both operations will incur signaling traffic in the resource limited wireless networks. The more frequent the location updates, the less paging in locating a mobile user; thus, there is a trade off in terms of signaling cost In this paper, we present a novel hybrid Bayesian neural network model for predicting locations on cellular networks. We investigate different parallel implementation techniques on mobile devices of the proposed approach and compare it to many standard neural network techniques such as: back-propagation, Elman, Resilient, Levenberg-Marqudat, and one-step secant models. In our experiments, we compare results of the proposed Bayesian neural network with 5 standard neural network techniques in predicting next location. Bayesian learning for neural networks predicts location better than standard neural network techniques since it uses well founded probability model to represent uncertainty about the relationship being learned. The result of Bayesian training is a posterior distribution over network weights.","2007","5","4","2025-12-02","https://university.edu/papers/ca45da38-85bc-45c9-a3fe-120b37f361b6.pdf");
INSERT INTO Paper VALUES ("1250","Combining keypoint-based and segment-based features for counting people in crowded scenes","A novel crowd counting system is proposed which utilizes both keypoint-based features and segment-based features together.The foreground segmentation scheme designed for this system works without having to estimate the background image.New statistical features extracted from keypoints to capture some clues regarding to the complexity of the crowds is introduced.Crowd counting is performed in a local manner rather than holistic level which results in a quite generalizable system. The counting of the number of people within a scene is a practical machine vision task, and it has been considered as an important application for security purposes. Most of the people counting algorithms generally extract the foreground segments and map the number of people to some features such as foreground area, texture, or edge count. Keypoint-based approaches, on the other hand, have also been proposed, which involves the use of statistical features of keypoints, such as the number of moving keypoints to estimate the crowd size. In contrast to the foreground segment-based methods, keypoint-based approaches are not sensitive to background changes, illuminations, occlusions, and shadows. However, they have limited performance due to the lack of sufficient features. In this paper, in order to estimate the crowd count, the combination of keypoint-based and segment-based (foreground) features is proposed. However, the whole approach is based on the keypoints and not all the image pixels. The proposed method, firstly, extracts the salient keypoints in the scene. Then, foreground segments are obtained by a simple morphological operation on the moving keypoints and hence the system does not suffer from difficulties associated with foreground/background segmentation. Various features are extracted from each foreground segment together with the corresponding keypoints which are highly correlated with the size, density, and occlusion level of the crowd. Finally, a combination of the segment-based and keypoint-based features is used to estimate the number of people in crowds. The experiment demonstrates that the proposed method achieves lower counting error rates compared to the existing approaches.","2016","18","4","2025-12-02","https://university.edu/papers/aeb0167f-a6c6-4baf-9677-b6fb3d437181.pdf");
INSERT INTO Paper VALUES ("1251","An autoclavable wireless palpation instrument for minimally invasive surgery","Minimally invasive surgery prevents surgeons from manually palpating organs to locate subsurface tumors and other structures. One solution is to use ultrasound; however, it is not always reliable. Various minimally invasive surgery instruments that provide tactile feedback have been proposed to augment ultrasound sensing for tumor localization; however, current designs have limitations such as cumbersome wiring, difficulty in manipulation, lack of sterilizability and high cost. This paper presents a novel, autoclavable, wireless, hand-held palpation instrument that uses a custom, low-cost, disposable tactile sensor to provide tactile and kinesthetic force feedback. The use of a replaceable, disposable tactile sensor avoids deterioration in sensor performance due to repeated autoclaving. The instrument features a passive joint in the end effector that allows the sensor to self-align to the palpation surface in a wide range of orientations. All of the electronics are packaged in a removable module that allows the rest of the instrument to be easily cleaned and autoclaved. Two versions of the tactile sensor, using piezoresistive sensing and capacitive sensing respectively, have been designed for use with this instrument. The instrument is shown to be able to detect 6 mm diameter spherical tumors at a depth of 9–10 mm in ex vivo tissue samples.","2016","16","3","2025-12-02","https://university.edu/papers/cc603380-ff64-4931-80d9-a52525a52f52.pdf");
INSERT INTO Paper VALUES ("1252","TurkDeck: Physical Virtual Reality Based on People","TurkDeck is an immersive virtual reality system that reproduces not only what users see and hear, but also what users feel. TurkDeck produces the haptic sensation using props, i.e., when users touch or manipulate an object in the virtual world, they simultaneously also touch or manipulate a corresponding object in the physical world. Unlike previous work on prop-based virtual reality, however, TurkDeck allows creating arbitrarily large virtual worlds in finite space and using a finite set of physical props. The key idea behind TurkDeck is that it creates these physical representations on the fly by making a group of human workers present and operate the props only when and where the user can actually reach them. TurkDeck manages these so-called 'human actuators' by displaying visual instructions that tell the human actuators when and where to place props and how to actuate them. We demonstrate TurkDeck at the example of an immersive 300m2 experience in 25m2 physical space. We show how to simulate a wide range of physical objects and effects, including walls, doors, ledges, steps, beams, switches, stompers, portals, zip lines, and wind. In a user study, participants rated the realism/immersion of TurkDeck higher than a traditional prop-less baseline condition (4.9 vs. 3.6 on 7 item Likert).","2015","4","4","2025-12-02","https://university.edu/papers/72448995-dab2-45cd-827b-edccc31ea331.pdf");
INSERT INTO Paper VALUES ("1253","Latent Fingerprint Matching","Latent fingerprint identification is of critical importance to law enforcement agencies in identifying suspects: Latent fingerprints are inadvertent impressions left by fingers on surfaces of objects. While tremendous progress has been made in plain and rolled fingerprint matching, latent fingerprint matching continues to be a difficult problem. Poor quality of ridge impressions, small finger area, and large nonlinear distortion are the main difficulties in latent fingerprint matching compared to plain or rolled fingerprint matching. We propose a system for matching latent fingerprints found at crime scenes to rolled fingerprints enrolled in law enforcement databases. In addition to minutiae, we also use extended features, including singularity, ridge quality map, ridge flow map, ridge wavelength map, and skeleton. We tested our system by matching 258 latents in the NIST SD27 database against a background database of 29,257 rolled fingerprints obtained by combining the NIST SD4, SD14, and SD27 databases. The minutiae-based baseline rank-1 identification rate of 34.9 percent was improved to 74 percent when extended features were used. In order to evaluate the relative importance of each extended feature, these features were incrementally used in the order of their cost in marking by latent experts. The experimental results indicate that singularity, ridge quality map, and ridge flow map are the most effective features in improving the matching accuracy.","2011","12","2","2025-12-02","https://university.edu/papers/7f3fefbf-e4c2-4827-bd28-12a4330c25ad.pdf");
INSERT INTO Paper VALUES ("1254","Influence of Risk Incentive by Limited Dividend Provision","Moral hazard problems, which have been broadly studied in economics, financial engineering and other areas, are understood as one of inefficiency to distribute the resources. It is interpreted that after some contract was concluded, one person who has more information than the other may change his behaviour and attitude toward his investment planning, causing some trouble to the other person. In this paper, we study a risk incentive problem between a creditor and shareholders, whose right to make a claim are different from each other, for corporate profits. In particular, we refer to and discuss limited provision on dividend, which may play a role to be able to solve the incentive problem. Some numerical examples are examined to illustrate the problem mentioned.","2011","1","3","2025-12-02","https://university.edu/papers/c4f0a075-51a1-40ce-ab6f-aad94fb9b49c.pdf");
INSERT INTO Paper VALUES ("1255","Analysis of Inverse Crosstalk Channel Estimation Using SNR Feedback","Digital subscriber line (DSL) data rates for short loops are typically limited by crosstalk between adjacent lines rather than by background noise. Precoding can reduce crosstalk in the downstream from the access node to the customer premises equipment significantly if an accurate estimate of the inverse crosstalk channel is provided. Recently, a backward-compatible method has been proposed for estimating downstream crosstalk channels using standardized signal-to-noise ratio (SNR) reports. This paper develops a probabilistic model of the estimation process and, within this model, provides conditions under which successive updates of the precoder are guaranteed to converge to the ideal inverse precoder. Bounds on estimator variance and convergence times are obtained and optimized with respect to system parameters. The analysis can be applied to the situation in which a new line is being activated and added to a group of precoded lines seamlessly, that is, with controlled impact on the SNR of the active lines. Two phases are proposed to achieve seamless activation; the protection phase is used to let the active lines learn the crosstalk from the activating line and the acquisition phase is used to let the activating line learn the crosstalk from the active lines. Results of the analysis are illustrated by numerical simulations.","2011","15","3","2025-12-02","https://university.edu/papers/5c25c5d6-f9cf-4218-8727-607d3693a502.pdf");
INSERT INTO Paper VALUES ("1256","Efficient Parameters for Compressed Sensing Recovery Algorithms","Compressed sensing CS has been an effective research area which it plays an efficient role in many applications such as cognitive radio, imaging, radar and many other applications. The main part of CS system is to recover an input signal by using minimum number of samples than used by conventional (Nyquist) sampling. In this paper, the minimum number of measurements and the number of sparsity level used to reconstruct the signal with minimum error, computational complexity and time will be optimized. Moreover, different recovery algorithms such as convex optimization, greedy algorithms, iterative hard thresholding and hard thresholding pursuit algorithms are used for optimal recovery of sparse signal from a small number of linear measurements. Furthermore, the effect of using CS as denosing will be investigated. Then comparisons study between CS as denoising and conventional denoising process will be made to reduce the effect of noise on the signal.","2017","14","2","2025-12-02","https://university.edu/papers/675a95d0-0f96-46b1-988c-d79e09d61da6.pdf");
INSERT INTO Paper VALUES ("1257","Deep vs. Shallow, Kernel vs. Language--What is Better for Heterogeneous Modeling in SystemC?","It is common for large designs to have heterogeneous components interacting with each other. These components often follow a particular model of computation such as controllers modeled using state machines, signal processing filters modeled as data flow and event-based components using discrete-event. Hence, there are several academic and industrial attempts at incorporating heterogeneity into the design flow, primarily in system level design languages and frameworks for modeling and simulation. A variety of attempts are proposed such as extending simulation kernels for existing frameworks and simply using language constructs to mimic other models of computation. However, the benefit of one over the other is not apparent to the designer and thus not clear which of the two is a better strategy for EDA tools to integrate. In this paper we argue whether Deep heterogeneity (kernel-level) or Shallow heterogeneity (language-level) is a suitable strategy for introducing heterogeneity in system level design languages and frameworks.","2006","20","2","2025-12-02","https://university.edu/papers/e33af608-c4fd-46b2-85bd-68889a0902e0.pdf");
INSERT INTO Paper VALUES ("1258","A Linear Text Classification Algorithm Based on Category Relevance Factors","In this paper, we present a linear text classification algorithm called CRF. By using category relevance factors, CRF computes the feature vectors of training documents belonging to the same category. Based on these feature vectors, CRF induces the profile vector of each category. For new unlabelled documents, CRF adopts a modified cosine measure to obtain similarities between these documents and categories and assigns them to categories that have the biggest similarity scores. In CRF, it is profile vectors not vectors of all training documents that join in computing the similarities between documents and categories. We evaluated our algorithm on a subset of Reuters-21578 and 20_newsgroups text collections and compared it against k-NN and SVM. Experimental results show that CRF outperforms k-NN and is competitive with SVM.","2002","13","3","2025-12-02","https://university.edu/papers/6697d3bf-8eab-4603-9ee8-a1ce412e2b60.pdf");
INSERT INTO Paper VALUES ("1259","Towards a social and context-aware mobile recommendation system for tourism","Loyalty in tourism is one of the main concerns for tourist organizations and researchers alike. Recently, technology in general and CRM and social networks in particular have been identified as important enablers for loyalty in tourism. This paper presents POST-VIA 360, a platform devoted to support the whole life-cycle of tourism loyalty after the first visit. The system is designed to collect data from the initial visit by means of pervasive approaches. Once data is analysed, POST-VIA 360 produces accurate after visit data and, once returned, is able to offer relevant recommendations based on positioning and bio-inspired recommender systems. To validate the system, a case study comparing recommendations from the POST-VIA 360 and a group of experts was conducted. Results show that the accuracy of system’s recommendations is remarkable compared to previous efforts in the field.","2016","6","1","2025-12-02","https://university.edu/papers/dfdc793b-3383-462f-9c84-1a6b215df15e.pdf");
INSERT INTO Paper VALUES ("1260","Graphical models, potential outcomes and causal inference: Comment on Ramsey, Spirtes and Glymour","Ramsey, Spirtes and Glymour (RSG) critique a method proposed by Neumann et al. (2010) for the discovery of functional networks from fMRI meta-analysis data. We concur with this critique, but are unconvinced that directed graphical models (DGMs) are generally useful for estimating causal effects. We express our reservations using the “potential outcomes” framework for causal inference widely used in statistics.","2011","7","4","2025-12-02","https://university.edu/papers/e25f408e-3265-4958-a31e-11f358fe50e5.pdf");
INSERT INTO Paper VALUES ("1261","Using Markov Models to Find Interesting Patient Pathways","Over recent years the concept of Interestingness has come to underpin Data Mining, leading to the discovery of much new knowledge. In particular recognition of interesting patient pathways can lead to the discovery of important rules and patterns such as high probability pathways, groups of patients who incur exceptional high costs or pathways that are very long lasting. In the current paper we show how Markov models can be used to identify such patient pathways. Using Markov modelling we show how patient pathways may be extracted and describe an algorithm based on branch and bound that we have developed to efficiently extract a number of interesting pathways, subject to the number of pathways required, or some other criterion being specified. The approach is illustrated using data on geriatric patients from an administrative database of a London hospital, and we identify interesting pathways for geriatric patients. Such an approach might be used in association with healthcare process improvement technologies, such as Lean Thinking or Six Sigma.","2007","12","2","2025-12-02","https://university.edu/papers/787cd4c0-837e-4e55-8d79-75c30f9f8a32.pdf");
INSERT INTO Paper VALUES ("1262","Error-related medial frontal theta activity predicts cingulate-related structural connectivity","Studies on electrophysiological signatures of error processing have focused on the medial frontal cortex, although widespread neuroanatomical networks support error/action monitoring. Here, electrophysiological responses to errors were combined with structural white matter diffusion tensor imaging (DTI) to investigate the long-range anatomical networks that support error processing. The approach taken here was to link individual differences in error-related EEG responses to individual differences in white matter connectional anatomy. Twenty subjects performed a speeded instructed choice task (a variant of the Simon task) designed to elicit response errors, and also underwent DTI scanning in a separate session. In the EEG data, significantly enhanced theta (4–8 Hz) oscillations were observed over medial frontal electrodes (centered on FCz) during response errors. Mid-frontal scalp sites (likely reflecting medial frontal cortex activity) also functioned as a strong “hub” for information flow, measured through theta-band phase synchronization degree. Next, a dipole source of the error-related theta-band activity was localized for each subject, accounting for approximately 80% of the topographical variance. Correlating individual differences in medial frontal theta dynamics with white matter tracts linking these dipole sources to the rest of the brain revealed that subjects with stronger error-related theta also had stronger white matter connectivity with the ventral striatum and inferior frontal gyrus. Further, subjects in whom medial frontal regions acted as a stronger synchronization “hub” had stronger connectivity between the dipole source location and the corpus callosum and dorsomedial prefrontal white matter pathways. These findings provide novel evidence for the role of widespread fronto-striatal networks in monitoring actions and signaling behavioral errors.","2011","1","3","2025-12-02","https://university.edu/papers/d495569d-30fa-4145-9253-9a7646eb799b.pdf");
INSERT INTO Paper VALUES ("1263","Detecting hypermutations in viral sequences with an emphasis on G --> A hypermutation.","This program compares sequence sets to a reference sequence, tallies G → A hypermutations, and presents the results in various tables and graphs, which include dinucleotide context, summaries of all observed nucleotide changes, and stop codons introduced by hypermutation.","2000","11","1","2025-12-02","https://university.edu/papers/af4132af-557f-4fc0-94ff-984140526bfe.pdf");
INSERT INTO Paper VALUES ("1264","Pinball attacks: Exploiting channel allocation in wireless networks","As wireless networks continue to grow rapidly denser with the introduction of various wireless-enabled elements, signal interference coupled with limited radio spectrum availability emerges as a significant hindrance to network performance. In order to retain high network throughput, channels must be strategically assigned to nodes in a way that minimizes signal overlap between neighboring nodes. Current static channel assignment techniques are intolerant of network variations and growth, but flexible dynamic techniques are becoming more feasible with the introduction of software defined networks and network function virtualization. As network maintenance tasks are increasingly handled by software, however, network stability becomes susceptible to malicious behavior. In this paper, we adopt an attacker's prespective and expose stealthy attacks — which we coin “pinball” Attacks — that aim to trigger unnecessary channel switching behavior in a network and increase signal interference between neighboring nodes. We develop a Markov Decision Process (MDP) framework and investigate suboptimal attack policies applied to a number of real-world topologies. We derive attack policies as approximate MDP solutions due to the exponentially large state space. Our results show that pinball attack outperforms other attack policies such as Denial of Service, Random, and other heuristic policies.","2016","12","3","2025-12-02","https://university.edu/papers/0e408c61-31a6-4163-9210-8665d55031ef.pdf");
INSERT INTO Paper VALUES ("1265","Educational Material for 3D Visualization of Spine Procedures: Methods for Creation and Dissemination","Spine anatomy can be difficult to master and is essential for performing spine procedures. We sought to utilize the rapidly expanding field of 3D technology to create freely available, interactive educational materials for spine procedures. Our secondary goal was to convey lessons learned about 3D modeling and printing. This project involved two parallel processes: the creation of 3D-printed physical models and interactive digital models. We segmented illustrative CT studies of the lumbar and cervical spine to create 3D models and then printed them using a consumer 3D printer and a professional 3D printing service. We also included downloadable versions of the models in an interactive eBook and platform-independent web viewer. We then provided these educational materials to residents with a pretest and posttest to assess efficacy. The “Spine Procedures in 3D” eBook has been downloaded 71 times as of October 5, 2016. All models used in the book are available for download and printing. Regarding test results, the mean exam score improved from 70 to 86%, with the most dramatic improvement seen in the least experienced trainees. Participants reported increased confidence in performing lumbar punctures after exposure to the material. We demonstrate the value of 3D models, both digital and printed, in learning spine procedures. Moreover, 3D printing and modeling is a rapidly expanding field with a large potential role for radiologists. We have detailed our process for creating and sharing 3D educational materials in the hopes of motivating and enabling similar projects.","2017","17","1","2025-12-02","https://university.edu/papers/325c15b0-45d3-4eb2-bf64-793b52d9b145.pdf");
INSERT INTO Paper VALUES ("1266","Situation-awareness for adaptive coordination in service-based systems","Service-based systems have many applications, including collaborative research and development, e-business, health care, environmental control, military applications, and homeland security. Service coordination is required for these systems to coordinate distributed activities. To achieve adaptive service coordination under changing environment and workload, situation-awareness is needed. In this paper, a model is presented for situation-awareness (SAW) requirements in service-based systems. Based on this model, SAW agents are developed to incorporate situation-awareness and adaptive coordination in service-based systems.","2005","20","3","2025-12-02","https://university.edu/papers/4f923a57-d08c-47af-aa34-3b498388a155.pdf");
INSERT INTO Paper VALUES ("1267","Type-and-scope safe programs and their proofs","We abstract the common type-and-scope safe structure from computations on I�-terms that deliver, e.g., renaming, substitution, evaluation, CPS-transformation, and printing with a name supply. By exposing this structure, we can prove generic simulation and fusion lemmas relating operations built this way. This work has been fully formalised in Agda.","2017","2","3","2025-12-02","https://university.edu/papers/a4c53c5e-dce3-4a3d-a75d-e4f99a4b57a3.pdf");
INSERT INTO Paper VALUES ("1268","The Role of Social Capital in the Creation of Community Wireless Networks","Community wireless networks (CWNs) offer free or affordable Internet access for the purpose of improving the well-being of the community. Many questions have been raised about the ownership, sustainability, and social and economic implications of CWNs. To address these concerns, we propose a conceptual framework that describes the role of social capital in the creation of CWNs. This framework takes into account a number of collective actions and cooperative activities that contribute to the development of CWNs. These actions and cooperative activities include donating money and hardware, volunteering manpower and technical skills, developing open source software for the network, and sharing wireless nodes with peers. We used the collective actions and cooperation construct of the social capital concept to attribute these types of community contributions. We collected data via a survey to support the proposed framework. The primary implication for practitioners is that mobilizing embedded resources in communities can build a common wireless infrastructure for their digital needs. This study is an important step towards advancing this topic as an intellectual stream.","2009","16","4","2025-12-02","https://university.edu/papers/fa9a33df-954a-427a-a4da-10a14383171b.pdf");
INSERT INTO Paper VALUES ("1269","Parametric Model Order Reduction via Balanced Truncation with Taylor Series Representation","This paper presents a new method for parametric model order reduction based on balanced truncation. Parametric model order reduction seeks to generate low-order models from larger models without losing the dependence on a parameter. Using a Taylor expansion of the original system, a Taylor expansion of the balanced system can be obtained. In contrast to interpolation-based approaches for the solution of the parametric model order reduction problem, the proposed approach permits calculation of the reduced system as well as the corresponding projection matrix for different parameter values with reduced computation power. This bypasses the problem of incompatible subspaces from different snapshot points potentially occurring in interpolation based approaches that can lead to unexpected behavior up to instability. The presented method can handle multidimensional parameter spaces. Sufficient conditions for the convergence of the Taylor series of the balanced system based on holomorphic functions are derived. The truncation step as well as error bounds are discussed. A Bernoulli beam model is used as an example to demonstrate the performance of the technique.","2016","2","3","2025-12-02","https://university.edu/papers/69cc1db5-98e3-45cd-a7bc-ad181d22264f.pdf");
INSERT INTO Paper VALUES ("1270","The interplay between energy-efficient train control and scheduled running time supplements","Energy-efficient train operation is not yet included in the timetable design process in the Netherlands. Hence, running time supplements are not optimally distributed in the timetable. Therefore research has been conducted on the possibilities to better incorporate energy-efficient train operation into the railway timetable. This paper describes the developed EZR model (energy-efficient operation or in Dutch ‘EnergieZuinig Rijden’) based on optimal control theory and an algorithm that determines the joint optimal cruising speed and coasting point for individual train trips; taking into account a desired robustness, the possibilities for energy-efficient operation, and the desired punctuality during operations. The model is applied in a case study of a regional train line in the Netherlands between Utrecht Centraal and Rhenen. The results show that it is better to distribute the running time supplements evenly than concentrating it near the main stations.","2015","9","1","2025-12-02","https://university.edu/papers/97ee954e-4938-4ca1-830d-3018496f5e49.pdf");
INSERT INTO Paper VALUES ("1271","Fast modular division for application in ECC on reconfigurable logic","Elliptic Curve Public Key Cryptosystems are becoming increasingly popular for use in mobile devices and applications where bandwidth and chip area are limited. They provide much higher levels of security per key length than established public key systems such as RSA. The underlying operation of elliptic curve point multiplication requires modular multiplication, division/inversion and addition/subtraction. Division is by far the most costly operation in terms of speed. This paper proposes a new divider architecture and implementation on FPGA for use in an ECC processor.","2003","19","1","2025-12-02","https://university.edu/papers/170b305f-8e8b-4548-a2ab-9890c4e91b65.pdf");
INSERT INTO Paper VALUES ("1272","A Novel Image Encryption Scheme Based on Generalized Multi-sawtooth Maps","In this paper, a generalized multi-sawtooth map based image encryption scheme with an efficient permutation-diffusion mechanism is proposed. In the permutation process, a general- ized multi-sawtooth map is utilized to generate one chaotic orbit used to get one index order se- quence for the permutation of image pixel positions, while in the diffusion process, two generalized multi-sawtooth maps are employed to yield two pseudo-random grey value sequences for a two- way diffusion of pixel grey values. The yielded grey value sequences are not only sensitive to the control parameters and initial conditions of the considere d chaotic maps, but also strongly depend on the plain-image processed, therefore the proposed scheme can effectively resist statistical attack, differential attack, known-plaintext as well as chosen-pl aintext attack. Experimental results show that the new image encryption scheme has satisfactory security thanks to its large key space and robust permutation-diffusion mechanism, which makes it a potential candidate for designing image encryption schemes.","2014","16","4","2025-12-02","https://university.edu/papers/f81be8ff-3266-4f9d-b7f5-15c33b27b64c.pdf");
INSERT INTO Paper VALUES ("1273","Study about decomposition and integration of continuous systems in discrete environment","A complex system is one composed of many interacting heterogeneous entities. This kind of system can be dealt with multi-modeling and co-simulation but individual models may also be heterogeneous (continuous, discrete, event-based...). To manage this complexity, we use MECSYCO1, a DEVS2 compliant environment for co-simulation.#R##N##R##N#MECSYCO handles heterogeneity issues, but the number of models which may interact during a co-simulation of a complex system raises performance issues and it is important to develop performance measurement tools to study these issues with MECSYCO.#R##N##R##N#In this article we present modular performance measurement tools for MECSYCO. We exemplify the use of these tools on our 'Multi-Room Heating' toy model, a scalable continuous system, to assert the tradeoff between accuracy and computational time when integrating continuous system in a discrete modeling environment. We explore the impact of decomposing a continuous system contained in one FMU3 into several FMUs which interact. Finally we study how, under some conditions, a large model that cannot be solved on one block, can be decomposed into smaller ones, solved and simulated in a co-simulation on MECSYCO without significant loss of accuracy.","2016","16","2","2025-12-02","https://university.edu/papers/3d97640c-7dd7-4048-a5bd-ba88d148985c.pdf");
INSERT INTO Paper VALUES ("1274","Self-Balancing Decentralized Distributed Platform for Urban Traffic Simulation","Microscopic traffic simulation is the most accurate tool for predictive analytics in urban environments. However, the amount of workload (i.e., cars simulated simultaneously) can be challenging for classical systems, particularly for scenarios requiring faster than real-time processing (e.g., for emergency units having to make quick decisions on traffic management). This challenge can be tackled with distributed simulations by sharing the load between simulation engines running on different computing nodes, hence balancing the processing power required. This paper studies the performance of dSUMO, i.e., a distributed microscopic traffic simulator. dSUMO is fully decentralized and can dynamically balance the workload between its computing nodes, hence showing important improvements against classical, centralized and not dynamic, solutions.","2017","16","1","2025-12-02","https://university.edu/papers/edb16526-cd36-4dd1-84e8-56b86fe40b50.pdf");
INSERT INTO Paper VALUES ("1275","Matching of Images with Rotation Transformation Based on the Virtual Electromagnetic Interaction","A novel approach of image matching for rotating transformation is presented and studied. The approach is inspired by electromagnetic interaction force between physical currents. The virtual current in images is proposed based on the significant edge lines extracted as the fundamental structural feature of images. The virtual electromagnetic force and the corresponding moment is studied between two images after the extraction of the virtual currents in the images. Then image matching for rotating transformation is implemented by exploiting the interaction between the virtual currents in the two images to be matched. The experimental results prove the effectiveness of the novel idea, which indicates the promising application of the proposed method in image registration.","2016","2","3","2025-12-02","https://university.edu/papers/2744e4f0-6b52-4183-905a-f3a687e13596.pdf");
INSERT INTO Paper VALUES ("1276","A scalable high-performance communication library for wide-area environments","We report our progress on SSOCK, a scalable high-performance communication library for wide-area environments. SSOCK has an API similar to that of the Socket library, but solves the connectivity and scalability issues involved with WANs. In one experiment, SSOCK was able to connect 1,262 processes with each other in a 13-cluster environment with firewalls and NAT, without any of the connectivity and resource allocation problems that were encountered when the Socket library was used. In another experiment in which 100 processes simultaneously tried to establish connections, SSOCK was able to establish connections between all pairs of processes in 1.2 seconds, while the Socket library suffered from a large number of packet losses and timed out after 189 seconds.","2008","1","2","2025-12-02","https://university.edu/papers/8f50c26e-7a19-450b-ae91-43fc9826428f.pdf");
INSERT INTO Paper VALUES ("1277","Yield enhancement of field programmable logic arrays by inherent component redundancy","A complete technique that does not use any additional components for enhancing the yield of field-programmable logic arrays (FPLAs) is presented. In this approach, the inherent sparsity (absence of devices at crosspoints) of programmable logic arrays (PLAs) is utilized to mask certain types of manufacturing defects within the unprogrammed FPLAs, thus reclaiming chips which are otherwise discarded. Two categories of faults (called type 1 and type 2) are considered. Type-1 faults, which can be diagnosed a priori, are considered first. After diagnosing type 1 faults, the mask can be reconfigured around the faulty crosspoints. A streamlined bipartite matching algorithm is presented to enhance the speed of this reconfiguration. The uniqueness of the approach is that the programming of an FPLA is formulated as a graph theoretic problem for which a polynomial time solution exists. Type-2 faults in general cannot be diagnosed a priori. Therefore, a dynamic technique is presented for the repair of type-2 faults. Unused product lines of the FPLA are utilized for the repair. With a sufficient number of excess product lines, it is shown that a defective FPLA is guaranteed to be rendered usable. A probability measure for the usability of defective FPLA is obtained both with and without the implementation of this technique. Computer studies have shown that FPLAs with even a large number of defects can be successfully repaired, thereby increasing the yield. >","1990","6","2","2025-12-02","https://university.edu/papers/d3b77f25-2b30-40fb-a302-b3a909d12087.pdf");
INSERT INTO Paper VALUES ("1278","Sample Complexity for Learning Recurrent Perceptron Mappings","Recurrent perceptron classifiers generalize the classical perceptron model. They take into account those correlations and dependences among input coordinates which arise from linear digital filtering. This paper provides tight bounds on sample complexity associated to the fitting of such models to experimental data.","1996","3","4","2025-12-02","https://university.edu/papers/93e83178-a1f2-45b4-8e25-d040258e58e9.pdf");
INSERT INTO Paper VALUES ("1279","The dBoard: A Digital Scrum Board for Distributed Software Development","In this paper we present the dBoard - a digital Scrum Board for distributed Agile software development teams. The dBoard is designed as a 'virtual window' between two Scrum team spaces. It connects two locations with live video and audio, which is overlaid with a synchronized and interactive digital Scrum board, and it adapts the fidelity of the video/audio to the presence of people in front of it. The dBoard is designed to work (i) as a passive information radiator from which it is easy to get an overview of the status of work, (ii) as a media space providing awareness about the presence of remote co-workers, and (iii) as an active meeting support tool. The paper presents a case study of distributed Scrum in a large software company that motivates the design of the dBoard, and details the design and technical implementation of the dBoard. The paper also reports on an initial user study, which shows that users found the dBoard both useful and easy to use. Based on this work, we suggest that superimposing collaborative applications onto live video is a useful way of designing collaborative meeting and awareness systems.","2015","4","1","2025-12-02","https://university.edu/papers/543c37bf-e1a8-4f3a-8a7b-37447696cc13.pdf");
INSERT INTO Paper VALUES ("1280","Lambda coordinates for binary elliptic curves","In this work we present the λ-coordinates, a new system for representing points in binary elliptic curves. We also provide efficient elliptic curve operations based on the new representation and timing results of our software implementation over the field $\mathbb{F}_{2^{254}}$. As a result, we improve speed records for protected/unprotected single/multi-core software implementations of random-point elliptic curve scalar multiplication at the 128-bit security level. When implemented on a Sandy Bridge 3.4GHz Intel Xeon processor, our software is able to compute a single/multi-core unprotected scalar multiplication in 72,300 and 47,900 clock cycles, respectively; and a protected single-core scalar multiplication in 114,800 cycles. These numbers improve by around 2% on the newer Core i7 2.8GHz Ivy Bridge platform.","2013","15","1","2025-12-02","https://university.edu/papers/c012bd74-d2ed-42b0-9a92-0055542d74f6.pdf");
INSERT INTO Paper VALUES ("1281","A Multi-service Group Key Management Scheme for Stateless Receivers in Wireless Mesh Networks","Wireless mesh networks facilitate the development of the many group oriented applications by extending the coverage area of the group communication. Group communication in a wireless mesh network is complicated due to dynamic intermediate mesh points, access control for communications between different administrative domains, and the absence of a centralized network controller. In this study, we propose a topology-matching decentralized multi-service group key management scheme for wireless mesh networks. It allows service providers to update and deliver their group keys to valid members in a distributed manner using the identity-based encryption scheme. The analysis result indicates that the proposed scheme has advantages with regard to the rekeying cost and storage overhead for a member and a mesh point in multi-sender group communication environments. The stateless property is also achieved such that a stateless member, who could not be constantly online, can easily decrypt the rekeying messages without recording the past history of transmission.","2010","11","1","2025-12-02","https://university.edu/papers/acd78d49-40c0-4bf3-88fa-cbdf19d7bbec.pdf");
INSERT INTO Paper VALUES ("1282","Provenance-based Integrity Protection for Windows","Existing malware defenses are primarily reactive in nature, with defenses effective only on malware that has previously been observed. Unfortunately, we are witnessing a generation of stealthy, highly targeted exploits and malware that these defenses are unprepared for. Thwarting such malware requires new defenses that are, by design, secure against unknown malware. In this paper, we present Spif, an approach that defends against malware by tracking code and data origin, and ensuring that any process that is influenced by code or data from untrusted sources will be prevented from modifying important system resources, and interacting with benign processes. Spif is designed for Windows, the most widely deployed desktop OS, and the primary platform targeted by malware. Spif is compatible with all recent Windows versions (Windows XP to Windows 10), and supports a wide range of feature rich, unmodified applications, including all popular browsers, office software and media players. Spif imposes minimal performance overheads while being able to stop a variety of malware attacks, including Stuxnet and the recently reported Sandworm malware. An open-source implementation of our system is available.","2015","18","3","2025-12-02","https://university.edu/papers/6496be49-370d-408a-90d7-d3d1e5549c6a.pdf");
INSERT INTO Paper VALUES ("1283","Real time user context modeling for information retrieval agents","The success of personal information agents depends on their ability to provide task-relevant information. This paper presents WordSieve, a new algorithm that generates context descriptions to guide document indexing and retrieval. WordSieve exploits information about the sequence of accessed documents to identify words which indicate a shift in context. We have tested WordSieve in a personal information agent, Calvin, which monitors a user's document access, generates a representation of the user's task context, indexes the resources consulted, and presents recommendations for other resources that were consulted in similar prior contexts. In initial experiments, WordSieve outperforms  term frequency/inverse document frequency  at matching documents to hand-coded vector representations of the task contexts in which they were originally consulted, where the task context representations are term vectors representing a specific search task given to the user.","2001","7","1","2025-12-02","https://university.edu/papers/cd0f824a-32a3-4017-8283-32c370e7c5e3.pdf");
INSERT INTO Paper VALUES ("1284","Assurance Process for Large Open Source Code Bases","Many organizations are investigating the possibility of adopting open source software or migrating their mission critical applications to open platforms. In this context, defining an assurance process for large open source code bases has becomes of paramount importance, and can help in filling the gap with proprietary solutions. In this paper, we discuss how assurance has become a primary requirement for organizations wishing to adopt open source products. Then, we describe how bug tracking and fixing can be enriched to support a more general cycle of assurance, and we evaluate how this process can be applied to large-scale open source projects like JADE and WADE.","2009","11","3","2025-12-02","https://university.edu/papers/a92cb0c5-b5a9-45d7-b060-06c9adafa9d0.pdf");
INSERT INTO Paper VALUES ("1285","Dynamic shape retrieval by hierarchical curve matching, snakes and data mining","This paper presents a new approach to similar shape retrieval by coarse-to-fine curve matching and data mining techniques. The proposed method extends the concepts of conventional data warehouse and image database for effective image indexing. An image data warehouse schema is developed to integrate multiple shape features for hierarchical shape representation, dynamic similarity measures and fast query processing. A guided search scheme is introduced, that combines the methods of invariant moments, 2D polygonal arc matching and B-spline curve matching, to search for the best similar shape in a hierarchical fashion. The proposed method is applied to the tropical cyclone pattern recognition by utilizing the active contour model (snake) to extend the traditional Dvorak technique for tropical cyclone intensity analysis and forecasting from satellite imagery.","2000","6","3","2025-12-02","https://university.edu/papers/e2a3c911-4289-4df8-b266-4f2745f26823.pdf");
INSERT INTO Paper VALUES ("1286","Automatic classication of large changes into maintenance categories","Large software systems undergo significant evolution during their lifespan, yet often individual changes are not well documented. In this work, we seek to automatically classify large changes into various categories of maintenance tasks — corrective, adaptive, perfective, feature addition, and non-functional improvement — using machine learning techniques. In a previous paper, we found that many commits could be classified easily and reliably based solely on the manual analysis of the commit metadata and commit messages (i.e., without reference to the source code). Our extension is the automation of classification by training Machine Learners on features extracted from the commit metadata, such as the word distribution of a commit message, commit author, and modules modified. We validated the results of the learners via 10-fold cross validation, which achieved accuracies consistently above 50%, indicating good to fair results. We found that the identity of the author of a commit provided much information about the maintenance class of a commit, almost as much as the words of the commit message. This implies that for most large commits, the Source Control System (SCS) commit messages plus the commit author identity is enough information to accurately and automatically categorize the nature of the maintenance task.","2009","17","1","2025-12-02","https://university.edu/papers/aa66942a-f5c4-4b27-b69a-1d6ffb78d6e5.pdf");
INSERT INTO Paper VALUES ("1287","Unsupervised Sense Disambiguation Using Bilingual Probabilistic Models","We describe two probabilistic models for unsupervised word-sense disambiguation using parallel corpora. The first model, which we call the Sense model, builds on the work of Diab and Resnik (2002) that uses both parallel text and a sense inventory for the target language, and recasts their approach in a probabilistic framework. The second model, which we call the Concept model, is a hierarchical model that uses a concept latent variable to relate different language specific sense labels. We show that both models improve performance on the word sense disambiguation task over previous unsupervised approaches, with the Concept model showing the largest improvement. Furthermore, in learning the Concept model, as a by-product, we learn a sense inventory for the parallel language.","2004","13","4","2025-12-02","https://university.edu/papers/55b69e63-49b3-4505-b46e-e2f1487491c5.pdf");
INSERT INTO Paper VALUES ("1288","A Method for Privacy Protection in Location Based Services","Privacy protection is a very important issue and solutions must be developed for wide acceptance of location based services (LBSs) in wireless applications. Current approaches rely mostly on the use of privacy policies to describe and solve this problem in an ad hoc way. In this paper, we propose a method based on the three-dimensional access control model to support privacy requirements. We show that our method can better describe and support user location privacy requirements in LBSs. By introducing the notions of privacy-concerning subjects and enhancing the traditional access control mechanism, we demonstrate how our method can provide all the privacy-concerning users with the necessary means of controlling access to private location information.","2009","2","1","2025-12-02","https://university.edu/papers/78565ccf-42c4-4867-89b0-b12d61d19798.pdf");
INSERT INTO Paper VALUES ("1289","Multi-level hierarchical scheduling in ethernet switches","The complexity of Networked Embedded Systems (NES) has been growing steeply, due to increases both in size and functionality, and is becoming a major development concern. This situation is pushing for paradigm changes in NES design methodologies towards higher composability and flexibility. Component-oriented design technologies, in particular supported by server-based scheduling, seem to be good candidates to provide the needed properties.   As a response we developed a multi-level hierarchical server-based architecture for Ethernet switches that provides composability and supports online adaptation and reconfiguration. This paper extends our work, presenting the associated response-time based schedulability analysis, necessary for the admission control procedure. Additionally, we have derived the temporal complexity of the analysis, which is shown to be  O ( n  2 ), where  n  is the number of higher priority components associated with a given server. Finally, we present a proof-of-concept implementation and a set of experimental results that validates the analysis.","2011","7","2","2025-12-02","https://university.edu/papers/564728f2-cda6-4970-aa1e-ab7887579a16.pdf");
INSERT INTO Paper VALUES ("1290","A multilevel longitudinal study of experiencing virtual presence in adolescence: the role of anxiety and openness to experience in the classroom","ABSTRACTPresence describes the feeling of reality and immersion that users of virtual/Internet environments have. Importantly, it has been suggested that there are individual and contextual differences regarding susceptibility to presence. These aspects of presence have been linked to both beneficial and disadvantageous uses of the Internet, such as online therapeutic applications and addictive Internet behaviours. In the present study, presence was studied in relation to individual anxiety symptoms and classroom-level openness to experience (OTE) using a normative sample of 648 adolescents aged between 16 and 18 years. Presence was assessed with the Presence II questionnaire, anxiety symptoms with the relevant subscales of the SCL-90-R, and OTE with the Five-Factor Questionnaire. A three-level hierarchical linear model was calculated. Results showed that experiencing presence in virtual environments dropped between the ages of 16 and 18 years. Additionally, although anxiety symptoms were associated with ...","2017","9","1","2025-12-02","https://university.edu/papers/adba01f3-0c8f-451b-8261-526de50b6489.pdf");
INSERT INTO Paper VALUES ("1291","A three way equivalence","In view of the well known core equivalence results in atomless economies, coincidence of market game equilibrium allocations with competitive allocations is tantamount to a three way equivalence between market game mechanisms, competitive equilibria and the core. Based on this idea we study equilibrium refinements of market games, which allow us to use the core equivalence machinery in order to provide an exact market game characterization of competitive equilibria.","2008","6","4","2025-12-02","https://university.edu/papers/91177aff-a60e-47d6-a8ce-825e90d22518.pdf");
INSERT INTO Paper VALUES ("1292","[Seeding Methods for Run Transferable Libraries] Capturing Domain Relevant Functionality through Schematic Manipulation for Genetic Programming","This paper applies a recently developed technique of expression structure analysis and parametric distribution to the generation of functional content relevant to the problem domain. This functional basis set will then be iteratively sampled by a GP system as part of the Run Transferable Libraries process. We introduce a new algorithm for adapting the schematic templates discovered by such an analysis into a family of related functional expressions, differentiated by the number of arguments to the abstraction and the ordering of those arguments within the body of the function. Furthermore we investigate techniques to reduce redundancy within the family of functions generated by the parameter assignment, which consequently decreases the set of functions to be sampled by RTL, further improving performance. We validate that this technique is able to discover germane functionality within the context of the problem domain and that the library generated by this approach is competitive with a library hand designed with the optimal function set.","2007","2","3","2025-12-02","https://university.edu/papers/5cdb9c27-5949-4d46-97b1-7242ff900ed4.pdf");
INSERT INTO Paper VALUES ("1293","Internal penetration testing of Bring Your Own Device (BYOD) for preventing vulnerabilities exploitation","Penetration testing is the process of detecting computer vulnerabilities and gaining access and data on targeted computer systems with goal to detect vulnerabilities and security issues and proactively protect system. In this paper we presented case of internal penetration test which helped to proactively prevent potential weaknesses of targeted system with inherited vulnerabilities which is Bring Your Own Device (BYOD). Many organizations suffer great losses due to risk materialization because of missing implementing standards for information security that includes patching, change management, active monitoring and penetration testing, with goal of better dealing with security vulnerabilities. With BYOD policy in place companies taking greater risk appetite allowing mobile device to be used on corporate networks. In this paper we described how we used network hacking techniques for penetration testing for the right cause which is to prevent potential misuse of computer vulnerabilities. This paper shows how different techniques and tools can be jointly used in step by step process to successfully perform penetration testing analysis and reporting.","2015","20","2","2025-12-02","https://university.edu/papers/e7a48b24-e722-47a2-8e35-a6ae6f4e5c18.pdf");
INSERT INTO Paper VALUES ("1294","Optimal Deployment of Multistatic Radar System Using Multi-Objective Particle Swarm Optimization","We consider an optimization deployment problem of multistatic radar system (MSRS). Through the antenna placing and the transmitted power allocating, we optimally deploy the MSRS for two goals: 1) the first one is to improve the coverage ratio of surveillance region; 2) the second goal is to get a even distribution of signal energy in surveillance region. In two typical working modes of MSRS, we formulate the optimization problem by introducing two objective functions according to the two mentioned goals, respectively. Addressing on two main challenges of applying multi-objective particle swarm optimization (MOPSO) in solving the proposed optimization problem, we propose a deployment algorithm based on multiobjective particle swarm optimization with non-dominated relative crowding distance (MOPSO-NRCD). For the challenge of value difference, we propose a novel selection method with a non-dominated relative crowding distance. For the challenge of particle allocation, a multi-swarm structure of MOPSO is also introduced. Finally, simulation results are given out to prove the advantages and validity of the proposed deployment algorithm. It is shown that with same number of employed particles, the proposed MOPSO-NRCD algorithm can achieve better optimization performance than that of traditional multiobjective particle swarm optimization with crowding distance (MOPSO-CD).","2016","17","4","2025-12-02","https://university.edu/papers/77857531-4b56-4b3d-a048-01f8b15a7972.pdf");
INSERT INTO Paper VALUES ("1295","Finding Top-k Min-Cost Connected Trees in Databases","It is widely realized that the integration of database and information retrieval techniques will provide users with a wide range of high quality services. In this paper, we study processing an l-keyword query, p 1 , p 1 , ..., p l , against a relational database which can be modeled as a weighted graph, G(V, E). Here V is a set of nodes (tuples) and E is a set of edges representing foreign key references between tuples. Let V i  ⊆ V be a set of nodes that contain the keyword p i . We study finding top-k minimum cost connected trees that contain at least one node in every subset V i , and denote our problem as GST-k When k = 1, it is known as a minimum cost group Steiner tree problem which is NP-complete. We observe that the number of keywords, l, is small, and propose a novel parameterized solution, with l as a parameter, to find the optimal GST-1, in time complexity O(3 l n + 2 l  ((l + logn)n + m)), where n and m are the numbers of nodes and edges in graph G. Our solution can handle graphs with a large number of nodes. Our GST-1 solution can be easily extended to support GST-k, which outperforms the existing GST-k solutions over both weighted undirected/directed graphs. We conducted extensive experimental studies, and report our finding.","2007","6","1","2025-12-02","https://university.edu/papers/e0660b6b-da38-40ed-9cc0-a5d38635091b.pdf");
INSERT INTO Paper VALUES ("1296","Using TMR Architectures for Yield Improvement","With the technology entering the nano dimension, manufacturing processes are less and less reliable, thus drastically impacting the yield. A possible solution to alleviate this problem in the future could consist in using fault tolerant architectures to tolerate manufacturing defects. In this paper, we use the classical triple modular redundancy (TMR) fault tolerant architecture as a case study. Firstly we analyze the conditions that make the use of TMR architectures interesting for yield improvement purpose. In the second part of the paper, we investigate the test requirements for the TMR architecture and we propose a solution for generating test patterns for this type of architecture. Finally, we propose a new manner to implement the TMR architecture that makes it very effective for yield improvement purpose. Experimental results are provided on ISCAS and ITC benchmark circuits to prove the efficiency of the proposed approach in terms of yield improvement with a low area overhead.","2008","10","3","2025-12-02","https://university.edu/papers/69f7c1db-e820-414d-a25a-bc2f0495e482.pdf");
INSERT INTO Paper VALUES ("1297","SoftHand Pro-D: Matching dynamic content of natural user commands with hand embodiment for enhanced prosthesis control","State of the art of hand prosthetics is divided between simple and reliable gripper-like systems and sophisticate hi-tech poly-articular hands which tend to be complex both in their design and for the patient to operate. In this paper, we introduce the idea of decoding different movement intentions of the patient using the dynamic frequency content of the control signals in a natural way. We move a step further showing how this idea can be embedded in the mechanics of an underactuated soft hand by using only passive damping components. In particular we devise a method to design the hand hardware to obtain a given desired motion. This method, that we call of the dynamic synergies, builds on the theory of linear descriptor systems, and is based on the division of the hand movement in a slow and a fast components. We use this method to evolve the design of the Pisa/IIT SoftHand in a prototype prosthesis which, while still having 19 degrees of freedom and just one motor, can move along two different synergistic directions of motion (and combinations of the two), to perform either a pinch or a power grasp. Preliminary experimental results are presented, demonstrating the effectiveness of the proposed design.","2016","18","3","2025-12-02","https://university.edu/papers/0d5b330f-845a-49b6-bbcf-ccc2f338d4ac.pdf");
INSERT INTO Paper VALUES ("1298","The generalized uniqueness wavelet descriptor","The theorem of the generalized uniqueness property inherent in the 1-D discrete periodized wavelet transform (DPWT) is developed in this paper. The uniqueness property facilitates a quantitative analysis of the one-to-one mapping between the variation of 1-D DPWT coefficients and the starting point shift of the originally sampled curve data. By employing the uniqueness property, a new shape descriptor called the generalized uniqueness wavelet descriptor (GUWD) by which the starting point is fixed entirely within the context of the wavelet representation is proposed. The existence theorem of the GUWD supports the availability of the wavelet descriptor for pattern recognition and can provide an effective method to solve the problem of starting point dependency in the wavelet-based applications. In addition, the generalized uniqueness property can be used for shape regularity measurement.","1999","4","3","2025-12-02","https://university.edu/papers/71750681-db35-42d9-9dbf-f7d1702371ae.pdf");
INSERT INTO Paper VALUES ("1299","A Two-Stage Classifier for Sentiment Analysis","In this paper, we present a study applying reject option to build a two-stage sentiment polarity classification system. We construct a Naive Bayes classifier at the first stage and a Support Vector Machine at the second stage, in which documents rejected at the first stage are forwarded to be classified at the second stage. The obtained accuracies are comparable to other state-of-the-art results. Furthermore, experiments show that our classifier requires less training data while still maintaining reasonable classification accuracy.","2013","15","1","2025-12-02","https://university.edu/papers/88865ee9-0ccd-4409-a7bd-0ce200d1d38c.pdf");
INSERT INTO Paper VALUES ("1300","Neurofuzzy Networks With Nonlinear Quantum Learning","Nonlinear quantum processing allows the solution of an optimization problem by the exhaustive search on all its possible solutions. Hence, it can replace advantageously the algorithms for learning from a training set. In order to pursue this possibility in the case of neurofuzzy networks, we propose in this paper to tailor their architectures to the requirements of quantum processing. In particular, superposition is introduced to pursue parallelism and entanglement to associate the network performance with each solution present in the superposition. Two aspects of the proposed method are considered in detail: the binary structure of membership functions and fuzzy reasoning and the use of a particular nonlinear quantum algorithm for extracting the optimal neurofuzzy network by exhaustive search.","2009","19","4","2025-12-02","https://university.edu/papers/d7d7d17c-b6f4-4800-b505-d6c817c1704c.pdf");
INSERT INTO Paper VALUES ("1301","Understanding the Boundary in Information Sharing and Integration","The definition of “boundary” in the context of multiorganizational information sharing and integration initiatives is developed in the paper. Both current literature and a case study of the product safety inspection environment are used to drive the development of a dual-directional, multi-dimensional and non-linear framework for understanding the meaning of “boundary”. The two directions are the vertical and horizontal directions and the multidimensions include organizational, geographic, personal, development phase, and process. The framework can be used both as a theoretical model for researchers and a comprehensive analytic tool for practitioners.","2009","3","1","2025-12-02","https://university.edu/papers/c23b8d64-51f2-437f-8ffa-2afa3c81903b.pdf");
INSERT INTO Paper VALUES ("1302","An ILP formulation for system level throughput and power optimization in multiprocessor SoC architectures","System-level low power scheduling techniques are required for optimizing the performance and power of embedded applications that are mapped to multiprocessor System-on-Chip (SoC) architectures. In this paper, we present an integer linear programming (ILP) formulation that combines loop transformations (pipelining and unrolling) and system-level low power optimization techniques (dynamic voltage scaling (DVS) and power management (DPM)) to minimize the power consumption, while satisfying the period and deadline constraints of the application. We also present three modifications that relax one or more constraints in the optimal formulation in order to obtain smaller run times. We present experimental analysis by applying the formulations on an MPEG decoder algorithm. All results are compared against two existing techniques. Our formulations result in large system-level power reductions (max: 48.2%, min: 15.92%, avg: 31.9%). The modified ILP formulations result in exponential decrease in runtimes, and a corresponding linear degradation in the result quality.","2004","3","2","2025-12-02","https://university.edu/papers/4ac82906-287d-4567-ba9a-307e867e1cd2.pdf");
INSERT INTO Paper VALUES ("1303","Clustering Comparable Corpora For Bilingual Lexicon Extraction","We study in this paper the problem of enhancing the comparability of bilingual corpora in order to improve the quality of bilingual lexicons extracted from comparable corpora. We introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and finally preserves most of the vocabulary of the original corpus. Our experiments illustrate the well-foundedness of this method and show that the bilingual lexicons obtained from the homogeneous corpus are of better quality than the lexicons obtained with previous approaches.","2011","3","2","2025-12-02","https://university.edu/papers/ca4bd718-bcae-4140-92c9-aebf73650655.pdf");
INSERT INTO Paper VALUES ("1304","Multicast server selection: problems, complexity, and solutions","We formulate and investigate fundamental problems that arise when multicast servers, that deliver content to multiple clients simultaneously, are replicated to enhance scalability and performance. Our study consists of two parts. First, we consider the problem under the assumption that the multicast clients are static for the duration of the multicast content distribution session. In this context, we examine two models for server behavior: fixed-rate servers, which transmit at a constant rate, and rate-adaptive servers, which adapt their transmission rate based on network conditions and/or feedback from clients. In both cases, we show that general versions of the client assignment problems are NP-hard. We then develop and evaluate efficient algorithms for interesting special cases, as well as heuristics for general cases. Second, we consider the case in which the set of clients changes dynamically during the multicast content distribution session. We again consider both fixed-rate and rate-adaptive servers. We formulate the problem as a Markov decision process, capturing the costs associated with trees, as well as the transition costs to dynamically change the trees. We use the properties of optimal solutions for small examples to develop a set of dynamic server selection heuristics.","2002","11","1","2025-12-02","https://university.edu/papers/602c0e29-678a-4c13-b001-93a2cccfaddb.pdf");
INSERT INTO Paper VALUES ("1305","Global state estimation by grid point observer","Dead reckoning and star reckoning are two basic self-localization methods for vehicles, but each method has inherent weakness. To recover these weaknesses, sensor-fusion via an initial state observer has proposed. However, the method can be applied under the assumption that the vehicles move in the limited field. In this paper, we propose a new sensor- fusion method by using a grid point observer. We confirm the effectiveness of proposed method by computer simulation and experiments for self localization of a two-wheeled mobile robot.","2007","6","1","2025-12-02","https://university.edu/papers/7f7e8f86-db0c-4b8a-b3b9-88f33ae0d19f.pdf");
INSERT INTO Paper VALUES ("1306","Whittaker-Kotel'nikov-Shannon approximation of $\varphi$-sub-Gaussian random processes","The article starts with generalizations of some classical results and new truncation error upper bounds in the sampling theorem for bandlimited stochastic processes. Then, it investigates   L p ([0,T])       L    p    (  [  0  ,  T  ]  )        and uniform approximations of  φ -sub-Gaussian random processes by finite time sampling sums. Explicit truncation error upper bounds are established. Some specifications of the general results for which the assumptions can be easily verified are given. Direct analytical methods are employed to obtain the results.","2016","7","3","2025-12-02","https://university.edu/papers/cc5ca199-e281-4a7f-bfd8-c7cb178daf1e.pdf");
INSERT INTO Paper VALUES ("1307","Content discovery in wireless information-centric networks","Information-centric networking (ICN) enables communication in isolated islands, where fixed infrastructure is not available, but also supports seamless communication if the infrastructure is up and running again. In disaster scenarios, when a fixed infrastructure is broken, content discovery algorithms are required to learn what content is locally available. For example, if preferred content is not available, users may also be satisfied with second best options. In this paper, we describe a new content discovery algorithm and compare it to existing Depth-first and Breadth-first traversal algorithms. Evaluations in mobile scenarios with up to 100 nodes show that it results in better performance, i.e., faster discovery time and smaller traffic overhead, than existing algorithms.","2015","15","1","2025-12-02","https://university.edu/papers/ed73b11c-79da-4e68-843d-d3674f230a47.pdf");
INSERT INTO Paper VALUES ("1308","On the fault-tolerant embeddings of complete binary trees in the mesh interconnection networks","In this article, several schemes are proposed for embedding complete binary trees (CBT) into meshes. All of the proposed methods outperform those in the previous studies. First, a link congestion 1 embedding is achieved. Its expansion ratio is at the lowest level as we know now. Except for this superiority, it also provides another capability for fault tolerance to resist abnormal system faults, thus the embedding structure can be more guaranteed and the node utilization is raised further. Second, a link congestion 1 embedding with no-bending constraint is obtained. This scheme provides efficient CBT embedding for both the optical mesh and general mesh at the same time while keeping those good properties as the previous scheme. The last one is an optimal embedding which is applied to a 3D cubic mesh, where the node is almost fully utilized and its link congestion is 2.","2003","8","3","2025-12-02","https://university.edu/papers/eee38d3e-b3c5-4ea2-b547-1b4b6ef268f4.pdf");
INSERT INTO Paper VALUES ("1309","A new paradigm for the description of image patterns-from pixels to fuzzy sets of rules","A paradigm for the description of image patterns is presented: it is proposed that images are described by fuzzy IF...THEN rules instead of pixel values. This approach may benefit from recognised fuzzy systems' superior incorporation of measurement uncertainties, greater resources for managing complexity and better ability to deal with natural language. The concept of relevance has been proposed as a measure of the relative importance of sets of rules (Salgado, 1999, and Salgado et al., 2000). Based on this concept a new methodology was developed: SLIM (separation of linguistic information methodology) (Salgado, 1999, and Salgado et al., 2000). An algorithm implementing SLIM is presented in this paper, derived from the fuzzy C-means clustering algorithm, here applied to organise the fuzzy IF...THEN rules that describe the image. The Lena and the Abington Cross images have been successfully used to illustrate the identification process. The proposed SLIM algorithm has been successfully applied to illustrate a segmentation operation in the 'fuzzy rules domain', using the Abington Cross image.","2000","7","2","2025-12-02","https://university.edu/papers/55bdfe44-51af-480d-b497-a42a5c136587.pdf");
INSERT INTO Paper VALUES ("1310","RBFNN-based model for heavy metal prediction for different climatic and pollution conditions","Heavy metal toxicity is a matter of considerable concern for environmental researchers. A highly cause of heavy metal toxicity in the aquatic environments is considered a serious issue that required full attention to understand in order to solve it. Heavy metal accumulation is a vital parameter for studying the water quality. Therefore, there is a need to develop an accurate prediction model for heavy metal accumulation. Recently, the artificial neural networks have been examined for similar prediction applications and showed great potential to tackle and detect its nonlinearity behavior. In this paper, radial basis function neural network algorithm has been utilized to investigate and mimic the relationship of heavy metals with the climatic and pollution conditions in lake water bodies. Thus, the present study was implemented in different climatic conditions (tropical “Malaysia” and arid “Libya”) as well as polluted and non-polluted lakes. Weekly records of physiochemical parameters data (e.g., pH, EC, WT, DO, TDS, TSS, CL, NO3, PO4 and SO4) and climatological parameters (e.g., air temperature, humidity and rainfall) were utilized as an input data for the modeling, whereas the heavy metal concentration was the output of the model. Three different scenarios for modeling the input architecture considering the climate, pollution or both have been investigated. In general, results obtained from all the scenarios are positively encouraging with high-performance accuracy. Furthermore, the results showed that an isolated model for each condition achieves a better prediction accuracy level rather than developing one general model for all conditions.","2016","10","1","2025-12-02","https://university.edu/papers/f026cc35-734a-4233-99db-bfdfc615a92f.pdf");
INSERT INTO Paper VALUES ("1311","Human Atrial Cell Models to Analyse Haemodialysis-Related Effects on Cardiac Electrophysiology: Work in Progress","During haemodialysis (HD) sessions, patients undergo alterations in the extracellular environment, mostly concerning plasma electrolyte concentrations, pH, and volume, together with a modification of sympathovagal balance. All these changes affect cardiac electrophysiology, possibly leading to an increased arrhythmic risk. Computational modeling may help to investigate the impact of HD-related changes on atrial electrophysiology. However, many different human atrial action potential (AP) models are currently available, all validated only with the standard electrolyte concentrations used in experiments. Therefore, they may respond in different ways to the same environmental changes. After an overview on how the computational approach has been used in the past to investigate the effect of HD therapy on cardiac electrophysiology, the aim of this work has been to assess the current state of the art in human atrial AP models, with respect to the HD context. All the published human atrial AP models have been considered and tested for electrolytes, volume changes, and different acetylcholine concentrations. Most of them proved to be reliable for single modifications, but all of them showed some drawbacks. Therefore, there is room for a new human atrial AP model, hopefully able to physiologically reproduce all the HD-related effects. At the moment, work is still in progress in this specific field.","2014","13","3","2025-12-02","https://university.edu/papers/ef805740-5fe5-4bd9-94e2-0120d3f6a4a1.pdf");
INSERT INTO Paper VALUES ("1312","New lot-sizing formulations for less nervous production schedules","Previously scheduled production plans frequently need to be updated because of demand uncertainty. After making a comprehensive de'nition of nervousness which includes costs for changes in production schedule and quantity, we suggest three methodologies. Two methods are modi'ed versions of very well-known methods: the Wagner}Whitin algorithm and the Silver}Meal heuristic. However, our de'nition of nervousness and its consequences for altering predetermined production volumes make the well-known property of producing either zero or a sum of several periods’ demand suboptimal. Therefore a third method, a new mixed integer linear programming formulation, is proposed which is shown to be more e!ective in some cases. Numerical analyses are carried out for a wide range of possible cases, through which we provide insights to the most appropriate algorithm in a parameterized space. Scope and purpose Uncertainty in demand forecasts and a rolling horizon create volatility in lot-sizing results. This volatility is characterized by frequent changes in predetermined production schedules and is highly undesirable for production managers. It causes nervousness in the system in terms of canceling existing setups, introducing new setups, and altering the production volumes. In this paper, we propose new cost structures for these changes, and o!er several models that identify less nervous production schedules in a rolling horizon basis. For practitioners, this work identi'es the most preferable algorithm for a variety of system parameters. ( 2000 Elsevier Science Ltd. All rights reserved.","2000","6","3","2025-12-02","https://university.edu/papers/b4eaa165-eb04-4635-9f96-4c54df19a8ab.pdf");
INSERT INTO Paper VALUES ("1313","Master data management fundamental and integrated solution","The importance of data has been continuously increasing. Different business processes that organizations employed to run their businesses such as making critical business decisions or serving their customers depend on the data they have. With numerous sources from inside and outside organizations, the availability of data has become abundant and the variety of data increases the complexity.","2014","5","3","2025-12-02","https://university.edu/papers/c2dbafad-6ab3-4fe6-9510-99f1b645af3b.pdf");
INSERT INTO Paper VALUES ("1314","A New Formula of Security Risk Analysis That Takes Risk Improvement Factor into Account","Risk analysis is the very first step for organizational information security, where a qualitative approach is a major methodology. Today, it is required that risk treatment is discussed also in terms of security investment. Considering that a security model can be represented as a set of risk formulas, we propose a new risk formula that can also represent improvement factors of security. The resulting formula is $/math/$R = e^C A^aA V^aV T^aT$/math/$, which includes the conventional multiplicative risk formula. We show how to calculate a's by using the risk reduction matrix. As an available scenario, we propose that we use the formula as a perturbation to the conventional risk formula. We show an example scenario in which by using the conventional multiplicative risk formula and a risk reduction matrix for representing the risk improving factor, a risk value is re-calculated. Security investment can also be evaluated by using our formula. Moreover, we propose that a's represent a factor of significance in decision making.","2011","14","2","2025-12-02","https://university.edu/papers/bd0bb1a3-6c72-438f-8ed9-6f1e137b8534.pdf");
INSERT INTO Paper VALUES ("1315","Tool set implementation for scenario-based multithreading of UML-RT models and experimental validation","This paper presents our tool set implementation for scenario-based multithreading of object-oriented real-time models and an accompanying experimental validation. Our tools enable the automated, schedulability-aware implementation of real-time object-oriented models, exploiting an existing CASE tool. Our implementation is facilitated by (1) our customized runtime system modified to support scenario-based thread execution, (2) a design model template that centralizes the arrival of external inputs, (3) a model analyzer tool, and (4) a model-specific code modifier tool. Our tools simplify design by removing thread-related design concerns from the modeling process, separating design and implementation. We performed validation by conducting experiments that clearly demonstrate the performance improvements that can be gained through our scenario-based implementation: response time improvements for high priority tasks of as much as 70% and a 5-fold decrease in blocking or the elimination of blocking for some tasks.","2003","7","3","2025-12-02","https://university.edu/papers/5416e148-5fbf-443f-a320-41c7eb6123a4.pdf");
INSERT INTO Paper VALUES ("1316","Power Adaptation in Multi-hop Sensor Networks for Energy Minimization","The power adaptation issue for multi-hop sensor networks is considered in this paper to minimize the energy consumption with a given requirement of the average end-to-end bit error rate (BER) performance. To optimize the power adaptation, a nonlinear programming problem is formulated and an analytical result is derived from its Karush-Kuhb-Tucker (KKT) necessary conditions. Numerical examples are presented to compare the networks with the proposed power adaptation scheme and a distributed power adaptation scheme, in which the transmitter of each individual hop adjusts its transmission power based on its own channel state information (CSI) and a specified BER requirement for this hop. A significant energy saving is achieved with the use of the proposed scheme.","2009","7","2","2025-12-02","https://university.edu/papers/d430495c-2b11-4d56-b7a2-1a047c259fda.pdf");
INSERT INTO Paper VALUES ("1317","System vulnerability assessment and critical nodes identification","Three metrics are designed to assess system vulnerability.A CNI algorithm is applied to identify critical nodes in complex systems using the three metrics.Performance of the CNI algorithm is compared to other widely used CNI algorithms. Critical nodes in complex systems need to be identified for protection or removal. Removal of critical nodes decreases or minimizes a system's ability to diffuse entities such as information, goods, or diseases. Previous research suggested some vulnerability metrics, but there remains a lack of understanding how a metric changes (e.g., upper bound and lower bound) and how it is related to the structure of a complex system. This research designs three metrics to assess system vulnerability, and analyzes their characteristics over different system structures. A polynomial-time algorithm using the three metrics is developed to identify critical nodes step by step (local optima). Their performance are examined and compared to other algorithms. The three metrics designed in this article are informative and their characteristics are thoroughly analyzed for various system structures. The metrics and algorithm may be used by domain experts to effectively assess system vulnerability and identify critical nodes.","2016","10","3","2025-12-02","https://university.edu/papers/424086a4-67ce-471e-9590-5d086be92187.pdf");
INSERT INTO Paper VALUES ("1318","Handling Non-linear Polynomial Queries over Dynamic Data","Applications that monitor functions over rapidly and unpredictably changing data, express their needs as continuous queries. Our focus is on a rich class of queries, expressed as polynomials over multiple data items. Given a set of polynomial queries at a coordinator C, and a user-specified accuracy bound (tolerable imprecision) for each query, we address the problem of assigning data accuracy bounds or filters to the source of each data item. Assigning data accuracy bounds for non-linear queries poses special challenges. Unlike linear queries, data accuracy bounds for non-linear queries depend on the current values of data items and hence need to be recomputed frequently. So, we seek an assignment such that a) if the value of each data item at C is within its data accuracy bound then the value of each query is also within its accuracy bound, b) the number of data refreshes sent by sources to C to meet the query accuracy bounds, is as low as possible, and c) the number of times the data accuracy bounds need to be recomputed is as low as possible. In this paper, we couple novel ideas with existing optimization techniques to derive such an assignment. Specifically, we make the following contributions: (i) Propose a novel technique that significantly reduces the number of times data accuracy bounds must be recomputed; (ii) Show that a small increase in the number of data refreshes can lead to a large reduction in the number of recomputations; we introduce this as a tradeoff in our approach; (iii) Give principled heuristics for addressing negative coefficient polynomial queries where no known optimization techniques can be used; we also prove that under many practically encountered conditions our heuristics can be close to optimal; and (iv) Present a detailed experimental evaluation demonstrating the efficacy of our techniques in handling large number of polynomial queries.","2008","15","3","2025-12-02","https://university.edu/papers/d7e282d7-8935-4ec8-b9d5-471d06717713.pdf");
INSERT INTO Paper VALUES ("1319","Highly soft viscoelastic robot skin with a contact object-location-sensing capability","This paper concerns the development of robot skin capable of accurately sensing the location of objects in area contact with the skin surface. There has been no report on tactile sensing which attained not only skin deformation detection but also contact object location sensing with high accuracy. In the category of optomechatronics technology, we apply optical fibers to transmit surface deformation information of soft skin for sensing the location of an object in contact with the soft skin accurately. In the paper, we illustrate the structure of the robot skin, and describe the principle of both detecting the position of the reflector chips and sensing the contact location of an object. The robot skin is characterized by the fact that the surface is low cost and easily replaceable, and the sensing performance is robust against any electromagnetic disturbance. We then show experimental results for verifying the principles using a wedge-shaped object. For evaluating the sensing accuracy, comparisons are made: 1) between the location of a real convex of the object and that of the corresponding estimated polygon and 2) for the position of two vertices of the object when independent fitting and Lagrangian fitting methods are applied.","2005","3","4","2025-12-02","https://university.edu/papers/bde36265-fe86-4359-8344-5be0060b276c.pdf");
INSERT INTO Paper VALUES ("1320","Lateral error recovery for application-level multicast","We consider the delivery of reliable and streaming services using application-level multicast (ALM) by means of UDP, where packet loss has to be recovered via retransmission in a timely manner in order to offer high level of service. Since packets may be lost due to congestion, tree-reconfiguration or node failure, the traditional 'vertical' recovery, whereby upstream nodes retransmit the lost packet is no longer effective. We therefore propose and investigate lateral error recovery (LER). In LER, hosts are divided into a number of planes, each of which forms an independent ALM tree. Since the correlation of error among the planes is likely to be low, a node can effectively recover its error 'laterally' from nearby nodes in other planes. We employ the technique of global network positioning (GNP) to map the hosts into a coordinate space and identify a set of close neighbors for error recovery by constructing a Voronoi diagram for each plane. We present centralized and distributed algorithm on how to construct the Voronoi diagrams. Using Internet-like topologies, we show via simulations that our system achieves low overheads in terms of relative delay penalty and physical link stress. For reliable service, lateral recovery greatly reduces the average recovery time as compared with vertical recovery schemes. For streaming applications, LER achieves much lower residual loss rate under a certain deadline constraint.","2004","12","3","2025-12-02","https://university.edu/papers/bdae9189-fa52-46dc-9437-0a3fcbd87dce.pdf");
INSERT INTO Paper VALUES ("1321","A comparison of image sharpness metrics and real-time sharpening methods with GPU implementations","Improving the quality of an image increases the probability, speed and accuracy with which possible objects of interest can be located and identified. Image sharpening, in particular, can correct for soft focus and strengthen the outlines of objects thus improving the identification and segmentation both by automatic means and by man in the loop systems. Output pixel independence is ensured so that a GPU can be used to sharpen the pixels in parallel, achieving processing performance increases of 20--360 fold. This work provides a metric which can quantify the sharpness of an image and shows that the sharpness of live video can easily be doubled in realtime on commercial desktop computers without inducing excessive noise.","2010","12","4","2025-12-02","https://university.edu/papers/778528b3-0289-4e0c-aee3-467ba73e35f3.pdf");
INSERT INTO Paper VALUES ("1322","A simple interaction model for learner agents: An evolutionary approach","Recently multi agent systems are used to solve complex problems. In these systems agents can cooperate when a problem is difficult or impossible to solve for an individual agent. Via learning, the agents attempt to maximize some of their utilities. In multi agent learning an agent learns to interact with other agents and considering their behaviors. By multi task learning, the agent simultaneously learns a set of related problems and with reinforcement learning, an agent learns a proper policy to achieve its goal. In learning process, using the experience of teammate agents by simple interactions among them is very beneficial. In this paper we have presented a simple model of agents' interactions using operators of an evolutionary algorithm. Applying the proposed model has improved significantly the performance of multi task learning in a nondeterministic and dynamic environment, specifically for the dynamic maze problem. The experimental results indicate our claim.","2016","6","1","2025-12-02","https://university.edu/papers/323991b0-8247-4986-8852-03079c952b31.pdf");
INSERT INTO Paper VALUES ("1323","Space-Constrained Massive MIMO: Hitting the Wall of Favorable Propagation","The recent development of the massive multiple-input multiple-output (MIMO) paradigm, has been extensively based on the pursuit of favorable propagation: in the asymptotic limit, the channel vectors become nearly orthogonal and inter-user interference tends to zero [1]. In this context, previous studies have considered fixed inter-antenna distance, which implies an increasing array aperture as the number of elements increases. Here, we focus on a practical, space-constrained topology, where an increase in the number of antenna elements in a fixed total space imposes an inversely proportional decrease in the inter-antenna distance. Our analysis shows that, contrary to existing studies, inter-user interference does not vanish in the massive MIMO regime, thereby creating a saturation effect on the achievable rate.","2015","19","4","2025-12-02","https://university.edu/papers/eb2f5b70-aa3c-4fe5-906e-eb6f77410927.pdf");
INSERT INTO Paper VALUES ("1324","Sparsity-driven radar auto-focus imaging under over-wavelength position perturbations","We consider a 2D imaging problem where a perturbed mono-static radar is used to detect localized targets situated in a region of interest. In order to deal with position-induced out-of-focus, we proposed a sparsity-driven auto-focus imaging approach in which each radar measurement is modeled as a superposition of weighted and delayed target signatures scattered from the corresponding target phase centers. We iteratively exploit the position-related delays and the target signatures by analyzing data coherence, and consequently form an adaptive projection matrix of the radar measurements. By imposing sparsity on the scattering weights, a sparse image and a dense image, without and with the target signatures respectively, are reconstructed. Compared to existing auto-focus methods, our approach significantly improves radar focus performance in imaging localized targets, even under position perturbations up to 10 wavelengths of the radar central frequency. We validate our algorithm with simulated noisy data.","2016","5","2","2025-12-02","https://university.edu/papers/ac8a6774-f09d-4c88-9ccc-e4cb9071b6fb.pdf");
INSERT INTO Paper VALUES ("1325","Variational Heteroscedastic Gaussian Process Regression","Standard Gaussian processes (GPs) model observations’ noise as constant throughout input space. This is often a too restrictive assumption, but one that is needed for GP inference to be tractable. In this work we present a non-standard variational approximation that allows accurate inference in heteroscedastic GPs (i.e., under inputdependent noise conditions). Computational cost is roughly twice that of the standard GP, and also scales as O(n 3 ). Accuracy is veried by comparing with the golden standard MCMC and its eectiveness is illustrated on several synthetic and real datasets of diverse characteristics. An application to volatility forecasting is also considered.","2011","14","3","2025-12-02","https://university.edu/papers/bdbe441f-81e8-44da-95cf-093ec68a227f.pdf");
INSERT INTO Paper VALUES ("1326","Over-the-Horizon: Not Just for Radar Anymore","A few months ago, I heard an interesting colloquium by John Hopcroft, one of the preeminent thinkers in the area of theoretical computer science. His talk mirrored his current investigative passion--future directions in theoretical computer science--but his approach can be instructive to anyone concerned with what I call adaptive anticipation (discerning trends and adapting behavior to changes before events require it).","2005","10","2","2025-12-02","https://university.edu/papers/b6a1a0f0-871f-453a-8f60-a785bc0c9c67.pdf");
INSERT INTO Paper VALUES ("1327","Invariant wideband spectrum sensing under unknown variances","In this paper, we divide a wide frequency range into multiple subbands and in each subband detect whether in a primary user (PU) is active or not. We assume that PU signal at each subband and the additive noise are white zero-mean independent Gaussian random processes with unknown variances. We also assume that at least a minimum given number of subbands is vacant of PU signal and propose an invariant generalized likelihood ratio (GLR) detector. The concept of the grouping of subbands allows faster spectrum sensing of a subset of subbands which may be occupied by a specific PU. Also, we evaluate trade-offs involved in the proposed algorithms by simulation.","2009","11","3","2025-12-02","https://university.edu/papers/f1e6afcd-39cc-490b-a6dd-3faadd2ea691.pdf");
INSERT INTO Paper VALUES ("1328","A Linear State-Space Analysis of the Migration Model in an Island Biogeography System","Biogeography deals with the study of the distribution of biodiversity over space and time and has been well studied by naturists and biologists for over the last five decades. Recently, the theory of biogeography has been applied to solve difficult engineering optimization problems in the form of a nature-inspired metaheuristic, known as biogeography-based optimization (BBO) algorithm. In this correspondence paper, we present an in-depth analysis of the linear time-invariant (LTI) system model of immigration and emigration of organisms in an island biogeography system that forms the basis of BBO. We find the bound of the eigenvalues of the general LTI system matrix using the Perron-Frobenius theorem from linear algebra. Based on the bounds of the eigenvalues, we further investigate four important properties of the LTI biogeography system, including the system reasonability with probability distribution vectors, stability, convergence, and nature of the equilibrium state. Our analysis gives a better insight into the dynamics of migration in actual biogeography systems and also helps in the understanding of the search mechanism of BBO on multimodal fitness landscapes.","2011","3","2","2025-12-02","https://university.edu/papers/b05866be-76b3-4d12-a221-c459b71d954b.pdf");
INSERT INTO Paper VALUES ("1329","An Architecture-Based Approach to Developing Context-Aware Adaptive Systems","Self-adaptive systems and context-aware systems have been proposed to provide the ability for a software system to adapt itself at runtime to cope with changes in its environment and user needs. However, research in self-adaptation and context-awareness has been carried out largely in separate communities, with limited reference to each other. Research in self-adaptation is more concerned with how to adapt the system, while research in context-awareness is more concerned with how to model, process, and manage the context information. In general, context-aware adaptive software systems need to consider both perspectives in a holistic manner. With the objective to gain a better understanding of the relationship between context-awareness and self-adaptation to advance the research and practice in this area, we in this paper introduce a layered architecture that integrates both perspectives. In addition, we demonstrate our approach through the development of a context-aware adaptive vehicle route planning software system.","2012","9","2","2025-12-02","https://university.edu/papers/94d197cd-0160-48f4-a749-b435a05c5536.pdf");
INSERT INTO Paper VALUES ("1330","GenIE: an Intelligent System for Writing Genetic Counseling Patient Letters *","We are developing GenIE, a prototype intelligent system to create first drafts of genetic counseling patient letters. GenIE will apply natural language generation techniques to construct the first draft of a letter for subsequent review and editing, if needed, by the genetic counselor. For purposes of knowledge acquisition, we have been analyzing a corpus of patient letters. Based on the corpus analysis we are developing a knowledge base and text generation strategies.","2005","15","3","2025-12-02","https://university.edu/papers/78d1e06f-3cba-4492-84c2-5d66f941d45d.pdf");
INSERT INTO Paper VALUES ("1331","Fast reconfiguration experiments of an optically differential reconfigurable gate array with nine configuration contexts","Optically differential reconfigurable gate arrays (ODRGAs) have been developed to achieve rapid reconfiguration and numerous reconfiguration contexts. Although fast reconfiguration experiments of a four-context ODRGA have been presented in earlier reports, the number of configuration contexts was insufficient for dynamic reconfiguration applications. Therefore, we have developed a more advanced nine-context ODRGA system. This paper presents fast 86.2 ns reconfiguration experiments using a nine-context ODRGA architecture and discusses plans for future work.","2009","2","1","2025-12-02","https://university.edu/papers/c10a3ac9-ad2e-4833-9d26-094f7db05e4e.pdf");
INSERT INTO Paper VALUES ("1332","Compiling and Optimizing Java 8 Programs for GPU Execution","GPUs can enable significant performance improvements for certain classes of data parallel applications and are widely used in recent computer systems. However, GPU execution currently requires explicit low-level operations such as 1) managing memory allocations and transfers between the host system and the GPU, 2) writing GPU kernels in a low-level programming model such as CUDA or OpenCL, and 3) optimizing the kernels by utilizing appropriate memory types on the GPU. Because of this complexity, in many cases, only expert programmers can exploit the computational capabilities of GPUs through the CUDA/OpenCL languages. This is unfortunate since a large number of programmers use high-level languages, such as Java, due to their advantages of productivity, safety, and platform portability, but would still like to exploit the performance benefits of GPUs. This paper presents a just-in-time (JIT) compiler that can generate and optimize GPU code from a pure Java program written using lambda expressions with the new parallel streams APIs in Java 8. These APIs allow Java programmers to express data parallelism at a higher level than threads and tasks. Our approach translates lambda expressions with parallel streams APIs in Java 8 into GPU code and automatically generates runtime calls that handle the low-level operations mentioned above. Additionally, our optimization techniques 1) allocate and align the starting address of the Java array body in the GPUs with the memory transaction boundary to increase memory bandwidth, 2) utilize read-only cache for array accesses to increase memory efficiency in GPUs, and 3) eliminate redundant data transfer between the host and the GPU. The compiler also performs loop versioning for eliminating redundant exception checks and for supporting virtual method invocations within GPU kernels. These features and optimizations are supported and automatically performed by a JIT compiler that is built on top of a production version of the IBM Java 8 runtime environment. Our experimental results on an NVIDIA Tesla GPU show significant performance improvements over sequential execution (127.9x geometric mean) and parallel execution (3.3x geometric mean) for eight Java 8 benchmark programs running on a 160-thread POWER8 machine. This paper also includes an in-depth analysis of GPU execution to show the impact of our optimization techniques by selectively disabling each optimization. Our experimental results show a geometric-mean speed-up of 1.15x in the GPU kernel over state-of-the-art approaches. Overall, our JIT compiler can improve the performance of Java 8 programs by automatically leveraging the computational capability of GPUs.","2015","17","2","2025-12-02","https://university.edu/papers/4250700a-120e-4758-8547-6a2f14d46bd7.pdf");
INSERT INTO Paper VALUES ("1333","An Out-of-Core Method for Physical Simulations on a Multi-GPU Architecture Using Lattice Boltzmann Method","Simulating complex physical phenomena implies the manipulation of an important amount of data. In order to simulate very large simulation domains on a limited computing architecture, such as industrial infrastructures, solutions have to be proposed. In this paper, a new out-of-core method is introduced in order to perform fast physical simulations using a complex Lattice Boltzmann model (LBM) on a single-node multi-GPU (CUDA) architecture. GPU global memory generally is far lower than the CPU main memory, can be problematic for a large simulation domain. The objective of this paper is to propose an efficient method of data exchanges between GPUs, the CPU main memory, which allows to perform fast complex simulations on large installations. The combination of this method with the massive parallelism of GPUs allows to keep good simulation performance. A complex simulation involving two physical components (water + air) is used in order to validate this method.","2016","16","2","2025-12-02","https://university.edu/papers/febf155c-9bf5-4edd-ac2f-ad67bd5c820c.pdf");
INSERT INTO Paper VALUES ("1334","Maximum likelihood learning of auditory feature maps for stationary vowels","A mathematical framework for learning the acoustic features from a central auditory representation is presented. The authors adopt a statistical approach that models the leaning process as to achieve a maximum likelihood estimation of the signal distribution. An algorithm, called statistical marching pursuit (SMP), is introduced to identify regions on the cortical surface when the features for each sound class are most prominent. They model the features with distributions of Gaussian mixture densities, and employ the expectation-maximization (EM) procedure to both improve the parameterization and refine iteratively the selection of cortical regions from which the features are extracted. The learning algorithm is applied to vowel classification on the TIMIT database where all the vowels (excluding diphthongs, nine in total) are regarded as individual classes. Experimental results show that models trained under the SMP/EM algorithm achieve a recognition accuracy comparable to that of conventional recognizers.","1996","15","3","2025-12-02","https://university.edu/papers/9585d637-fe05-4952-9844-4556af1cd48e.pdf");
INSERT INTO Paper VALUES ("1335","Fast Multiscale Modeling of Cardiac Electrophysiology Including Purkinje System","In this paper, we present a modeling methodology to couple the cardiac conduction system to cardiac myocytes through a model of Purkinje-ventricular junctions to yield fast and realistic electrical activation of the ventricles. A patient-specific biventricular geometry is obtained from processing computed tomography scan data. A one-manifold implementation of the fast marching method based on Eikonal-type equations is used for modeling heart electrophysiology, which facilitates the multiscale 1-D-3-D coupling at very low computational costs. The method is illustrated in in-silico experiments where we analyze and compare alternative pacing strategies on the same patient-specific anatomy. We also show very good agreement between the results from the proposed approach and more detailed and comprehensive biophysical models for modeling cardiac electrophysiology. The effect of atrioventricular delay on the distribution of activation time in myocardium is studied with two experiments. Given the reasonable computational times and realistic activation sequences provided by our method, it can have an important clinical impact on the selection of optimal implantation sites of pacing leads or placement of ablation catheter's tip in the context of cardiac rhythm management therapies.","2011","12","4","2025-12-02","https://university.edu/papers/506b6373-ed76-4d70-b5cf-974e73424430.pdf");
INSERT INTO Paper VALUES ("1336","An EM algorithm for SCFG in formal syntax-based translation","In this paper, we investigate the use of bilingual parsing on parallel corpora to better estimate the rule parameters in a formal syntax-based machine translation system, which are normally estimated from the inaccurate heuristics. We use an Expectation-Maximization (EM) algorithm to re-estimate the parameters of synchronous context-free grammar (SCFG) rules according to the derivation knowledge from parallel corpora based on maximum likelihood principle, rather than using only the heuristic information. The proposed algorithm produces significantly better BLEU scores than a state-of-the-art formal syntax-based machine translation system on the IWSLT 2006 Chinese to English task.","2009","19","1","2025-12-02","https://university.edu/papers/ffc847c3-8512-4f89-85ed-eb9bcaa2ae03.pdf");
INSERT INTO Paper VALUES ("1337","Quantum Key Distribution and String Oblivious Transfer in Noisy Channels","We prove the unconditional security of a quantum key distribution (QKD) protocol on a noisy channel against the most general attack allowed by quantum physics. We use the fact that in a previous paper we have reduced the proof of the unconditionally security of this QKD protocol to a proof that a corresponding Quantum String Oblivious Transfer (String-QOT) protocol would be unconditionally secure against Bob if implemented on top of an unconditionally secure bit commitment scheme. We prove a lemma that extends a security proof given by Yao for a (one bit) QOT protocol to this String-QOT protocol. This result and the reduction mentioned above implies the unconditional security of our QKD protocol despite our previous proof that unconditionally secure bit commitment schemes are impossible.","1996","11","1","2025-12-02","https://university.edu/papers/cf817524-98ec-43f2-8c3a-867ad75ffdc2.pdf");
INSERT INTO Paper VALUES ("1338","The flexible signature dictionary","Dictionary learning and Sparse representation of signals and images has been a hot topic for the past decade and aims to help find the sparsest representation for the signal(s) at hand. Typically, the Dictionary learning process involves finding a large number of free variables. Also, the resulting dictionary in general does not have a specific structure. In this paper we use the ideas from Image Signature Dictionary and General overlapping frames and proposed a flexible signature dictionary. We show that the resulting signatures capture the essence of the signal and can represent signals of their own type very well in opposed to signals of other types.","2015","12","1","2025-12-02","https://university.edu/papers/c5d4b131-5262-44ef-be3d-375acff45e5e.pdf");
INSERT INTO Paper VALUES ("1339","Data synchronization and noisy environments","This paper investigates maximum a posteriori probability (MAP) frame alignment strategies based on raw (analog) and quantized samples from a noise-contaminated channel. Particular attention is paid to systems with significant channel noise (for example, wireless systems), where accurate frame alignment is still possible, provided that the noise is compensated for by high transmitter frame integrity. A functional central limit theorem is derived that characterizes the performance of the MAP strategies in such high-noise cases. This prescribes optimal thresholds for the quantization process, and shows in particular that, for binary systems, worthwhile gains can be made by the use of raw or multibit quantized samples, rather than the usual 1-bit samples used by alignment strategies operating post bit decisions. It also shows that, for systems with significant channel noise, the performance of frame alignment strategies depends on the alignment pattern only through its autocorrelation function. Simulations confirm the validity of the characterization.","2002","6","4","2025-12-02","https://university.edu/papers/54b960d7-eb17-4ea4-be2d-32f263b651fb.pdf");
INSERT INTO Paper VALUES ("1340","RKHS approach to detection and estimation problems--V: Parameter estimation","Using reproducing-kernel Hilbert space (RKHS) techniques, we obtain new results for three different parameter estimation problems. The new results are 1) an explicit formula for the minimum-variance unbiased estimate of the arrival time of a step function in white Gaussian noise, 2) a new interpretation of the Bhattacharyya bounds on the variance of an unbiased estimate of a function of regression coefficients, and 3) a concise formula for the Cramer-Rao bound on the variance of an unbiased estimate of a parameter determining the covariance of a zero-mean Gaussian process.","1973","16","3","2025-12-02","https://university.edu/papers/7fb957af-d88e-48ba-b276-6c20cbf2a02f.pdf");
INSERT INTO Paper VALUES ("1341","Resource Provisioning for Enriched Services in Cloud Environment","Cloud services are based on the provisioning of computing, storage, and networking resources in order to satisfy requests generated by remote end-users. High speed Internet access and multi-core Virtual Machines (VMs) enable today the provisioning of diversified and enriched types of services in Cloud environment. In this paper, we consider several types of basic services and show how their orchestration may lead to the provisioning of more sophisticated services. For this purpose, we define four types of requests that cover the wide spectrum of possible services. We then formulate the resource provisioning problem as a Mixed Integer Linear Program (MILP). We assume that the underlying infrastructure is based on a set of end-to-end connections with guaranteed sustainable bandwidth such as Carrier-Grade Ethernet (CGE) circuits. We investigate the impact of two innovative services on resource allocation carried out by a Cloud Service Provider (CSP). These services correspond to distributed data storage and to multicast data transfer. For the former service, we consider the possibility of splitting a storage request onto different remote storage nodes. The latter service aims to distribute a same data sequence from one server towards multiple remote nodes assuming a limited number of network nodes have multicast capacities. These two innovative services provide a gain of 7% in terms of accepted requests when applied to the 18-node NSFnet backbone network.","2010","11","1","2025-12-02","https://university.edu/papers/dd39f4f4-e59b-4f38-8b92-6348ac07b19b.pdf");
INSERT INTO Paper VALUES ("1342","Writing for synthesis of evidence in empirical software engineering","Context  : Systematic literature reviews have become common in software engineering in the last decade, but challenges remain.     Goal  : Given the challenges, the objective is to describe improvement areas in writing primary studies, and hence provide a good basis for researchers aiming at synthesizing research evidence in a specific area.     Method  : The results presented are based on a literature review with respect to synthesis of research results in software engineering with a particular focus on empirical software engineering. The literature review is complemented and exemplified with experiences from conducting systematic literature reviews and working with research methodologies in empirical software engineering.     Results  : The paper presents three areas where improvements are needed to become more successful in synthesizing empirical evidence. These three areas are: terminology, paper content and reviewing.     Conclusion  : It is concluded that it must be possible to improve the primary studies, but it requires that researchers start having synthesis in mind when writing their research papers.","2014","6","3","2025-12-02","https://university.edu/papers/e170719c-d96e-4766-9664-3be21c1be093.pdf");
INSERT INTO Paper VALUES ("1343","Fast BVH Construction on GPUs","Abstract#R##N##R##N#We present two novel parallel algorithms for rapidly constructing bounding volume hierarchies on manycore GPUs. The first uses a linear ordering derived from spatial Morton codes to build hierarchies extremely quickly and with high parallel scalability. The second is a top-down approach that uses the surface area heuristic (SAH) to build hierarchies optimized for fast ray tracing. Both algorithms are combined into a hybrid algorithm that removes existing bottlenecks in the algorithm for GPU construction performance and scalability leading to significantly decreased build time. The resulting hierarchies are close in to optimized SAH hierarchies, but the construction process is substantially faster, leading to a significant net benefit when both construction and traversal cost are accounted for. Our preliminary results show that current GPU architectures can compete with CPU implementations of hierarchy construction running on multicore systems. In practice, we can construct hierarchies of models with up to several million triangles and use them for fast ray tracing or other applications.","2009","10","2","2025-12-02","https://university.edu/papers/8c8e55c5-7e85-4ad8-b0a7-410a69705ad4.pdf");
INSERT INTO Paper VALUES ("1344","Exploring the Relationships among Corporate Entrepreneurship, IT Governance, and Risk Management","This study develops a more comprehensive picture of how a hospitals' entrepreneurial behavior influences its focus on IT governance and IT risk management. The key findings of this study contribute to the IT and corporate culture literatures in several ways. First, it presents corporate entrepreneurship as an antecedent to both IT governance and IT risk management. Second, it establishes a causal relationship between IT governance and IT risk management. Third, it introduces culture strength as moderator of the relationship between corporate entrepreneurship and IT risk management.","2011","15","2","2025-12-02","https://university.edu/papers/a1137849-ae72-4c55-a23f-e18dab302c36.pdf");
INSERT INTO Paper VALUES ("1345","Functional qualification of TLM verification","The topic will cover the use of functional qualification for measuring the quality of functional verification of TLM models. Functional qualification is based on the theory of mutation analysis but considers a mutation to have been killed only if a testcase fails. A mutation model of TLM behaviors is proposed to qualify a verification environment based on both testcases and assertions. The presentation describes at first the theoretic aspects of this topic and then it focuses on its application to real cases by using actual EDA tools, thus showing advantages and limitations of the application of mutation analysis to TLM.","2009","1","4","2025-12-02","https://university.edu/papers/f2ec3820-a8b9-4f11-b4ab-5d9515e0f7af.pdf");
INSERT INTO Paper VALUES ("1346","Integrated routing and addressing for improved IPv4 and IPv6 coexistence","We claim that the slow deployment of IPv6 seen so far is related with the complete decoupling with IPv4 regarding to routing and addressing. In this paper we propose Integrated Routing and Addressing (InRA), a new solution to allow IPv6 to integrate with IPv4 routing and addressing in order to decrease management cost during the coexistence period, and speed up IPv6 deployment. Addressing and routing integration are achieved by the use of a new address format derived from IPv4 address assignment, and the use of a new type of encapsulation allowing packets to be forwarded according to the most detailed information known by a router (InRA or IPv4).","2010","20","4","2025-12-02","https://university.edu/papers/d73fff82-965d-42b6-af5b-8504a98888d2.pdf");
INSERT INTO Paper VALUES ("1347","Presence as experience: film informing ways of staying there","Experience and the activities that provide it are associated with the virtual places where they were encountered, and this may instill in our imagination an illusion of an environment other than where an interactive mediated environment (a virtual environment, virtual reality, or computer game) resides (home, work, or on the move). Appropriate and/or stimulating experience may encourage users to continue, or become engaged in, pursing activities in a mediated environment. The term staying there is used to describe this situation of engagement. Conversely, if experience from use does not match up or deliver on expectations or purpose, or it is dull, boring, or uninteresting, then it may not hold user's attention and can potentially shift attention from the mediated to the real world. This paper describes the background work towards the development of a framework of experience with the aim of informing analysis and design of interactive mediated environments (IMEs) to induce/evoke stimulating experience in users and to encourage them in 'staying there.' informed from filmmaking, three levels of experience are explored: voyeuristic ('joy of seeing the new and the wonderful'), visceral (thrill of spectacle and attractions), and vicarious (transfer of emotion through another person, being, or object). With varying degrees of emphasis, story is experienced by spectators through one or a combination of these three to provide meaning. Drawing a parallel between developments in film and IMEs, situations, circumstances, features, and elements of IME design are identified that can induce/evoke these experiences in users. As well as informing analysis and design of experience of IMEs, this may provide an alternative way to reason about engagement and presence.","2003","19","4","2025-12-02","https://university.edu/papers/e959de85-86ca-4ddb-996c-cc0bb66ee07b.pdf");
INSERT INTO Paper VALUES ("1348","Support vector-based online detection of abrupt changes","We present a machine learning technique aimed at detecting abrupt changes in a sequence of vectors. Our algorithm requires a Mercer kernel together with the corresponding feature space. A stationarity index is designed in the feature space, and consists of comparing two circles corresponding to two /spl nu/-SV novelty detectors via a Fisher-like ratio. An abrupt change corresponds to a large distance between the circle centers (with respect to their radii). We show that the index can be computed in the input space, and simulation results show its efficiency in front of real data.","2003","13","4","2025-12-02","https://university.edu/papers/4beee1ae-7339-4e25-938f-19160c796112.pdf");
INSERT INTO Paper VALUES ("1349","A generic platform for estimation of multi-threaded program performance on heterogeneous multiprocessors","This paper deals with a methodology for software estimation to enable design space exploration of heterogeneous multiprocessor systems. Starting from fork-join representation of application specification along with high level description of multiprocessor target architecture and mapping of application components onto architecture resource elements, it estimates the performance of application on target multiprocessor architecture. The methodology proposed includes the effect of basic compiler optimizations, integrates light weight memory simulation and instruction mapping for complex instruction to improve the accuracy of software estimation. To estimate performance degradation due to contention for shared resources like memory and bus, synthetic access traces coupled with interval analysis technique is employed. The methodology has been validated on a real heterogeneous platform. Results show that using estimation it is possible to predict performance with average errors of around 11%.","2009","8","3","2025-12-02","https://university.edu/papers/ca8066c1-c444-45fc-ad55-7a84f346c31e.pdf");
INSERT INTO Paper VALUES ("1350","Exploratory modeling of forest disturbance scenarios in central Oregon using computational experiments in GIS","Exploratory modeling is an approach used when process and/or parameter uncertainties are such that modeling attempts at realistic prediction are not appropriate. Exploratory modeling makes use of computational experimentation to test how varying model scenarios drive model outcome. The goal of exploratory modeling is to better understand the system of interest through delineation of plausible boundaries, description of patterns within multidimensional model space, and to the extent possible, quantification of the likelihood of occurrence of different model outcomes. This study makes use of exploratory modeling in GIS to delineate boundaries of likely and plausible variability in past Oregon forests due to natural fire disturbance processes interacting with climate change, and compares those with current forests modified by harvest disturbance and with a hypothetical forest scenario. The implications of different forest landscapes for biodiversity are quantified, using a rule base constructed from empirical data describing forest age class, elevation, and heterogeneity requirements by species. Results show: 1) a wide range of natural forest structure plausibly existed in the past, 2) portions of the current forest are outside of the most liberal models of the natural range of forest variability, and 3) large changes in forest structure produce relatively small changes in biodiversity indicators. These findings suggest that disturbance processes (natural or human) that retain forested land cover but alter forest age class structure do not have a strong impact on biodiversity. As an exploratory exercise, the findings are not the end objective; rather, they serve as a basis for dialogue about which forest landscape factors are most important for assessment of biodiversity impacts.","2007","12","3","2025-12-02","https://university.edu/papers/8415ad71-c7ca-410b-94d4-aee528a0d62d.pdf");
INSERT INTO Paper VALUES ("1351","The CREATE project: mixed reality for design, education, and cultural heritage with a constructivist approach","The global scope of the CREATE project is to develop a mixed-reality framework that enables highly interactive real-time construction and manipulation of photo-realistic, virtual worlds based on real data sources. This framework will be tested and applied to cultural heritage content in an educational context, as well as to the design and review of architectural/urban planning settings. The evaluation of the project is based on a human-centered, constructivist approach to working and learning, with special attention paid to the evaluation of the resulting mixed reality experience. Through this approach, participants in an activity 'construct' their own knowledge by testing ideas and concepts based on their prior knowledge and experience, applying these to a new situation, and integrating the new knowledge gained with pre-existing intellectual constructs. CREATE project uses a high degree of interactivity, and includes provision for other senses (haptics and sound). The application developed in CREATE are designed to run on different platforms, and the targeted running systems are SGI and PC driven, with immersive stereo-displays such as a workbench, a ReaCTor (CAVE-like environment), and a wide projection screen.","2003","16","4","2025-12-02","https://university.edu/papers/c4400a41-0cf9-4d22-b1d2-53015a6318d5.pdf");
INSERT INTO Paper VALUES ("1352","Medical diagnosis by the virtual physician","The purpose of this work is to train a backpropagation neural network to make correct diagnosis of thyroid diseases and to compare its performance with human practitioners of medicine. An 84-14-12 neural network is implemented using 84 signs and symptoms of thyroid diseases as input and the 12 kinds of thyroid illness as output. The training takes place first by varying the number of hidden nodes, then by varying the number of hidden layers, the learning coefficient, the momentum coefficient, the noise inject and the tolerance between output and targets. The training is terminated when the neural network can diagnose all the targeted diseases. A field tested investigation of performance is conducted. The study shows that it is possible to train a 'virtual' physician as implemented by a neural network to make correct diagnosis of thyroid diseases based on the signs and symptoms. Such a 'virtual' physician outperforms human doctors.","1999","10","1","2025-12-02","https://university.edu/papers/6accce2c-4db8-46b1-b639-2429ef7e81b1.pdf");
INSERT INTO Paper VALUES ("1353","Fusion of multispectral and panchromatic images using improved IHS and PCA mergers based on wavelet decomposition","Since Chavez proposed the highpass filtering procedure to fuse multispectral and panchromatic images, several fusion methods have been developed based on the same principle: to extract from the panchromatic image spatial detail information to later inject it into the multispectral one. In this paper, we present new fusion alternatives based on the same concept, using the multiresolution wavelet decomposition to execute the detail extraction phase and the intensity-hue-saturation (IHS) and principal component analysis (PCA) procedures to inject the spatial detail of the panchromatic image into the multispectral one. The multiresolution wavelet decomposition has been performed using both decimated and undecimated algorithms and the resulting merged images compared both spectral and spatially. These fusion methods, as well as standard IHS-, PCA-, and wavelet-based methods have been used to merge Systeme Pour l'Observation de la Terre (SPOT) 4 XI and SPOT 4 M images with a ratio 4:1. We have estimated the validity of each fusion method by analyzing, visually and quantitatively, the quality of the resulting fused images. The methodological approaches proposed in this paper result in merged images with improved quality with respect to those obtained by standard IHS, PCA, and standard wavelet-based fusion methods. For both proposed fusion methods, better results are obtained when an undecimated algorithm is used to perform the multiresolution wavelet decomposition.","2004","8","1","2025-12-02","https://university.edu/papers/d2102bd3-49ac-4385-80a3-ec394e904a63.pdf");
INSERT INTO Paper VALUES ("1354","Joint channel assignment and routing for throughput optimization in multi-radio wireless mesh networks","Multi-hop infrastructure wireless mesh networks offer increased reliability, coverage and reduced equipment costs over their single-hop counterpart, wireless LANs. Equipping wireless routers with multiple radios further improves the capacity by transmitting over multiple radios simultaneously using orthogonal channels. Efficient channel assignment and routing is essential for throughput optimization of mesh clients. Efficient channel assignment schemes can greatly relieve the interference effect of close-by transmissions; effective routing schemes can alleviate potential congestion on any gateways to the Internet, thereby improving per-client throughput. Unlike previous heuristic approaches, we mathematically formulate the joint channel assignment and routing problem, taking into account the interference constraints, the number of channels in the network and the number of radios available at each mesh router. We then use this formulation to develop a solution for our problem that optimizes the overall network throughput subject to fairness constraints on allocation of scarce wireless capacity among mobile clients. We show that the performance of our algorithms is within a constant factor of that of any optimal algorithm for the joint channel assignment and routing problem. Our evaluation demonstrates that our algorithm can effectively exploit the increased number of channels and radios, and it performs much better than the theoretical worst case bounds.","2005","14","4","2025-12-02","https://university.edu/papers/a4a037bd-99cb-4e6b-94af-6b5eb80bc895.pdf");
INSERT INTO Paper VALUES ("1355","Performance evaluation of in-home broadband PLC systems using a cooperative MAC protocol","In this article, we present an in-depth analysis of cooperation benefits in power line communication (PLC) networks. In order to conduct our evaluation, we present a new, yet simple, cooperative medium access control protocol (CMAC). Our new CMAC protocol uses system nodes as relays adaptively, according to these nodes idleness or busyness. Moreover, the new protocol also explores path diversity offered by an in-home broadband PLC. We have conducted simulations, based on real packet error ratios of in-home networks, using a wide range of configurations. In sum, our results show that cooperation reduces packet loss ratio and improves goodput. For instance, in some scenarios, the protocol we proposed is able to enhance goodput up to 36% and reduce packet loss ratio up to 43% in comparison to a system without cooperative protocols. Moreover, our simulations allow us to delimit the most suitable scenarios to use cooperation. Based on our analyses, we can state the following: (i) improvements increase when frequency bandwidth increases; (ii) irrelevant improvement occurs if total transmission power is too high or too low; (iii) gains offered by cooperation are more relevant depending on relative node relay position in relation to nodes source and destination; (iv) the proposed protocol show improvements regardless of the choice between OFDMA-TDMA and TDMA-OFDM schemes, but improvements are higher when it is used together with the OFDMA-TDMA scheme.","2016","9","4","2025-12-02","https://university.edu/papers/7a3f6b8d-f665-4575-bc20-b752eddfcfa8.pdf");
INSERT INTO Paper VALUES ("1356","Multiple aggregations over data streams","Monitoring aggregates on IP traffic data streams is a compelling application for data stream management systems. The need for exploratory IP traffic data analysis naturally leads to posing related aggregation queries on data streams, that differ only in the choice of grouping attributes. In this paper, we address this problem of efficiently computing multiple aggregations over high speed data streams, based on a two-level LFTA/HFTA DSMS architecture, inspired by Gigascope.Our first contribution is the insight that in such a scenario, additionally computing and maintaining fine-granularity aggregation queries (phantoms) at the LFTA has the benefit of supporting shared computation. Our second contribution is an investigation into the problem of identifying beneficial LFTA configurations of phantoms and user-queries. We formulate this problem as a cost optimization problem, which consists of two sub-optimization problems: how to choose phantoms and how to allocate space for them in the LFTA. We formally show the hardness of determining the optimal configuration, and propose cost greedy heuristics for these independent sub-problems based on detailed analyses. Our final contribution is a thorough experimental study, based on real IP traffic data, as well as synthetic data, to demonstrate the effectiveness of our techniques for identifying beneficial configurations.","2005","19","1","2025-12-02","https://university.edu/papers/671e5d42-1d88-4e24-9b2f-ac6c5e73db2a.pdf");
INSERT INTO Paper VALUES ("1357","The effects of the number of links and navigation support on cognitive load and learning with hypertext: The mediating role of reading order","Problems in learning with hypertext systems have been claimed to be caused by high levels of disorientation and cognitive load. This was recognized by DeStefano and LeFevre [DeStefano, D., & LeFevre, J. -A., (2007). Cognitive load in hypertext reading: A review. Computers in Human Behavior, 23(3), 1616-1641.] who predicted an increase of cognitive load and impairment of learning for hypertexts with a higher number of links per page. From a practical perspective, several navigation support techniques, such as providing link suggestions, have been proposed for guiding learners and reducing cognitive overload. In an experiment, we tested DeStefano and LeFevre's predictions as well as the usefulness of link suggestions. Participants used different versions of a hypertext, either with 3-links or 8-links per page, presenting link suggestions or not. We tested their cognitive load and learning outcomes. Results showed that there was a benefit of using link suggestions for learning, but no effect of number of links on learning was found. Moreover, the effects of our manipulations on cognitive load were mediated by the reading order that participants selected. Implications for research and the design of navigation support systems are discussed.","2009","6","2","2025-12-02","https://university.edu/papers/c1d4755a-7002-4814-bd3f-66e98b973de4.pdf");
INSERT INTO Paper VALUES ("1358","Using opposition-based learning to enhance differential evolution: A comparative study","Opposition-based learning (OBL) is a recently proposed method, which is successfully used to accelerate the search process of some well-known techniques in soft computing, such as swarm and evolutionary algorithms, artificial neural networks, reinforcement learning, and fuzzy logic systems. Among these opposition-based algorithms, opposition-based differential evolution (ODE) is one of the most popular algorithm. In the past several years, several variants of OBL scheme have been proposed. This paper presents a comparative study conducted on various OBL schemes, all utilized in differential evolution (DE) in order to enhance its accuracy or convergence rate. In the experiments, eight different OBL versions, namely the original OBL, quasi opposition, quasi reflection opposition, current optimum opposition, generalized opposition, centroid opposition, extended opposition, and reflected extended opposition, are embedded in DE algorithm and studied. Results on the CEC-2014 benchmark set for dimensions 10, 30, and 50 are reported.","2016","10","2","2025-12-02","https://university.edu/papers/6abd95b7-d66f-4c06-93f2-921aca507011.pdf");
INSERT INTO Paper VALUES ("1359","Die Stacking Technology for Terabit Chip-to-Chip Communications","In this paper a die stacking technology, leveraging on through die via (TDV) integration and wafer bonding, is presented. Using state-of-the-art volume manufacturing environment, 10:1 aspect ratio TDV and wafer-level bonding technology are developed and initial electrical and reliability characterization results of TDVs are provided. The opportunities for die-stacking technology to alleviate chip-to-chip communication bottleneck are discussed and visions for stacked-die applications, utilizing a programmable virtual backplane, are presented.","2006","19","2","2025-12-02","https://university.edu/papers/fb7da97c-cf7e-4909-a1c3-4128618eb743.pdf");
INSERT INTO Paper VALUES ("1360","Virtual Preservation of Contemporary Architectural Heritage in Developing Countries in Absence of Protection: Digital Reconstrction, Recording, and Archiving before Complete Disappearance","Virtual reconstruction of cultural heritage is limited to the availability of reference materials. This study looks at the state of preservation and archiving of cultural heritage in the Southeast Asia region through reviewing 2 cases in Malaysia. Many iconic heritage buildings were demolished in this country during the past decades without being properly achieved for the future generations. Despite living in the digital era, virtual conservation in this region still lags. This study tries to address some of those issues by looking at the available alternatives (the methodology), and also answering the question, what can be done in absence of archived reference materials while the building is still available? Different areas such as digital reconstruction and its importance, digital archiving, virtual reality, the future usage are covered by this study, including social impacts.","2015","5","3","2025-12-02","https://university.edu/papers/3769f626-1809-40cb-9dad-92e7c2d244f9.pdf");
INSERT INTO Paper VALUES ("1361","Reim & ReImInfer: checking and inference of reference immutability and method purity","Reference immutability ensures that a reference is not used to modify the referenced object, and enables the safe sharing of object structures. A pure method does not cause side-effects on the objects that existed in the pre-state of the method execution. Checking and inference of reference immutability and method purity enables a variety of program analyses and optimizations. We present ReIm, a type system for reference immutability, and ReImInfer, a corresponding type inference analysis. The type system is concise and context-sensitive. The type inference analysis is precise and scalable, and requires no manual annotations. In addition, we present a novel application of the reference immutability type system: method purity inference.   To support our theoretical results, we implemented the type system and the type inference analysis for Java. We include a type checker to verify the correctness of the inference result. Empirical results on Java applications and libraries of up to 348kLOC show that our approach achieves both scalability and precision.","2012","2","1","2025-12-02","https://university.edu/papers/4acda6d4-094b-463b-88e0-a4fe30439af1.pdf");
INSERT INTO Paper VALUES ("1362","Socioeconomic Correlations and Stratification in Social Communication Networks","The uneven distribution of wealth and individual economic capacities are among the main forces, which shape modern societies. They arguably bias the emerging social structure, lay behind spatial and social segregation, and induce differences in terms of consumer behaviour, mobility, or even communication patterns. However, the observation of these correlations is difficult due to the com- plexity of their dependencies, and due to the lack of multidimensional data, which simultaneously records the economic status and social network of individuals. In this work we aimed to close this gap through the analysis of a coupled dataset of mobile phone communication records and bank credit history of a large set of individuals living in Mexico. After mapping the spatially em- bedded social structure and estimating individual economic capacities we addressed four different aspects about their correlations: (a) We show that individual economic indicators such as average monthly purchases, and surprisingly individual debts are unevenly distributed in the population in agreement with the Pareto’s principle (b) After grouping egos into nine socioeconomic classes we detect signatures of status homophily and find evidences of stratification in the socioeconomic network (see Fig.1a). We also observe that the social structure is upward biased towards wealthier classes (see Fig.1b) and show assortative correlations giving rise to strongly connected ”rich-clubs” in the network. (c) Further we demonstrate that people of the same class live closer to each other, and their commuting distances are positively correlated with their economic status; (d) We de- tect purchasing patterns typical to socioeconomic classes and show them to be correlated with the social strata and finally we quantify the importance of the social network in terms of shaping consumption behaviour.","2016","10","2","2025-12-02","https://university.edu/papers/27fe5b8c-1ecb-4845-a756-5a140d4e5dbd.pdf");
INSERT INTO Paper VALUES ("1363","Fully differential difference transconductance amplifier using FG-MOS transistors","This paper presents a fully differential difference transconductance amplifier for applications to low-voltage and low-power analogue circuits. Differential difference input voltage can be obtained using floating-gate MOS transistor technique and it can be taken also the possibility of low supply voltage of the circuit. The proposed active building block has been simulated using TSMC 0.18 µm n-well CMOS technology. The circuit uses ±0.4 V supply voltage and consumes a 27 µW of static power. A fully differential universal filter using proposed circuit as active device was presented as an example application.","2015","12","4","2025-12-02","https://university.edu/papers/6c9fdaa6-7060-416a-af0a-ef1deef42082.pdf");
INSERT INTO Paper VALUES ("1364","Optimization-based computation of analytic interpolants of bounded complexity","This paper provides a unifying algorithm for computing any analytic interpolant of bounded complexity. Such computation can be performed by solving an optimization problem, due to a theorem by Georgiou and Lindquist. This optimization problem is numerically solvable by a continuation method. The proposed numerical algorithm is useful, among other cases, for designing a low-degree controller for a benchmark problem in robust control. The algorithm unifies previously developed algorithms for the Caratheodory extension and the Nevanlinna–Pick interpolation to one for more general interpolation problems.","2005","13","2","2025-12-02","https://university.edu/papers/f83ed2a8-62e4-40fd-b42e-deec179f36a1.pdf");
INSERT INTO Paper VALUES ("1365","A Collision Avoidance Mechanism for IEEE 802.11e EDCA Protocol to Improve Voice Transmissions in Wireless Local Area Networks","Enhanced distributed channel access (EDCA) is the basis protocol in IEEE 802.11e protocol suite. It is used for providing differentiated quality of service (QoS) in IEEE 802.11e standard wireless local area networks (WLANs). One of the main drawbacks in EDCA is the small values used for minimum and maximum contention window (CW) sizes for the AC_VO access category, the queue designated for voice transmission. The AC_VO queues of the QSTAs are very aggressive in transmitting their packets on to the channel due to their small CW sizes. This leads to degradation in the actual voice throughput performance even when the network size is small. This work proposes a new modification to the collision avoidance mechanism used by AC_VO queues without seriously effecting the performance of other traffic categories such as video and data. Extensive simulations are carried out to verify the performance of the proposed enhancement to the original collision avoidance mechanism.","2007","15","1","2025-12-02","https://university.edu/papers/8487428e-8fc8-48ac-a578-b9eac12fc565.pdf");
INSERT INTO Paper VALUES ("1366","Adaptive control of plants that are practically impossible to control by fixed-gain control laws","Some LTI plants are practically impossible to control due to extremely small gain and phase margins. These plants tend to be either unstable or nonminimum phase or both. Since practical control of these plants using fixed-gain controllers is not feasible, it is of interest to determine whether adaptive control can overcome these difficulties. To investigate this question, we apply retrospective cost adaptive control (RCAC) to a collection of plants that are practically impossible to control from an LTI perspective. For each plant, we introduce a destabilizing perturbation in order to determine whether or not RCAC can re-adapt in such a way as to compensate for the loss of margin and restabilize the closed-loop system without manual retuning. Since these plants are inherently difficult to control, it is of interest to determine whether or not restabilization is possible and, if so, assess the severity of the transient response.","2016","5","2","2025-12-02","https://university.edu/papers/63e12002-596f-4d07-87be-ecd5aac06583.pdf");
INSERT INTO Paper VALUES ("1367","Predicting homologous signaling pathways using machine learning","Motivation: In general, each cell signaling pathway involves many proteins, each with one or more specific roles. As they are essential components of cell activity, it is important to understand how these proteins work—and in particular, to determine which of the species' proteins participate in each role. Experimentally determining this mapping of proteins to roles is difficult and time consuming. Fortunately, many pathways are similar across species, so we may be able to use known pathway information of one species to understand the corresponding pathway of another.#R##N##R##N#Results: We present an automatic approach, Predict Signaling Pathway (PSP), which uses the signaling pathways in well-studied species to predict the roles of proteins in less-studied species. We use a machine learning approach to create a predictor that achieves a generalization F-measure of 78.2% when applied to 11 different pathways across 14 different species. We also show our approach is very effective in predicting the pathways that have not yet been experimentally studied completely.#R##N##R##N#Availability: The list of predicted proteins for all pathways over all considered species is available at http://www.cs.ualberta.ca/~bioinfo/signaling.#R##N##R##N#Contact:bioinfo@cs.ualberta.ca; duane@cs.ualberta.ca","2009","6","3","2025-12-02","https://university.edu/papers/ee7944cb-bb77-4b0e-b497-17f0e211397a.pdf");
INSERT INTO Paper VALUES ("1368","Conceptual modelling for invoice document processing","This paper is concerned with the presentation of a declarative knowledge base, the Conceptual Model, which describes the invoice domain as generally as possible. Such a model is based on a semantic network that is able to describe the invoice domain by different levels of abstraction. The Conceptual Model can be used for the labelling procedure of physical rectangles, extracted from invoices, in order to construct a model (Document Model) for each class of invoices. The Document Model contains physical coordinates for each rectangle, which can be estimated from an invoice, and the related semantic label. Once the Document Model is constructed, it can be applied to understand an invoice instance, whose class is univocally identified by its logo.","1997","10","1","2025-12-02","https://university.edu/papers/dc000ac6-951a-433e-8400-f6620338da12.pdf");
INSERT INTO Paper VALUES ("1369","MINERVA: multimedia on the Internet for virtual arts","This paper describes a design that implements a Virtual Museum for its access through Internet. It can not only provide the information so far available in the Web, but also allows a three-dimensional (3D) walk through the whole Museum, watching its collections, plus a presentation of single objects in 3D, with different resolutions according to each visitor interests and with a real possibility of visitor-object interaction. All this opens a wide new path of investigation, as it brings 3D into Internet and means a contribution to the increase of interactivity in Web pages.","1999","6","2","2025-12-02","https://university.edu/papers/7b3cdd9c-f722-4c11-9c9c-0f138555ebfd.pdf");
INSERT INTO Paper VALUES ("1370","Towards Adaptive Evolutionary Architecture","This paper presents first results from an interdisciplinary project, in which the fields of architecture, philosophy and artificial life are combined to explore possible futures of architecture. Through an interactive evolutionary installation, called EvoCurtain, we investigate aspects of how living in the future could occur, if built spaces could evolve and adapt alongside inhabitants. As such, present study explores the interdisciplinary possibilities in utilizing computational power to co-create with users and generate designs based on human input. We argue that this could lead to the development of designs tailored to the individual preferences of inhabitants, changing the roles of architects and designers entirely. Architecture-as-it-could-be is a philosophical approach conducted through artistic methods to anticipate the technological futures of human-centered development within architect.","2016","7","4","2025-12-02","https://university.edu/papers/7b091e41-9d2b-4561-a689-8d6ee199dc49.pdf");
INSERT INTO Paper VALUES ("1371","On the tuning of the free parameters of a new adaptive robot control based on geometric principles of Hamiltonian mechanics","A novel approach toward the adaptive control of robots dynamically interacting with an unmodelled environment and having only approximately known dynamic parameters has previously been developed on the basis of the principles of the Hamiltonian mechanics. Like different means of modern soft computing technology such as artificial neural networks (ANNs) or fuzzy controllers having a more or less uniform architecture independent of the particular details of the problems to be solved by them, the proposed method also has a uniform structure not strictly tailored to the peculiar properties of the mechanical system to be controlled. However, as special kinds of ANNs are fit to solve wide but typical classes of tasks the proposed method is invented for tackling problems related to the control of mechanical devices in which the dominating nonlinear coupling originates from the laws of classical mechanics. As ANNs have plenty of free parameters (connection weights and threshold values) the tuning of which means learning, this mechanical model also contains tunable parameters so offering the possibility for learning. In this paper the model's free parameters, possible constraints imposed on them as well as different tuning strategies are discussed partly on the basis of computer simulations.","1997","3","2","2025-12-02","https://university.edu/papers/b8132a83-f39c-4e9c-8870-3ffc616ef1d2.pdf");
INSERT INTO Paper VALUES ("1372","Regularized Logistic Regression Fusion for Speaker Verification.","Fusion of the base classifiers is seen as the way to achieve stateof-the art performance in the speaker verfication systems. Standard approach is to pose the fusion problem as the linear binary classification task. Most successful loss function in speaker verification fusion has been the weighted logistic regression popularized by the FoCal toolkit. However, it is known that optimizing logistic regression can overfit severely without appropriate regularization. In addition, subset classifier selection can be achieved by using an external 0/1 loss function on the best subset. In this work, we propose to use LASSO based regularization on the FoCal cost function to achive improved performance and classifier subset selection method integrated into one optimization task. Proposed method is able to achieve 51% relative improvement in Actual DCF over the FoCal baseline. Index Terms: logistic regression, regularization, compressed sensing, linear fusion, speaker verification","2011","5","3","2025-12-02","https://university.edu/papers/3ac4ba2a-d07f-4160-a1e0-444d4dcadb96.pdf");
INSERT INTO Paper VALUES ("1373","Selecting the best system in steady-state simulations using batch means","Suppose that we want to compare k different systems, where /spl mu//sub i/ denotes the steady state mean performance of system i. Our goal is to use simulation to pick the 'best' system (i.e., the one with the largest or smallest steady state mean). To do this, we present some two stage procedures based on the method of batch means. Our procedures also construct multiple comparisons with the best (MCB) confidence intervals for /spl mu//sub i/-max/sub j/spl ne/i//spl mu//sub j/, i=1,...,k. Under the assumption of an indifference zone of (absolute or relative) width /spl delta/, we can show that asymptotically (as /spl delta//spl rarr/0 with the size of the batches proportional to 1//spl delta//sup 2/), the joint probability of correctly selecting the best system and of the MCB confidence intervals simultaneously containing /spl mu//sub i/-max/sub j/spl ne/i//spl mu//sub j/, i=1,...,k, is at least 1-/spl alpha/, where /spl alpha/ is prespecified by the user.","1995","1","4","2025-12-02","https://university.edu/papers/ef5b17ef-7b7e-434b-8ebc-b399d634a385.pdf");
INSERT INTO Paper VALUES ("1374","Virtual reality and augmented reality as a training tool for assembly tasks","In this paper we investigate whether virtual reality (VR) and augmented reality (AR) offer potential for the training of manual skills, such as for assembly tasks, in comparison to conventional media. We present results from experiments that compare assembly completion times for a number of different conditions. We firstly investigate completion times for a task where participants can study an engineering drawing and an assembly plan and then conduct the task. We then investigate the task under various VR conditions and context-free AR. We discuss the relative advantages and limitations of using VR and AR as training media for investigating assembly operations, and we present the results of our experimental work.","1999","6","3","2025-12-02","https://university.edu/papers/93eb8af7-ade0-4d84-ab5c-d96eec914dec.pdf");
INSERT INTO Paper VALUES ("1375","MetaSV: An accurate and integrative structural-variant caller for next generation sequencing","Summary: Structural variations (SVs) are large genomic rearrangements that vary significantly in size, making them challenging to detect with the relatively short reads from next-generation sequencing (NGS). Different SV detection methods have been developed; however, each is limited to specific kinds of SVs with varying accuracy and resolution. Previous works have attempted to combine different methods, but they still suffer from poor accuracy particularly for insertions. We propose MetaSV, an integrated SV caller which leverages multiple orthogonal SV signals for high accuracy and resolution. MetaSV proceeds by merging SVs from multiple tools for all types of SVs. It also analyzes soft-clipped reads from alignment to detect insertions accurately since existing tools underestimate insertion SVs. Local assembly in combination with dynamic programming is used to improve breakpoint resolution. Paired-end and coverage information is used to predict SV genotypes. Using simulation and experimental data, we demonstrate the effectiveness of MetaSV across various SV types and sizes.#R##N##R##N#Availability and implementation: Code in Python is at http://bioinform.github.io/metasv/.#R##N##R##N#Contact: moc.anib@dr#R##N##R##N#Supplementary information: Supplementary data are available at Bioinformatics online.","2015","4","4","2025-12-02","https://university.edu/papers/501177a1-ea17-40a9-b95a-0b38b2846749.pdf");
INSERT INTO Paper VALUES ("1376","Using Cultural Algorithms to Improve Wearable Device Gesture Recognition Performance","Wearable computing devices are now mainstream. Many such devices have capable MEMS sensors that can be exploited for recognizing dynamic, in-the-air gestures. Noting the somewhat limited compute and battery life of today's devices, we present a computationally efficient approach to gesture recognition that can be effectively used inside an app running on standard, off-the-shelf hardware, such as an Android Smart watch. Our approach has two phases. The first phase is to construct finite state machines (FSM) for gesture recognition. We present a novel approach - which leverages techniques from functional programming languages - to define rich yet compact FSM. Such FSM can be further tuned for higher accuracy with help of some training data and a suitable optimization method - this is the second phase. To demonstrate effectiveness, we created a gesture recognition system for an automotive scenario as an Android Smart watch app and then tuned the gesture recognition engine using Cultural Algorithms optimization and training data. We achieved 77% gesture recognition accuracy which is on par which more computationally intensive techniques such as Hidden Markov Models.","2015","18","4","2025-12-02","https://university.edu/papers/7c118fc3-bbf0-4950-ac2e-e03aff923e50.pdf");
INSERT INTO Paper VALUES ("1377","Randomly-oriented k-d Trees Adapt to Intrinsic Dimension","The classic k-d tree data structure continues to be widely used in spite of its vulnerability to the so-called curse of dimensionality. Here we provide a rigorous explanation: for randomly rotated data, a k-d tree adapts to the intrinsic dimension of the data and is not affected by the ambient dimension, thus keeping the data structure efficient for objects such as low-dimensional manifolds and sparse data.#R##N#The main insight of the analysis can be used as an algorithmic pre-processing step to realize the same benefit: rotate the data randomly; then build a k-d tree. Our work can be seen as a refinement of Random Projection trees [Dasgupta 2008], which also adapt to intrinsic dimension but incur higher traversal costs as the resulting cells are polyhedra and not cuboids. Using k-d trees after a random rotation results in cells that are cuboids, thus preserving the traversal efficiency of standard k-d trees.","2012","7","4","2025-12-02","https://university.edu/papers/9c27a187-4092-4b14-8e5c-7c8cfb79b05e.pdf");
INSERT INTO Paper VALUES ("1378","Subversive participatory design: reflections on a case study","This paper grounds in a research experience for engaging older people as co-designers of several wearable and in-house technologies. We start by describing a case study that is a precommercial procurement aimed at developing innovative services for the welfare of citizens, with a focus on older people. We present and discuss the qualitative data gathered on the occasion of a bodystorming with two groups of participants. The analysis led to the identification of the 'aesthetic appropriateness', the 'social sensitivity', and the 'gender awareness' as three different dimensions that affected the acceptability of the technological devices. This approach created the conditions for instantiating the subversive power of participation. At the same time, such a subversion proved the authenticity of the participatory process. By drawing on this project, the purpose of the paper is to further our understanding of the conditions for Participatory Design.","2016","13","4","2025-12-02","https://university.edu/papers/2e3c722c-d09a-4cb0-9d04-85d90c9d505c.pdf");
INSERT INTO Paper VALUES ("1379","Exploiting semantic web and ontologies for personalised learning services: towards semantic web-enabled learning portals for real learning experiences","This paper presents an in-depth analysis of the semantic web contribution towards personalisation in e-learning content exploitation. The aim of this research work is to develop a framework for analysing the semantic web and ontological issues related with the design and implementation of high performance e-learning systems enabled by advanced semantic web and ontological engineering. Within this context the concept of personalisation is linked to the state of the art of semantic web and ontologies research. The main emphasis is paid to the management of personal profiles and identities. Real learning experiences are promoted through the definition of value-adding layers within semantic e-learning portals.","2008","8","1","2025-12-02","https://university.edu/papers/66bff278-182f-4698-aaaf-489d5b2da0a5.pdf");
INSERT INTO Paper VALUES ("1380","Taming the Shrew - Resolving Structural Heterogeneities with Hierarchical CPNs.","Model transformations play a key role in the vision of Model- Driven Engineering (MDE) whereby the overcoming of structural hetero- geneities, being a result of applying dierent meta-modeling constructs for the same semantic concept, is a challenging, recurring problem, ur- gently demanding for reuse of transformations. In this respect, an ap- proach is required which (i) abstracts from the concrete execution lan- guage allowing to focus on the resolution of structural heterogeneities, (ii) keeps the impedance mismatch between specification and execution low enabling seamless debuggability, and (iii) provides formal underpinnings enabling model checking. Therefore, we propose to specify model trans- formations by applying a set of abstract mapping operators (MOPs), each resolving a certain kind of structural heterogeneity. For specifying the operational semantics of the MOPs, we propose to use Transforma- tion Nets (TNs), a DSL on top of Colored Petri Nets (CPNs), since it allows (i) to keep the impedance mismatch between specification and execution low and (ii) to analyze model transformations by evaluating behavioral properties of CPNs.","2010","13","2","2025-12-02","https://university.edu/papers/0ac8025c-4883-42ed-9d7a-1133a84d3027.pdf");
INSERT INTO Paper VALUES ("1381","Convergence index filter for vector fields","This paper proposes a unique fitter called an iris filter, which evaluates the degree of convergence of the gradient vectors within its region of support toward a pixel of interest. The degree of convergence is related to the distribution of the directions of the gradient vectors and not to their magnitudes. The convergence index of a gradient vector at a given pixel is defined as the cosine of its orientation with respect to the line connecting the pixel and the pixel of interest. The output of the iris filter is the average of the convergence indices within its region of support and lies within the range [-1,1]. The region of support of the iris filter changes so that the degree of convergence of the gradient vectors in it becomes a maximum, i.e., the size and shape of the region of support at each pixel of interest changes adaptively according to the distribution pattern of the gradient vectors around it. Theoretical analysis using models of a rounded convex region and a semi-cylindrical one is given. These show that rounded convex regions are generally enhanced, even if the contrast to their background is weak and also that elongated objects are suppressed. The filter output is 1//spl pi/ at the boundaries of rounded convex regions and semi-cylindrical ones. This value does not depend on the contrast to their background. This indicates that boundaries of rounded or slender objects, with weak contrast to their background, are enhanced by the iris filter and that the absolute value of 1//spl pi/ can be used to detect the boundaries of these objects. These theoretical characteristics are confirmed by experiments using X-ray images.","1999","11","2","2025-12-02","https://university.edu/papers/ec984cef-237a-4f8a-857f-f98d212c5155.pdf");
INSERT INTO Paper VALUES ("1382","To Combat Multi-Class Imbalanced Problems by Means of Over-Sampling Techniques","Class imbalance problem is quite pervasive in our nowadays human practice. This problem basically refers to the skewness in the data underlying distribution which, in turn, imposes many difficulties on typical machine learning algorithms. To deal with the emerging issues arising from multi-class skewed distributions, existing efforts are mainly divided into two categories: model-oriented solutions and data-oriented techniques. Focusing on the latter, this paper presents a new over-sampling technique which is inspired by Mahalanobis distance. The presented over-sampling technique, called MDO (Mahalanobis Distance-based Over-sampling technique), generates synthetic samples which have the same Mahalanobis distance from the considered class mean as other minority class examples. By preserving the covariance structure of the minority class instances and intelligently generating synthetic samples along the probability contours, new minority class instances are modelled better for learning algorithms. Moreover, MDO can reduce the risk of overlapping between different class regions which are considered as a serious challenge in multi-class problems. Our theoretical analyses and empirical observations across wide spectrum multi-class imbalanced benchmarks indicate that MDO is the method of choice by offering statistical superior MAUC and precision compared to the popular over-sampling techniques.","2016","13","3","2025-12-02","https://university.edu/papers/8f791e01-1bce-48d4-97cf-90e1b61418bb.pdf");
INSERT INTO Paper VALUES ("1383","Class-based QoS control scheme by flow management in the Internet router","With the Internet transforming into multimedia and high-speed, the various traffic requiring different qualities of service (QoS) will co-exist in the network. Also, classified service based on Diff-Serv (differentiated service), MPLS (Multi Protocol Label Switching) and so on, have come into wide use. In today's environment of the Internet, it is necessary for the routers to perform the control mechanism to guarantee various QoS. We propose the buffer management scheme of the Internet router with class-based priority control, focusing on per-flow queueing, and evaluate the performance. We aim at the realization of differentiated services and the dissolution of the buffer occupation by specific flow.","2000","10","4","2025-12-02","https://university.edu/papers/578fceea-edc4-4dc5-9561-1971868801b9.pdf");
INSERT INTO Paper VALUES ("1384","Speech enhancement based on a hybrid a priori signal-to-noise ratio (SNR) estimator and a self-adaptive Lagrange multiplier","Speech enhancement techniques, using spectral subtraction, have the drawback of generating an annoying residual noise with musical character. An accurate estimate of the a priori SNR is critical for eliminating musical noise. In this paper, for an accurate estimate of the a priori SNR we have proposed a hybrid a priori SNR estimator and a self-adaptive Lagrange multiplier with Wiener denoising technique. Objective evaluations showed that the proposed method performed better than the Decision-Directed (DD) approach.","2008","20","4","2025-12-02","https://university.edu/papers/f88d59c4-b861-4cb8-b791-e5b344b8b964.pdf");
INSERT INTO Paper VALUES ("1385","Generating tests from counterexamples","We have extended the software model checker BLAST to automatically generate test suites that guarantee full coverage with respect to a given predicate. More precisely, given a C program and a target predicate p, BLAST determines the set L of program locations which program execution can reach with p true, and automatically generates a set of test vectors that exhibit the truth of p at all locations in L. We have used BLAST to generate test suites and to detect dead code in C programs with up to 30 K lines of code. The analysis and test vector generation is fully automatic (no user intervention) and exact (no false positives).","2004","18","1","2025-12-02","https://university.edu/papers/dbe948b3-842e-46bc-893e-166e92795011.pdf");
INSERT INTO Paper VALUES ("1386","Automatic layout generation for mixed analog-digital VLSI neural chips","A systematic approach to automatic layout generation for the emerging mixed analog-digital VLSI neural systems is described. A macro-cell layout methodology based on a hierarchical floorplanning and placement procedure, a constraint-driven analog module generator, and a priority-based block router have been exclusively developed for neural chip implementation. Special analog VLSI layout constraints are analyzed and properly incorporated into the layout generation on each level of the circuit hierarchy to achieve both high performance and overall area efficiency. The floorplans for single-layer fully-connected Hopfield neural chips and multiple-layer neural chips have been developed. Experimental results on a 16-neuron neural circuit are presented. >","1990","12","4","2025-12-02","https://university.edu/papers/587e8ae4-632a-4c63-9554-b88c5df4a2cf.pdf");
INSERT INTO Paper VALUES ("1387","An open source software selection process and a case study","In this study, I design an empirical open source software selection process, which reuses some ideas from Commercial Off-the-Shelf selection methods and addresses the characteristics of the open source software. Basically, it consists of three basic steps: identification, screening and evaluation. The identification step is to find all possible alternatives to open source software that can meet the high level requirements. The next step is screening, in which the refined requirements are applied to filter the alternatives. The evaluation step is based on the Analytic Hierarchy Process, in which the alternatives are inspected from functional suitability, source code, support strength and popularity. In more detail, under functionality suitability criterion, alternatives to open source software are evaluated in viewing of how much functionality can fit in with the functional user requirements. The source code of the alternatives is evaluated from six criteria: programming language, code size, code comment, code intra-module complexity and code inter-module complexity. The evaluation of support strength depends on the evaluation of field support and support resources. The field support includes commercial support and community support. The community support specifically refers to the direct responses from the community to the support requests. Aside from field support, open source software projects also provide various support-related resources such as, documents, wiki, blog, etc. To determine the popularity of the alternatives, I evaluate them from software use, development participation and web popularity. #R##N#In the case study, I utilize the process to select the best open source unified modeling language tool from the ten alternatives for the software development process. After the screening phase, the four competitive alternatives, BOUML, ArgoUML, UMLet and Violet, are evaluated from functionality, source code, support strength and popularity criteria. The evaluation result indicates that ArgoUML is the best tool for the requirement. The case study demonstrates the effectiveness of the selection process. Various important attributes of open source software are taken into consideration systematically and the final decision is reached based on comprehensive investigation and analysis. The process provides an operable solution to the open source selection problem in practice.","2007","19","1","2025-12-02","https://university.edu/papers/a42c6df8-40d7-4ebf-8550-d979136653ef.pdf");
INSERT INTO Paper VALUES ("1388","Improved upper bounds on the ML performance of turbo codes for interleaved Rician fading channels, with comparison to iterative decoding","The ensemble performance of ML decoded turbo codes using coherent BPSK signaling on fully interleaved (memoryless) Rician fading channels is considered, where the ensemble is generated by a uniform choice of the interleaver. The improved bound proposed here is advantageous over the ubiquitous union bound, and it is especially pronounced in the rate region exceeding the cutoff rate (where the performance of turbo codes is most appealing but the union bounds become useless). The upper bounds are compared to simulation results of the log-MAP iterative decoding algorithm for various degrees of space diversity, demonstrating a good match. Hence the improved bounds can be used also as a fast technique to approximately assess the performance of efficient iterative decoding.","2000","8","2","2025-12-02","https://university.edu/papers/d226a85b-6227-48d1-867b-69c54656248f.pdf");
INSERT INTO Paper VALUES ("1389","A competitive strategy for routing flow over time","Network routing games are used to understand the impact of individual users' decisions on network efficiency. Prior work on routing games uses a simplified model of network flow where all flow exists simultaneously. In our work, we examine routing games in a flow-over-time model. We show that by reducing network capacity judiciously, the network owner can ensure that the equilibrium is no worse than a small constant times the optimal in the original network, for two natural measures of optimality. These are the first upper bounds on the price of anarchy in the flow-over-time model for general networks.","2011","8","3","2025-12-02","https://university.edu/papers/a418399e-1707-402b-bba3-8f8ffb8a8994.pdf");
INSERT INTO Paper VALUES ("1390","Swarm Intelligence and Weak Artificial Creativity","Swarm intelligence via its infamous struggle to identify a suitable balance between exploration and exploitation phases, provides a valuable mean to approach artificial creativity. This work deploys two swarm intelligence algorithms, one simulating the behaviour of birds flocking and fish schooling (Particle Swarm Optimisation) and the other mimicking the behaviour of ants foraging (Stochastic Diffusion Search) in order to lay the foundation for a discussion addressing the concepts of freedom and constraint within the topic of creativity in general, and more specifically their impact on the artificial creativity of the underlying systems. An analogy is drawn on mapping these two `prerequisites' of creativity onto the two well-known aforementioned phases of exploration and exploitation in swarm intelligence algorithms. This is accompanied by the visualisation of the behaviour of the swarms whose performance are evaluated in the context of the arguments presented. Additionally in the spirit of Searle's definition of weak and strong artificial intelligence, a discussion on weak vs. strong artificial creativity in swarm intelligence systems is presented.","2013","12","3","2025-12-02","https://university.edu/papers/a8a46e0b-ef4b-4385-a194-e889a43ade36.pdf");
INSERT INTO Paper VALUES ("1391","A distributed diffusion method for dynamic load balancing on parallel computers","Parallel applications can be divided into tasks that can be executed simultaneously in different processors. Depending on prior knowledge about computational requirements of the problem, the assignment of tasks to processors can be guided in two ways: static and dynamic. We propose a new dynamic load balancing algorithm based on the diffusion approach which employs overlapping balancing domains to achieve global balancing. Since current diffusion methods consider discrete units, the algorithms may produce solutions which, although they are locally balanced prove to be globally unbalanced. Our method solves this problem taking into account the load maximum difference between two processors within each domain, providing a more efficient load balancing process. >","1995","17","1","2025-12-02","https://university.edu/papers/733dbeca-b1f6-4619-b72a-d5a91e827cb4.pdf");
INSERT INTO Paper VALUES ("1392","Constrained regularization methods for superresolution","We apply constrained Tikhonov-Miller regularization to superresolution. The effective solution of this problem necessitates the imposition of a positivity constraint on the conjugate gradient method. This results in a fast projection based quadratic programming method for image superresolution. Difficulties with existing algorithms for this problem are also examined.","1998","20","4","2025-12-02","https://university.edu/papers/534176e7-d400-4138-8aa9-3f7ca656bab2.pdf");
INSERT INTO Paper VALUES ("1393","Kalman filtering for low distortion speech enhancement in mobile communication","This paper presents a model-based approach for noise suppression of speech contaminated by additive noise. A Kalman filter based speech enhancement system is presented and its performance is investigated in detail. It is shown that with a novel speech parameter estimation algorithm, it is possible to achieve 10 dB noise suppression with a high total audible quality.","1997","3","2","2025-12-02","https://university.edu/papers/faf241a9-735e-4fb9-9359-518833d7576d.pdf");
INSERT INTO Paper VALUES ("1394","Multi-domain feature of event-related potential extracted by nonnegative tensor factorization: 5 vs. 14 electrodes EEG data","As nonnegative tensor factorization (NTF) is particularly useful for the problem of underdetermined linear transform model, we performed NTF on the EEG data recorded from 14 electrodes to extract the multi-domain feature of N170 which is a visual event-related potential (ERP), as well as 5 typical electrodes in occipital-temporal sites for N170 and in frontal-central sites for vertex positive potential (VPP) which is the counterpart of N170, respectively. We found that the multi-domain feature of N170 from 5 electrodes was very similar to that from 14 electrodes and more discriminative for different groups of participants than that of VPP from 5 electrodes. Hence, we conclude that when the data of typical electrodes for an ERP are decomposed by NTF, the estimated multi-domain feature of this ERP keeps identical to its counterpart extracted from the data of all electrodes used in one ERP experiment.","2012","5","4","2025-12-02","https://university.edu/papers/e5a05e34-b717-45a9-96d5-3413c1efec97.pdf");
INSERT INTO Paper VALUES ("1395","An Anonymous DoS-Resistant Password-Based Authentication, Key Exchange and Pseudonym Delivery Protocol for Vehicular Networks","Vehicular networks are gaining popularity because vehicularcommunications are able to help minimize accidents, improvetraffic conditions and provide infotainment services. Security and privacy are important challenges in the deployment of vehicular networks. Authentication, key exchange and pseudonym delivery protocols can be used to provide security and privacy in vehicular networks. However, two important aspects of security and privacy,namely protection against DoS attacks and vehicle node anonymity, are currently not being addressed in existing authentication, key exchange and pseudonym delivery protocols for vehicular networks. In this paper, we propose an anonymous DoS-resistant password-based AUthentiCation, Key Exchange and Pseudonym delivERy(AUCKEPER) Protocol for vehicular networks that provides both protection against DoS attacks and vehicle node anonymity. A security and complexity analysis shows that the proposed AUCKEPER protocol is secure, more efficient and has advantages over a recently proposed state-of-the-art authentication, key exchange and pseudonym delivery protocol.","2009","7","1","2025-12-02","https://university.edu/papers/bd8a5be9-27bc-4997-aa6a-ef5f87f6418a.pdf");
INSERT INTO Paper VALUES ("1396","Bayesian nonparametric multiple testing","Multiple testing, or multiplicity problems often require testing several means with the assumption of rejecting infrequently, as motivated by the need to analyze DNA microarray data. The goal is to keep the combined rate of false discoveries and non-discoveries as small as possible. A discrete approximation to a Polya tree prior that enjoys fast, conjugate updating, centered at the usual Gaussian distribution is proposed. This new technique and the advantages of this approach are demonstrated using extensive simulation and data analysis accompanied by a Java web application. The numerical studies demonstrate that this new procedure shows promising false discovery rate and estimation of key values in the mixture model with very reasonable computational speed.","2016","7","3","2025-12-02","https://university.edu/papers/c0529e01-9de7-4090-bef9-66ca18c9707a.pdf");
INSERT INTO Paper VALUES ("1397","Formulations and algorithms for multichannel complex NMF","This paper studies some formulations and algorithms for the multichannel extension of nonnegative matrix factorization (NMF). We model the inter-channel characteristics of each NMF basis, including both the amplitude ratios and the phase differences on a channel pair. The learned inter-channel characteristics provide useful information for binding each NMF basis to each source component in such a situation that multiple sources are mixed in a convolutive manner and observed at multiple microphones. Effective optimization algorithms based on majorization are derived by using properly designed auxiliary functions. Experimental results show that the algorithms converged favorably regardless of the initialization.","2011","14","1","2025-12-02","https://university.edu/papers/b2f7fb31-dfc5-4493-8761-68d79eb0097b.pdf");
INSERT INTO Paper VALUES ("1398","Near-optimal experimental design for model selection in systems biology","Motivation: Biological systems are understood through iterations of modeling and experimentation. Not all experiments, however, are equally valuable for predictive modeling. This study introduces an efficient method for experimental design aimed at selecting dynamical models from data. Motivated by biological applications, the method enables the design of crucial experiments: it determines a highly informative selection of measurement readouts and time points. Results: We demonstrate formal guarantees of design efficiency on the basis of previous results. By reducing our task to the setting of graphical models, we prove that the method finds a near-optimal design selection with a polynomial number of evaluations. Moreover, the method exhibits the best polynomial-complexity constant approximation factor, unless P ¼NP. We measure the performance of the method in comparison with established alternatives, such as ensemble non-centrality, on example models of different complexity. Efficient design accelerates the loop between modeling and experimentation: it enables the inference of complex mechanisms, such as those controlling central metabolic operation. Availability: Toolbox ‘NearOED’ available with source code under GPL on the Machine Learning Open Source Software Web site","2013","11","4","2025-12-02","https://university.edu/papers/8badae48-d8b3-4c4d-bdf0-e2e31e4638b3.pdf");
INSERT INTO Paper VALUES ("1399","Uniqueness and semigroup for the Vlasov equation with elastic-diffusive reflexion boundary conditions","Abstract   In this paper, we investigate some uniqueness results for the Vlasov equation with elastic-diffusive boundary conditions. As an application, we build the associated semigroup in an  L  1  setting.","2004","6","4","2025-12-02","https://university.edu/papers/6b972421-dc2d-4013-8329-c45c665b7b61.pdf");
INSERT INTO Paper VALUES ("1400","Revealing Mistakes in Concern Mapping Tasks: An Experimental Evaluation","Concern mapping is the activity of assigning a stakeholder’s concern to its corresponding elements in the source code. This activity is primordial to guide software maintainers in several tasks, such as understanding and restructuring the implementation of existing concerns. Even though different techniques are emerging to facilitate the concern mapping process, they are still manual and error-prone according to recent studies. Existing work does not provide any guidance to developers to review and correct concern mappings. In this context, this paper presents the characterization and classification of eight concern mapping mistakes commonly made by developers. These mistakes were found to be associated with various properties of concerns and modules in the source code. The mistake categories were derived from actual mappings of 10 concerns in 12 versions of industry systems. In order to further evaluate to what extent these mistakes also occur in wider contexts, we ran two experiments where 26 subjects mapped 10 concerns in two systems. Our experimental results confirmed the mapping mistakes that often occur when developers need to interact with the source code.","2011","5","3","2025-12-02","https://university.edu/papers/ba6371a2-fcce-448a-b7d1-b7bc608bbfda.pdf");
INSERT INTO Paper VALUES ("1401","Spectrum agile radio: capacity and QoS implications of dynamic spectrum assignment","Radio spectrum is very scarce today because a considerable amount of the spectrum is set aside for licensed wireless applications. With the rapid growth of wireless technologies, spectrum scarcity has become a serious problem as more and more wireless applications compete for very little spectrum. On the other hand the licensed spectrum allocated to applications like television, cellular telephony and public safety show very little usage over time at different geographical locations. The evolution of newer technologies has been seriously impaired because of current regulatory constraints on the operation of these networks in licensed spectrum, such as TV bands, and is being addressed by FCC through its recent rule making. With the goal of ubiquitous communication in mind, we look into spectrum agile radio, a new technology enabled by such FCC rule making, and study its advantages over conventional radios. In this paper, we first show the utilization achievable by agile radios through simple analysis. Then we will outline two types of agile radios and derive their maximum capacities. Then we will go ahead and derive the rules that increase the spectrum utilization using agile radios. We then highlight how spectrum agile radio impacts quality of service as defined in conventional sense","2005","10","4","2025-12-02","https://university.edu/papers/d93929e3-3c8a-4bc9-9a83-96115c7c13cc.pdf");
INSERT INTO Paper VALUES ("1402","On levels in arrangements of curves","Analyzing the worst-case complexity of the k-level in a planar arrangement of n curves is a fundamental problem in combinatorial geometry. We give the first subquadratic upper bound (roughly O(nk/sup 1-2/3/*)) for curves that are graphs of polynomial functions of an arbitrary fixed degree s. Previously, nontrivial results were known only for the case s=1 and s=2. We also improve the earlier bound for pseudo-parabolas (curves that pairwise intersect at most twice) to O(nk/sup 7/9/log/sup 2/3/ k). The proofs are simple and rely on a theorem of Tamaki and Tokuyama on cutting pseudo-parabolas into pseudo-segments, as well as a new observation for cutting pseudo-segments into pieces that can be extended to pseudo-lines. We mention applications to parametric and kinetic minimum spanning trees.","2000","16","1","2025-12-02","https://university.edu/papers/58d89a6c-45dd-44fd-b29f-6323a6257ac7.pdf");
INSERT INTO Paper VALUES ("1403","Marketing Impact on Diffusion in Social Networks","The article proposes a way to add marketing into the standard threshold model of social networks. Within this framework, the article studies logical properties of the influence relation between sets of agents in social networks. Two different forms of this relation are considered: one for promotional marketing and the other for preventive marketing. In each case a sound and complete logical system describing properties of the influence relation is proposed. Both systems could be viewed as extensions of Armstrong's axioms of functional dependency from the database theory.","2017","9","4","2025-12-02","https://university.edu/papers/abbd52a9-e211-4c7c-8b21-ec01f10425f1.pdf");
INSERT INTO Paper VALUES ("1404","Open-Loop Tracking of Rising and Setting GPS Radio-Occultation Signals From an Airborne Platform: Signal Model and Error Analysis","Global Positioning System (GPS) radio-occultation (RO) is an atmospheric sounding technique utilizing the received GPS signal through the stratified atmosphere to measure refractivity, which provides information on temperature and humidity. The GPS-RO technique is now operational on several Low Earth Orbiting (LEO) satellites, which cannot provide high temporal and spatial resolution soundings necessary to observe localized transient events, such as tropical storms. An airborne RO (ARO) system has thus been developed for localized GPS-RO campaigns. RO signals in the lower troposphere are adversely affected by rapid phase accelerations and severe signal power fading. These signal dynamics often cause the phase-locked loop in conventional GPS survey receivers to lose lock in the lower troposphere, and the open-loop (OL) tracking in postprocessing is used to overcome this problem. OL tracking also allows robust processing of rising GPS signals, approximately doubling the number of observed occultations. An approach for “backward” OL tracking was developed, in which the correlations are computed sequentially in reverse time so that the signal can be acquired and tracked at high elevations for rising occultations. Ultimately, the signal-to-noise ratio (SNR) limits the depth of tracking in the atmosphere. We have developed a model relating the SNR to the variance in the residual phase of the observed signal produced from OL tracking. In this paper, we demonstrate the applicability of the phase variance model to airborne data. We then apply this model to set a threshold on refractivity retrieval based upon the cumulative unwrapping error bias to determine the altitude limit for reliable signal tracking. We also show consistency between the ARO SNR and collocated COSMIC satellite observations and use these results to evaluate the antenna requirements for an improved ARO system.","2016","6","2","2025-12-02","https://university.edu/papers/911030b2-ec5a-486f-85b7-75d6c44c9104.pdf");
INSERT INTO Paper VALUES ("1405","Using Methods & Measures from Network Analysis for GUI Testing","Graphical user interfaces (GUIs) for today's applications are extremely large. Moreover, they provide many degrees of freedom to the end-user, thus allowing the user to perform a very large number of event sequences on the GUI. The large sizes and degrees of freedom create severe problems for GUI quality assurance, including GUI testing. In this paper, we leverage methods and measures from network analysis to analyze and study GUIs, with the goal of aiding GUI testing activities. We apply these methods and measures on the event-flow graph model of GUIs. Results of a case study show that 'network centrality measures' are able to identify the most important events in the GUI as well as the most important sequences of events. These events and sequences are good candidates for test prioritization. In addition, the 'betweenness clustering' method is able to partition the GUI into regions that can be tested separately.","2010","13","1","2025-12-02","https://university.edu/papers/b6018e89-1bc4-4665-a983-f7bc4e3fef6c.pdf");
INSERT INTO Paper VALUES ("1406","TORISHIKI-KAI, An Autogenerated Web Search Directory","With this research we present a system that suggests valuable complementary information relevant to a user's topic of interest, in the form of keywords. For this purpose we have automatically constructed a Web search directory called TORISHIKI-KAI from a large collection of Web documents, using state of the art knowledge acquisition methods. TORISHIKI-KAI maps out the use context of the terms input by the user, and classifies topically related search terms according to semantic categories such as potential troubles, methods or tools in order to help the user find potentially valuable 'unknown unknowns'.","2008","15","1","2025-12-02","https://university.edu/papers/f9e11a23-7595-4159-9d3e-b7772df0f817.pdf");
INSERT INTO Paper VALUES ("1407","Decision making using incomplete data","Decision-making often relies on relevant information extracted from data. To obtain such information, many data analysis techniques can be applied, including statistical analysis, clustering algorithms and modeling techniques using neural nets or machine learning. Unfortunately, in practice, missing data is common and most analysis techniques are not applicable to incomplete data. This paper investigates an approach to handling missing data, using heuristics, in a machine learning system, SORCER. We applied SORCER to decide if certain characteristics of COLIA1 gene mutations are or are not associated with fatal type of, OI (osteogenesis imperfecta), a genetic disease. We compare the accuracies of SORCER's decisions with a high performing machine learning system, See5 with different percentages of missing data. The results show that average accuracies obtained from See5 tend to decline as the degree of incompleteness increases at a greater rate than those obtained from SORCER","2004","12","1","2025-12-02","https://university.edu/papers/5e724be9-2035-459d-8ddf-52abd040e303.pdf");
INSERT INTO Paper VALUES ("1408","Competence Development of Pre-Service Teachers with the Support of LeContract","Competency-based approach to upgrade one's dispositions has received a lot of attention as an alternative way of evaluating qualifications in various areas. In order to carry out successful study projects and practices that support specific competence advancement a learning contract procedure can be a promising technique. Learning contract procedure has a dual focus here. It explicates learner's perceived learning environment and learner's understanding of how they are going to develop desired competences. This paper interprets learning contract procedure as a response to one's learning progress and the effectiveness of learning environment. This conceptual position paper focuses on preservice teachers and their competence development with the support of learning contracts. Finally the paper proposes to design a web-based tool LeContract.","2011","13","1","2025-12-02","https://university.edu/papers/8b40f657-600b-41e2-9ba7-588eda6b01a0.pdf");
INSERT INTO Paper VALUES ("1409","Analytic study on a ( 2 + 1 )-dimensional nonlinear Schrödinger equation in the Heisenberg ferromagnetism","In this paper, a ( 2 + 1 )-dimensional nonlinear Schrodinger equation for a ( 2 + 1 )-dimensional Heisenberg ferromagnetic spin chain with the bilinear and anisotropic interactions is investigated. Via the Hirota method and symbolic computation, bilinear forms and multi-soliton solutions are derived. The one, two and three solitons are analyzed graphically and we find the amplitudes and widths of the two and three solitons keep invariant after each interaction. The bell-shape one soliton as well as parallel, crossed two and three solitons are respectively observed. Through the asymptotic analysis, expressions which denote the two solitons before and after the interactions are obtained and interactions between the two solitons are proved to be elastic.","2016","6","3","2025-12-02","https://university.edu/papers/20e5455f-eb4b-4232-b65e-ff17bf1ec7a1.pdf");
INSERT INTO Paper VALUES ("1410","Directed indices for exploring gene expression data","Motivation: Large expression studies with clinical outcome data are becoming available for analysis. An important goal is to identify genes or clusters of genes where expression is related to patient outcome. While clustering methods are useful data exploration tools, they do not directly allow one to relate the expression data to clinical outcome. Alternatively, methods which rank genes based on their univariate significance do not incorporate gene function or relationships to genes that have been previously identified. In addition, after sifting through potentially thousands of genes, summary estimates (e.g. regression coefficients or error rates) algorithms should address the potentially large bias introduced by gene selection. Results: We developed a gene index technique that generalizes methods that rank genes by their univariate associations to patient outcome. Genes are ordered based on simultaneously linking their expression both to patient outcome and to a specific gene of interest. The technique can also be used to suggest profiles of gene expression related to patient outcome. A cross-validation method is shown to be important for reducing bias due to adaptive gene selection. The methods are illustrated on a recently collected gene expression data set based on 160 patients with diffuse large cell lymphoma (DLCL). Availability: Ap rogram written in the R language implementing the gene index can be obtained at http://www.","2003","5","4","2025-12-02","https://university.edu/papers/a6f55d2b-4a73-48b1-90e8-56ac65e20e41.pdf");
INSERT INTO Paper VALUES ("1411","An HMM Based Pitch-Contour Generation Method for Mandarin Speech Synthesis","In this paper, a method is proposed to generate pitch-contours for Mandarin speech synthesis. In this method, an HMM (hidden Markov model) is used to model the pro- sodic states implicitly stayed and a syllable's pitch-contour is treated as an observation generated from a prosodic state. Such an HMM is called a syllable pitch-contour HMM (SPC-HMM). For training the SPC-HMM, we developed a feasible method to normalize a pitch-contour's height. After normalization, each training syllable's pitch-contour is vector quantized and represented with a VQ (vector quantization) code. Then, the VQ code and its adjacent syllables' lexical tones are combined to define an observation symbol for training the SPC-HMM. In the synthesis phase, a sentence-wide most prob- able observation symbol sequence is searched on the SPC-HMM using a dynamic pro- gramming algorithm proposed here. Then, the observation symbol found for a syllable is decoded to obtain its pitch-contour VQ code. We conducted testing experiments to de- termine the size of a pitch-contour codebook and the number of states for an SPC-HMM. The results indicate that setting the codebook size to eight and using six states are the best choices. Also, we conducted perception tests to compare the naturalness levels of synthetic speech files. The results show that the two generation modes for operating an SPC-HMM studied here are comparable to each other in naturalness level.","2011","15","1","2025-12-02","https://university.edu/papers/098a94d7-dc3e-44c3-aab4-728590542c59.pdf");
INSERT INTO Paper VALUES ("1412","Engineering Online Evolution of Robot Behaviour: (Doctoral Consortium)","Evolutionary computation techniques have been widely studied to automate the synthesis of behavioural control for robots. In online evolution, an evolutionary algorithm is executed on the robots themselves during task execution so as to continuously optimise the robot controllers. Online evolution provides numerous potential benefits, including enabling robots to modify their behaviour in response to changes in the task and in the environment. Current approaches to online evolution on physical robots, however, often require a prohibitively long evolution time and a substantial amount of human experimentation, and have not yet scaled to complex real-world tasks. In this research, we study how to accelerate and scale online evolution to more complex tasks while minimising the amount of human intervention. Our ultimate objective is to enable the realisation of real-world multirobot systems that can effectively learn new behaviours and adapt online to take on dynamic tasks in a timely manner.","2015","16","4","2025-12-02","https://university.edu/papers/eb3623e9-e434-4b49-9019-0e5206d3d907.pdf");
INSERT INTO Paper VALUES ("1413","Improved feature selection based on scatter degree","Feature reduction is important in machine learning, data mining and pattern recognition fields. Feature reduction consists of two methods: 1. Feature Extraction 2. Feature Selection. Feature selection methods try to select feature subset from feature set. Thus high dimension documents are projected on to lower dimension documents. The goal is selection of best subset that causes minimum error in classification. Scatter degree is one of the feature selection methods which attributes a degree of scattering for each feature. Features are selected that have higher scatter degree. In this paper, classification error has been reduced by considering other aspects in computing scatter degree (Improved Scatter Degree). Obtained results from this method have been compared with Scatter degree method.","2011","14","1","2025-12-02","https://university.edu/papers/d7fcbe0f-78a9-426e-97bc-74f5b24c7c25.pdf");
INSERT INTO Paper VALUES ("1414","Evaluation of Generalized Force Derivatives by Means of a Recursive Newton–Euler Approach","An accurate estimation of the dynamics efforts acting on a robot manipulator represents an important issue for both the analysis of its behavior and the synthesis of appropriate controllers. This paper proposes an iterative algorithm, which is based on the Newton-Euler approach, for the efficient evaluation of the manipulators' high-order kinematics and dynamics. In particular, the algorithm computes velocities, accelerations, and jerks of each link, while new dynamic equations are devised in order to evaluate the first derivative of generalized forces. Due to its moderate computational burden, the algorithm is suited to be used in online applications.","2009","10","4","2025-12-02","https://university.edu/papers/c7a6c75c-4826-47ef-9592-81cb855b0d07.pdf");
INSERT INTO Paper VALUES ("1415","A Generalised Approach to the use of Sampling for Rapid Object Location","This paper has developed a generalised sampling strategy for the rapid location of objects in digital images. In this strategy a priori information on the possible locations of objects is used to guide the sampling process, and earlier body-based and edge-based approaches emerge automatically on applying the right a priori probability maps. In addition, the limitations of the earlier regular sampling technique have been clarified and eased-with the result that sampling patterns are better matched to the positions of the image boundaries. These methods lead to improved speeds of operation both in the cases where all the objects in an image have to be located and also where the positions of individual objects have to be updated. Finally, the method is interesting in being intrinsically able to perform full binary search tree edge location without the need for explicit programming.","2008","9","1","2025-12-02","https://university.edu/papers/9e69d69f-3fe2-48e2-987e-6efe42c8dee2.pdf");
INSERT INTO Paper VALUES ("1416","Parallel R-tree search algorithm on DSVM","Though parallel database systems have been extensively studied, as far as we know, the parallel algorithms of R-tree proposed so far are limited to one workstation with multiprocessors or multi disks, where a parallel sorting algorithm or concurrent I/O is used to improve the performance. For the searching of R-trees, multiple search paths from the root to leaves are traversed sequentially. This sequential traverse can be transformed into multiple parallel traverses based on multiple search paths, where the query is divided into subqueries which can be executed concurrently. Aiming at parallel I/O and CPU operations, we introduce a parallel R-tree search algorithm running on distributed shared virtual memory (DSVM), especially on Shusseuo which is an ODBMS providing global persistent object management on persistent DSVM. The related problems are discussed and the evaluations are made based on Shusseuo. Experimental results show that optimal performance can be reached in dealing with large volumes of data.","1999","20","4","2025-12-02","https://university.edu/papers/ad2ad379-4aca-4f4f-8ad8-d1fb2a4143a6.pdf");
INSERT INTO Paper VALUES ("1417","Implementing Large-Scale Autonomic Server Monitoring Using Process Query Systems","In this paper we present a new server monitoring method based on a new and powerful approach to dynamic data analysis: process query systems (PQS). PQS enables user-space monitoring of servers and, by using advanced behavioral models, makes accurate and fast decisions regarding server and service state. Data to support state estimation come from multiple sensor feeds located within a server network. By post-processing a system's state estimates, it becomes possible to identify, isolate and/or restart anomalous systems, thus avoiding cross-infection or prolonging performance degradation. The PQS system we use is a generic process detection software platform. It builds on the wide variety of system-level information that past autonomic computing research has studied by implementing a highly flexible, scalable and efficient process-based analytic engine for turning raw system information into actionable system and service state estimates","2005","17","3","2025-12-02","https://university.edu/papers/ca93b014-bc50-4721-98d6-c96ec577334f.pdf");
INSERT INTO Paper VALUES ("1418","The Red Queen, Success Bias, and Organizational Inertia","Why do successful organizations often move in new directions and then fail? We propose that this pattern is especially likely among organizations that have survived a history of competition. Such experience adapts organizations to their environment, through so-called “Red Queen” evolution, but being well adapted for one context makes moving into new contexts more hazardous. Meanwhile, managers in such organizations infer from their histories of competitive success a biased assessment of their organization's ability to change. Consequently, although surviving competition makes organizational change especially hazardous, managers in surviving organizations are especially inclined to such initiatives. We develop these ideas in an empirically testable model, and find supportive evidence in estimates of the model using data from the history of the U.S. computer industry.","2008","16","3","2025-12-02","https://university.edu/papers/ed883074-2058-420b-8a98-291860373193.pdf");
INSERT INTO Paper VALUES ("1419","B-METHODS FOR THE NUMERICAL SOLUTION OF EVOLUTION PROBLEMS WITH BLOW-UP SOLUTIONS PART I: VARIATION OF THE CONSTANT ∗","In the last two decades, the field of geometric numerical integration and structure-preserving algorithms has focused on the design of numerical methods that preserve properties of Hamiltonian systems, evolution problems on manifolds, and problems with highly oscillatory solutions. In this paper, we show that a different geometric property, namely, the blow up of solutions in finite time, can also be taken into account in the numerical integrator, giving rise to geometric methods we call B-methods. We give a first systematic approach for deriving such methods for scalar and systems of semi- and quasi-linear parabolic and hyperbolic partial differential equations. We show both analytically and numerically that B-methods have substantially better approximation properties than standard numerical integrators as the solution approaches the blow-up time.","2015","18","3","2025-12-02","https://university.edu/papers/d91ea380-6665-444c-97bf-ff543dc8f8c7.pdf");
INSERT INTO Paper VALUES ("1420","Towards automating the finite element method: a test-bed for soft computing","A program to automate the finite element method (FEM) using various soft-computing techniques is presented. The overall program is discussed, and the implementations of three specific sub-problems (mesh placement, node numbering, and adaptive meshing) are described. It is also argued that the overall architecture of an “intelligent finite element package” can serve as a “test-bed” for many soft-computing techniques. © 2003 Elsevier Science B.V. All rights reserved.","2003","4","2","2025-12-02","https://university.edu/papers/82bb7811-28e0-40e3-b495-6dc78ad450c0.pdf");
INSERT INTO Paper VALUES ("1421","Computer vision issues in the design of a scrub nurse robot","A robot scrub nurse (RSN) is an example of a robotic assistant for surgical environments. Ideally, by taking over management of instruments, it would lower costs of an operation and cut down on mistakes. Of vital importance for such robots is how they interface with the environment. A scrub nurse robot requires the ability to sense the human operators before it can assist. Computer vision offers here a number of advantages over other sensing modalities. In this paper we examine a visual tracking system for a robot scrub nurse. The system works by estimating the hand position and orientation of the main surgeon. This information is needed to guide the robot in delivering instruments directly to the surgeon. Our work outlines the entire visual tracking process and evaluates robustness and accuracy. The end result is a re-implementable and working application, suitable for surgical environments, that also offers a degree of operation robustness.","2011","14","4","2025-12-02","https://university.edu/papers/8719d7d6-1b0d-4966-a120-f750724ec231.pdf");
INSERT INTO Paper VALUES ("1422","A variational Expectation-Maximization algorithm for temporal data clustering","The problem of temporal data clustering is addressed using a dynamic Gaussian mixture model. In addition to the missing clusters used in the classical Gaussian mixture model, the proposed approach assumes that the means of the Gaussian densities are latent variables distributed according to random walks. The parameters of the proposed algorithm are estimated by the maximum likelihood approach. However, the EM algorithm cannot be applied directly due to the complex structure of the model, and some approximations are required. Using a variational approximation, an algorithm called VEM-DyMix is proposed to estimate the parameters of the proposed model. Using simulated data, the ability of the proposed approach to accurately estimate the parameters is demonstrated. VEM-DyMix outperforms, in terms of clustering and estimation accuracy, other state-of-the-art algorithms. The experiments performed on real world data from two fields of application (railway condition monitoring and object tracking from videos) show the strong potential of the proposed algorithms.","2016","3","2","2025-12-02","https://university.edu/papers/60f3446e-d4bb-4b6b-82ca-19dcd44c2997.pdf");
INSERT INTO Paper VALUES ("1423","An axiomatic study of objective functions for graph clustering","We investigate axioms that intuitively ought to be satised by graph clustering objective functions. Two tailored for graph clustering objectives are introduced, and the four axioms introduced in previous work on distance based clustering are reformulated and generalized for the graph setting. We show that modularity, a standard objective for graph clustering, does not satisfy all these axioms. This leads us to consider adaptive scale modularity, a variant of modularity, that does satisfy the axioms. Adaptive scale modularity has two parameters, which give greater control over the clustering. Standard graph clustering objectives, such as normalized cut and unnormalized cut, are obtained as special cases of adaptive scale modularity. We furthermore show that adaptive scale modularity does not have a resolution limit. In general, the results of our investigation indicate that the considered axioms cover existing ‘good’ objective functions for graph clustering, and can be used to derive an interesting new family of objectives.","2013","1","3","2025-12-02","https://university.edu/papers/4b49229d-77db-40b4-85f3-62c059c1c40e.pdf");
INSERT INTO Paper VALUES ("1424","Selected aspects of conditions in the use of new media as an important part of the training of teachers in the Czech Republic and Poland - differences, risks and threats","The paper presents the complex problems of preparation of pedagogy students to work as teachers in the context of their readiness to use ICT in the didactic process. The complexity of this subject matter has been proved by the current, ongoing, discussion about the direction of the expected transformations of contemporary schools and the prospective teachers education system in the age of prevalent digitization. Considering the complexity of conditions, the main research problem has been formulated as follows: Conditions of what type affect the preparation of prospective teachers to use new media in learning and teaching process?. Thus, the empirical analysis conducted in the paper focuses on the following issues: the style of using new media by students, identification of students’ attitudes towards media, subjective (from the students’ point of view) assessment of how university level schools are prepared to shape modern media competences among their students and self-evaluation of media and IT competences in the group of prospective teachers. Czech and Polish students, despite being the so called digital natives, do not present homogeneous styles of using new media. They also reveal different attitudes toward applying digital solutions to the didactic process. Factors such as: low evaluation of one’s own competences or lack of evaluation in this area, lack of creative approach to the use of new media, lack of education in the area of new applications, lack of skills necessary to handle basic digital tools (e.g. interactive board, e-learning platforms) negatively affect, in most cases, the attitude toward the active use of ICT tools in future didactic work. On the basis of the gathered empirical data and inductive qualitative analysis a typology of students attitudes toward new media was developed. It consists of four categories: techno-optimist, techno-realist, techno-pessimist and techno-ignorant. The whole of analyses has the character of comparative research and involves two neighboring countries of the Visegrad Group: Poland (N = 466) and Czech Republic (N = 168).","2017","19","3","2025-12-02","https://university.edu/papers/afe12c87-bfa3-42db-ac99-e37ab905a127.pdf");
INSERT INTO Paper VALUES ("1425","Overcoming limitations of approximate query answering in OLAP","Two important limitations of approximate query answering in OLAP are recognized and investigated. These limitations are: (i) scalability of the techniques, i.e. their reliability on highly-dimensional data cubes; and (ii) need for guarantees on the degree of approximation of the answers. In this paper, we focus on the first limitation, and propose adopting the well-known Karhunen-Loeve transform (KLT) to obtain dimensionality reduction of data cubes, thus devising a transformation methodology that is independent by the number of dimensions of the data cubes. To tailor the KLT for the specific OLAP context, effective optimizations are also proposed, by taking into account the query-consciousness feature. Finally, some encouraging preliminary experimental results are presented.","2005","7","4","2025-12-02","https://university.edu/papers/a558560f-11d4-4e77-957d-2bd2ac1cc474.pdf");
INSERT INTO Paper VALUES ("1426","Wireless mesh and optical burst switching convergence for a novel metropolitan area network architecture","Wireless mesh networks (WMN) have attracted increasing attention from the research community as a high-performance and low-cost solution to last-mile broadband Internet access. In the other side, optical burst switching (OBS) is a promising metropolitan solution [1] that uses optical fiber with burst switching paradigm. In this paper, we propose a novel Metropolitan Area Network (MAN) architecture, called Optical Burst Wireless Mesh Architecture (OBWMA) which integrates WMN at the user access side and OBS at the core of the MAN. OBWMA aims to combine advantages of both WMNs and OBS networks, such as large coverage at low cost and bandwidth availability. We specify the details of the interconnection and the internetworking of WMNs and the OBS network in OBWMA. Moreover, we develop an analytical model to compute the end-to-end delay in OBWMA in order to support flow requests with delay constraints. Furthermore, we propose: (1) a bandwidth provisioning scheme for the WMN part (WBP); (2) a bandwidth provisioning scheme for the OBS part (WPBP); (3) an adaptive burst assembly scheme (AHBA) at the border between WMN and OBS; and (4) a control bridge (CB) that ensures Quality of Service (QoS) mapping at the border between the WMN and OBS. Simulation results using ns-2 demonstrate the feasibility of OBWMA, the accuracy of the proposed analytical model and the effectiveness of WBP, WPBP and AHBA to provide QoS provisioning for the converged network.","2011","14","1","2025-12-02","https://university.edu/papers/8d7795ce-fc22-4044-8915-74adb583fc98.pdf");
INSERT INTO Paper VALUES ("1427","Rivulet: 3D Neuron Morphology Tracing with Iterative Back-Tracking","The digital reconstruction of single neurons from 3D confocal microscopic images is an important tool for understanding the neuron morphology and function. However the accurate automatic neuron reconstruction remains a challenging task due to the varying image quality and the complexity in the neuronal arborisation. Targeting the common challenges of neuron tracing, we propose a novel automatic 3D neuron reconstruction algorithm, named Rivulet, which is based on the multi-stencils fast-marching and iterative back-tracking. The proposed Rivulet algorithm is capable of tracing discontinuous areas without being interrupted by densely distributed noises. By evaluating the proposed pipeline with the data provided by the Diadem challenge and the recent BigNeuron project, Rivulet is shown to be robust to challenging microscopic imagestacks. We discussed the algorithm design in technical details regarding the relationships between the proposed algorithm and the other state-of-the-art neuron tracing algorithms.","2016","15","3","2025-12-02","https://university.edu/papers/ae24c051-8554-448d-92cf-9aeac462d29a.pdf");
INSERT INTO Paper VALUES ("1428","Gain-Scheduling-Based State Feedback Integral Control for Networked Control Systems","This paper presents a new controller design method for networked control systems (NCSs), which is motivated by that static state feedback control (SSFC) shows an offset in the plant output when there is nonzero disturbance. Different from the existing SSFC results, the proposed method constructs a gain-scheduling-based state feedback integral controller, where an integral action is introduced to address the nonzero disturbance issue, and most especially, a gain scheduling strategy is employed to improve the control performance of NCSs. Moreover, the obtained results are also extended to the output feedback case. Simulation and experimental results are given to demonstrate the effectiveness of the proposed approach.","2011","2","1","2025-12-02","https://university.edu/papers/eb8daebf-ba8b-4a16-b68d-3685007488f4.pdf");
INSERT INTO Paper VALUES ("1429","Shape and spatially-varying BRDFs from photometric stereo","This paper describes a photometric stereo method designed for surfaces with spatially-varying BRDFs, including surfaces with both varying diffuse and specular properties. Our method builds on the observation that most objects are composed of a small number of fundamental materials. This approach recovers not only the shape but also material BRDFs and weight maps, yielding compelling results for a wide variety of objects. We also show examples of interactive lighting and editing operations made possible by our method.","2005","16","4","2025-12-02","https://university.edu/papers/ea216de3-230d-40ab-b999-ef922cfd88bc.pdf");
INSERT INTO Paper VALUES ("1430","Information transfer techniques for mobile devices by 'toss' and 'swing' actions","In recent years, mobile devices have rapidly penetrated into our daily lives. Several drawbacks of mobile devices have been mentioned so far, such as their limited computational capability, small screen real estate, and, so on, as compared with notebook or desktop computers. However, by fully utilizing the most notable feature of mobile devices, that is, mobility, we can explore possibilities for a new user interface of the devices. In this paper, we use PDAs and propose intuitive information transfer techniques for them, which could not be achieved with notebook or desktop computers. By using the system called Toss-It, a user can send information from the user's PDA to other electronic devices with a 'toss' or 'swing' action, as the user would toss a ball or deals cards to others. We have developed a circuit board designed to be attached to a PDA and algorithms for recognizing 'toss' and 'swing' actions. Preliminary user studies of Toss-It indicated that it could correctly identify receivers of information by 'toss' or 'swing' actions. Our research project is in progress, and this paper describes the current status of the project by focusing on issues related to HCI (human computer interaction). We discuss about several critical issues to be investigated in our future studies.","2004","12","1","2025-12-02","https://university.edu/papers/d9232091-48f3-4af7-8a8f-9ae68678e95e.pdf");
INSERT INTO Paper VALUES ("1431","Using the Multi-Attribute Global Inference of Quality (MAGIQ) Technique for Software Testing","The Multi-Attribute Global Inference of Quality (MAGIQ) technique is a simple way to assign a single measure of overall quality to each of a set of similar software systems. Software testing activities can produce a wide range of useful information such as bug counts, performance metrics, and mean time to failure data. However, techniques to aggregate quality and testing metrics into a single quality meta-value are not widely known or used. The MAGIQ technique uses rank order centroids to convert system comparison attributes into normalized numeric weights, and then computes an overall measure of quality as a weighted (by comparison attributes) sum of system ratings. MAGIQ was originally developed to validate the results of analytic hierarchy process (AHP) analyses. Although MAGIQ has not been subjected to extensive research, the technique has proven highly useful in practice.","2009","20","3","2025-12-02","https://university.edu/papers/d378c3ce-c970-4ecc-9f3b-cd53828b2bd7.pdf");
INSERT INTO Paper VALUES ("1432","Quantization of Multiple Sources Using Nonnegative Integer Bit Allocation","Asymptotically optimal real-valued bit allocation among a set of quantizers for a finite collection of sources was derived in 1963 by Huang and Schultheiss, and an algorithm for obtaining an optimal nonnegative integer-valued bit allocation was given by Fox in 1966. We prove that, for a given bit budget, the set of optimal nonnegative integer-valued bit allocations is equal to the set of nonnegative integer-valued bit allocation vectors which minimize the Euclidean distance to the optimal real-valued bit-allocation vector of Huang and Schultheiss. We also give an algorithm for finding optimal nonnegative integer-valued bit allocations. The algorithm has lower computational complexity than Fox's algorithm, as the bit budget grows. Finally, we compare the performance of the Huang-Schultheiss solution to that of an optimal integer-valued bit allocation. Specifically, we derive upper and lower bounds on the deviation of the mean-squared error (MSE) using optimal integer-valued bit allocation from the MSE using optimal real-valued bit allocation. It is shown that, for asymptotically large transmission rates, optimal integer-valued bit allocations do not necessarily achieve the same performance as that predicted by Huang-Schultheiss for optimal real-valued bit allocations","2006","9","4","2025-12-02","https://university.edu/papers/dd429109-0217-4fe6-b4e4-b2817044fdae.pdf");
INSERT INTO Paper VALUES ("1433","Solving the grid defender's dilemma: Tamper protection for distributed cyber-physical systems","Embedded devices installed as part of the smart grid rollout present a major dilemma for grid defenders, because they are soft targets that could allow an attacker to access critical assets (generators, control centers, etc.) deeper in the utility's network. While both physical tampering and intrusion protection are large, well-studied fields, state-of-the-art protection schemes suffer from several flaws: They are not powerful enough to respond properly to different tamper events, their severe responses can lead to reduced grid availability, and they often require more setup resources than a utility operator can provide. To protect these networks, we present TEDDI (Tamper Event Detection on Distributed Infrastructure), a distributed, sensor-based tamper protection architecture for embedded devices on utility networks. TEDDI uses data gathered from across the network to make more-informed and more-accurate tamper decisions, and can customize its response based on the event it sees. It can also be configured and installed quickly, without needing a large base of knowledge beforehand. In this paper, we lay out the TEDDI architecture, and discuss how TEDDI solves the grid defender's dilemma better than current work.","2015","11","3","2025-12-02","https://university.edu/papers/c5b4c4a4-3d6c-4b50-846c-53458aba1f2a.pdf");
INSERT INTO Paper VALUES ("1434","Performance evaluation of TCP and its extensions over lossy links in a small satellite environment","Space communication protocol standards-transport protocol (SCPS-TP) is a set of extensions to transmission control protocol (TCP) aimed at improving TCP performance in space communications. It is expected to have an experimental evaluation of the throughput performance of SCPS-TP over lossy communication links in a small satellite environment, especially by comparing it with standard TCP. This paper describes a performance evaluation of TCP and SCPS-TP over lossy links in a simulated small satellite environment using a test-bed. The results show that SCPS-TP is more tolerant of heavy noise and asymmetric channel and shows a much better performance, which make it more favorable over standard TCP in similar communication environments.","2005","1","3","2025-12-02","https://university.edu/papers/e70661fa-dd3d-4a99-b7ea-75e346333831.pdf");
INSERT INTO Paper VALUES ("1435","Towards Robustness in Neural Network Based Fault Diagnosis","Challenging design problems arise regularly in modern fault diagnosis systems. Unfortunately, classical analytical techniques often cannot provide acceptable solutions to such difficult tasks. This explains why soft computing techniques such as neural networks become more and more popular in industrial applications of fault diagnosis. Taking into account the two crucial aspects, i.e., the nonlinear behaviour of the system being diagnosed as well as the robustness of a fault diagnosis scheme with respect to modelling uncertainty, two different neural network based schemes are described and carefully discussed. The final part of the paper presents an illustrative example regarding the modelling and fault diagnosis of a DC motor, which shows the performance of the proposed strategy.","2008","6","3","2025-12-02","https://university.edu/papers/68774cc8-4bff-4d61-9210-57a8fc38ca39.pdf");
INSERT INTO Paper VALUES ("1436","Inverse Game Theory: Learning Utilities in Succinct Games","One of the central questions in game theory deals with predicting the behavior of an agent. Here, we study the inverse of this problem: given the agents' equilibrium behavior, what are possible utilities that motivate this behavior? We consider this problem in arbitrary normal-form games in which the utilities can be represented by a small number of parameters, such as in graphical, congestion, and network design games. In all such settings, we show how to efficiently, i.e. in polynomial time, determine utilities consistent with a given correlated equilibrium. However, inferring both utilities and structural elements e.g., the graph within a graphical game is in general NP-hard. From a theoretical perspective our results show that rationalizing an equilibrium is computationally easier than computing it; from a practical perspective a practitioner can use our algorithms to validate behavioral models.","2015","12","4","2025-12-02","https://university.edu/papers/b6c579ae-704f-44c1-8a6d-49ba662f8627.pdf");
INSERT INTO Paper VALUES ("1437","Real time signature extraction from a supervised classifier system","Recently some algorithms have been proposed to clean post-training rule populations evolved by XCS, a state of the art Learning Classifier System (LCS). We present an algorithm to extract optimal rules, which we refer to as signatures, during the operation of UCS, a recent variant of XCS. In a benchmark binary valued dataset our method seconds the generalization and optimality hypotheses for UCS and provide mechanisms for retrieving all maximally general rules in real time. In real valued problems, where precise realization of decision boundaries is often not possible, our algorithm is able to retrieve near optimal representations with the help of a modified subsumption operator. The algorithm is able to reduce the processing time asymptotically and provides a mechanism for early stopping of the learning process.","2007","1","4","2025-12-02","https://university.edu/papers/e366f3c3-ed0d-472d-a50d-b57006008ab0.pdf");
INSERT INTO Paper VALUES ("1438","Customizando heurísticas de usabilidade para celulares","Mobile phones have been the fastest growing segment of the technology market increasing the importance of interface design for this type of device. Yet, as many of the assumptions about user interactions that we know from 'traditional' computer usage do not hold true for mobile devices, a key question is, if there exist specific usability heuristics for this type of device. To answer this question, we conduct a systematic literature review on usability heuristics for mobile (touch) phones and compare and map the identified heuristics. We also develop a checklist for heuristic evaluations based on the unified set of heuristics. The results are expected to contribute to the improvement of usability of cell phone applications considering their specific characteristics and limitations.","2012","11","3","2025-12-02","https://university.edu/papers/4fe628ac-7c6b-4da0-aeaf-75bc0b2b12f3.pdf");
INSERT INTO Paper VALUES ("1439","Different Senses of Entropy—Implications for Education","A challenge in the teaching of entropy is that the word has several different senses, which may provide an obstacle for communication. This study identifies five distinct senses of the word entropy ...","2010","2","1","2025-12-02","https://university.edu/papers/c0b63577-63b9-4aa4-886a-ccde591c735f.pdf");
INSERT INTO Paper VALUES ("1440","Factoring analytic multivariate polynomials and non-standard Cauchy–Riemann conditions","Motivated by previous work on the simplification of parametrizations of curves, in this paper we generalize the well-known notion of analytic polynomial (a bivariate polynomial P(x, y), with complex coefficients, which arises by substituting z→x+iy on a univariate polynomial p(z)∈ℂ[z], i.e. p(z)→p(x+iy)=P(x, y)) to other finite field extensions, beyond the classical case of ℝ⊂ℂ. In this general setting we obtain different properties on the factorization, gcd's and resultants of analytic polynomials, which seem to be new even in the context of Complex Analysis. Moreover, we extend the well-known Cauchy–Riemann conditions (for harmonic conjugates) to this algebraic framework, proving that the new conditions also characterize the components of generalized analytic polynomials.","2014","12","1","2025-12-02","https://university.edu/papers/d17364b1-f107-4b7f-ae7f-494e97101522.pdf");
INSERT INTO Paper VALUES ("1441","The Door","We want to express digital communication with a human touch. So we pay attention to the properties of a door because it links one place to another. We think the linking of different places and sharing of places is one of the substantial qualities of network technology. Another reason that we focus on a door is because it bears great meanings. For example, a door is the first spot for a meeting with someone or for kissing someone goodbye. It could be your children, spouse, or your friends. These days, we talk and say hello to friends by Messenger or mobiles. Accustomed to digital devices which neglect time or space, we expect that the devices can carry our emotions to others. However, these have limits in expression. We want to show through the our work 'The Door' that network technology should have a little more humanity and love in the near future.","2011","18","4","2025-12-02","https://university.edu/papers/40e51e3b-6669-47f4-a4fb-1d831fb386c3.pdf");
INSERT INTO Paper VALUES ("1442","Building Robust Wireless LAN for Industrial Control with the DSSS-CDMA Cell Phone Network Paradigm","Wireless LAN for industrial control (IC-WLAN) provides many benefits, such as mobility, low deployment cost, and ease of reconfiguration. However, the top concern is robustness of wireless communications. Wireless control loops must be maintained under persistent adverse channel conditions, such as noise, large-scale path loss, fading, and many electromagnetic interference sources in industrial environments. The conventional IEEE 802.11 WLANs, originally designed for high bandwidth instead of high robustness, are therefore inappropriate for IC-WLAN. A solution lies in the direct sequence spread spectrum (DSSS) technology: by deploying the largest possible processing gain (slowest bit rate) that fully exploits the low data rate feature of industrial control, much higher robustness can be achieved. We hereby propose using DSSS-CDMA to build IC-WLAN. We carry out fine-grained physical layer simulations and Monte Carlo comparisons. The results show that DSSS-CDMA IC-WLAN provides much higher robustness than IEEE 802.11/802.15.4 WLAN, so that reliable wireless industrial control loops become feasible. We also show that deploying larger processing gain is preferable, to deploying more intensive convolutional coding. The DSSS-CDMA IC-WLAN scheme also opens up a new problem space for interdisciplinary study, involving real-time scheduling, resource management, communication, networking, and control","2007","8","2","2025-12-02","https://university.edu/papers/f255a776-a3b1-45a1-b13d-7f495224115b.pdf");
INSERT INTO Paper VALUES ("1443","Topological mapping using spectral clustering and classification","In this work we present an online method for generating topological maps from raw sensor information. We first describe an algorithm to automatically decompose a map into submap segments using a graph partitioning technique known as spectral clustering. We then describe how to train a classifier to recognize graph submaps from laser signatures using the AdaBoost machine learning algorithm. We demonstrate that the we can perform topological mapping by incrementally segmenting the world as the robot moves through its environment, and we can close the loop when the learned classifier recognizes that the robot has returned to a previously visited location.","2007","3","1","2025-12-02","https://university.edu/papers/77ffc816-1b9f-474b-9b66-79f4938f919c.pdf");
INSERT INTO Paper VALUES ("1444","Enabling Enterprise-Class Workloads in the Cloud","Enterprise-level workloads -- such as SAP and Oracle workloads - require infrastructure with high availability, clustering, or physical server appliances, features which are often not a part of a cloud offering. As a result, businesses are forced to run enterprise workloads in their legacy environments, and cannot take advantage of the cloud's flexibility, elasticity, and low cost. IBM Cloud Managed Services (CMS) cloud implements shared storage, clustering support, and private networks. These features effectively enable a large number of SAP and Oracle workloads to run in both virtualized and non-virtualized cloud environments. In this paper, we discuss a diverse set of enterprise applications implemented in the IBM CMS cloud.","2016","5","2","2025-12-02","https://university.edu/papers/f00fa795-aad9-4678-9542-8a488293b3bb.pdf");
INSERT INTO Paper VALUES ("1445","Development of an experimental portable electroencephalograph (case study: Alpha wave detector)","This paper describes the development of an electroencephalograph (EEG device) with portable application possibilities. The hardware design is based on the ModularEEG. It is redeveloped mainly to run from 3 V batteries and consume less power. The developed firmware detects the alpha brainwave without using any computer (PC). It uses signal correlation and windowing technique to detect the alpha frequency band. The same technique is used to detect the 50 Hz artifact concurrently. This artifact together with the average of the signal is used to disable the alpha detection output to reduce false-positive results. The device can also deliver the plain digitized EEG signal to a PC using the ModularEEG packet format version 3.","2011","16","4","2025-12-02","https://university.edu/papers/de2ca517-ddc4-4a6a-87b6-627a72b79373.pdf");
INSERT INTO Paper VALUES ("1446","Geometric conditions for the extendability of ternary linear codes","We give the necessary and sufficient conditions for the extendability of ternary linear codes of dimension k, 4 ≤k ≤6, with minimum distance d ≡ 1 or 2 (mod 3) from a geometrical point of view. We also give the necessary and sufficient conditions for the extendability of ternary linear codes with diversity (θ k-2,  3 κ-2  ) ,  (θ k-2  +3 k-3 , 4.3 k-3 ), (θ k-2  - 3 k-3 , 5. 3 k-3 ) for k ≥ 6, where θ j  = (3 J+1  - 1)/2.","2006","9","3","2025-12-02","https://university.edu/papers/ed88276f-8c39-4013-994a-9c797cd17ffa.pdf");
INSERT INTO Paper VALUES ("1447","Dublin City University at CLEF 2005: Multilingual Merging Experiments","This year the Dublin City University group participated in the CLEF 2005 Multilingual merging task. We tested different a range of standard merging techniques for merging the provided ranked result lists and show that the success of these techniques can sometimes be dependent on the retrieval system used.","2005","15","2","2025-12-02","https://university.edu/papers/b10e7ad2-3a61-4f7a-8453-febbb5a36515.pdf");
INSERT INTO Paper VALUES ("1448","Can automatic design error correction be applied to large circuits","Boolean equivalence checking has turned out to be a powerful method for verifying combinational circuits and is already an integrated part of the design cycle. If equivalence checking fails, Design Error Diagnosis and Correction (DEDC) is performed which can locate and correct design errors fully automatically in many cases. However DEDC algorithms always have to consider the circuit as a whole and cannot be applied locally to a small sub portion of the design. Thus, the size of rectifiable circuits is often limited which is a hard restriction for applying DEDC in industrial environments. We address the problem of how to make DEDC applicable to larger circuits. We show how a small sub circuit can be safely extracted from a bigger circuit under consideration of its environment. Our extraction method surrounds the extracted component with automatically derived logic such that the rectification of the newly constructed, much smaller circuit yields the same results as rectifying the original, much bigger circuit. In addition, we compare the extraction method with the circuit abstraction method presented by D.W. Hoffmann and T. Kropf (1999).","2000","17","4","2025-12-02","https://university.edu/papers/62084857-c1f5-47eb-bdfb-fb9c66c22bb0.pdf");
INSERT INTO Paper VALUES ("1449","Optimal Visual Servoing for differentially flat underactuated systems","This work introduces a hybrid visual servoing technique for differentially flat, underactuated systems that is well suited for aggressive dynamics. Standard Position-Based Visual Servoing (PBVS) and Image-Based Visual Servoing (IBVS) approaches for underactuated systems, such as quadrotors, oftentimes do not explicitly ensure that the relevant image features stay in the camera's field of view, especially while the system is performing agile maneuvers. We present a control technique that is designed to mitigate this issue and that results in increased robustness. Given a goal image, we first solve a constrained Perspective-n-Point (PnP) problem to find an equilibrium pose which aligns the camera with the goal. We then formulate the task of navigating to the goal pose as an optimal control problem, where a cost over the resulting image feature tracks along the trajectory is minimized which implicitly keeps features in the field of view over the course of the trajectory. The optimization is performed over a polynomial parametrization of the flat outputs of the system to decrease the dimensionality of the optimization. Simulations and physical experiments are performed with a quadrotor system to benchmark the algorithm's performance against a typical PBVS approach.","2016","2","1","2025-12-02","https://university.edu/papers/7bf813cd-9656-458f-bab5-9d1d1aa327c2.pdf");
INSERT INTO Paper VALUES ("1450","Implementing differential distributed orthogonal space time block coding using coefficient vectors","A coefficient vector technique implemented on a differential distributed space time block coding (DDSTBC) scheme is presented in this paper to improve on the computation complexity of existing DDSTBC schemes. The full mapping scheme and differential technique for utilizing the co-efficient vectors in a two-relay cooperative network is presented and comparison is made between the proposed technique and the traditional unitary matrices based technique. Results obtained from the numerical and simulation analysis conducted, showed that the proposed method presents an improvement in terms of computation complexity and BER performance. The proposed scheme was extended to accommodate networks with four and eight relay nodes utilizing square-real orthogonal codes.","2016","11","3","2025-12-02","https://university.edu/papers/300ac1c9-0c5c-4c9f-962d-d6dfb8693c81.pdf");
INSERT INTO Paper VALUES ("1451","The Role of Context and Resilient Middleware in Next Generation Smart Grids","The emerging trends of volatile distributed energy resources and micro-grids are putting pressure on electrical power system infrastructure. This pressure is motivating the integration of digital technology and advanced power-industry practices to improve the management of distributed electricity generation, transmission, and distribution, thereby creating a web of systems. Unlike legacy power system infrastructure, however, this emerging next-generation smart grid should be context-aware and adaptive to enable the creation of applications needed to enhance grid robustness and efficiency. This paper describes key factors that are driving the architecture of smart grids and describes orchestration middleware needed to make the infrastructure resilient. We use an example of adaptive protection logic in smart grid substations as a use case to motivate the need for contextawareness and adaptivity.","2016","2","2","2025-12-02","https://university.edu/papers/5a45398c-3706-4ab5-838d-add97541708a.pdf");
INSERT INTO Paper VALUES ("1452","Properties of Bethe free energies and message passing in Gaussian models","We address the problem of computing approximate marginals in Gaussian probabilistic models by using mean field and fractional Bethe approximations. We define the Gaussian fractional Bethe free energy in terms of the moment parameters of the approximate marginals, derive a lower and an upper bound on the fractional Bethe free energy and establish a necessary condition for the lower bound to be bounded from below. It turns out that the condition is identical to the pairwise normalizability condition, which is known to be a sufficient condition for the convergence of the message passing algorithm. We show that stable fixed points of the Gaussian message passing algorithm are local minima of the Gaussian Bethe free energy. By a counterexample, we disprove the conjecture stating that the unboundedness of the free energy implies the divergence of the message passing algorithm.","2011","20","1","2025-12-02","https://university.edu/papers/db999129-3467-4819-9139-9ec429604baa.pdf");
INSERT INTO Paper VALUES ("1453","Semantic-Driven Selection of Printer Color Rendering Intents","In this paper we introduce a unified framework that automatically selects the optimal color rendering intent for a given print job. We first present how we extract information from both the image features and the semantic information contained in keywords attached to this image. Then we show how our framework unifies the two inputs to select the optimal ICC rendering intent. The framework is evaluated with a psychophysical experiment on an image data set printed with the ICC media-relative colorimetric and perceptual intents using an Oce large format printer. We find that our method is correctly able to predict the observers preferences in 81% of the images tested when the keyword is included compared to 58% when the keyword is not included.","2012","13","1","2025-12-02","https://university.edu/papers/859afd67-702d-4d29-aedb-fd490fb03a7e.pdf");
INSERT INTO Paper VALUES ("1454","Polytypic Programming With Ease (Extended Abstract)","This paper proposes a new framework for a polytypic extension of functional programming languages. A functional polytypic program is one that is parameterised by datatype. Since polytypic functions are defined by induction on types rather than by induction on values, they typically operate on a higher level of abstraction than their monotypic counterparts. However, polytypic programming is not necessarily more complicated than conventional programming. In fact, a polytypic function is uniquely defined by its action on constant functors, projection functors, sums, and products. This information is sufficient to specialize a polytypic function to arbitrary datatypes, including mutually recursive datatypes and nested datatypes. The key idea is to use infinite trees as index sets for polytypic functions and to interpret datatypes as algebraic trees. This approach is simpler, more general, and more efficient than previous ones that are based on the initial algebra semantics of datatypes.","1999","11","3","2025-12-02","https://university.edu/papers/75868401-7484-40a9-b7bd-893e95e02b40.pdf");
INSERT INTO Paper VALUES ("1455","Theory of quantum pulse position modulation and related numerical problems","The paper deals with quantum pulse position modulation (PPM), both in the absence (pure states) and in the presence (mixed states) of thermal noise, using the Glauber representation of coherent laser radiation. The objective is to find optimal (or suboptimal) measurement operators and to evaluate the corresponding error probability. For PPM, the correct formulation of quantum states is given by the tensorial product of m identical Hilbert spaces, where m is the PPM order. The presence of mixed states, due to thermal noise, generates an optimization problem involving matrices of huge dimensions, which already for 4-PPM, are of the order of ten thousand. To overcome this computational complexity, the currently available methods of quantum detection, which are based on explicit results, convex linear programming and square root measurement, are compared to find the computationally less expensive one. In this paper a fundamental role is played by the geometrically uniform symmetry of the quantum PPM format. The evaluation of error probability confirms the vast superiority of the quantum detection over its classical counterpart.","2010","14","4","2025-12-02","https://university.edu/papers/557cff76-d517-46bd-bd58-8f03153c0904.pdf");
INSERT INTO Paper VALUES ("1456","Demo Abstract: Building IoT Applications with Accessors in CapeCode","We demonstrate CapeCode, a tool for composing actor-oriented building blocks for applications in the Internet of Things design space.","2016","1","2","2025-12-02","https://university.edu/papers/9da88ac4-8d35-4076-a926-38ddc2ae33ff.pdf");
INSERT INTO Paper VALUES ("1457","Biologically-inspired characterization of sparseness in natural images","Natural images follow statistics inherited by the structure of our physical (visual) environment. In particular, a prominent facet of this structure is that images can be described by a relatively sparse number of features. We designed a sparse coding algorithm biologically-inspired by the architecture of the primary visual cortex. We show here that coefficients of this representation exhibit a power-law distribution. For each image, the exponent of this distribution characterizes sparseness and varies from image to image. To investigate the role of this sparseness, we designed a new class of random textured stimuli with a controlled sparseness value inspired by measurements of natural images. Then, we provide with a method to synthesize random textures images with a given sparseness statistics that match that of some class of natural images and provide perspectives for their use in neurophysiology.","2016","9","1","2025-12-02","https://university.edu/papers/544d4f76-420e-4bb6-a851-7b9822d55af1.pdf");
INSERT INTO Paper VALUES ("1458","A generalized sampling and preconditioning scheme for sparse approximation of polynomial chaos expansions","In this paper we propose an algorithm for recovering sparse orthogonal polynomials using stochastic collocation. Our approach is motivated by the desire to use generalized polynomial chaos expansions (PCE) to quantify uncertainty in models subject to uncertain input parameters. The standard sampling approach for recovering sparse polynomials is to use Monte Carlo (MC) sampling of the density of orthogonality. However MC methods result in poor function recovery when the polynomial degree is high. Here we propose a general algorithm that can be applied to any admissible weight function on a bounded domain and a wide class of exponential weight functions defined on unbounded domains. Our proposed algorithm samples with respect to the weighted equilibrium measure of the parametric domain, and subsequently solves a preconditioned $\ell^1$-minimization problem, where the weights of the diagonal preconditioning matrix are given by evaluations of the Christoffel function. We present theoretical analysis to motivate the algorithm, and numerical results that show our method is superior to standard Monte Carlo methods in many situations of interest. Numerical examples are also provided that demonstrate that our proposed Christoffel Sparse Approximation algorithm leads to comparable or improved accuracy even when compared with Legendre and Hermite specific algorithms.","2016","14","1","2025-12-02","https://university.edu/papers/7942569e-2efa-455f-9e9c-44631876c139.pdf");
INSERT INTO Paper VALUES ("1459","Highly accurate doubling algorithms for M-matrix algebraic Riccati equations","The doubling algorithms are very efficient iterative methods for computing the unique minimal nonnegative solution to an M-matrix algebraic Riccati equation (MARE). They are globally and quadratically convergent, except for MARE in the critical case where convergence is linear with the linear rate 1 / 2. However, the initialization phase and the doubling iteration kernel of any doubling algorithm involve inverting nonsingular M-matrices. In particular, for MARE in the critical case, the M-matrices in the doubling iteration kernel, although nonsingular, move towards singular M-matrices at convergence. These inversions are causes of concerns on entrywise relative accuracy of the eventually computed minimal nonnegative solution. Fortunately, a nonsingular M-matrix can be inverted by the GTH-like algorithm of Alfa et al. (Math Comp 71:217–236, 2002) to almost full entrywise relative accuracy, provided a triplet representation of the matrix is known. Recently, Nguyen and Poloni (Numer Math 130(4):763–792, 2015) discovered a way to construct triplet representations in a cancellation-free manner for all involved M-matrices in the doubling iteration kernel, for a special class of MAREs arising from Markov-modulated fluid queues. In this paper, we extend Nguyen’s and Poloni’s work to all MAREs by also devising a way to construct the triplet representations cancellation-free. Our construction, however, is not a straightforward extension of theirs. It is made possible by an introduction of novel recursively computable auxiliary nonnegative vectors. As the second contribution, we propose an entrywise relative residual for an approximate solution. The residual has an appealing feature of being able to reveal the entrywise relative accuracies of all entries, large and small, of the approximation. This is in marked contrast to the usual legacy normalized residual which reflects relative accuracies of large entries well but not so much those of very tiny entries. Numerical examples are presented to demonstrate and confirm our claims.","2017","7","3","2025-12-02","https://university.edu/papers/77ad9799-fb31-4d32-8bb9-9e9899095103.pdf");
INSERT INTO Paper VALUES ("1460","Modeling Users, Context and Devices for Ambient Assisted Living Environments","The participation of users within AAL environments is increasing thanks to the capabilities of the current wearable devices. Furthermore, the significance of considering user's preferences, context conditions and device's capabilities help smart environments to personalize services and resources for them. Being aware of different characteristics of the entities participating in these situations is vital for reaching the main goals of the corresponding systems efficiently. To collect different information from these entities, it is necessary to design several formal models which help designers to organize and give some meaning to the gathered data. In this paper, we analyze several literature solutions for modeling users, context and devices considering different approaches in the Ambient Assisted Living domain. Besides, we remark different ongoing standardization works in this area. We also discuss the used techniques, modeled characteristics and the advantages and drawbacks of each approach to finally draw several conclusions about the reviewed works.","2014","10","2","2025-12-02","https://university.edu/papers/7db372fc-e840-45f9-8501-25fbfc15bde3.pdf");
INSERT INTO Paper VALUES ("1461","Automatic segmentation and analysis of the main pulmonary artery on standard post-contrast CT studies using iterative erosion and dilation","Purpose#R##N#To describe an algorithm for the accurate segmentation of the main pulmonary artery (MPA) and determining its length, mid-cross-sectional area and mid-circumferential perimeter. This will help with accurate, rapid and reproducible MPA measurements which can be used to detect diseases that cause raised pulmonary arterial pressure, and allow standardized serial measurements to assess progression or response to treatment.","2015","2","3","2025-12-02","https://university.edu/papers/5d1c58d9-5d67-4759-8091-18fee3af1d8d.pdf");
INSERT INTO Paper VALUES ("1462","A Helly theorem in weakly modular space","The d-convex sets in a metric space are those subsets which include the metric interval between any two of its elements. Weak modularity is a certain interval property for triples of points. The d-convexity of a discrete weakly modular space X coincides with the geodesic convexity of the graph formed by the two-point intervals in X. The Helly number of such a space X turns out to be the same as the clique number of the associated graph. This result thus entails a Helly theorem for quasi-median graphs, pseudo-modular graphs, and bridged graphs.","1996","19","4","2025-12-02","https://university.edu/papers/994865bd-7d33-4ef1-921c-a5e0ba6b898d.pdf");
INSERT INTO Paper VALUES ("1463","Modeling and Analysis of Correlated Binary Fingerprints for Content Identification","Multimedia identification via content fingerprints is used in many applications, such as content filtering on user-generated content websites, and automatic multimedia identification and tagging. A compact “fingerprint” is computed for each multimedia signal that captures robust and unique properties of the perceptual content, which is later used for identifying the multimedia. Several different multimedia fingerprinting schemes have been proposed in the literature and have been evaluated through experiments. To complement these experimental evaluations and provide guidelines for choosing system parameters and designing better schemes, this paper develops models for content fingerprinting and provides an analysis of the identification performance under these models. As a first step, bounds on the identification accuracy and the required fingerprint length for the simplest case when the fingerprint bits are modeled as i.i.d. are summarized. Markov Random Fields are then used to address more realistic settings of fingerprints with correlated components. The optimal likelihood ratio detector is derived and a statistical physics inspired approach for computing the probability of detection and probability of false alarm is described. The analysis shows that the commonly used Hamming distance detection criterion is susceptible to correlations among fingerprint bits, whereas the optimal log-likelihood ratio decision rule yields 5-20% improvement in the accuracy over a range of correlations. Simulation results demonstrate the validity of the theoretical predictions.","2011","7","4","2025-12-02","https://university.edu/papers/81d281c7-260e-43da-93d2-c99c7365ab50.pdf");
INSERT INTO Paper VALUES ("1464","Exploiting Domain Knowledge in Aspect Extraction","Aspect extraction is one of the key tasks in sentiment analysis. In recent years, statistical models have been used for the task. However, such models without any domain knowledge often produce aspects that are not interpretable in applications. To tackle the issue, some knowledge-based topic models have been proposed, which allow the user to input some prior domain knowledge to generate coherent aspects. However, existing knowledge-based topic models have several major shortcomings, e.g., little work has been done to incorporate the cannot-link type of knowledge or to automatically adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called MC-LDA (LDA with m-set and c-set), to address these problems, which is based on an Extended generalized Polya urn (E-GPU) model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MCLDA outperforms the existing state-of-the-art models markedly.","2013","9","2","2025-12-02","https://university.edu/papers/3221a8c8-12a1-4777-853e-e1c112d8c099.pdf");
INSERT INTO Paper VALUES ("1465","Minimizing the Variance of Cluster Mixture Models for Clustering Uncertain Objects","The increasing demand for dealing with uncertainty in data has led to the development of effective and efficient approaches in the data management and mining contexts. Clustering uncertain data objects has particularly attracted great attention in the data mining community. Most existing clustering methods however have urgently to come up with a number of issues, some of which are related to a poor efficiency mainly due to an expensive computation of the distance between uncertain objects. In this work, we propose a novel formulation to the problem of clustering uncertain objects, which allows for reaching accurate solutions by minimizing the variance of the mixture models that represent the clusters to be identified. We define a heuristic, MMVar, which exploits some analytical properties about the computation of variance for mixture models to compute local minima of the objective function at the basis of the proposed formulation. This characteristic allows MMVar to discard any distance measure between uncertain objects and, therefore, to achieve high efficiency. Experiments have shown that MMVar outperforms state-of-the-art algorithms from an efficiency viewpoint, while achieving better average performance in terms of accuracy.","2010","9","1","2025-12-02","https://university.edu/papers/bdb96569-1d96-403f-b9b7-b6be53b23b67.pdf");
INSERT INTO Paper VALUES ("1466","Reducing L1 caches power by exploiting software semantics","To access a set-associative L1 cache in a high-performance processor, all ways of the selected set are searched and fetched in parallel using physical address bits. Such a cache is oblivious of memory references' software semantics such as stack-heap bifurcation of the memory space, and user-kernel ring levels. This constitutes a waste of energy since e.g., a user-mode instruction fetch will never hit a cache block that contains kernel code. Similarly, a stack access will not hit a cacheline that contains heap data.   We propose to exploit software semantics in cache design to avoid unnecessary associative searches, thus reducing dynamic power consumption. Specifically, we utilize virtual memory region properties to optimize the data cache and ring level information to optimize the instruction cache. Our design does not impact performance, and incurs very small hardware cost. Simulations results using SPEC CPU and SPECjapps indicate that the proposed designs help to reduce cache block fetches from DL1 and IL1 by 27% and 57% respectively, resulting in average savings of 15% of DL1 power and more than 30% of IL1 power compared to an aggressively clock-gated baseline.","2012","20","4","2025-12-02","https://university.edu/papers/57bdf11d-2a69-44ca-960c-f608dbdd8f33.pdf");
INSERT INTO Paper VALUES ("1467","A 0.5V Power and Area Efficient Laplacian Pyramid Processing Engine using FIFO with Adaptive Data Compression","This paper proposes a power and area efficient Laplacian Pyramid processing engine (LPPE) for multi- resolution image representation in image/video processing. In the proposed LPPE, a novel FIFO architecture with adaptive data compression is proposed to reduce the power and area consumption of LPPE. A new filtering extension method is also proposed to reduce the output errors. In circuit level, near- threshold design is adopted to further reduce the power consumption by supply voltage scaling. The proposed LPPE fabricated in a 0.18 µm CMOS process technology can process 112 frames per second at 3.68 MHz and 0.5 V while consuming only 452 µW.","2015","6","3","2025-12-02","https://university.edu/papers/81fd51a8-efda-489f-a83b-ea2d182504a5.pdf");
INSERT INTO Paper VALUES ("1468","MISDA: Web Services Discovery Approach Based on Mining Interface Semantics","This paper proposes a novel Web service discovery approach that depend on the mining the underlying semantic structures of interaction interface parameters, which can match interfaces with high precision when the parameters of those interfaces contain meaningful synonyms, abbreviations, and combinations of disordered fragments. Especially, we propose a conceptual Web services description model in which we include the type path for the interaction interface parameters in addition to the traditional text description. Then, based on this description model, we mine the underlying semantics of the interaction interface to create index libraries by clustering interaction interface names and fragments under the supervision of co-occurrence probability. Finally, we propose a Web service Operations Discovery algorithm (OpD) that support the 'Single' operations and services with 'Composite' operations discovery. The experimental shows that our approach performs better than other approaches in terms of both discovery time and precision.","2016","9","1","2025-12-02","https://university.edu/papers/d4cd8baf-8baa-497d-a032-2053f523cd29.pdf");
INSERT INTO Paper VALUES ("1469","Numerical computational solution of the Volterra integral equations system of the second kind by using an expansion method","An expansion method is used for treatment of second kind Volterra integral equations system. This method gives an analytic solution for the system. The method reduces the system of integral equations to a linear system of ordinary differential equations. After constructing boundary conditions, this system reduces to a system of equations that can be solved easily with any of the usual methods. Finally, for showing the efficiency of the method we use some numerical examples.","2007","14","2","2025-12-02","https://university.edu/papers/656c6b7c-2c95-46dd-8744-d1370db7de01.pdf");
INSERT INTO Paper VALUES ("1470","Total Generalized Variation Based Denoising Models for Ultrasound Images","In this paper, we introduce a class of variational models for the restoration of ultrasound images corrupted by noise. The proposed models involve the convex or nonconvex total generalized variation regularization. The total generalized variation regularization ameliorates the staircasing artifacts that appear in the restored images of total variation based models. Incorporating total generalized variation regularization with nonconvexity helps preserve edges in the restored images. To realize the proposed convex model, we adopt the alternating direction method of multipliers, and the iteratively reweighted \(\ell _1\) algorithm is employed to handle the nonconvex model. These methods result in fast and efficient optimization algorithms for solving our models. Numerical experiments demonstrate that the proposed models are superior to other state-of-the-art models.","2017","1","4","2025-12-02","https://university.edu/papers/b8bbdc2b-ba10-43fe-b95f-a8b9627600a5.pdf");
INSERT INTO Paper VALUES ("1471","On Edge Coloring Bipartite Graphs","The present paper shows how to find a minimal edge coloring of a bipartite graph with E edges and V vertices in time $O(E\log V)$.","1980","5","3","2025-12-02","https://university.edu/papers/f8fbf364-aec7-4721-bbcc-7b0966cedce8.pdf");
INSERT INTO Paper VALUES ("1472","Robust interference suppression for DS-CDMA under Gaussian and non-Gaussian noise channels","In many physical channels, such as urban and indoor radio channels, the ambient noise is known through experimental measurements to be decidedly non-Gaussian, which makes the system performance degradation under non-Gaussian channels for those only utilizing the conventional Gaussian interference suppression scheme. In this paper, a robust multi-stage nonlinear interference suppression scheme is developed for synchronous DS-CDMA system under either Gaussian or non-Gaussian noise channels. For the DS-CDMA systems, simulation results show that the proposed scheme not only has nearly the same performance with the classical Gaussian interference suppression scheme under Gaussian noise channels, but also offers significant performance gain over the classical Gaussian interference suppression scheme under non-Gaussian noise channels.","2003","9","4","2025-12-02","https://university.edu/papers/7a60af51-a7d8-4108-9086-f0375ea779c4.pdf");
INSERT INTO Paper VALUES ("1473","Intelligent interleaving of scenarios: a novel approach to system level test generation","Parallelism in system architecture and design imposes a verification challenge as the exponential growth in the number of execution combinations becomes unwieldy. We report on a method for system-level test case generation. This method relies on dynamic interleaving of scenarios from the core level or sub-system level. We discuss the relevance of this method for the system level. We also describe a tool that implements this method and show how it was used in IBM for system verification of the Xbox 360 chip and power management in the cell processor, as well as verification of the pSeries eServers. We claim that this method shortened the system level verification cycle and allowed reuse in and across projects, which led to exposure of system-level bugs in a relatively short time.","2007","20","3","2025-12-02","https://university.edu/papers/714b3c06-6d95-4319-9a28-b011f082c35a.pdf");
INSERT INTO Paper VALUES ("1474","Personalized celebrity video search based on cross-space mining","Online videos are becoming popular these days. Personalized search has been recognized as effective solution for user accessing desired information when facing a daunting volume of videos. Personalized query understanding serves as one of the most challenges in personalized search, which indicates that unique query has distributed meanings and produce different semantics for different users. Take query of celebrity as example, many celebrities are engaged in multiple fields and certain user may be just interested in the field of videos related to his/her own preference. In this paper, we address the challenge of personalized query understanding by focusing on the problem of personalized celebrity video search. An interest-popularity cross-space mining based method is proposed for solution. Specifically, celebrity popularity and user interest distributions are first learned by topic modeling from heterogeneous data of expert knowledge and user online activities, respectively. We then exploit topic-word distribution refinement to correlate the two heterogeneous topic spaces. Finally the candidate videos are re-ranked based on the derived interest-popularity correlations. Carefully designed experiments have demonstrated the effectiveness of the proposed method. The obtained ranking list is highly consistent with the test users' preferences.","2012","4","2","2025-12-02","https://university.edu/papers/aebdcca4-dc19-4958-8fc8-dec0c2f9e53d.pdf");
INSERT INTO Paper VALUES ("1475","Summarizing Large Query Logs in Ettu","Database access logs are large, unwieldy, and hard for humans to inspect and summarize. In spite of this, they remain the canonical go-to resource for tasks ranging from performance tuning to security auditing. In this paper, we address the challenge of compactly encoding large sequences of SQL queries for presentation to a human user. Our approach is based on the Weisfeiler-Lehman (WL) approximate graph isomorphism algorithm, which identifies salient features of a graph or in our case of an abstract syntax tree. Our generalization of WL allows us to define a distance metric for SQL queries, which in turn permits automated clustering of queries. We also present two techniques for visualizing query clusters, and an algorithm that allows these visualizations to be constructed at interactive speeds. Finally, we evaluate our algorithms in the context of a motivating example: insider threat detection at a large US bank. We show experimentally on real world query logs that (a) our distance metric captures a meaningful notion of similarity, and (b) the log summarization process is scalable and performant.","2016","8","1","2025-12-02","https://university.edu/papers/e14db15c-8978-42d4-8f2c-42a6d181e4b8.pdf");
INSERT INTO Paper VALUES ("1476","Optimal Binary Periodic Almost-Complementary Pairs","A pair of sequences is called a periodic complementary pair (PCP) if the periodic autocorrelations of the constituent sequences sum up to zero for all nonzero time shifts. Owing to the scarcity of PCPs, we investigate optimal binary periodic almost-complementary pairs (BP-ACPs), each displaying correlation property closest to that of PCP. We show that an optimal BP-ACP of even length   $N$    has zero out-of-phase periodic autocorrelation sums (PACSs) except at the time shift of   $N/2$  , where the corresponding PACS has minimum magnitude of 4. We also show that for any arbitrary odd   $N$   , all the out-of-phase PACSs of an optimal BP-ACP should have identical magnitude of    $\text{2}$  . A number of optimal BP-ACPs from analytical constructions as well as computer search are presented. In addition, our proposed optimal BP-ACPs for the even-length case lead to two new families of base-two almost difference families.","2016","11","2","2025-12-02","https://university.edu/papers/91da995e-7400-4ba1-bea4-fd921fc9bc34.pdf");
INSERT INTO Paper VALUES ("1477","Solving the sorting network problem using iterative optimization with evolved hypermutations","This paper presents an application of a prototype optimization with evolved improvement steps algorithm (POEMS) to the well-known problem of optimal sorting network design. The POEMS is an iterative algorithm that seeks the best variation of the current solution in each iteration. The variations, also called hypermutations, are evolved by means of an evolutionary algorithm. We compared the POEMS to two mutation-based optimizers, namely the (\mu+\lambda)- and (1+\lambda)-evolution strategies. For experimental evaluation 10-input, 12-input, 14-input and 16-input instances of the sorting network problem were used. Results show that the proposed POEMS approach clearly outperforms both compared algorithms. Moreover, POEMS was able to find several perfect networks that are equivalent w.r.t. the number of comparators to the best known solutions for the 10-input, 12-input, 14-input, and 16-input problems. Finally, we propose a modification to the POEMS approach that might further improve its performance.","2009","3","3","2025-12-02","https://university.edu/papers/749c1752-0357-495f-be44-edee2a38fa66.pdf");
INSERT INTO Paper VALUES ("1478","Detection and repair faults of sensors in sampled control system","In order to improve reliability and safety of computer control system, it is very important to detect and to diagnose faults in sensors. Generally, pulse-type faults in sensors result in outliers in a sampled time series of computer control system. Based on the fact that the median estimator is the most robust one among all estimators, a new algorithm for detection and magnitude identification of abrupt outliers is established in this paper. The algorithm is composed of four parts: outlier-tolerant filtering, detection of pulse-type faults, magnitude identification and outliers repairing. This new algorithm can be used directly not only to deal with pulse-type faults in sensors but also to eliminate isolated outliers as well as patches in a sampled time series. Results from some simulated examples indicate that this new algorithm is practical and efficient.","2015","20","4","2025-12-02","https://university.edu/papers/f4e84ff9-95ca-4728-a80d-ffd0e4b5f017.pdf");
INSERT INTO Paper VALUES ("1479","Traffic convexity aware cellular networks: a vehicular heavy user perspective","Rampant mobile traffic increase in modern cellular networks is largely due to large-sized multimedia contents. Recent advancements in smart devices as well as radio access technologies promote the consumption of bulky content, even for passengers in moving vehicles, referred to as vehicular heavy users. In this article the emergence of vehicular heavy user traffic is observed by field experiments conducted in 2012 and 2015 in Seoul, Korea. The experiments reveal that such traffic is becoming dominant, as shown by the 8.62 times increase in vehicular heavy user traffic while total traffic increased just 3.04 times. To resolve this so-called VHP, we propose a cell association algorithm that exploits user demand diversity for different velocities. This user traffic pattern is discovered first by our field trials, which is convex-shaped over velocity, that is, walking user traffic is less than stationary or vehicular user traffic. As VHP becomes severe, our numerical evaluation verifies that the proposed cell association outperforms in practice a well-known load balancing association, cell range expansion. In addition to cell association, several complementary techniques are suggested in line with the technical trend toward 5G.","2016","19","4","2025-12-02","https://university.edu/papers/9e39b318-2951-4e7e-bb6f-41649c77ce18.pdf");
INSERT INTO Paper VALUES ("1480","A connection between discrete individual-based and continuous population-based models: A forest modelling case study","Modelling is perceived as a way of dealing with real life activities. The aim of this work is to compare two approaches to study forest dynamics, namely discrete individual-based and continuous population-based models, in order to contribute to an improvement in their use among researchers. An analysis of the strengths, weaknesses, opportunities and threats of the two different approaches, jointly with a mention of the state-of-the-art, allows us to illustrate this discussion. We will also provide a bridge or connection between these two modelling methodologies. This link will be developed in detail in a particular study case. Firstly, an individual-tree based model to deal with dynamics of forests is presented. Secondly, this model is scaled up to a system of partial differential equations, which represents the limiting behaviour of the individual-  based model.","2013","20","3","2025-12-02","https://university.edu/papers/d6893ba4-3f6f-4706-9f7c-b9d8f9c10246.pdf");
INSERT INTO Paper VALUES ("1481","An Investigation of Teaching and Learning Interaction Factors for the Use of the Interactive Whiteboard Technology","Researchers who have examined the use of interactive whiteboards (IWBs) for pedagogic uses have often suggested that IWBs would likely affect both teachers’ teaching and students’ learning styles. This article defines four IWB supported teaching and learning interaction factors: IWB Supported Teaching (IST), IWB Supported Learning (ISL), Teacher Supported Learning (TSL), and Student Interactive Learning (SIL). A quantitative analysis of classroom observation records (683 instructional events) was conducted using descriptive statistics and a chi-square test to uncover the association between interaction factors. The results show that these four interaction factors were significantly associated with each other, and over 90% of the instructional events examined simultaneously complied with IST and TSL behaviors. Finally, this study may be of importance to explain the dynamic association between interaction factors and to provide a novel approach for educators to gain insight into how teaching and learning interaction about IWB technology relates to their usage.","2012","18","4","2025-12-02","https://university.edu/papers/ebe7c056-c75b-4798-a9b1-d0ff3f7edfa6.pdf");
INSERT INTO Paper VALUES ("1482","Empirical performance analysis of computer-supported code-reviews","Checklist-based code-reviews have been generally accepted as valuable means for software development and management. In order to overcome shortcomings of manual reviewing techniques, such as high costs and lack of systematization, we have already developed and implemented a knowledge-based approach for semi-automation of some steps of individual code-reviews based on checklists. The aim of this paper is to evaluate the performance of our approach for code-reviews. Therefore, two independent groups of reviewers were analyzing the same piece of code (conventional C-programs developed in the automotive industry for gear unit control), where one of the groups deployed the semi-automated approach and the other group used the traditional manual technique. The resulting empirical data were analyzed by means of software metrics and software reliability modeling. Metrics specific to review processes, e.g. average review rate, average preparation rate, etc. were adapted for our knowledge-based methodology in order to capture the particularities of our approach. The results of these empirical investigations are compared with other methods (e.g. statistical, plan-based scenario-based) for reviews' computer support.","1997","16","1","2025-12-02","https://university.edu/papers/fe613986-5e32-4fc5-b0f1-021263b1ffd2.pdf");
INSERT INTO Paper VALUES ("1483","SNIT: SNP identification for strain typing","With ever-increasing numbers of microbial genomes being sequenced, efficient tools are needed to perform strain-level identification of any newly sequenced genome. Here, we present the SNP identification for strain typing (SNIT) pipeline, a fast and accurate software system that compares a newly sequenced bacterial genome with other genomes of the same species to identify single nucleotide polymorphisms (SNPs) and small insertions/deletions (indels). Based on this information, the pipeline analyzes the polymorphic loci present in all input genomes to identify the genome that has the fewest differences with the newly sequenced genome. Similarly, for each of the other genomes, SNIT identifies the input genome with the fewest differences. Results from five bacterial species show that the SNIT pipeline identifies the correct closest neighbor with 75% to 100% accuracy. The SNIT pipeline is available for download at http://www.bhsai.org/snit.html","2011","11","3","2025-12-02","https://university.edu/papers/c0a35623-09e4-4dee-8b1a-661523c2db7d.pdf");
INSERT INTO Paper VALUES ("1484","The universal expression of periodical average publication delay at steady state","The steady state solution of differential equations of periodical publication process is deduced, and based on this, the indicator of periodical publication delay, which reflects the degree of information ageing in editorial board of a periodical, is established. The indicator is proved to be the sum of two items: the pure publication delay, which reflects the editing rapidity of a periodical, and the ratio of deposited contribution quantity to the publishing quantity in one year, which reflects the waiting period of adopted papers deposited in editorial board. As a demonstration, the delay indicators of seven periodicals are calculated. Finally, the application of this indicator is discussed.","2004","11","3","2025-12-02","https://university.edu/papers/e642b9f5-fb2d-4732-8ae2-623f01da6bf3.pdf");
INSERT INTO Paper VALUES ("1485","Constant-Rank Codes and Their Connection to Constant-Dimension Codes","Constant-dimension codes have recently received attention due to their significance to error control in noncoherent random linear network coding. What the maximal cardinality of any constant-dimension code with finite dimension and minimum distance is and how to construct the optimal constant-dimension code (or codes) that achieves the maximal cardinality both remain open research problems. In this paper, we introduce a new approach to solving these two problems. We first establish a connection between constant-rank codes and constant-dimension codes. Via this connection, we show that optimal constant-dimension codes correspond to optimal constant-rank codes over matrices with sufficiently many rows. As such, the two aforementioned problems are equivalent to determining the maximum cardinality of constant-rank codes and to constructing optimal constant-rank codes, respectively. To this end, we then derive bounds on the maximum cardinality of a constant-rank code with a given minimum rank distance, propose explicit constructions of optimal or asymptotically optimal constant-rank codes, and establish asymptotic bounds on the maximum rate of a constant-rank code.","2010","15","2","2025-12-02","https://university.edu/papers/d1d23fa6-54d0-4091-b987-acc5c0624fad.pdf");
INSERT INTO Paper VALUES ("1486","Effect of Traffic Arrival Distributions on Routing Strategyin Multi-Hop Wireless Networks","The basic problem of whether direct transmission or multi- hop routing increases good put in multi-hop wireless net- works still lacks investigation from many aspects. This article, approaches this problem by considering the effect of different traffic arrival distributions on the choice of routing strategy for enhancing goodput of IEEE 802.11 DCF based multi-hop wireless networks under hidden terminal existence. Different traffic arrival distributions; including Poisson, constant bit rate (CBR), Pareto and Exponential are considered, relaxing the generally adopted Poisson assumption, for various data rates over a wide range of traffic loads extending from unsaturated to saturated traffic loads. The goodput performance for all traffic arrival distributions is found to be dependent on the traffic load in multi- hop networks. Of the four traffic models used, the network achieved the best goodput with Pareto and Exponential ar- rival distributions for light trafficc loads, where CBR performs slightly better under heavy loads. The results suggest that a traffic load-aware pre-control mechanism on the traffic arrivals to the IEEE 802.11 MAC layer might provide signifcant goodput gains in multi-hop wireless networks.","2016","15","4","2025-12-02","https://university.edu/papers/9e49243a-2de6-4829-9cdc-3a04ebf121b2.pdf");
INSERT INTO Paper VALUES ("1487","Stable fuzzy self-tuning computed-torque control of robot manipulators","Computed-torque control is a well known motion control strategy for manipulators which ensures global asymptotic stability for fixed symmetric positive definite (proportional and derivative) gain matrices. We show that the global asymptotic stability attribute also holds for a class of gain matrices depending on the manipulators state. This feature increases the potential of the computed-torque scheme to handle practical constraints in actual robots such as presence of friction in the joints and actuators with limited torque capabilities. We illustrate this potential by means of a fuzzy self-tuning algorithm to select the proportional and derivative gains according to the actual tracking position error. Experiments on a two degrees of freedom robot arm shown the usefulness of the proposed approach.","1998","7","2","2025-12-02","https://university.edu/papers/8e02d7a9-4018-4fea-b420-e73a2c4eda19.pdf");
INSERT INTO Paper VALUES ("1488","An LP lower bound for rate distortion with variable side information","We consider a rate distortion problem with side information at multiple decoders. Several lower bounds have been proposed for this general problem or special cases of it. We provide a lower bound for general instances of this problem, which was inspired by a linear-programming lower bound for index coding, and show that it subsumes most of the lower bounds in literature. Using this bound, we explicitly characterize the rate distortion function of a problem which can be seen as a Gaussian analogue of the “odd-cycle” index coding problem.","2016","13","3","2025-12-02","https://university.edu/papers/9f86118e-40c9-403c-89de-9d38256c5bb2.pdf");
INSERT INTO Paper VALUES ("1489","Trajectory generation for a 2-dof over-actuated parallel manipulator with actuator speed and torque limits consideration","This paper discusses the problem of generating trajectory for a 2-dof parallel manipulator with actuator redundancy. We investigate how to transform the speed and torque limits of the actuators to the velocity and acceleration limits in the end-effector space where the desired trajectory is normally specified. How these limits vary over the workspace is also investigated in details for the particular platform. With these limits, the automatic trajectory generation algorithm for traditional x-y table is modified to suit our parallel manipulator with actuator redundancy. Our trajectory generation algorithm can automatically generate symmetric straight line point-to-point trapezoidal trajectory for the parallel manipulator given the start point, the end point, and the desired traveling time. If it is impossible for the parallel manipulator to travel the distance within the desired traveling time under the velocity and acceleration limits, the shortest time trajectory will be generated instead.","2003","13","1","2025-12-02","https://university.edu/papers/9c7e3a7e-35e8-48db-bc60-bb5e3afd54a7.pdf");
INSERT INTO Paper VALUES ("1490","The simulation of the non-linear dynamic behavior of distributed routing networks using DECSIM","DECSIM, a logic hardware simulator, was used to model a router. Various load conditions were simulated on a mesh of 25 and 400 routers to characterize the network behavior both in the linear and in the nonlinear regions. Different scheduling methods were used to characterize the systems' bandwidth. Simulation results are presented and compared to the nonlinear behavior of natural systems. For the present routing algorithm the deterministic and random scheduling schemes did not show appreciable differences in network message routing capacity prior to saturation. Fundamental congestion problems occurred in both cases under similar load conditions. The random behavior of the coin flip was shown to introduce enough variability in the system to allow some extra routing capacity once saturation was entered. The flexibility of a hardware simulator for this type of work was shown. The ability to program and monitor network activity in an interactive or batch environment makes this a flexible approach. The simulations presented confirm that this router mesh exhibits complex behavior that is analogous to that seen in natural systems. >","1991","19","1","2025-12-02","https://university.edu/papers/ba5926ff-71c6-4bb9-ae17-d918061eaa3a.pdf");
INSERT INTO Paper VALUES ("1491","Diversity of MMSE MIMO receivers","This work settles a long-standing open problem by providing a complete characterization of the diversity of the MMSE MIMO receiver for all fixed rates (spectral efficiencies). The MMSE MIMO receivers exhibit a complicated behavior in the fixed-rate regime that cannot be obtained via DMT analysis. Specifically, we show that in a system with M transmit antennas, N receive antennas, and rate R, the diversity is given by d = ⌈M2 −R over M ⌉ 2  + (N − M)⌈M2 −R over M ⌉. This verifies and refines earlier results that were obtained only for two extremal operating points: diversity MN at very low rates and diversity N − M + 1 at very high rates.","2010","16","3","2025-12-02","https://university.edu/papers/a009fe5f-d2c0-44dd-8aac-5ca5e81fb625.pdf");
INSERT INTO Paper VALUES ("1492","The Development of Software Pricing Schemata and Its Application to Software Industry in Korea","This paper aims to suggest a comprehensive pricing schemata that software developers, sellers, and distributers can use regardless of the state of software uses. To do so, first, it reviews the criteria of pricing that are frequently discussed in the current fields of economics and management and thereby establishes the basis that leads to a pricing schemata. Then the prices of software in Korea will be applied to the schemata, which will eventually make it possible to produce the complete pricing schemata unique in Korea.","2008","3","2","2025-12-02","https://university.edu/papers/ce171196-ca22-4b8b-9f6a-6f211cbfe1d8.pdf");
INSERT INTO Paper VALUES ("1493","Using Lexical Stress in Authorship Attribution of Historical Texts","This paper presents some early results from a comprehensive project, whose goal is to investigate the use of intonation and lexical stress in authorship attribution. We demonstrate how lexical stress patterns extracted from written text can be used to train a variety of machine learning algorithms to perform attribution of texts of unknown or disputed authorship. Specifically, we apply our methodology to a collection of 18$$^\mathrm{th}$$ century American and British political writings, and demonstrate how combining lexical stress with other lexical features can significantly improve the attribution results.","2015","17","3","2025-12-02","https://university.edu/papers/12d1b4de-6039-447c-b096-5d7a57735121.pdf");
INSERT INTO Paper VALUES ("1494","Flexible and abstract communication and interconnect modeling for MPSoC","Current multiprocessor systems on chip (MPSoC) architectures integrate a massive number of IPs that need to exchange data in complex and diverse synchronization ways. The key challenge when designing MPSoC is that the communication architecture needs to be decided at the beginning of the design, before all the details about mapping the application on the architecture are known. These early decisions cause two difficulties: how to select the best communication architecture and how to estimate the effect of mapping the application onto the communication resources. In this paper, we propose high level communication models that allow early accurate performance estimation of both communication architecture and communication mapping. We applied the proposed modeling methods to analyze the impact on performance in case of two network topologies and several communication mapping schemes for the H.264 Encoder application.","2009","10","3","2025-12-02","https://university.edu/papers/4cb5ab49-ecce-4e31-8b86-980757c9ae78.pdf");
INSERT INTO Paper VALUES ("1495","Gain and loss of phosphorylation sites in human cancer","Motivation: Coding-region mutations in human genes are responsible for a diverse spectrum of diseases and phenotypes. Among lesions that have been studied extensively, there are insights into several of the biochemical functions disrupted by disease-causing mutations. Currently, there are more than 60 000 coding-region mutations associated with inherited disease catalogued in the Human Gene Mutation Database (HGMD, August 2007) and more than 70 000 polymorphic amino acid substitutions recorded in dbSNP (dbSNP, build 127). Understanding the mechanism and contribution these variants make to a clinical phenotype is a formidable problem.#R##N##R##N#Results: In this study, we investigate the role of phosphorylation in somatic cancer mutations and inherited diseases. Somatic cancer mutation datasets were shown to have a signi.cant enrichment for mutations that cause gain or loss of phosphorylation when compared to our control datasets (putatively neutral nsSNPs and random amino acid substitutions). Of the somatic cancer mutations, those in kinase genes represent the most enriched set of mutations that disrupt phosphorylation sites, suggesting phosphorylation target site mutation is an active cause of phosphorylation deregulation. Overall, this evidence suggests both gain and loss of a phosphorylation site in a target protein may be important features for predicting cancercausing mutations and may represent a molecular cause of disease for a number of inherited and somatic mutations.#R##N##R##N#Contact: sdmooney@iupui.edu","2008","11","4","2025-12-02","https://university.edu/papers/fc1e9aa6-9ef7-43f4-a169-4d1624f3af1a.pdf");
INSERT INTO Paper VALUES ("1496","A Hybrid Model for Emotion Detection from Text","Emotions can be judged by a combination of cues such as speech facial expressions and actions. Emotions are also articulated by text. This paper shows a new hybrid model for detecting emotion from text which depends on ontology with keywords semantic similarity. The text labelled with one of the six basic Ekman emotion categories. The main idea is to extract ontology from input sentences and match it with the ontology base which created from simple ontologies and the emotion of each ontology. The ontology extracted from the input sentence by using a triplet subject, predicate, and object extraction algorithm, then the ontology matching process is applied with the ontology base. After that the emotion of the input sentence is the emotion of the ontology which it matches with the highest score of matching. If the extracted ontology doesn't match with any ontology from the ontology base, then the keyword semantic similarity approach used. The suggested approach depends on the meaning of each sentence, the syntax and semantic analysis of the context.","2017","15","1","2025-12-02","https://university.edu/papers/bc670630-fcb5-4cad-839d-01ccbbfd3b48.pdf");
INSERT INTO Paper VALUES ("1497","Poster: RailCop: Detecting Missing Rail on Railway Using Wireless Sensor Networks","In recent times, derailments due to uprooting rails on a railway track has become a banal and noteworthy occurrence in Bangladesh due to different reasons such as political unrest, mass protest, etc. However, the railway tracks in Bangladesh are yet to deploy an automated system that can prevent the losses due to derailments through early detection of missing rails on a railway track. As a remedy to this situation, in this project, we propose to develop a WSN based automated system, which can sense the discontinuity of rail blocks and thus prevent from derailment of trains.","2016","5","2","2025-12-02","https://university.edu/papers/910205da-abae-45a1-ab85-ac7e4bbb231f.pdf");
INSERT INTO Paper VALUES ("1498","Scheduling satellite launch missions: an MILP approach","The paper deals with an MILP model to schedule satellite launches with alternative launchers and different mission profiles, subject to resource constraints. The model is part of a simulation tool developed within a joint research project with the European space agency. The focus is on geostationary transfer orbit (GTO) launches of payloads, which are associated with a given time window for launch, a payload mass, and a potential revenue. A launch requires the payload, a launcher compatible with both payload mass and mission profile, a launch complex for that launcher, and a launch range (i.e., resources that are shared by the launch complexes, including a mission control station). We consider three launcher types, which differ in cost and performance, are produced at a limited rate, and cannot be stocked in large amounts. One of the launchers is also able to carry out dual launch missions, i.e., missions in which two payloads are launched together, provided that their joint mass does not exceed launcher's mass capacity and their time windows overlap. After each launch, the launch complexes and the launch range need some latency time to be reset. Two natural objectives are minimizing the number of lost payloads and maximizing profit. Here we report experiences with a discrete-time MILP model formulation, which is rather flexible and can be extended to cope with additional problem features. Natural concerns, such as computational effort and the effect of time discretization, are addressed in the paper.","2013","20","3","2025-12-02","https://university.edu/papers/daf6fa74-a84c-428e-9e1e-e14f6563cbe6.pdf");
INSERT INTO Paper VALUES ("1499","L-Q design of PID controllers for robot arms","An explicit solution for the robot arm controller, optimal in the linear quadratic sense, is obtained. Based on this formulation, a PID controller with acceleration feedback is proposed which is computationally efficient and robust relative to variations in the dynamic model and external disturbances.","1985","19","4","2025-12-02","https://university.edu/papers/a6cfbe7f-01c4-4ba8-b950-05e258ffd169.pdf");
INSERT INTO Paper VALUES ("1500","Grey Coupled Prediction Model for Traffic Flow with Panel Data Characteristics","This paper studies the grey coupled prediction problem of traffic data with panel data characteristics. Traffic flow data collected continuously at the same site typically has panel data characteristics. The longitudinal data (daily flow) is time-series data, which show an obvious intra-day trend and can be predicted using the autoregressive integrated moving average (ARIMA) model. The cross-sectional data is composed of observations at the same time intervals on different days and shows weekly seasonality and limited data characteristics; this data can be predicted using the rolling seasonal grey model (RSDGM(1,1)). The length of the rolling sequence is determined using matrix perturbation analysis. Then, a coupled model is established based on the ARIMA and RSDGM(1,1) models; the coupled prediction is achieved at the intersection of the time-series data and cross-sectional data, and the weights are determined using grey relational analysis. Finally, numerical experiments on 16 groups of cross-sectional data show that the RSDGM(1,1) model has good adaptability and stability and can effectively predict changes in traffic flow. The performance of the coupled model is also better than that of the benchmark model, the coupled model with equal weights and the Bayesian combination model.","2016","14","1","2025-12-02","https://university.edu/papers/342358b0-f1ce-499e-b0f5-0cbfe48c8af4.pdf");
